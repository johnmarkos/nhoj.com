{
  "unit": 7,
  "unitTitle": "Scaling Compute",
  "chapter": 1,
  "chapterTitle": "Load Balancing Fundamentals",
  "chapterDescription": "Core load balancing decisions across L4/L7 routing, health checks, stickiness, failover behavior, and production traffic management.",
  "problems": [
    {
      "id": "sc-lb-001",
      "type": "multiple-choice",
      "question": "A checkout API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Traffic is steady but p99 spikes during GC events.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use round robin because simple even distribution when request cost is similar",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "This prompt focuses on A checkout API has 8 healthy instances and request cost is variable. Prioritize \"Use round robin because simple even distribution when request cost is similar\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "If you keep \"checkout API has 8 healthy instances and request cost is variable\" in view, the correct answer separates faster. Eliminate answers that do not directly address the failure mode, recovery path, or blast radius. Tie the decision to concrete operational outcomes, not abstract reliability language. Numbers such as 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-002",
      "type": "multiple-choice",
      "question": "A image upload API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Request sizes vary 20x between tenants.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use least connections because better for uneven request duration because it tracks active load"
      ],
      "correct": 3,
      "explanation": "For A image upload API has 8 healthy instances and request cost is variable, \"Use least connections because better for uneven request duration because it tracks active load\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "This prompt is really about \"image upload API has 8 healthy instances and request cost is variable\". Prefer the choice that keeps client behavior explicit while preserving evolvability. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Numbers such as 8 and 20x should be normalized first so downstream reasoning stays consistent. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-003",
      "type": "multiple-choice",
      "question": "A search API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? A few endpoints hold connections for 30+ seconds.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use least response time because reacts to backend latency differences",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "Treat A search API has 8 healthy instances and request cost is variable as a sequencing problem: \"Use least response time because reacts to backend latency differences\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "Use \"search API has 8 healthy instances and request cost is variable\" as your starting point, then verify tradeoffs carefully. Discard options that weaken contract clarity or compatibility over time. Interface decisions should be justified by contract stability and client impact over time. Keep quantities like 8 and 30 in aligned units before selecting an answer. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-004",
      "type": "multiple-choice",
      "question": "A mobile gateway has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Background exports share the same backend pool.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use weighted round robin because supports heterogeneous backend capacity"
      ],
      "correct": 3,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for A mobile gateway has 8 healthy instances and request cost is variable is \"Use weighted round robin because supports heterogeneous backend capacity\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "Read this as a scenario about \"mobile gateway has 8 healthy instances and request cost is variable\". Discard plans that assume linear scaling despite shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-005",
      "type": "multiple-choice",
      "question": "A billing service has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? One AZ has 15% fewer healthy instances today.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use round robin because simple even distribution when request cost is similar",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "This prompt focuses on A billing service has 8 healthy instances and request cost is variable. Prioritize \"Use round robin because simple even distribution when request cost is similar\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "The decision turns on \"billing service has 8 healthy instances and request cost is variable\". Discard plans that assume linear scaling despite shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 8 and 15 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-006",
      "type": "multiple-choice",
      "question": "A inventory API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Queue depth on some instances grows faster than others.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use least connections because better for uneven request duration because it tracks active load"
      ],
      "correct": 3,
      "explanation": "For A inventory API has 8 healthy instances and request cost is variable, \"Use least connections because better for uneven request duration because it tracks active load\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "Start from \"inventory API has 8 healthy instances and request cost is variable\", then pressure-test the result against the options. Prefer the choice that keeps client behavior explicit while preserving evolvability. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Numbers such as 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-007",
      "type": "multiple-choice",
      "question": "A profile service has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Bot traffic causes bursty arrival patterns.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use least response time because reacts to backend latency differences",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "Treat A profile service has 8 healthy instances and request cost is variable as a sequencing problem: \"Use least response time because reacts to backend latency differences\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "The key clue in this question is \"profile service has 8 healthy instances and request cost is variable\". Eliminate options that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-008",
      "type": "multiple-choice",
      "question": "A recommendation API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Cache-miss requests are much heavier than cache hits.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use weighted round robin because supports heterogeneous backend capacity"
      ],
      "correct": 3,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for A recommendation API has 8 healthy instances and request cost is variable is \"Use weighted round robin because supports heterogeneous backend capacity\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "The core signal here is \"recommendation API has 8 healthy instances and request cost is variable\". Discard options that weaken contract clarity or compatibility over time. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Numbers such as 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-009",
      "type": "multiple-choice",
      "question": "A admin dashboard has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Periodic cron bursts hit at minute boundaries.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use round robin because simple even distribution when request cost is similar",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "This prompt focuses on A admin dashboard has 8 healthy instances and request cost is variable. Prioritize \"Use round robin because simple even distribution when request cost is similar\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "If you keep \"admin dashboard has 8 healthy instances and request cost is variable\" in view, the correct answer separates faster. Discard plans that assume linear scaling despite shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 8 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-010",
      "type": "multiple-choice",
      "question": "A notification API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Long-lived HTTP/2 streams coexist with short RPC calls.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use least connections because better for uneven request duration because it tracks active load"
      ],
      "correct": 3,
      "explanation": "Treat A notification API has 8 healthy instances and request cost is variable as a sequencing problem: \"Use least connections because better for uneven request duration because it tracks active load\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "The key clue in this question is \"notification API has 8 healthy instances and request cost is variable\". Discard options that weaken contract clarity or compatibility over time. Prioritize explicit semantics and upgrade safety, not just short-term convenience. If values like 8 and 2 appear, convert them into one unit basis before comparison. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-011",
      "type": "multiple-choice",
      "question": "A auth edge has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? A canary backend has half the CPU of stable nodes.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use least response time because reacts to backend latency differences",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for A auth edge has 8 healthy instances and request cost is variable is \"Use least response time because reacts to backend latency differences\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "Start from \"auth edge has 8 healthy instances and request cost is variable\", then pressure-test the result against the options. Discard plans that assume linear scaling despite shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 8 in aligned units before selecting an answer. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-012",
      "type": "multiple-choice",
      "question": "A stream metadata API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? TLS handshake cost dominates a subset of requests.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use weighted round robin because supports heterogeneous backend capacity"
      ],
      "correct": 3,
      "explanation": "This prompt focuses on A stream metadata API has 8 healthy instances and request cost is variable. Prioritize \"Use weighted round robin because supports heterogeneous backend capacity\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "The decision turns on \"stream metadata API has 8 healthy instances and request cost is variable\". Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Keep quantities like 8 in aligned units before selecting an answer. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-013",
      "type": "multiple-choice",
      "question": "A checkout API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Partial dependency outage affects only write paths.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use round robin because simple even distribution when request cost is similar",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "For A checkout API has 8 healthy instances and request cost is variable, \"Use round robin because simple even distribution when request cost is similar\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "Read this as a scenario about \"checkout API has 8 healthy instances and request cost is variable\". Discard options that weaken contract clarity or compatibility over time. Good API choices balance client ergonomics, compatibility, and long-term evolvability. If values like 8 appear, convert them into one unit basis before comparison. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-014",
      "type": "multiple-choice",
      "question": "A image upload API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Mobile clients retry aggressively on 5xx.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use least connections because better for uneven request duration because it tracks active load"
      ],
      "correct": 3,
      "explanation": "Treat A image upload API has 8 healthy instances and request cost is variable as a sequencing problem: \"Use least connections because better for uneven request duration because it tracks active load\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "Use \"image upload API has 8 healthy instances and request cost is variable\" as your starting point, then verify tradeoffs carefully. Prioritize the option that best protects the reliability objective under the stated failure conditions. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. If values like 8 appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-015",
      "type": "multiple-choice",
      "question": "A search API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Regional failover shifted 30% extra traffic into this pool.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use least response time because reacts to backend latency differences",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for A search API has 8 healthy instances and request cost is variable is \"Use least response time because reacts to backend latency differences\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "This prompt is really about \"search API has 8 healthy instances and request cost is variable\". Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Numbers such as 8 and 30 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-016",
      "type": "multiple-choice",
      "question": "A mobile gateway has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Some tenants require strict per-user affinity.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use weighted round robin because supports heterogeneous backend capacity"
      ],
      "correct": 3,
      "explanation": "This prompt focuses on A mobile gateway has 8 healthy instances and request cost is variable. Prioritize \"Use weighted round robin because supports heterogeneous backend capacity\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "If you keep \"mobile gateway has 8 healthy instances and request cost is variable\" in view, the correct answer separates faster. Prefer the choice that maps cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 8 in aligned units before selecting an answer. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-017",
      "type": "multiple-choice",
      "question": "A billing service has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Blue/green deploy is draining 20% of nodes.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use round robin because simple even distribution when request cost is similar",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "For A billing service has 8 healthy instances and request cost is variable, \"Use round robin because simple even distribution when request cost is similar\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "The core signal here is \"billing service has 8 healthy instances and request cost is variable\". Prefer the choice that maps cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 8 and 20 in aligned units before selecting an answer. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-018",
      "type": "multiple-choice",
      "question": "A inventory API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? Observed backend latency variance doubled this week.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use least connections because better for uneven request duration because it tracks active load"
      ],
      "correct": 3,
      "explanation": "Treat A inventory API has 8 healthy instances and request cost is variable as a sequencing problem: \"Use least connections because better for uneven request duration because it tracks active load\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "The key clue in this question is \"inventory API has 8 healthy instances and request cost is variable\". Discard options that weaken contract clarity or compatibility over time. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Keep quantities like 8 in aligned units before selecting an answer. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-019",
      "type": "multiple-choice",
      "question": "A profile service has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? One shard serves premium users with heavier workloads.",
      "options": [
        "Route randomly and ignore backend saturation",
        "Use least response time because reacts to backend latency differences",
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead"
      ],
      "correct": 1,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for A profile service has 8 healthy instances and request cost is variable is \"Use least response time because reacts to backend latency differences\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "Start from \"profile service has 8 healthy instances and request cost is variable\", then pressure-test the result against the options. Discard plans that assume linear scaling despite shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 8 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-020",
      "type": "multiple-choice",
      "question": "A recommendation API has 8 healthy instances and request cost is variable. Which load-balancing choice is strongest as a default? API gateway now supports request hedging for reads.",
      "options": [
        "Pin all traffic to one backend to preserve cache warmth",
        "Disable health checks to reduce LB overhead",
        "Route randomly and ignore backend saturation",
        "Use weighted round robin because supports heterogeneous backend capacity"
      ],
      "correct": 3,
      "explanation": "For A recommendation API has 8 healthy instances and request cost is variable, \"Use weighted round robin because supports heterogeneous backend capacity\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "This prompt is really about \"recommendation API has 8 healthy instances and request cost is variable\". Prefer the choice that keeps client behavior explicit while preserving evolvability. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Numbers such as 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-021",
      "type": "multiple-choice",
      "question": "A team requires URL path based routing (`/api/*` vs `/static/*`) at the balancer. What layer capability is required?",
      "options": [
        "Anycast without proxying",
        "L4 TCP load balancing",
        "L7 HTTP-aware load balancing",
        "DNS round robin only"
      ],
      "correct": 2,
      "explanation": "Treat A team requires URL path based routing (`/api/*` vs `/static/*`) at the balancer as a sequencing problem: \"L7 HTTP-aware load balancing\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "Use \"team requires URL path based routing (`/api/*` vs `/static/*`) at the balancer\" as your starting point, then verify tradeoffs carefully. Discard options that weaken contract clarity or compatibility over time. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-022",
      "type": "multiple-choice",
      "question": "An LB marks backend healthy only if TCP connects, but app returns many 500s. What is the most direct fix?",
      "options": [
        "Use application-level health checks for dependency readiness",
        "Disable checks to avoid false positives",
        "Switch to sticky sessions",
        "Increase idle timeout only"
      ],
      "correct": 0,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for An LB marks backend healthy only if TCP connects, but app returns many 500s is \"Use application-level health checks for dependency readiness\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "The core signal here is \"lB marks backend healthy only if TCP connects, but app returns many 500s\". Discard plans that assume linear scaling despite shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 500s appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-023",
      "type": "multiple-choice",
      "question": "During deploys, in-flight requests fail when instances are terminated immediately. Best mitigation?",
      "options": [
        "Reduce replica count first",
        "Terminate faster to finish rollout",
        "Connection draining/graceful deregistration before removal",
        "Force all requests to retry twice"
      ],
      "correct": 2,
      "explanation": "This prompt focuses on During deploys, in-flight requests fail when instances are terminated immediately. Prioritize \"Connection draining/graceful deregistration before removal\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "If you keep \"during deploys, in-flight requests fail when instances are terminated immediately\" in view, the correct answer separates faster. Discard plans that assume linear scaling despite shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-024",
      "type": "multiple-choice",
      "question": "A product requires user session affinity for short-lived cart state kept in memory. Which trade-off is true?",
      "options": [
        "Sticky sessions eliminate all failover risk",
        "Sticky sessions are required for stateless services",
        "Sticky sessions reduce need for health checks",
        "Sticky sessions improve locality but reduce rebalance flexibility on node failure"
      ],
      "correct": 3,
      "explanation": "For A product requires user session affinity for short-lived cart state kept in memory, \"Sticky sessions improve locality but reduce rebalance flexibility on node failure\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "Start from \"product requires user session affinity for short-lived cart state kept in memory\", then pressure-test the result against the options. Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-025",
      "type": "multiple-choice",
      "question": "What does fail-open behavior usually mean for a load balancer?",
      "options": [
        "Bypass observability",
        "Reject all traffic when uncertain about backend health",
        "Continue routing to potentially unhealthy backends to preserve availability",
        "Disable retries globally"
      ],
      "correct": 2,
      "explanation": "Treat What does fail-open behavior usually mean for a load balancer as a sequencing problem: \"Continue routing to potentially unhealthy backends to preserve availability\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "The key clue in this question is \"fail-open behavior usually mean for a load balancer\". Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-026",
      "type": "multiple-choice",
      "question": "What is the strongest reason to terminate TLS at the edge load balancer?",
      "options": [
        "Centralizes certificate management and enables L7 routing/inspection",
        "It guarantees zero latency overhead",
        "It prevents need for mTLS anywhere",
        "It removes all encryption requirements internally"
      ],
      "correct": 0,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for What is the strongest reason to terminate TLS at the edge load balancer is \"Centralizes certificate management and enables L7 routing/inspection\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "Read this as a scenario about \"the strongest reason to terminate TLS at the edge load balancer\". Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-027",
      "type": "multiple-choice",
      "question": "A single regional load balancer is a critical SPOF. Which architecture is the standard mitigation?",
      "options": [
        "Disable autoscaling",
        "Add retries at clients only",
        "Run redundant LB instances/zones with health-checked failover",
        "Increase one LB size vertically forever"
      ],
      "correct": 2,
      "explanation": "This prompt focuses on A single regional load balancer is a critical SPOF. Prioritize \"Run redundant LB instances/zones with health-checked failover\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "The decision turns on \"single regional load balancer is a critical SPOF\". Prefer the choice that maps cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-028",
      "type": "multiple-choice",
      "question": "Backend CPUs are low, but request latency is rising due to long queues per instance. Which LB algorithm often helps first?",
      "options": [
        "Least connections / least outstanding requests",
        "Hash by client IP",
        "Random with equal weight",
        "Round robin static"
      ],
      "correct": 0,
      "explanation": "For Backend CPUs are low, but request latency is rising due to long queues per instance, \"Least connections / least outstanding requests\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "This prompt is really about \"backend CPUs are low, but request latency is rising due to long queues per instance\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-029",
      "type": "multiple-choice",
      "question": "A system needs deterministic per-user routing to improve cache hit ratio without full sticky sessions. Which approach fits?",
      "options": [
        "Disable caching",
        "Consistent hashing by user key",
        "Random routing",
        "Global FIFO at LB"
      ],
      "correct": 1,
      "explanation": "Treat A system needs deterministic per-user routing to improve cache hit ratio without full sticky sessions as a sequencing problem: \"Consistent hashing by user key\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "Use \"system needs deterministic per-user routing to improve cache hit ratio without full\" as your starting point, then verify tradeoffs carefully. Reject options that improve speed but weaken freshness or invalidation correctness. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-030",
      "type": "multiple-choice",
      "question": "What is a typical downside of client-side load balancing compared with centralized server-side LB?",
      "options": [
        "Clients must maintain fresher backend membership/health data",
        "Lower request latency always",
        "No retry logic needed",
        "No need for service discovery"
      ],
      "correct": 0,
      "explanation": "This prompt focuses on What is a typical downside of client-side load balancing compared with centralized server-side LB. Prioritize \"Clients must maintain fresher backend membership/health data\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "If you keep \"a typical downside of client-side load balancing compared with centralized server-side\" in view, the correct answer separates faster. Eliminate options that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-031",
      "type": "multiple-choice",
      "question": "If one backend has 2x CPU capacity, which policy best uses it?",
      "options": [
        "Use only DNS randomization",
        "Equal round robin weights",
        "Weighted routing reflecting backend capacity",
        "Disable that backend to avoid skew"
      ],
      "correct": 2,
      "explanation": "For If one backend has 2x CPU capacity, which policy best uses it, \"Weighted routing reflecting backend capacity\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "The core signal here is \"if one backend has 2x CPU capacity, which policy best uses it\". Eliminate options that fail under peak load or saturation conditions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 2x should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-032",
      "type": "multiple-choice",
      "question": "What is the key risk when health checks are too aggressive (short interval + low timeout)?",
      "options": [
        "Instance flapping and unnecessary traffic churn",
        "Higher cache hit ratio",
        "Guaranteed lower latency",
        "Zero false positives"
      ],
      "correct": 0,
      "explanation": "Treat What is the key risk when health checks are too aggressive (short interval + low timeout) as a sequencing problem: \"Instance flapping and unnecessary traffic churn\" is correct since it targets the scenario risk with the best near-term effect.",
      "detailedExplanation": "Use \"the key risk when health checks are too aggressive (short interval + low timeout)\" as your starting point, then verify tradeoffs carefully. Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-033",
      "type": "multiple-choice",
      "question": "A CDN fronts static assets, but dynamic API traffic still needs origin balancing. Why?",
      "options": [
        "Only DNS is needed for APIs",
        "CDN replaces all backend balancing",
        "Dynamic requests still require origin-level load distribution and failover",
        "CDN makes health checks obsolete"
      ],
      "correct": 2,
      "explanation": "In Load Balancing Fundamentals, the highest-leverage move for A CDN fronts static assets, but dynamic API traffic still needs origin balancing is \"Dynamic requests still require origin-level load distribution and failover\" because it lowers recurrence risk and improves operational control.",
      "detailedExplanation": "This prompt is really about \"cDN fronts static assets, but dynamic API traffic still needs origin balancing\". Prefer the choice that keeps client behavior explicit while preserving evolvability. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-034",
      "type": "multiple-choice",
      "question": "What is the most accurate statement about DNS round-robin for load balancing?",
      "options": [
        "It is simple but limited by DNS caching and slower failover dynamics",
        "It replaces layer-7 policy routing",
        "It guarantees equal load always",
        "It provides per-request health-aware balancing"
      ],
      "correct": 0,
      "explanation": "This prompt focuses on What is the most accurate statement about DNS round-robin for load balancing. Prioritize \"It is simple but limited by DNS caching and slower failover dynamics\" first to reduce the core failure path before secondary optimizations.",
      "detailedExplanation": "The decision turns on \"the most accurate statement about DNS round-robin for load balancing\". Eliminate answers that do not directly address the failure mode, recovery path, or blast radius. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-035",
      "type": "multiple-choice",
      "question": "You need to canary 5% traffic to v2 based on request headers. Best place?",
      "options": [
        "Kernel socket backlog",
        "L4 network ACL",
        "L7 load balancer/proxy routing rules",
        "DNS TTL changes only"
      ],
      "correct": 2,
      "explanation": "For You need to canary 5% traffic to v2 based on request headers, \"L7 load balancer/proxy routing rules\" is strongest because it directly addresses the identified bottleneck in Load Balancing Fundamentals.",
      "detailedExplanation": "Read this as a scenario about \"you need to canary 5% traffic to v2 based on request headers\". Discard plans that assume linear scaling despite shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 5 in aligned units before selecting an answer. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a flash-sale checkout API. First symptom: tail latency doubles under promo traffic. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because latency spikes during promotions",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node"
          ],
          "correct": 1,
          "explanation": "For stage 1 in Load Balancing Fundamentals, \"Investigate load-balancer policy because latency spikes during promotions\" is the highest-signal move for You operate a flash-sale checkout API.",
          "detailedExplanation": "If you keep \"you operate a flash-sale checkout API\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the mitigation that improves distribution without sacrificing resilience.",
          "options": [
            "Remove observability labels from requests",
            "Adopt least connections with queue-aware routing",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend"
          ],
          "correct": 1,
          "explanation": "This stage tests control under pressure for After confirming imbalance, which mitigation is the strongest next move. \"Adopt least connections with queue-aware routing\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "This prompt is really about \"after confirming imbalance, which mitigation is the strongest next move? Choose the\". Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency."
        }
      ],
      "detailedExplanation": "The key clue in this question is \"load Balancing Fundamentals\". Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This item rewards stage continuity for You operate a flash-sale checkout API: carry the diagnosis (the incident signal) into follow-up action (\"Adopt least connections with queue-aware routing\")."
    },
    {
      "id": "sc-lb-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a photo upload gateway. First symptom: long-lived uploads starve short requests. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Investigate load-balancer policy because frequent backend restarts in deploy windows",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day"
          ],
          "correct": 0,
          "explanation": "Stage 1: for You operate a photo upload gateway, \"Investigate load-balancer policy because frequent backend restarts in deploy windows\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "This prompt is really about \"you operate a photo upload gateway\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the next action that is safest for production rollout.",
          "options": [
            "Adopt graceful draining before deregistration",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests"
          ],
          "correct": 0,
          "explanation": "For stage 2 in Load Balancing Fundamentals, \"Adopt graceful draining before deregistration\" is the highest-signal move for After confirming imbalance, which mitigation is the strongest next move.",
          "detailedExplanation": "If you keep \"after confirming imbalance, which mitigation is the strongest next move? Pick the next\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization."
        }
      ],
      "detailedExplanation": "Start from \"load Balancing Fundamentals\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "Treat this as a linked decision chain in Load Balancing Fundamentals. Diagnose the main signal, then execute \"Adopt graceful draining before deregistration\" for durable control."
    },
    {
      "id": "sc-lb-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a fintech transfer API. First symptom: one zone intermittently degrades network quality. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because one AZ shows intermittent packet loss"
          ],
          "correct": 3,
          "explanation": "At stage 1, prioritize \"Investigate load-balancer policy because one AZ shows intermittent packet loss\" for You operate a fintech transfer API; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "The key clue in this question is \"you operate a fintech transfer API\". Do not reset assumptions between stages; carry forward prior constraints directly. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Prioritize the fix with the best latency-to-risk trade-off.",
          "options": [
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt zonal health checks with zone-aware failover"
          ],
          "correct": 3,
          "explanation": "Stage 2: for After confirming imbalance, which mitigation is the strongest next move, \"Adopt zonal health checks with zone-aware failover\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "Read this as a scenario about \"after confirming imbalance, which mitigation is the strongest next move? Prioritize the\". Do not reset assumptions between stages; carry forward prior constraints directly. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "If you keep \"load Balancing Fundamentals\" in view, the correct answer separates faster. Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "For You operate a fintech transfer API, scoring is sequential: stage 1 isolates the governing risk and stage 2 prioritizes \"Adopt zonal health checks with zone-aware failover\"."
    },
    {
      "id": "sc-lb-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a gaming matchmaking service. First symptom: specific cohorts overload a subset of nodes. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because hot users overload a subset of nodes",
            "Disable health checks to reduce control plane noise"
          ],
          "correct": 2,
          "explanation": "This stage tests control under pressure for You operate a gaming matchmaking service. \"Investigate load-balancer policy because hot users overload a subset of nodes\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "The core signal here is \"you operate a gaming matchmaking service\". Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the control that addresses root cause rather than symptoms.",
          "options": [
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt consistent hashing with virtual nodes",
            "Rely on client retries only with no routing changes"
          ],
          "correct": 2,
          "explanation": "At stage 2, prioritize \"Adopt consistent hashing with virtual nodes\" for After confirming imbalance, which mitigation is the strongest next move; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "Use \"after confirming imbalance, which mitigation is the strongest next move? Pick the\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak."
        }
      ],
      "detailedExplanation": "The core signal here is \"load Balancing Fundamentals\". Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This two-stage prompt in Load Balancing Fundamentals evaluates diagnosis then mitigation for You operate a gaming matchmaking service: identify the core risk first, then apply \"Adopt consistent hashing with virtual nodes\"."
    },
    {
      "id": "sc-lb-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a back-office reporting API. First symptom: sticky workflows fail after node rotation. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because session-bound workflows break after re-route",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node"
          ],
          "correct": 1,
          "explanation": "Stage 1: for You operate a back-office reporting API, \"Investigate load-balancer policy because session-bound workflows break after re-route\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "Read this as a scenario about \"you operate a back-office reporting API\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Select the option that reduces tail risk under failure.",
          "options": [
            "Remove observability labels from requests",
            "Adopt externalize session state to shared store",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend"
          ],
          "correct": 1,
          "explanation": "For stage 2 in Load Balancing Fundamentals, \"Adopt externalize session state to shared store\" is the highest-signal move for After confirming imbalance, which mitigation is the strongest next move.",
          "detailedExplanation": "The key clue in this question is \"after confirming imbalance, which mitigation is the strongest next move? Select the\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"load Balancing Fundamentals\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "Treat this as a linked decision chain in Load Balancing Fundamentals. Diagnose the main signal, then execute \"Adopt externalize session state to shared store\" for durable control."
    },
    {
      "id": "sc-lb-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a public search endpoint. First symptom: p99 grows while average latency stays flat. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Investigate load-balancer policy because latency spikes during promotions",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day"
          ],
          "correct": 0,
          "explanation": "At stage 1, prioritize \"Investigate load-balancer policy because latency spikes during promotions\" for You operate a public search endpoint; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "Use \"you operate a public search endpoint\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the mitigation that scales with future traffic growth.",
          "options": [
            "Adopt least connections with queue-aware routing",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests"
          ],
          "correct": 0,
          "explanation": "Stage 2: for After confirming imbalance, which mitigation is the strongest next move, \"Adopt least connections with queue-aware routing\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "The core signal here is \"after confirming imbalance, which mitigation is the strongest next move? Choose the\". Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes."
        }
      ],
      "detailedExplanation": "The decision turns on \"load Balancing Fundamentals\". Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "For You operate a public search endpoint, scoring is sequential: stage 1 isolates the governing risk and stage 2 prioritizes \"Adopt least connections with queue-aware routing\"."
    },
    {
      "id": "sc-lb-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a B2B webhook ingress service. First symptom: retry bursts create uneven target pressure. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because frequent backend restarts in deploy windows"
          ],
          "correct": 3,
          "explanation": "This stage tests control under pressure for You operate a B2B webhook ingress service. \"Investigate load-balancer policy because frequent backend restarts in deploy windows\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "This prompt is really about \"you operate a B2B webhook ingress service\". Do not reset assumptions between stages; carry forward prior constraints directly. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the action that preserves debuggability and rollback safety.",
          "options": [
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt graceful draining before deregistration"
          ],
          "correct": 3,
          "explanation": "At stage 2, prioritize \"Adopt graceful draining before deregistration\" for After confirming imbalance, which mitigation is the strongest next move; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "If you keep \"after confirming imbalance, which mitigation is the strongest next move? Pick the\" in view, the correct answer separates faster. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks."
        }
      ],
      "detailedExplanation": "Start from \"load Balancing Fundamentals\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This two-stage prompt in Load Balancing Fundamentals evaluates diagnosis then mitigation for You operate a B2B webhook ingress service: identify the core risk first, then apply \"Adopt graceful draining before deregistration\"."
    },
    {
      "id": "sc-lb-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a feature-flag delivery API. First symptom: canary nodes show elevated 5xx during rollout. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because one AZ shows intermittent packet loss",
            "Disable health checks to reduce control plane noise"
          ],
          "correct": 2,
          "explanation": "For stage 1 in Load Balancing Fundamentals, \"Investigate load-balancer policy because one AZ shows intermittent packet loss\" is the highest-signal move for You operate a feature-flag delivery API.",
          "detailedExplanation": "If you keep \"you operate a feature-flag delivery API\" in view, the correct answer separates faster. Do not reset assumptions between stages; carry forward prior constraints directly. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Select the fix that improves both fairness and throughput.",
          "options": [
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt zonal health checks with zone-aware failover",
            "Rely on client retries only with no routing changes"
          ],
          "correct": 2,
          "explanation": "This stage tests control under pressure for After confirming imbalance, which mitigation is the strongest next move. \"Adopt zonal health checks with zone-aware failover\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "This prompt is really about \"after confirming imbalance, which mitigation is the strongest next move? Select the fix\". Solve this as chained reasoning where stage two must respect stage one assumptions. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure."
        }
      ],
      "detailedExplanation": "The key clue in this question is \"load Balancing Fundamentals\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This item rewards stage continuity for You operate a feature-flag delivery API: carry the diagnosis (the incident signal) into follow-up action (\"Adopt zonal health checks with zone-aware failover\")."
    },
    {
      "id": "sc-lb-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a catalog browse API. First symptom: cache-miss traffic clusters on a few instances. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because hot users overload a subset of nodes",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node"
          ],
          "correct": 1,
          "explanation": "Stage 1: for You operate a catalog browse API, \"Investigate load-balancer policy because hot users overload a subset of nodes\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "The core signal here is \"you operate a catalog browse API\". Solve this as chained reasoning where stage two must respect stage one assumptions. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the option that best contains blast radius.",
          "options": [
            "Remove observability labels from requests",
            "Adopt consistent hashing with virtual nodes",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend"
          ],
          "correct": 1,
          "explanation": "For stage 2 in Load Balancing Fundamentals, \"Adopt consistent hashing with virtual nodes\" is the highest-signal move for After confirming imbalance, which mitigation is the strongest next move.",
          "detailedExplanation": "Use \"after confirming imbalance, which mitigation is the strongest next move? Choose the\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization."
        }
      ],
      "detailedExplanation": "The core signal here is \"load Balancing Fundamentals\". Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "Treat this as a linked decision chain in Load Balancing Fundamentals. Diagnose the main signal, then execute \"Adopt consistent hashing with virtual nodes\" for durable control."
    },
    {
      "id": "sc-lb-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate an auth token introspection service. First symptom: TLS handshake overhead spikes CPU on select backends. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Investigate load-balancer policy because session-bound workflows break after re-route",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day"
          ],
          "correct": 0,
          "explanation": "At stage 1, prioritize \"Investigate load-balancer policy because session-bound workflows break after re-route\" for You operate an auth token introspection service; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "The key clue in this question is \"you operate an auth token introspection service\". Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the change that aligns with stateless scaling goals.",
          "options": [
            "Adopt externalize session state to shared store",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests"
          ],
          "correct": 0,
          "explanation": "Stage 2: for After confirming imbalance, which mitigation is the strongest next move, \"Adopt externalize session state to shared store\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "Read this as a scenario about \"after confirming imbalance, which mitigation is the strongest next move? Pick the\". Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak."
        }
      ],
      "detailedExplanation": "If you keep \"load Balancing Fundamentals\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "For You operate an auth token introspection service, scoring is sequential: stage 1 isolates the governing risk and stage 2 prioritizes \"Adopt externalize session state to shared store\"."
    },
    {
      "id": "sc-lb-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a document rendering API. First symptom: slow jobs accumulate on already-busy targets. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because latency spikes during promotions"
          ],
          "correct": 3,
          "explanation": "This stage tests control under pressure for You operate a document rendering API. \"Investigate load-balancer policy because latency spikes during promotions\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "Start from \"you operate a document rendering API\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the action that avoids retry amplification.",
          "options": [
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt least connections with queue-aware routing"
          ],
          "correct": 3,
          "explanation": "At stage 2, prioritize \"Adopt least connections with queue-aware routing\" for After confirming imbalance, which mitigation is the strongest next move; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "The decision turns on \"after confirming imbalance, which mitigation is the strongest next move? Choose the\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "This prompt is really about \"load Balancing Fundamentals\". Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This two-stage prompt in Load Balancing Fundamentals evaluates diagnosis then mitigation for You operate a document rendering API: identify the core risk first, then apply \"Adopt least connections with queue-aware routing\"."
    },
    {
      "id": "sc-lb-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a travel pricing service. First symptom: weighted routing no longer matches real capacity. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because frequent backend restarts in deploy windows",
            "Disable health checks to reduce control plane noise"
          ],
          "correct": 2,
          "explanation": "For stage 1 in Load Balancing Fundamentals, \"Investigate load-balancer policy because frequent backend restarts in deploy windows\" is the highest-signal move for You operate a travel pricing service.",
          "detailedExplanation": "The decision turns on \"you operate a travel pricing service\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the mitigation with strongest SLO protection.",
          "options": [
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt graceful draining before deregistration",
            "Rely on client retries only with no routing changes"
          ],
          "correct": 2,
          "explanation": "This stage tests control under pressure for After confirming imbalance, which mitigation is the strongest next move. \"Adopt graceful draining before deregistration\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "Start from \"after confirming imbalance, which mitigation is the strongest next move? Pick the\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure."
        }
      ],
      "detailedExplanation": "Use \"load Balancing Fundamentals\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This item rewards stage continuity for You operate a travel pricing service: carry the diagnosis (the incident signal) into follow-up action (\"Adopt graceful draining before deregistration\")."
    },
    {
      "id": "sc-lb-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a social feed read API. First symptom: cross-zone forwarding increased after maintenance. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because one AZ shows intermittent packet loss",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node"
          ],
          "correct": 1,
          "explanation": "Stage 1: for You operate a social feed read API, \"Investigate load-balancer policy because one AZ shows intermittent packet loss\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "Read this as a scenario about \"you operate a social feed read API\". Solve this as chained reasoning where stage two must respect stage one assumptions. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the step that most directly reduces flapping.",
          "options": [
            "Remove observability labels from requests",
            "Adopt zonal health checks with zone-aware failover",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend"
          ],
          "correct": 1,
          "explanation": "For stage 2 in Load Balancing Fundamentals, \"Adopt zonal health checks with zone-aware failover\" is the highest-signal move for After confirming imbalance, which mitigation is the strongest next move.",
          "detailedExplanation": "The key clue in this question is \"after confirming imbalance, which mitigation is the strongest next move? Choose the\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"load Balancing Fundamentals\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "Treat this as a linked decision chain in Load Balancing Fundamentals. Diagnose the main signal, then execute \"Adopt zonal health checks with zone-aware failover\" for durable control."
    },
    {
      "id": "sc-lb-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate an IoT command API. First symptom: regional failover shifted unexpected load into one pool. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Investigate load-balancer policy because hot users overload a subset of nodes",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day"
          ],
          "correct": 0,
          "explanation": "At stage 1, prioritize \"Investigate load-balancer policy because hot users overload a subset of nodes\" for You operate an IoT command API; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "Use \"you operate an IoT command API\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the fix with lowest operational complexity for on-call teams.",
          "options": [
            "Adopt consistent hashing with virtual nodes",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests"
          ],
          "correct": 0,
          "explanation": "Stage 2: for After confirming imbalance, which mitigation is the strongest next move, \"Adopt consistent hashing with virtual nodes\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "The core signal here is \"after confirming imbalance, which mitigation is the strongest next move? Pick the fix\". Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak."
        }
      ],
      "detailedExplanation": "The decision turns on \"load Balancing Fundamentals\". Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "For You operate an IoT command API, scoring is sequential: stage 1 isolates the governing risk and stage 2 prioritizes \"Adopt consistent hashing with virtual nodes\"."
    },
    {
      "id": "sc-lb-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a loyalty points service. First symptom: health checks pass but business requests fail. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because session-bound workflows break after re-route"
          ],
          "correct": 3,
          "explanation": "For stage 1 in Load Balancing Fundamentals, \"Investigate load-balancer policy because session-bound workflows break after re-route\" is the highest-signal move for You operate a loyalty points service.",
          "detailedExplanation": "The decision turns on \"you operate a loyalty points service\". Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the option that improves failover behavior under zonal loss.",
          "options": [
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt externalize session state to shared store"
          ],
          "correct": 3,
          "explanation": "This stage tests control under pressure for After confirming imbalance, which mitigation is the strongest next move. \"Adopt externalize session state to shared store\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "Start from \"after confirming imbalance, which mitigation is the strongest next move? Choose the\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "Use \"load Balancing Fundamentals\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This item rewards stage continuity for You operate a loyalty points service: carry the diagnosis (the incident signal) into follow-up action (\"Adopt externalize session state to shared store\")."
    },
    {
      "id": "sc-lb-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a fraud scoring endpoint. First symptom: dependency saturation causes large response-time variance. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because latency spikes during promotions",
            "Disable health checks to reduce control plane noise"
          ],
          "correct": 2,
          "explanation": "Stage 1: for You operate a fraud scoring endpoint, \"Investigate load-balancer policy because latency spikes during promotions\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "Start from \"you operate a fraud scoring endpoint\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the approach that supports heterogenous backend capacity.",
          "options": [
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt least connections with queue-aware routing",
            "Rely on client retries only with no routing changes"
          ],
          "correct": 2,
          "explanation": "For stage 2 in Load Balancing Fundamentals, \"Adopt least connections with queue-aware routing\" is the highest-signal move for After confirming imbalance, which mitigation is the strongest next move.",
          "detailedExplanation": "The decision turns on \"after confirming imbalance, which mitigation is the strongest next move? Pick the\". Do not reset assumptions between stages; carry forward prior constraints directly. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "This prompt is really about \"load Balancing Fundamentals\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "Treat this as a linked decision chain in Load Balancing Fundamentals. Diagnose the main signal, then execute \"Adopt least connections with queue-aware routing\" for durable control."
    },
    {
      "id": "sc-lb-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate an order history API. First symptom: new nodes appear healthy but serve cold-cache latency. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because frequent backend restarts in deploy windows",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node"
          ],
          "correct": 1,
          "explanation": "At stage 1, prioritize \"Investigate load-balancer policy because frequent backend restarts in deploy windows\" for You operate an order history API; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "The key clue in this question is \"you operate an order history API\". Solve this as chained reasoning where stage two must respect stage one assumptions. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the action that best handles long-tail request variance.",
          "options": [
            "Remove observability labels from requests",
            "Adopt graceful draining before deregistration",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend"
          ],
          "correct": 1,
          "explanation": "Stage 2: for After confirming imbalance, which mitigation is the strongest next move, \"Adopt graceful draining before deregistration\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "Read this as a scenario about \"after confirming imbalance, which mitigation is the strongest next move? Choose the\". Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization."
        }
      ],
      "detailedExplanation": "If you keep \"load Balancing Fundamentals\" in view, the correct answer separates faster. Do not reset assumptions between stages; carry forward prior constraints directly. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "For You operate an order history API, scoring is sequential: stage 1 isolates the governing risk and stage 2 prioritizes \"Adopt graceful draining before deregistration\"."
    },
    {
      "id": "sc-lb-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a customer support API. First symptom: backend flapping causes frequent routing churn. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Investigate load-balancer policy because one AZ shows intermittent packet loss",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day"
          ],
          "correct": 0,
          "explanation": "This stage tests control under pressure for You operate a customer support API. \"Investigate load-balancer policy because one AZ shows intermittent packet loss\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "The core signal here is \"you operate a customer support API\". Solve this as chained reasoning where stage two must respect stage one assumptions. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the response that keeps canary risk bounded.",
          "options": [
            "Adopt zonal health checks with zone-aware failover",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests"
          ],
          "correct": 0,
          "explanation": "At stage 2, prioritize \"Adopt zonal health checks with zone-aware failover\" for After confirming imbalance, which mitigation is the strongest next move; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "Use \"after confirming imbalance, which mitigation is the strongest next move? Pick the\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "The core signal here is \"load Balancing Fundamentals\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This two-stage prompt in Load Balancing Fundamentals evaluates diagnosis then mitigation for You operate a customer support API: identify the core risk first, then apply \"Adopt zonal health checks with zone-aware failover\"."
    },
    {
      "id": "sc-lb-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a payments dispute API. First symptom: drain windows are shorter than request lifetimes. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because hot users overload a subset of nodes"
          ],
          "correct": 3,
          "explanation": "For stage 1 in Load Balancing Fundamentals, \"Investigate load-balancer policy because hot users overload a subset of nodes\" is the highest-signal move for You operate a payments dispute API.",
          "detailedExplanation": "If you keep \"you operate a payments dispute API\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the mitigation that reduces persistent skew fastest.",
          "options": [
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt consistent hashing with virtual nodes"
          ],
          "correct": 3,
          "explanation": "This stage tests control under pressure for After confirming imbalance, which mitigation is the strongest next move. \"Adopt consistent hashing with virtual nodes\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "This prompt is really about \"after confirming imbalance, which mitigation is the strongest next move? Choose the\". Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks."
        }
      ],
      "detailedExplanation": "The key clue in this question is \"load Balancing Fundamentals\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This item rewards stage continuity for You operate a payments dispute API: carry the diagnosis (the incident signal) into follow-up action (\"Adopt consistent hashing with virtual nodes\")."
    },
    {
      "id": "sc-lb-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a map tile metadata API. First symptom: bot traffic generates burst patterns at minute boundaries. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because session-bound workflows break after re-route",
            "Disable health checks to reduce control plane noise"
          ],
          "correct": 2,
          "explanation": "Stage 1: for You operate a map tile metadata API, \"Investigate load-balancer policy because session-bound workflows break after re-route\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "This prompt is really about \"you operate a map tile metadata API\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the control that improves readiness signal quality.",
          "options": [
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt externalize session state to shared store",
            "Rely on client retries only with no routing changes"
          ],
          "correct": 2,
          "explanation": "For stage 2 in Load Balancing Fundamentals, \"Adopt externalize session state to shared store\" is the highest-signal move for After confirming imbalance, which mitigation is the strongest next move.",
          "detailedExplanation": "If you keep \"after confirming imbalance, which mitigation is the strongest next move? Pick the\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks."
        }
      ],
      "detailedExplanation": "Start from \"load Balancing Fundamentals\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "Treat this as a linked decision chain in Load Balancing Fundamentals. Diagnose the main signal, then execute \"Adopt externalize session state to shared store\" for durable control."
    },
    {
      "id": "sc-lb-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a recommendation candidate API. First symptom: hash-key skew sends hot users to few nodes. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because latency spikes during promotions",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node"
          ],
          "correct": 1,
          "explanation": "At stage 1, prioritize \"Investigate load-balancer policy because latency spikes during promotions\" for You operate a recommendation candidate API; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "Use \"you operate a recommendation candidate API\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the option that best supports graceful deployments.",
          "options": [
            "Remove observability labels from requests",
            "Adopt least connections with queue-aware routing",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend"
          ],
          "correct": 1,
          "explanation": "Stage 2: for After confirming imbalance, which mitigation is the strongest next move, \"Adopt least connections with queue-aware routing\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "The core signal here is \"after confirming imbalance, which mitigation is the strongest next move? Choose the\". Do not reset assumptions between stages; carry forward prior constraints directly. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "The decision turns on \"load Balancing Fundamentals\". Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "For You operate a recommendation candidate API, scoring is sequential: stage 1 isolates the governing risk and stage 2 prioritizes \"Adopt least connections with queue-aware routing\"."
    },
    {
      "id": "sc-lb-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a real-time bidding edge. First symptom: gRPC streams and unary calls compete unfairly. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Investigate load-balancer policy because frequent backend restarts in deploy windows",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day"
          ],
          "correct": 0,
          "explanation": "This stage tests control under pressure for You operate a real-time bidding edge. \"Investigate load-balancer policy because frequent backend restarts in deploy windows\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "Read this as a scenario about \"you operate a real-time bidding edge\". Solve this as chained reasoning where stage two must respect stage one assumptions. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the change that preserves per-user correctness constraints.",
          "options": [
            "Adopt graceful draining before deregistration",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests"
          ],
          "correct": 0,
          "explanation": "At stage 2, prioritize \"Adopt graceful draining before deregistration\" for After confirming imbalance, which mitigation is the strongest next move; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "The key clue in this question is \"after confirming imbalance, which mitigation is the strongest next move? Pick the\". Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"load Balancing Fundamentals\". Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This two-stage prompt in Load Balancing Fundamentals evaluates diagnosis then mitigation for You operate a real-time bidding edge: identify the core risk first, then apply \"Adopt graceful draining before deregistration\"."
    },
    {
      "id": "sc-lb-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a merchant onboarding API. First symptom: request mix changed after new partner launch. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because one AZ shows intermittent packet loss"
          ],
          "correct": 3,
          "explanation": "For stage 1 in Load Balancing Fundamentals, \"Investigate load-balancer policy because one AZ shows intermittent packet loss\" is the highest-signal move for You operate a merchant onboarding API.",
          "detailedExplanation": "The decision turns on \"you operate a merchant onboarding API\". Do not reset assumptions between stages; carry forward prior constraints directly. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: ambiguous contracts that hide behavior changes."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the mitigation that prevents control-plane thrash.",
          "options": [
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt zonal health checks with zone-aware failover"
          ],
          "correct": 3,
          "explanation": "This stage tests control under pressure for After confirming imbalance, which mitigation is the strongest next move. \"Adopt zonal health checks with zone-aware failover\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "Start from \"after confirming imbalance, which mitigation is the strongest next move? Choose the\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "Use \"load Balancing Fundamentals\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This item rewards stage continuity for You operate a merchant onboarding API: carry the diagnosis (the incident signal) into follow-up action (\"Adopt zonal health checks with zone-aware failover\")."
    },
    {
      "id": "sc-lb-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate a subscription billing API. First symptom: retry amplification appears during transient faults. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Route all traffic to the newest node",
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because hot users overload a subset of nodes",
            "Disable health checks to reduce control plane noise"
          ],
          "correct": 2,
          "explanation": "Stage 1: for You operate a subscription billing API, \"Investigate load-balancer policy because hot users overload a subset of nodes\" is correct because it addresses the incident signal in Load Balancing Fundamentals.",
          "detailedExplanation": "Start from \"you operate a subscription billing API\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Pick the step that improves both correctness and availability.",
          "options": [
            "Pin traffic permanently to one backend",
            "Remove observability labels from requests",
            "Adopt consistent hashing with virtual nodes",
            "Rely on client retries only with no routing changes"
          ],
          "correct": 2,
          "explanation": "For stage 2 in Load Balancing Fundamentals, \"Adopt consistent hashing with virtual nodes\" is the highest-signal move for After confirming imbalance, which mitigation is the strongest next move.",
          "detailedExplanation": "The decision turns on \"after confirming imbalance, which mitigation is the strongest next move? Pick the step\". Do not reset assumptions between stages; carry forward prior constraints directly. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "This prompt is really about \"load Balancing Fundamentals\". Do not reset assumptions between stages; carry forward prior constraints directly. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "Treat this as a linked decision chain in Load Balancing Fundamentals. Diagnose the main signal, then execute \"Adopt consistent hashing with virtual nodes\" for durable control."
    },
    {
      "id": "sc-lb-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate an internal graph query API. First symptom: tail regressions correlate with stale LB membership. What is the most likely control-plane area to evaluate first?",
          "options": [
            "Increase DNS TTL to 1 day",
            "Investigate load-balancer policy because session-bound workflows break after re-route",
            "Disable health checks to reduce control plane noise",
            "Route all traffic to the newest node"
          ],
          "correct": 1,
          "explanation": "This stage tests control under pressure for You operate an internal graph query API. \"Investigate load-balancer policy because session-bound workflows break after re-route\" is strongest because it targets the scenario risk directly.",
          "detailedExplanation": "This prompt is really about \"you operate an internal graph query API\". Do not reset assumptions between stages; carry forward prior constraints directly. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "After confirming imbalance, which mitigation is the strongest next move? Choose the fix most robust to uncertain failure attribution.",
          "options": [
            "Remove observability labels from requests",
            "Adopt externalize session state to shared store",
            "Rely on client retries only with no routing changes",
            "Pin traffic permanently to one backend"
          ],
          "correct": 1,
          "explanation": "At stage 2, prioritize \"Adopt externalize session state to shared store\" for After confirming imbalance, which mitigation is the strongest next move; it best reduces the named risk before follow-on changes.",
          "detailedExplanation": "If you keep \"after confirming imbalance, which mitigation is the strongest next move? Choose the fix\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization."
        }
      ],
      "detailedExplanation": "Start from \"load Balancing Fundamentals\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior",
      "explanation": "This two-stage prompt in Load Balancing Fundamentals evaluates diagnosis then mitigation for You operate an internal graph query API: identify the core risk first, then apply \"Adopt externalize session state to shared store\"."
    },
    {
      "id": "sc-lb-061",
      "type": "multi-select",
      "question": "Which factors should influence choosing L4 vs L7 load balancing? (Select all that apply)",
      "options": [
        "Office seating layout",
        "Need for header/path routing",
        "TLS termination strategy",
        "Required protocol awareness"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The right answer for Which factors should influence choosing L4 vs L7 load balancing is a combined strategy: Need for header/path routing, TLS termination strategy, Required protocol awareness. Single-choice responses leave material risk unaddressed.",
      "detailedExplanation": "The key clue in this question is \"factors should influence choosing L4 vs L7 load balancing? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-062",
      "type": "multi-select",
      "question": "Healthy production load balancing usually includes which controls? (Select all that apply)",
      "options": [
        "Graceful connection draining",
        "Per-backend metrics",
        "No failure budget policy",
        "Active health checks"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "In Load Balancing Fundamentals, Healthy production load balancing usually includes which controls is best handled with coordinated controls. Select Graceful connection draining, Per-backend metrics, Active health checks to close the most important gaps.",
      "detailedExplanation": "Read this as a scenario about \"healthy production load balancing usually includes which controls? (Select all that\". Validate each option independently; do not select statements that are only partially true. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-063",
      "type": "multi-select",
      "question": "Sticky sessions can cause which risks? (Select all that apply)",
      "options": [
        "Guaranteed statelessness",
        "Uneven load under skewed users",
        "Harder failover when node dies",
        "Reduced cross-node rebalance flexibility"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "This scenario for Sticky sessions can cause which risks is multi-dimensional. The strongest combination is Uneven load under skewed users, Harder failover when node dies, Reduced cross-node rebalance flexibility, covering prevention and containment together.",
      "detailedExplanation": "The decision turns on \"sticky sessions can cause which risks? (Select all that apply)\". Treat every option as a separate true/false test under the same constraints. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-064",
      "type": "multi-select",
      "question": "Signals of unhealthy balancing quality include which? (Select all that apply)",
      "options": [
        "Persistent tail-latency despite spare cluster CPU",
        "Frequent backend flapping",
        "Perfectly stable p95 and no errors",
        "High variance in backend utilization"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "For Signals of unhealthy balancing quality include which in Load Balancing Fundamentals, this requires a control bundle, not one tactic. The correct set is Persistent tail-latency despite spare cluster CPU, Frequent backend flapping, High variance in backend utilization.",
      "detailedExplanation": "This prompt is really about \"signals of unhealthy balancing quality include which? (Select all that apply)\". Treat every option as a separate true/false test under the same constraints. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-065",
      "type": "multi-select",
      "question": "When using weighted balancing, what should weights reflect? (Select all that apply)",
      "options": [
        "Alphabetical hostname order",
        "Relative backend capacity",
        "Observed performance constraints",
        "Intentional traffic shaping goals"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The right answer for When using weighted balancing, what should weights reflect is a combined strategy: Relative backend capacity, Observed performance constraints, Intentional traffic shaping goals. Single-choice responses leave material risk unaddressed.",
      "detailedExplanation": "Use \"using weighted balancing, what should weights reflect? (Select all that apply)\" as your starting point, then verify tradeoffs carefully. Treat every option as a separate true/false test under the same constraints. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-066",
      "type": "multi-select",
      "question": "What are valid reasons to keep retries bounded at clients and proxies? (Select all that apply)",
      "options": [
        "Protect overloaded backends",
        "Preserve latency SLOs",
        "Guarantee infinite success",
        "Avoid retry storms"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "In Load Balancing Fundamentals, What are valid reasons to keep retries bounded at clients and proxies is best handled with coordinated controls. Select Protect overloaded backends, Preserve latency SLOs, Avoid retry storms to close the most important gaps.",
      "detailedExplanation": "The core signal here is \"valid reasons to keep retries bounded at clients and proxies? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-067",
      "type": "multi-select",
      "question": "Which controls improve zonal resilience with load balancers? (Select all that apply)",
      "options": [
        "Single-zone only deployment",
        "Zone-aware health checks",
        "Cross-zone failover policy",
        "Capacity headroom per zone"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "This scenario for Which controls improve zonal resilience with load balancers is multi-dimensional. The strongest combination is Zone-aware health checks, Cross-zone failover policy, Capacity headroom per zone, covering prevention and containment together.",
      "detailedExplanation": "If you keep \"controls improve zonal resilience with load balancers? (Select all that apply)\" in view, the correct answer separates faster. Treat every option as a separate true/false test under the same constraints. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-068",
      "type": "multi-select",
      "question": "For canary releases at the load balancer, which practices are strong? (Select all that apply)",
      "options": [
        "Automatic rollback thresholds",
        "Segment-specific routing rules",
        "Immediate 100% cutover by default",
        "Small initial traffic percentage"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "For canary releases at the load balancer in Load Balancing Fundamentals, this requires a control bundle, not one tactic. The correct set is Automatic rollback thresholds, Segment-specific routing rules, Small initial traffic percentage.",
      "detailedExplanation": "Start from \"for canary releases at the load balancer, which practices are strong? (Select all that\", then pressure-test the result against the options. Treat every option as a separate true/false test under the same constraints. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-069",
      "type": "multi-select",
      "question": "Important LB observability dimensions include which? (Select all that apply)",
      "options": [
        "Only host disk size",
        "Per-target success/error rates",
        "Target selection distribution",
        "End-to-end latency percentiles"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The right answer for Important LB observability dimensions include which is a combined strategy: Per-target success/error rates, Target selection distribution, End-to-end latency percentiles. Single-choice responses leave material risk unaddressed.",
      "detailedExplanation": "The key clue in this question is \"important LB observability dimensions include which? (Select all that apply)\". Treat every option as a separate true/false test under the same constraints. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-070",
      "type": "multi-select",
      "question": "Reasons to externalize session state from app memory include which? (Select all that apply)",
      "options": [
        "Reduce reliance on sticky sessions",
        "Simplify failover across instances",
        "Increase node-local coupling",
        "Enable stateless horizontal scaling"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "This scenario for Reasons to externalize session state from app memory include which is multi-dimensional. The strongest combination is Reduce reliance on sticky sessions, Simplify failover across instances, Enable stateless horizontal scaling, covering prevention and containment together.",
      "detailedExplanation": "The decision turns on \"reasons to externalize session state from app memory include which? (Select all that\". Treat every option as a separate true/false test under the same constraints. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-071",
      "type": "multi-select",
      "question": "What can make DNS-based balancing insufficient alone? (Select all that apply)",
      "options": [
        "Native header-based routing",
        "Client-side DNS caching",
        "Lack of request-level health awareness",
        "Slow failover reaction to node failure"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "For What can make DNS-based balancing insufficient alone in Load Balancing Fundamentals, this requires a control bundle, not one tactic. The correct set is Client-side DNS caching, Lack of request-level health awareness, Slow failover reaction to node failure.",
      "detailedExplanation": "Read this as a scenario about \"make DNS-based balancing insufficient alone? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-072",
      "type": "multi-select",
      "question": "What should a robust LB health endpoint validate? (Select all that apply)",
      "options": [
        "Ability to serve core requests",
        "Resource exhaustion guardrails",
        "Marketing copy freshness",
        "Critical dependency readiness"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The right answer for What should a robust LB health endpoint validate is a combined strategy: Ability to serve core requests, Resource exhaustion guardrails, Critical dependency readiness. Single-choice responses leave material risk unaddressed.",
      "detailedExplanation": "The key clue in this question is \"a robust LB health endpoint validate? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-073",
      "type": "multi-select",
      "question": "Common causes of load imbalance include which? (Select all that apply)",
      "options": [
        "Uniform request cost and perfect signals",
        "Unequal backend capacity with equal weights",
        "Hash skew from low-cardinality keys",
        "Slow target deregistration"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "In Load Balancing Fundamentals, Common causes of load imbalance include which is best handled with coordinated controls. Select Unequal backend capacity with equal weights, Hash skew from low-cardinality keys, Slow target deregistration to close the most important gaps.",
      "detailedExplanation": "Start from \"common causes of load imbalance include which? (Select all that apply)\", then pressure-test the result against the options. Treat every option as a separate true/false test under the same constraints. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-074",
      "type": "multi-select",
      "question": "Which are valid trade-offs when terminating TLS at edge LB? (Select all that apply)",
      "options": [
        "Potential internal trust-boundary requirements",
        "L7 policy enablement",
        "Automatic elimination of authn/authz",
        "Centralized cert lifecycle"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "This scenario for Which are valid trade-offs when terminating TLS at edge LB is multi-dimensional. The strongest combination is Potential internal trust-boundary requirements, L7 policy enablement, Centralized cert lifecycle, covering prevention and containment together.",
      "detailedExplanation": "If you keep \"valid trade-offs when terminating TLS at edge LB? (Select all that apply)\" in view, the correct answer separates faster. Validate each option independently; do not select statements that are only partially true. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-075",
      "type": "multi-select",
      "question": "When should fail-closed behavior be preferred? (Select all that apply)",
      "options": [
        "Any consumer social feed",
        "Safety-critical correctness dominates availability",
        "Regulated operations require strict backend health certainty",
        "Serving stale/incorrect responses is unacceptable"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "For When should fail-closed behavior be preferred in Load Balancing Fundamentals, this requires a control bundle, not one tactic. The correct set is Safety-critical correctness dominates availability, Regulated operations require strict backend health certainty, Serving stale/incorrect responses is unacceptable.",
      "detailedExplanation": "The core signal here is \"fail-closed behavior be preferred? (Select all that apply)\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-076",
      "type": "multi-select",
      "question": "Good rollback triggers for LB canaries include which? (Select all that apply)",
      "options": [
        "Tail latency regression",
        "Saturation increase at target pool",
        "Weekend calendar date",
        "Error rate regression"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The right answer for Good rollback triggers for LB canaries include which is a combined strategy: Tail latency regression, Saturation increase at target pool, Error rate regression. Single-choice responses leave material risk unaddressed.",
      "detailedExplanation": "Use \"good rollback triggers for LB canaries include which? (Select all that apply)\" as your starting point, then verify tradeoffs carefully. Avoid pattern guessing and evaluate each candidate directly against the scenario. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-077",
      "type": "multi-select",
      "question": "For client-side load balancing, clients must typically handle which concerns? (Select all that apply)",
      "options": [
        "Datacenter power distribution",
        "Service discovery updates",
        "Endpoint health filtering",
        "Retry/backoff semantics"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "In Load Balancing Fundamentals, client-side load balancing is best handled with coordinated controls. Select Service discovery updates, Endpoint health filtering, Retry/backoff semantics to close the most important gaps.",
      "detailedExplanation": "This prompt is really about \"for client-side load balancing, clients must typically handle which concerns? (Select\". Validate each option independently; do not select statements that are only partially true. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-078",
      "type": "numeric-input",
      "question": "An LB receives 24,000 requests/second and has 12 equally capable backends. Approximate requests/second per backend?",
      "answer": 2000,
      "unit": "rps",
      "tolerance": 0.01,
      "explanation": "The sizing math for An LB receives 24,000 requests/second and has 12 equally capable backends yields 2000 rps. Use within +/-1% as the grading bound.",
      "detailedExplanation": "The decision turns on \"lB receives 24,000 requests/second and has 12 equally capable backends\". Normalize units before computing so conversion mistakes do not propagate. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 24,000 and 12 appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-079",
      "type": "numeric-input",
      "question": "Traffic jumps to 36,000 rps while still on 12 backends. What is per-backend load?",
      "answer": 3000,
      "unit": "rps",
      "tolerance": 0.01,
      "explanation": "For Traffic jumps to 36,000 rps while still on 12 backends in Load Balancing Fundamentals, the expected result is 3000 rps. Answers within +/-1% are acceptable.",
      "detailedExplanation": "Read this as a scenario about \"traffic jumps to 36,000 rps while still on 12 backends\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 36,000 rps and 12 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-080",
      "type": "numeric-input",
      "question": "Each backend can safely do 2,500 rps. At 36,000 total rps, minimum backend count needed?",
      "answer": 15,
      "unit": "instances",
      "tolerance": 0,
      "explanation": "This estimate anchors the decision for Each backend can safely do 2,500 rps: 15 instances. Responses within +/-0% show correct reasoning.",
      "detailedExplanation": "The core signal here is \"each backend can safely do 2,500 rps\". Normalize units before computing so conversion mistakes do not propagate. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 2,500 rps and 36,000 appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-081",
      "type": "numeric-input",
      "question": "Health checks run every 5s with timeout 1s; 180 backends are probed. Approximate probes per minute?",
      "answer": 2160,
      "unit": "probes",
      "tolerance": 0,
      "explanation": "The sizing math for Health checks run every 5s with timeout 1s; 180 backends are probed yields 2160 probes. Use within +/-0% as the grading bound.",
      "detailedExplanation": "If you keep \"health checks run every 5s with timeout 1s\" in view, the correct answer separates faster. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Numbers such as 5s and 1s should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-082",
      "type": "numeric-input",
      "question": "If 3% of 40,000 rps requires expensive auth checks, how many rps hit that path?",
      "answer": 1200,
      "unit": "rps",
      "tolerance": 0.01,
      "explanation": "For If 3% of 40,000 rps requires expensive auth checks, how many rps hit that path in Load Balancing Fundamentals, the expected result is 1200 rps. Answers within +/-1% are acceptable.",
      "detailedExplanation": "This prompt is really about \"if 3% of 40,000 rps requires expensive auth checks, how many rps hit that path\". Normalize units before computing so conversion mistakes do not propagate. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 3 and 40,000 rps appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-083",
      "type": "numeric-input",
      "question": "A canary gets 5% of 18,000 rps. What canary traffic rate is expected?",
      "answer": 900,
      "unit": "rps",
      "tolerance": 0.01,
      "explanation": "In Load Balancing Fundamentals, A canary gets 5% of 18,000 rps evaluates to 900 rps. Any result within +/-1% demonstrates sound capacity judgment.",
      "detailedExplanation": "Use \"canary gets 5% of 18,000 rps\" as your starting point, then verify tradeoffs carefully. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 5 and 18,000 rps should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-084",
      "type": "numeric-input",
      "question": "A backend pool has weights 1:2:3 across three targets with 12,000 rps total. Approximate rps to heaviest target?",
      "answer": 6000,
      "unit": "rps",
      "tolerance": 0.01,
      "explanation": "This estimate anchors the decision for A backend pool has weights 1:2:3 across three targets with 12,000 rps total: 6000 rps. Responses within +/-1% show correct reasoning.",
      "detailedExplanation": "Read this as a scenario about \"backend pool has weights 1:2:3 across three targets with 12,000 rps total\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 1 and 2 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-085",
      "type": "numeric-input",
      "question": "Client retry policy can add up to 0.2 extra requests per original request. At 25,000 original rps, what is worst-case effective rps?",
      "answer": 30000,
      "unit": "rps",
      "tolerance": 0.01,
      "explanation": "The sizing math for Client retry policy can add up to 0 yields 30000 rps. Use within +/-1% as the grading bound.",
      "detailedExplanation": "The decision turns on \"client retry policy can add up to 0\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Numbers such as 0.2 and 25,000 should be normalized first so downstream reasoning stays consistent. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-086",
      "type": "numeric-input",
      "question": "LB target has p95 latency 180ms and queueing adds 40ms. Approximate new p95?",
      "answer": 220,
      "unit": "ms",
      "tolerance": 0.02,
      "explanation": "For LB target has p95 latency 180ms and queueing adds 40ms in Load Balancing Fundamentals, the expected result is 220 ms. Answers within +/-2% are acceptable.",
      "detailedExplanation": "Start from \"lB target has p95 latency 180ms and queueing adds 40ms\", then pressure-test the result against the options. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Tie the decision to concrete operational outcomes, not abstract reliability language. Numbers such as 180ms and 40ms should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-087",
      "type": "numeric-input",
      "question": "To keep 30% headroom for 28,000 rps demand, what capacity should pool provide?",
      "answer": 40000,
      "unit": "rps",
      "tolerance": 0.03,
      "explanation": "In Load Balancing Fundamentals, To keep 30% headroom for 28,000 rps demand, what capacity should pool provide evaluates to 40000 rps. Any result within +/-3% demonstrates sound capacity judgment.",
      "detailedExplanation": "The key clue in this question is \"to keep 30% headroom for 28,000 rps demand, what capacity should pool provide\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 30 and 28,000 rps should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-088",
      "type": "numeric-input",
      "question": "A deploy drains 2 instances/minute from a 20-instance pool. How many minutes to drain all instances (if no replacements)?",
      "answer": 10,
      "unit": "minutes",
      "tolerance": 0,
      "explanation": "This estimate anchors the decision for A deploy drains 2 instances/minute from a 20-instance pool: 10 minutes. Responses within +/-0% show correct reasoning.",
      "detailedExplanation": "The core signal here is \"deploy drains 2 instances/minute from a 20-instance pool\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 2 and 20 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-089",
      "type": "numeric-input",
      "question": "Error budget allows 0.1% failed requests over 5,000,000 requests/day. Max failed requests/day?",
      "answer": 5000,
      "unit": "requests",
      "tolerance": 0,
      "explanation": "The sizing math for Error budget allows 0 yields 5000 requests. Use within +/-0% as the grading bound.",
      "detailedExplanation": "If you keep \"error budget allows 0\" in view, the correct answer separates faster. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Numbers such as 0.1 and 5,000 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-090",
      "type": "ordering",
      "question": "Order a safe target removal flow during deployment.",
      "items": [
        "Mark instance as draining",
        "Stop new request routing to instance",
        "Finish in-flight requests",
        "Deregister instance"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Correct ordering for Load Balancing Fundamentals starts at Mark instance as draining and ends at Deregister instance, preserving operational safety.",
      "detailedExplanation": "The key clue in this question is \"order a safe target removal flow during deployment\". Build the rank from biggest differences first, then refine with adjacent checks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-091",
      "type": "ordering",
      "question": "Order by increasing routing sophistication.",
      "items": [
        "DNS round robin",
        "L4 TCP balancing",
        "L7 HTTP balancing",
        "L7 with header/path + canary policies"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "In Order by increasing routing sophistication, this ordering minimizes rework and blast radius: DNS round robin comes before L7 with header/path + canary policies.",
      "detailedExplanation": "Start from \"order by increasing routing sophistication\", then pressure-test the result against the options. Build the rank from biggest differences first, then refine with adjacent checks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-092",
      "type": "ordering",
      "question": "Order canary rollout steps.",
      "items": [
        "Route 1-5% traffic to canary",
        "Monitor guardrail metrics",
        "Increase traffic gradually",
        "Promote or rollback"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The safe sequence in Load Balancing Fundamentals is dependency-first: begin with Route 1-5% traffic to canary and finish with Promote or rollback.",
      "detailedExplanation": "The decision turns on \"order canary rollout steps\". Build the rank from biggest differences first, then refine with adjacent checks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-093",
      "type": "ordering",
      "question": "Order incident triage for sudden LB-induced 5xx spike.",
      "items": [
        "Confirm scope and affected routes",
        "Check target health and selection skew",
        "Apply mitigation (drain bad targets/rollback rule)",
        "Run post-incident fix plan"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "For Order incident triage for sudden LB-induced 5xx spike, order steps from Confirm scope and affected routes to Run post-incident fix plan; Load Balancing Fundamentals requires stabilization before optimization.",
      "detailedExplanation": "Read this as a scenario about \"order incident triage for sudden LB-induced 5xx spike\". Place obvious extremes first, then sort the middle by pairwise comparison. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-094",
      "type": "ordering",
      "question": "Order health-check strictness from loosest to strictest.",
      "items": [
        "TCP connect only",
        "HTTP 200 on /healthz",
        "HTTP readiness with dependency checks",
        "Synthetic transaction health test"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Correct ordering for Load Balancing Fundamentals starts at TCP connect only and ends at Synthetic transaction health test, preserving operational safety.",
      "detailedExplanation": "Use \"order health-check strictness from loosest to strictest\" as your starting point, then verify tradeoffs carefully. Build the rank from biggest differences first, then refine with adjacent checks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-095",
      "type": "ordering",
      "question": "Order by likely failover reaction speed (slowest to fastest).",
      "items": [
        "DNS TTL-based failover",
        "Passive error-based target eviction",
        "Active periodic health checks",
        "Per-request circuit-breaker style routing"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "In Order by likely failover reaction speed (slowest to fastest), this ordering minimizes rework and blast radius: DNS TTL-based failover comes before Per-request circuit-breaker style routing.",
      "detailedExplanation": "This prompt is really about \"order by likely failover reaction speed (slowest to fastest)\". Place obvious extremes first, then sort the middle by pairwise comparison. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 1035: Domain names - implementation and specification",
          "url": "https://www.rfc-editor.org/rfc/rfc1035"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-096",
      "type": "ordering",
      "question": "Order controls to reduce retry amplification.",
      "items": [
        "Set bounded retry count",
        "Add exponential backoff",
        "Add jitter",
        "Enforce retry budget/hedging guardrails"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The safe sequence in Load Balancing Fundamentals is dependency-first: begin with Set bounded retry count and finish with Enforce retry budget/hedging guardrails.",
      "detailedExplanation": "If you keep \"order controls to reduce retry amplification\" in view, the correct answer separates faster. Place obvious extremes first, then sort the middle by pairwise comparison. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-097",
      "type": "ordering",
      "question": "Order by increasing session externalization maturity.",
      "items": [
        "In-memory per-node sessions",
        "Sticky sessions at LB",
        "Shared session store",
        "Stateless token/session-minimized design"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "For Order by increasing session externalization maturity, order steps from In-memory per-node sessions to Stateless token/session-minimized design; Load Balancing Fundamentals requires stabilization before optimization.",
      "detailedExplanation": "The core signal here is \"order by increasing session externalization maturity\". Build the rank from biggest differences first, then refine with adjacent checks. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-098",
      "type": "ordering",
      "question": "Order balancing policies by dependence on real-time load telemetry (least to most).",
      "items": [
        "Round robin",
        "Weighted round robin",
        "Least connections",
        "Least response time"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Correct ordering for Load Balancing Fundamentals starts at Round robin and ends at Least response time, preserving operational safety.",
      "detailedExplanation": "The key clue in this question is \"order balancing policies by dependence on real-time load telemetry (least to most)\". Order by relative scale and bottleneck effect, then validate neighboring items. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-099",
      "type": "ordering",
      "question": "Order steps for introducing weighted balancing safely.",
      "items": [
        "Measure baseline per-target metrics",
        "Assign initial weights by capacity",
        "Watch skew/error regressions",
        "Tune weights iteratively"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "In Order steps for introducing weighted balancing safely, this ordering minimizes rework and blast radius: Measure baseline per-target metrics comes before Tune weights iteratively.",
      "detailedExplanation": "Start from \"order steps for introducing weighted balancing safely\", then pressure-test the result against the options. Place obvious extremes first, then sort the middle by pairwise comparison. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    },
    {
      "id": "sc-lb-100",
      "type": "ordering",
      "question": "Order capacity management loop for LB pools.",
      "items": [
        "Track demand and utilization",
        "Forecast near-term peaks",
        "Pre-scale with headroom",
        "Validate post-peak and adjust model"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The safe sequence in Load Balancing Fundamentals is dependency-first: begin with Track demand and utilization and finish with Validate post-peak and adjust model.",
      "detailedExplanation": "If you keep \"order capacity management loop for LB pools\" in view, the correct answer separates faster. Build the rank from biggest differences first, then refine with adjacent checks. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["scaling-compute", "load-balancing-fundamentals"],
      "difficulty": "senior"
    }
  ]
}
