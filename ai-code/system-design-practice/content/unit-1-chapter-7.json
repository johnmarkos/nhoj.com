{
  "unit": 1,
  "unitTitle": "Estimation",
  "chapter": 7,
  "chapterTitle": "Reasonableness Checks",
  "chapterDescription": "Validating estimates, spotting red flags, and checking calculations against real-world constraints",
  "problems": [
    {
      "id": "sanity-001",
      "type": "multiple-choice",
      "question": "A teammate estimates their new service will need 1 PB of RAM. What's the most likely issue?",
      "options": [
        "Confusing RAM with disk storage",
        "Correct for a large-scale service",
        "Underestimating by 10x",
        "Using wrong units (should be EB)"
      ],
      "correct": 0,
      "explanation": "1 PB of RAM would cost ~$10B and require thousands of servers. Even Google Search doesn't use this much RAM for a single service. They likely mean disk storage.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Reject approaches that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 1 and 10B should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-002",
      "type": "multiple-choice",
      "question": "Estimate says a single MySQL instance will handle 1M QPS. Is this reasonable?",
      "options": [
        "Yes, with proper indexing",
        "No, typical limit is 10K-50K QPS",
        "No, typical limit is 100-1K QPS",
        "Yes, with read replicas"
      ],
      "correct": 1,
      "explanation": "A well-tuned MySQL instance handles 10K-50K QPS for simple queries. 1M QPS requires sharding across many instances. This estimate is off by ~20-100x.",
      "detailedExplanation": "Generalize from estimate says a single MySQL instance will handle 1M QPS to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 1M and 10K appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-003",
      "type": "multiple-choice",
      "question": "Design doc claims 99.999% availability with a single-region deployment. Red flag?",
      "options": [
        "No, achievable with redundant servers",
        "Yes, single region can't survive regional outages",
        "No, cloud providers guarantee this",
        "Depends on the database choice"
      ],
      "correct": 1,
      "explanation": "Five 9s (5.26 min/year downtime) requires surviving regional failures. A single region deployment has a single point of failure for the entire region. Multi-region is required.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Numbers such as 99.999 and 9s should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-004",
      "type": "multiple-choice",
      "question": "Estimate: 'We'll store 1 billion user profiles at 10 KB each = 10 TB.' Sanity check?",
      "options": [
        "Math is correct",
        "Off by 1000x (should be 10 PB)",
        "Off by 10x (should be 100 TB)",
        "Off by 1000x (should be 10 GB)"
      ],
      "correct": 0,
      "explanation": "1B × 10 KB = 10B KB = 10 TB. The math checks out. This is a reasonable size for a large user database.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Discard options that depend on unrealistic assumptions hidden in the estimate. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Numbers such as 1 and 10 KB should be normalized first so downstream reasoning stays consistent. Common pitfall: propagating an early bad assumption through all steps.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-005",
      "type": "multiple-choice",
      "question": "Team claims their API p99 latency is 1ms with a cross-country database call. Issue?",
      "options": [
        "Plausible with edge caching",
        "Impossible - network RTT alone is 30-70ms",
        "Correct if using TCP fast open",
        "Plausible with connection pooling"
      ],
      "correct": 1,
      "explanation": "Cross-country (e.g., NYC to LA) network RTT is 30-70ms minimum due to speed of light. 1ms p99 is physically impossible without local caching.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that directly address failure mode, recovery path, and blast radius. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 1ms and 30 should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-006",
      "type": "multiple-choice",
      "question": "Capacity plan shows 100 servers handling 10M QPS total. Per-server load reasonable?",
      "options": [
        "Yes, 100K QPS per server is typical",
        "No, that's 100K QPS per server - too high for most apps",
        "No, that's only 1K QPS per server - underutilized",
        "Depends entirely on the workload"
      ],
      "correct": 0,
      "explanation": "10M ÷ 100 = 100K QPS per server. For simple stateless web servers with fast backends, this is achievable. For complex processing, it might be high. Context matters, but it's in the reasonable range.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 100 and 10M should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-007",
      "type": "multiple-choice",
      "question": "Estimate claims 1 TB/second of network throughput from a single server. Valid?",
      "options": [
        "Yes, with 100 Gbps NIC",
        "No, fastest NICs are ~400 Gbps = 50 GB/s",
        "Yes, with NVMe storage",
        "No, but achievable with kernel bypass"
      ],
      "correct": 1,
      "explanation": "1 TB/s = 8 Tbps. The fastest commodity NICs are 400 Gbps (~50 GB/s). 1 TB/s would need 20+ of the fastest NICs. This is off by ~20x.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. If values like 1 TB and 8 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-008",
      "type": "multiple-choice",
      "question": "Design proposes storing 10 years of logs at 1 GB/day. Total storage estimate of 3.6 TB. Check?",
      "options": [
        "Correct",
        "Wrong - should be ~36 TB",
        "Wrong - should be ~365 GB",
        "Wrong - should be ~3.6 PB"
      ],
      "correct": 0,
      "explanation": "10 years × 365 days × 1 GB = 3,650 GB ≈ 3.6 TB. The estimate is correct.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Reject approaches that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 10 and 1 GB in aligned units before deciding on an implementation approach. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-009",
      "type": "multiple-choice",
      "question": "Proposal: 'Each user uploads 1 photo/day. 100M users = 100M photos/day = 1,157 photos/second.' Sanity check?",
      "options": [
        "Math is correct",
        "Wrong - should be ~11,574/second",
        "Wrong - should be ~115/second",
        "Wrong - should be ~1.16M/second"
      ],
      "correct": 0,
      "explanation": "100M ÷ 86,400 seconds = 1,157 photos/second. The math checks out.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prefer the answer that survives a sanity check against known anchor numbers. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. If values like 1 and 100M appear, convert them into one unit basis before comparison. Common pitfall: accepting implausible outputs because arithmetic is clean.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-010",
      "type": "multiple-choice",
      "question": "Teammate says Redis will handle their 10 TB dataset in memory. Concern?",
      "options": [
        "No concern, Redis scales horizontally",
        "Major concern - largest instances are ~500 GB RAM",
        "No concern with Redis Cluster",
        "Minor concern - may need 2-3 instances"
      ],
      "correct": 1,
      "explanation": "10 TB in-memory requires enormous hardware. The largest cloud instances have ~500 GB-1 TB RAM. You'd need 10-20+ of the largest instances. Consider if all data needs to be in memory.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Numbers such as 10 TB and 500 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-011",
      "type": "multiple-choice",
      "question": "Estimate: 'P99 latency of 500ms is fine for our real-time chat app.' Red flag?",
      "options": [
        "Acceptable for non-critical features",
        "Major red flag - users expect <100ms for chat",
        "Fine if most requests are faster",
        "Acceptable for mobile users"
      ],
      "correct": 1,
      "explanation": "Real-time chat users expect near-instant delivery. 500ms p99 means 1% of messages take half a second - very noticeable. Target should be <100ms p99.",
      "detailedExplanation": "Generalize from estimate: 'P99 latency of 500ms is fine for our real-time chat app to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prioritize the approach that best protects reliability objectives under stated failure conditions. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 500ms and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-012",
      "type": "multiple-choice",
      "question": "Design claims a single Kafka broker will handle 10M messages/second. Reasonable?",
      "options": [
        "Yes, Kafka is designed for this scale",
        "No, typical limit is 100K-500K msg/sec per broker",
        "No, typical limit is 1K-10K msg/sec per broker",
        "Yes, with proper partitioning"
      ],
      "correct": 1,
      "explanation": "A single Kafka broker typically handles 100K-500K messages/second depending on message size. 10M msg/sec needs 20-100 brokers. Off by ~20-100x.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Reject designs that improve throughput while weakening reliability guarantees. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Numbers such as 10M and 100K should be normalized first so downstream reasoning stays consistent. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-013",
      "type": "multiple-choice",
      "question": "Cost estimate: '$0.10/GB storage × 1 PB = $100,000/month.' Check the math.",
      "options": [
        "Correct",
        "Wrong - should be $100M/month",
        "Wrong - should be $10,000/month",
        "Wrong - should be $1M/month"
      ],
      "correct": 0,
      "explanation": "1 PB = 1,000,000 GB. $0.10 × 1,000,000 = $100,000/month. Math is correct. (Though $0.10/GB is high - S3 standard is ~$0.023/GB.)",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Reject approaches that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 0.10 and 1 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-014",
      "type": "multiple-choice",
      "question": "Architect claims their service processes 1 request in 10 nanoseconds. Believable?",
      "options": [
        "Yes, with optimized code",
        "No, a single L1 cache access takes ~1ns",
        "Yes, with FPGA acceleration",
        "No, context switches alone take longer"
      ],
      "correct": 1,
      "explanation": "10ns is only ~30 CPU cycles. Even reading from L1 cache takes 1ns, L2 takes 4ns. A complete request/response with any I/O or logic is impossible in 10ns. Minimum realistic is microseconds.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. If values like 1 and 10 appear, convert them into one unit basis before comparison. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-015",
      "type": "multiple-choice",
      "question": "Proposal estimates 10 engineers can build and operate a global distributed database in 6 months. Realistic?",
      "options": [
        "Realistic for experienced team",
        "Unrealistic - takes 50+ engineers years",
        "Realistic if using existing frameworks",
        "Depends on feature set"
      ],
      "correct": 1,
      "explanation": "Production-grade distributed databases (CockroachDB, Spanner, etc.) took massive teams many years. Even with shortcuts, a reliable global database is a multi-year, large-team effort. Use existing solutions.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 10 and 6 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-016",
      "type": "multiple-choice",
      "question": "Estimate: 'Our 50-node cluster has 50 × 16 cores = 800 cores, so we can handle 800 concurrent requests.' Flaw?",
      "options": [
        "No flaw, math is correct",
        "Flaw: most requests involve I/O waiting, not CPU",
        "Flaw: should account for hyperthreading (1600)",
        "Flaw: need to subtract OS overhead"
      ],
      "correct": 1,
      "explanation": "Concurrent requests ≠ CPU cores. Most web requests spend time waiting on I/O (database, network). A single core can handle hundreds or thousands of concurrent I/O-bound requests with async processing.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Reject designs that improve throughput while weakening reliability guarantees. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Numbers such as 50 and 16 should be normalized first so downstream reasoning stays consistent. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-017",
      "type": "multiple-choice",
      "question": "Team proposes 100% cache hit rate as their target. Issue?",
      "options": [
        "Achievable with enough cache",
        "Unrealistic - cold starts, cache eviction, new data",
        "Achievable with predictive caching",
        "Fine as an aspirational goal"
      ],
      "correct": 1,
      "explanation": "100% hit rate is impossible: new/updated data isn't cached, cold starts after deployments, cache eviction under memory pressure, and long-tail requests for rarely-accessed data. Typical targets are 90-99%.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Reject approaches that improve speed but weaken freshness or invalidation correctness. Cache design quality is mostly about correctness boundaries, not only hit rate. If values like 100 and 90 appear, convert them into one unit basis before comparison. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-018",
      "type": "multiple-choice",
      "question": "Design doc: 'With 1M users and 10 friends average, we'll have 10M friend relationships.' Missing factor?",
      "options": [
        "No missing factor, math is correct",
        "Friendships are bidirectional - actually 5M edges",
        "Should account for follow asymmetry",
        "Missing power-law distribution"
      ],
      "correct": 1,
      "explanation": "If friendships are mutual (A friends B means B friends A), each friendship is counted twice in '10 friends average.' Actual edges = 1M × 10 ÷ 2 = 5M relationships.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 1M and 10 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-019",
      "type": "multiple-choice",
      "question": "Estimate claims SSD random read latency of 1 microsecond. Accurate?",
      "options": [
        "Yes, modern NVMe SSDs achieve this",
        "No, typical is 50-100 microseconds",
        "No, typical is 10-20 milliseconds",
        "Yes, with Intel Optane"
      ],
      "correct": 1,
      "explanation": "NVMe SSD random read latency is typically 50-100 microseconds. Intel Optane is faster (~10μs) but still not 1μs. 1μs would be closer to RAM access speeds.",
      "detailedExplanation": "Generalize from estimate claims SSD random read latency of 1 microsecond to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer the approach that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 1 and 50 should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-020",
      "type": "multiple-choice",
      "question": "Load test shows server handling 50K QPS at 10% CPU utilization. Extrapolation to 100% CPU = 500K QPS. Valid?",
      "options": [
        "Valid linear extrapolation",
        "Invalid - performance degrades non-linearly at high utilization",
        "Valid if using autoscaling",
        "Invalid - should use 80% as max"
      ],
      "correct": 1,
      "explanation": "CPU utilization doesn't scale linearly. At high utilization, context switching, lock contention, and queueing cause degradation. Never plan for 100% utilization. Use 70-80% as practical max.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer approaches that directly address failure mode, recovery path, and blast radius. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. If values like 50K and 10 appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-021",
      "type": "multiple-choice",
      "question": "Estimate: 'Twitter has 500M users tweeting 10x/day = 5B tweets/day = 58K tweets/second.' Reality check?",
      "options": [
        "Reasonable estimate",
        "Too high - actual is ~6K tweets/second",
        "Too low - actual is ~500K tweets/second",
        "Can't verify without internal data"
      ],
      "correct": 1,
      "explanation": "Not all 500M users are daily active, and most users read more than write. Actual tweet rate is ~500M tweets/day = ~6K/second. The 10x/day assumption is too high for average users.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer the answer that survives a sanity check against known anchor numbers. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Keep quantities like 500M and 10x in aligned units before deciding on an implementation approach. Common pitfall: skipping anchor checks against known scale.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-022",
      "type": "multiple-choice",
      "question": "Proposal to process 1M images/second with 10 GPU servers. Each image takes 100ms on GPU. Feasible?",
      "options": [
        "Feasible with batching",
        "Infeasible - 10 GPUs × 10/sec = 100 images/sec max",
        "Feasible with model optimization",
        "Infeasible without TPUs"
      ],
      "correct": 1,
      "explanation": "If each image takes 100ms, one GPU processes 10 images/second. 10 GPUs = 100 images/second. For 1M/sec, you'd need 100,000 GPUs. Off by 10,000x.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 1M and 10 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-023",
      "type": "multiple-choice",
      "question": "Cost projection: 'AWS bill will stay flat as we 10x users because we'll optimize.' Realistic?",
      "options": [
        "Realistic with good engineering",
        "Unrealistic - costs scale with usage",
        "Realistic if already over-provisioned",
        "Depends on pricing model"
      ],
      "correct": 1,
      "explanation": "While optimization helps, 10x users means ~10x compute, storage, and bandwidth. You might achieve 3-5x efficiency gains, but flat costs while 10x-ing is unrealistic without fundamental architecture changes.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Reject approaches that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 10x and 3 in aligned units before deciding on an implementation approach. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-024",
      "type": "multiple-choice",
      "question": "Design assumes 0ms network latency between microservices 'because they're in the same datacenter.' Problem?",
      "options": [
        "No problem, same-DC latency is negligible",
        "Problem: same-DC RTT is 0.5-2ms, adds up with many hops",
        "No problem with service mesh",
        "Problem only at very high scale"
      ],
      "correct": 1,
      "explanation": "Same-datacenter RTT is 0.5-2ms, not 0. With 10 microservice hops, that's 5-20ms just in network latency. This matters for latency-sensitive applications and is often underestimated.",
      "detailedExplanation": "Generalize from design assumes 0ms network latency between microservices 'because they're in the same to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Discard bandwidth plans that omit overhead and burst behavior. Treat network capacity as a steady-state constraint, then test against peak windows. Numbers such as 0ms and 0.5 should be normalized first so downstream reasoning stays consistent. Common pitfall: planning on average transfer while peak bursts dominate.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-025",
      "type": "multiple-choice",
      "question": "Teammate's estimate: '1 billion rows × 100 bytes = 100 GB, easily fits in RAM.' What's missing?",
      "options": [
        "Nothing missing, estimate is complete",
        "Index overhead (often 2-3x data size)",
        "Missing replication factor",
        "Should use compression ratio"
      ],
      "correct": 1,
      "explanation": "Database indexes often add 1-3x the raw data size. B-tree indexes, secondary indexes, and internal metadata mean 100 GB of data might need 200-400 GB total. Always account for index overhead.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Discard modeling choices that look clean but perform poorly for the target queries. Schema and index choices should follow access patterns and write/read amplification constraints. If values like 1 and 100 appear, convert them into one unit basis before comparison. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-026",
      "type": "multiple-choice",
      "question": "SLA promises 99.99% availability. System has 10 components in series, each 99.99% available. Actual availability?",
      "options": [
        "99.99% (matches SLA)",
        "99.9% (10x worse)",
        "99% (100x worse)",
        "~99.9% (close but misses SLA)"
      ],
      "correct": 3,
      "explanation": "Serial availability: 0.9999^10 = 0.999 = 99.9%. Each additional component in the critical path reduces overall availability. To achieve 99.99% overall, individual components need higher availability.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Reject approaches that sound good in general but do not reduce concrete reliability risk. Tie decisions to concrete operational outcomes, not abstract reliability language. If values like 99.99 and 10 appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-027",
      "type": "multiple-choice",
      "question": "Estimate: 'Video transcoding takes 1 hour for 1 hour of video on 1 server. For 1M hours/day, we need 1M servers.' Flaw?",
      "options": [
        "No flaw, math is correct",
        "Flaw: can parallelize transcoding of single video",
        "Flaw: 1M servers is cost-prohibitive, need queueing",
        "Flaw: should use 1 hour = 1 server-hour, so 1M server-hours/day ÷ 24 = 42K servers"
      ],
      "correct": 3,
      "explanation": "1M hours of video needs 1M server-hours of work. Spread over 24 hours: 1M ÷ 24 = 41,667 servers running continuously. The original estimate doesn't account for time distribution.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 1 hour and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-028",
      "type": "multiple-choice",
      "question": "Design shows read/write ratio of 1:1 for a social media feed. Suspicious?",
      "options": [
        "Normal for social apps",
        "Suspicious - reads typically 100-1000x writes",
        "Suspicious - writes typically 10x reads",
        "Depends on the feature"
      ],
      "correct": 1,
      "explanation": "Social feeds are read-heavy: users scroll through many posts but create few. Typical ratio is 100:1 to 1000:1 reads:writes. 1:1 suggests misunderstanding the access pattern or wrong metrics.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 1 and 100 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-029",
      "type": "multiple-choice",
      "question": "Capacity plan: 'We need 1 TB of bandwidth per second for 1 billion video views per day.' Check?",
      "options": [
        "Reasonable for short-form video",
        "Too high by ~100x",
        "Too low by ~10x",
        "Need more info about video quality"
      ],
      "correct": 3,
      "explanation": "1B views/day = 11,574 views/sec. If each view streams 10 MB (short video), that's 115 GB/s, not 1 TB/s. For 2-hour 4K movies at 20 GB each, concurrent streams matter more than daily views. Need video duration/quality.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 1 TB and 1 in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-030",
      "type": "multiple-choice",
      "question": "Startup claims their ML model achieves 99.9% accuracy on fraud detection. Red flag?",
      "options": [
        "Impressive but achievable",
        "Red flag - likely overfit or wrong metric",
        "Normal for mature ML systems",
        "Depends on the dataset"
      ],
      "correct": 1,
      "explanation": "99.9% accuracy on imbalanced data (fraud is rare) is often meaningless - predicting 'not fraud' always achieves >99% accuracy. Need precision/recall/F1. Also suggests possible overfitting on test data.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Eliminate choices that are numerically tidy but operationally implausible. A harsh sanity check should identify which assumption is most likely wrong. Numbers such as 99.9 and 99 should be normalized first so downstream reasoning stays consistent. Common pitfall: propagating an early bad assumption through all steps.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-031",
      "type": "multiple-choice",
      "question": "Estimate: 'Compression will reduce our 100 TB to 10 TB (10x ratio).' Reasonable for JSON logs?",
      "options": [
        "Reasonable, JSON compresses well",
        "Too optimistic - expect 3-5x for JSON",
        "Too pessimistic - JSON compresses 20x+",
        "Depends on compression algorithm"
      ],
      "correct": 0,
      "explanation": "JSON logs compress very well due to repetitive keys and structure. 10x compression (90% reduction) is achievable with gzip/zstd for typical log data. Some achieve even higher ratios.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Discard options that depend on unrealistic assumptions hidden in the estimate. Cross-check with anchor numbers to test plausibility before finalizing. Keep quantities like 100 TB and 10 TB in aligned units before deciding on an implementation approach. Common pitfall: skipping anchor checks against known scale.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-032",
      "type": "multiple-choice",
      "question": "Design assumes all 1M users are online simultaneously for capacity planning. Issue?",
      "options": [
        "Correct for worst-case planning",
        "Over-provisioned - typical concurrency is 1-10% of total users",
        "Under-provisioned - should plan for 2M",
        "Depends on application type"
      ],
      "correct": 1,
      "explanation": "Simultaneous online users are typically 1-10% of total users, depending on app type. 1M total users might mean 10K-100K concurrent. Planning for 100% concurrency wastes resources.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 1M and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-033",
      "type": "multiple-choice",
      "question": "Latency budget: 'Database: 50ms, API processing: 50ms, Network: 0ms, Total: 100ms.' Missing component?",
      "options": [
        "Serialization/deserialization overhead",
        "All components accounted for",
        "Should include retry latency",
        "Missing database connection time"
      ],
      "correct": 0,
      "explanation": "Serialization (JSON/protobuf encoding/decoding) often adds 1-10ms. Network is never 0ms (even localhost has overhead). Queue wait times, GC pauses, and connection overhead are also often missed.",
      "detailedExplanation": "Generalize from latency budget: 'Database: 50ms, API processing: 50ms, Network: 0ms, Total: 100ms to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Discard options that weaken contract clarity or compatibility over time. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Keep quantities like 50ms and 0ms in aligned units before deciding on an implementation approach. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-034",
      "type": "multiple-choice",
      "question": "Security estimate: 'Bcrypt password hashing at 100ms/hash, 1000 logins/second needs 100 seconds of CPU.' Implication?",
      "options": [
        "Need 100+ dedicated CPU cores for auth",
        "Can handle with 10 cores",
        "Should switch to faster hashing",
        "Async processing solves this"
      ],
      "correct": 0,
      "explanation": "1000 logins/sec × 100ms/hash = 100 CPU-seconds of work per real second. You need 100+ cores just for password hashing. This is a real constraint that affects architecture (dedicated auth servers, rate limiting).",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 100ms and 1000 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-035",
      "type": "multiple-choice",
      "question": "Team says 'We'll just cache everything in Redis' for their 50 TB dataset. Problem?",
      "options": [
        "No problem with Redis Cluster",
        "Problem: cost-prohibitive, RAM is 10-30x more expensive than SSD",
        "No problem with proper eviction policy",
        "Problem only if data changes frequently"
      ],
      "correct": 1,
      "explanation": "50 TB in RAM costs $500K-$1.5M in hardware vs $5-15K for SSD. Also requires massive cluster management. Cache the hot subset (typically 10-20% of data handles 80%+ of requests).",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Keep quantities like 50 TB and 500K in aligned units before deciding on an implementation approach. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-036",
      "type": "multiple-choice",
      "question": "Estimate: 'Our API gateway adds 0.1ms latency.' After adding auth, rate limiting, logging, and metrics. Realistic?",
      "options": [
        "Realistic for optimized gateways",
        "Unrealistic - each feature adds latency, expect 5-20ms",
        "Realistic with async logging",
        "Depends on implementation"
      ],
      "correct": 1,
      "explanation": "Auth (JWT validation, token lookup), rate limiting (Redis call), logging, and metrics each add latency. A full-featured API gateway typically adds 5-20ms. 0.1ms is only achievable with minimal processing.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer the approach that keeps client behavior explicit while preserving evolvability. Interface decisions should be justified by contract stability and client impact over time. Keep quantities like 0.1ms and 5 in aligned units before deciding on an implementation approach. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-037",
      "type": "multiple-choice",
      "question": "Design: 'We'll use eventual consistency and guarantee updates propagate in under 100ms globally.' Conflict?",
      "options": [
        "No conflict, modern systems achieve this",
        "Conflict: global propagation takes 100-300ms minimum (speed of light)",
        "No conflict with edge caching",
        "Conflict only for writes"
      ],
      "correct": 1,
      "explanation": "Speed of light limits global RTT to 100-300ms minimum. 'Eventual' consistency that's guaranteed under 100ms globally is physically impossible. Either relax the time guarantee or use synchronous replication.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer the approach that preserves correctness guarantees for the stated consistency boundary. Strong answers connect quorum/coordination settings to concrete correctness goals. Keep quantities like 100ms and 100 in aligned units before deciding on an implementation approach. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-038",
      "type": "multiple-choice",
      "question": "Cost estimate: '100 engineers × $200K salary = $20M/year in engineering costs.' What's missing?",
      "options": [
        "Nothing, salary is total cost",
        "Benefits, equipment, office space add 30-50%",
        "Should include management overhead",
        "Should subtract equity compensation"
      ],
      "correct": 1,
      "explanation": "Total employee cost includes benefits (health, 401k), payroll taxes, equipment, office space, software licenses, and overhead. Rule of thumb: multiply salary by 1.3-1.5 for true cost.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 100 and 200K in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-039",
      "type": "multiple-choice",
      "question": "Architect proposes synchronous writes to 5 datacenters for strong consistency. Latency concern?",
      "options": [
        "No concern with fast networks",
        "Major concern: must wait for slowest DC, likely 100-300ms",
        "Minor concern, can use quorum writes",
        "No concern if DCs are in same region"
      ],
      "correct": 1,
      "explanation": "Synchronous writes wait for ALL replicas. With 5 global DCs, you wait for the slowest (likely 100-300ms RTT away). This makes sub-100ms writes impossible. Use quorum writes or async replication.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Reject approaches that ignore delivery semantics or backpressure behavior. Throughput is only one part; replay behavior and consumer lag handling matter equally. Keep quantities like 5 and 100 in aligned units before deciding on an implementation approach. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-040",
      "type": "multiple-choice",
      "question": "Load test shows 1ms average latency at 1K QPS. Team extrapolates to 1ms at 100K QPS. Valid?",
      "options": [
        "Valid if system is stateless",
        "Invalid - latency increases with load due to queueing",
        "Valid with horizontal scaling",
        "Invalid only if approaching capacity"
      ],
      "correct": 1,
      "explanation": "Latency increases with load due to queueing theory (Little's Law). As utilization rises, queue wait times increase non-linearly. Must load test at target QPS, not extrapolate from low load.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Reject approaches that ignore delivery semantics or backpressure behavior. Throughput is only one part; replay behavior and consumer lag handling matter equally. Numbers such as 1ms and 1K should be normalized first so downstream reasoning stays consistent. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-041",
      "type": "multiple-choice",
      "question": "Estimate: 'UUID is 32 characters = 32 bytes.' Correct?",
      "options": [
        "Correct",
        "Wrong - UUID is 36 characters with hyphens, but 16 bytes binary",
        "Wrong - UUID is 128 bytes",
        "Depends on encoding"
      ],
      "correct": 1,
      "explanation": "UUID string is 36 characters (32 hex + 4 hyphens) = 36 bytes as string. But a UUID is fundamentally 128 bits = 16 bytes in binary. Store as binary (16 bytes) not string (36 bytes) when possible.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 32 and 36 in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-042",
      "type": "multiple-choice",
      "question": "Team plans to retry failed requests 10 times with no backoff. During an outage, what happens?",
      "options": [
        "System recovers faster",
        "Retry storm amplifies load 10x, delays recovery",
        "Normal behavior for resilient systems",
        "Only problematic at scale"
      ],
      "correct": 1,
      "explanation": "10 retries without backoff means each failed request generates 10x the load. During outages, this creates a 'retry storm' that overwhelms the recovering system. Always use exponential backoff with jitter.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer approaches that directly address failure mode, recovery path, and blast radius. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Keep quantities like 10 and 10x in aligned units before deciding on an implementation approach. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-043",
      "type": "multiple-choice",
      "question": "Design assumes 'stateless' services can be scaled infinitely. What's the hidden bottleneck?",
      "options": [
        "No bottleneck if truly stateless",
        "Database becomes the bottleneck",
        "Network bandwidth limits",
        "CPU always limits eventually"
      ],
      "correct": 1,
      "explanation": "Stateless services still depend on stateful backends (databases, caches). Scaling 100 stateless servers that all hit one database just moves the bottleneck. Must scale data tier too.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 100 should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-044",
      "type": "multiple-choice",
      "question": "Estimate: 'S3 GET request cost is $0.0004. At 1B requests/month = $400K/month.' Is there a cheaper option?",
      "options": [
        "No, S3 is already cheapest",
        "Yes, CloudFront reduces GET costs with caching",
        "No, all object stores have similar pricing",
        "Yes, switch to blob storage"
      ],
      "correct": 1,
      "explanation": "CDN caching (CloudFront, etc.) serves repeated requests from edge at lower cost (~$0.01/GB vs per-request). For cacheable content with repeated access, CDN dramatically reduces costs.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Reject approaches that ignore sustained peak transfer constraints. Convert bits/bytes carefully and include sustained peak assumptions in transfer planning. If values like 0.0004 and 1B appear, convert them into one unit basis before comparison. Common pitfall: bits-vs-bytes conversion mistakes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-045",
      "type": "multiple-choice",
      "question": "Proposal: 'Our ML pipeline processes data in real-time with 50ms latency.' Pipeline has 20 sequential steps. Feasible?",
      "options": [
        "Feasible with optimization",
        "Infeasible - 50ms ÷ 20 steps = 2.5ms/step is very tight",
        "Feasible with parallel processing",
        "Depends on step complexity"
      ],
      "correct": 1,
      "explanation": "20 sequential steps in 50ms means 2.5ms average per step. Even without any I/O, this is very tight. Any single slow step breaks the budget. Consider parallelizing or reducing steps.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject approaches that fail under peak load or saturation conditions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 50ms and 20 should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-046",
      "type": "multiple-choice",
      "question": "Design claims 'zero downtime deployments' with a single database server. Gap?",
      "options": [
        "No gap with blue-green deployment",
        "Gap: database migrations can require downtime",
        "No gap with rolling deployments",
        "Gap only for schema changes"
      ],
      "correct": 1,
      "explanation": "Zero downtime requires handling database schema changes without locking. Single DB is a bottleneck: ALTER TABLE can lock tables, breaking zero-downtime claims. Need online schema migration tools.",
      "detailedExplanation": "Generalize from design claims 'zero downtime deployments' with a single database server to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prioritize the approach that best protects reliability objectives under stated failure conditions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-047",
      "type": "multiple-choice",
      "question": "Cost model: 'Serverless at $0.20/million invocations beats servers at $100/month.' At what volume does this flip?",
      "options": [
        "Never flips, serverless always cheaper",
        "~500M invocations/month",
        "~50M invocations/month",
        "~5M invocations/month"
      ],
      "correct": 1,
      "explanation": "$100/month ÷ $0.20/million = 500M invocations breakeven. Below 500M/month, serverless is cheaper. Above, dedicated servers win. But also consider compute time costs, not just invocations.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 0.20 and 100 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-048",
      "type": "multiple-choice",
      "question": "Teammate estimates 'JSON parsing is essentially free.' Their service parses 100K JSON docs/second, each 10 KB. Concern?",
      "options": [
        "No concern, JSON parsing is fast",
        "Concern: 1 GB/sec of parsing has real CPU cost",
        "No concern with modern hardware",
        "Concern only for nested JSON"
      ],
      "correct": 1,
      "explanation": "100K × 10 KB = 1 GB/second of JSON parsing. Fast parsers achieve 1-2 GB/sec per core. This could consume an entire CPU core just for parsing. Not free at scale.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 100K and 10 KB in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-049",
      "type": "multiple-choice",
      "question": "Plan: 'We'll handle 100K WebSocket connections per server.' Realistic for commodity hardware?",
      "options": [
        "Realistic with epoll/kqueue",
        "Unrealistic - typical limit is 10K per server",
        "Realistic only with specialized hardware",
        "Unrealistic - memory alone is prohibitive"
      ],
      "correct": 0,
      "explanation": "With proper async I/O (epoll/kqueue), 100K-1M connections per server is achievable. Each connection uses ~10-20 KB RAM (socket buffers). 100K × 20 KB = 2 GB RAM - manageable.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Reject approaches that ignore delivery semantics or backpressure behavior. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Keep quantities like 100K and 1M in aligned units before deciding on an implementation approach. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-050",
      "type": "multiple-choice",
      "question": "Estimate assumes 'database read replicas have zero replication lag.' When does this break down?",
      "options": [
        "Only under extreme write load",
        "Always - async replication inherently has lag (typically ms-seconds)",
        "Never with synchronous replication",
        "Only during network partitions"
      ],
      "correct": 1,
      "explanation": "Async replication always has some lag (often ms, sometimes seconds during load). Read-after-write consistency requires reading from primary or accepting stale reads. 'Zero lag' is misleading.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-051",
      "type": "multiple-choice",
      "question": "Capacity plan for image CDN: '1 PB storage, 10 Gbps bandwidth.' If average image is 100 KB, what's daily serve capacity?",
      "options": [
        "~1 billion images/day",
        "~10 billion images/day",
        "~100 million images/day",
        "Need concurrent connection info"
      ],
      "correct": 0,
      "explanation": "10 Gbps = 1.25 GB/s. At 100 KB/image: 1,250 MB/s ÷ 0.1 MB = 12,500 images/second = 1.08B images/day. Storage of 1 PB holds 10B images. Bandwidth is likely the constraint.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Discard storage decisions that optimize one dimension while violating another core requirement. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 1 and 10 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-052",
      "type": "multiple-choice",
      "question": "Design doc claims 'our service is horizontally scalable - just add more servers.' What needs verification?",
      "options": [
        "Nothing, horizontal scaling is automatic",
        "Whether shared state exists (database, cache)",
        "Only network topology",
        "Only load balancer capacity"
      ],
      "correct": 1,
      "explanation": "True horizontal scaling requires no shared mutable state between servers. Verify: Is there a shared database? Shared cache? Session affinity? Distributed locks? Any of these can bottleneck scaling.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-053",
      "type": "multiple-choice",
      "question": "Estimate: 'gRPC will be faster than REST because binary protocol.' Always true?",
      "options": [
        "Yes, binary is always faster than text",
        "Not always - small payloads show minimal difference",
        "Yes, but only for streaming",
        "Not always - REST over HTTP/2 closes the gap"
      ],
      "correct": 1,
      "explanation": "For small payloads, protobuf vs JSON difference is minimal. HTTP/2 provides multiplexing for both. gRPC shines for: streaming, large payloads, strict schemas. Small request/response? Difference is often negligible.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. If values like 2 appear, convert them into one unit basis before comparison. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-054",
      "type": "multiple-choice",
      "question": "Team plans 30-day data retention. Deletes run weekly. What's the actual retention?",
      "options": [
        "30 days as planned",
        "30-37 days depending on timing",
        "23-30 days depending on timing",
        "Exactly 28 days (4 weeks)"
      ],
      "correct": 1,
      "explanation": "Weekly deletion of 30-day old data means data survives 30-37 days. Data created right after a deletion run survives until next week's run: 30 days + up to 7 days = 37 days max.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer the approach that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 30 and 37 days should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-055",
      "type": "multiple-choice",
      "question": "Load balancer health check: ping every 10 seconds, mark unhealthy after 3 failures. How long until unhealthy server is removed?",
      "options": ["~10 seconds", "~30 seconds", "~60 seconds", "~90 seconds"],
      "correct": 1,
      "explanation": "3 failures × 10 seconds between checks = 30 seconds minimum to detect failure. Add time for actual removal and propagation. Meanwhile, traffic continues to failing server. Consider faster checks.",
      "detailedExplanation": "Generalize from load balancer health check: ping every 10 seconds, mark unhealthy after 3 failures to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 10 seconds and 3 in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-056",
      "type": "multiple-choice",
      "question": "Estimate: 'Our caching layer has 99% hit rate, so origin handles 1% of traffic.' At 10M QPS total, origin load is:",
      "options": ["100 QPS", "1,000 QPS", "10,000 QPS", "100,000 QPS"],
      "correct": 3,
      "explanation": "1% of 10M = 100,000 QPS to origin. Even with 99% cache hit rate, 100K QPS is substantial load. High cache hit rates at scale still mean significant origin traffic.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Discard cache tactics that hide consistency bugs under high load. Cache design quality is mostly about correctness boundaries, not only hit rate. Keep quantities like 99 and 1 in aligned units before deciding on an implementation approach. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-057",
      "type": "multiple-choice",
      "question": "Proposal: 'We'll use microservices for our 3-person team.' Concern?",
      "options": [
        "Good architecture for any team size",
        "Overhead may exceed benefits for small teams",
        "Only concerning without DevOps expertise",
        "No concern with managed Kubernetes"
      ],
      "correct": 1,
      "explanation": "Microservices add deployment, monitoring, and debugging complexity. A 3-person team may spend more time on infrastructure than features. Monolith is often better until team/scale justify the split.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 3 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-058",
      "type": "multiple-choice",
      "question": "Design assumes 'network is reliable' for distributed transactions. What's the actual packet loss rate in datacenters?",
      "options": [
        "Effectively 0% in modern datacenters",
        "0.01-0.1% is typical",
        "1-5% is typical",
        "Varies too much to estimate"
      ],
      "correct": 1,
      "explanation": "Even in well-run datacenters, packet loss is 0.01-0.1%. At 10K QPS, that's 1-10 failures/second. Design must handle network failures, timeouts, and retries. 'Reliable network' is a distributed systems fallacy.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 0.01 and 0.1 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-059",
      "type": "multiple-choice",
      "question": "Monitoring plan: 'We'll sample 1% of requests for distributed tracing.' At 100K QPS, traces per second?",
      "options": [
        "10 traces/second",
        "100 traces/second",
        "1,000 traces/second",
        "10,000 traces/second"
      ],
      "correct": 2,
      "explanation": "1% of 100K = 1,000 traces/second. Each trace has multiple spans. At 10 spans/trace, that's 10K spans/second to store and query. Ensure tracing backend can handle this volume.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 1 and 100K in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-060",
      "type": "multiple-choice",
      "question": "Cost estimate: 'Free tier covers our needs.' Product has 100K users sending 100 requests/day each. Red flag for which service?",
      "options": [
        "Compute (likely within free tier)",
        "Database queries (likely within free tier)",
        "Email notifications (likely exceeds free tier)",
        "All likely within free tier"
      ],
      "correct": 2,
      "explanation": "Email services typically have 100-1000 emails/day free tier. 100K users × even 1 email/day = 100K emails. Most free tiers cap at 100-1000/day. Email, SMS, and push notifications often exceed free tiers.",
      "detailedExplanation": "Generalize from cost estimate: 'Free tier covers our needs to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer the approach that preserves correctness guarantees for the stated consistency boundary. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. If values like 100K and 100 appear, convert them into one unit basis before comparison. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-061",
      "type": "multiple-choice",
      "question": "Teammate says 'Kubernetes will handle our scaling automatically.' What does Kubernetes NOT handle?",
      "options": [
        "Pod autoscaling",
        "Load balancing",
        "Database scaling",
        "Container health checks"
      ],
      "correct": 2,
      "explanation": "Kubernetes autoscales stateless pods well. But databases, caches, and stateful services require manual capacity planning. You can't just 'add pods' to PostgreSQL. Stateful scaling remains hard.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-062",
      "type": "multiple-choice",
      "question": "Estimate: 'Base64 encoding adds 33% overhead.' When storing 1 GB of binary data as Base64, total size?",
      "options": [
        "~1 GB (negligible overhead)",
        "~1.33 GB",
        "~2 GB",
        "Depends on content"
      ],
      "correct": 1,
      "explanation": "Base64 encodes 3 bytes as 4 characters = 33% overhead. 1 GB binary becomes ~1.33 GB Base64. For large binary data, this overhead matters. Consider binary storage or compression.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Reject approaches that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 33 and 1 GB in aligned units before deciding on an implementation approach. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-063",
      "type": "multiple-choice",
      "question": "Design claims 'consistent hashing solves all data distribution problems.' Limitation?",
      "options": [
        "Only works for key-value data",
        "Hotspots when keys are skewed",
        "Requires prime number of nodes",
        "Only works for reads"
      ],
      "correct": 1,
      "explanation": "Consistent hashing distributes uniformly across nodes IF keys are uniformly distributed. Hot keys (celebrity users, viral content) still cause hotspots regardless of hashing. Need additional strategies.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-064",
      "type": "multiple-choice",
      "question": "Proposal: 'We'll achieve sub-millisecond latency by moving to GraphQL.' Likely outcome?",
      "options": [
        "Significant latency reduction",
        "Latency unchanged or worse - GraphQL adds parsing overhead",
        "Slight improvement from reduced payload",
        "Depends on query complexity"
      ],
      "correct": 1,
      "explanation": "GraphQL adds query parsing, validation, and resolution overhead. It reduces over-fetching but doesn't inherently reduce latency. For latency, database/network dominate. GraphQL is about flexibility, not speed.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer the approach that keeps client behavior explicit while preserving evolvability. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-065",
      "type": "multiple-choice",
      "question": "Estimate: 'Feature flags are free - just IF statements.' At 10K QPS with 100 flags evaluated per request, what's the load?",
      "options": [
        "Negligible - just CPU cycles",
        "1M flag evaluations/second - noticeable if flags hit database",
        "Only matters for A/B test flags",
        "Depends on flag complexity"
      ],
      "correct": 1,
      "explanation": "10K × 100 = 1M flag evaluations/second. If flags are in-memory, fast. If they hit a remote service for each evaluation, you've added 1M external calls/second. Ensure flags are cached locally.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 10K and 100 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-066",
      "type": "multiple-choice",
      "question": "Backup strategy: 'Daily backups with 7-day retention.' If corruption is discovered 10 days after it started, recovery options?",
      "options": [
        "Restore from any backup within 7 days",
        "No clean backup available - corruption propagated to all backups",
        "Point-in-time recovery solves this",
        "Incremental backup helps"
      ],
      "correct": 1,
      "explanation": "If corruption started 10 days ago and backups retain 7 days, ALL backups contain corrupted data. Need longer retention or different backup verification strategy to catch silent corruption.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Reject approaches that sound good in general but do not reduce concrete reliability risk. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Keep quantities like 7 and 10 days in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-067",
      "type": "multiple-choice",
      "question": "Design: 'Users can upload files up to 100 GB.' Via standard HTTP upload. Problem?",
      "options": [
        "No problem with chunked encoding",
        "Problem: HTTP timeouts, connection resets over long uploads",
        "No problem with keep-alive",
        "Problem only on mobile networks"
      ],
      "correct": 1,
      "explanation": "100 GB upload at 10 MB/s = 2.7 hours. Network interruptions, proxy timeouts, and connection limits make single HTTP uploads unreliable for large files. Need resumable/chunked upload protocol.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Good API choices balance client ergonomics, compatibility, and long-term evolvability. If values like 100 GB and 10 MB appear, convert them into one unit basis before comparison. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-068",
      "type": "multiple-choice",
      "question": "Estimate: 'Adding an index will speed up all queries on that column.' Counter-example?",
      "options": [
        "No counter-example, indexes always help reads",
        "Write-heavy workloads slow down (index maintenance)",
        "Only fails for very small tables",
        "Only fails for composite indexes"
      ],
      "correct": 1,
      "explanation": "Indexes speed reads but slow writes. Each INSERT/UPDATE must update all indexes. For write-heavy tables, index overhead can outweigh read benefits. Also, full table scans beat indexes for low selectivity.",
      "detailedExplanation": "Generalize from estimate: 'Adding an index will speed up all queries on that column to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Discard modeling choices that look clean but perform poorly for the target queries. Choose data shape based on workload paths, not on normalization dogma alone. Common pitfall: indexing that over-amplifies writes.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-069",
      "type": "multiple-choice",
      "question": "Monitoring: 'CPU <50% means we have plenty of headroom.' During incident, CPU is 40% but latency spiked. What else to check?",
      "options": [
        "Network bandwidth",
        "Memory/swap usage",
        "Disk I/O wait",
        "All of the above"
      ],
      "correct": 3,
      "explanation": "Low CPU doesn't mean no bottleneck. Services can be I/O bound (waiting on disk, network, external services) or memory bound (swapping). Check: disk I/O, network I/O, memory, and external dependencies.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer approaches that directly address failure mode, recovery path, and blast radius. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Numbers such as 50 and 40 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-070",
      "type": "multiple-choice",
      "question": "Team estimates 'We need 2x capacity for peak.' Peak is Black Friday at 20x normal. Issue?",
      "options": [
        "2x is sufficient with autoscaling",
        "2x is 10x short of 20x peak capacity needed",
        "2x is reasonable with queuing",
        "Depends on acceptable degradation"
      ],
      "correct": 1,
      "explanation": "If peak is 20x normal, you need infrastructure that can handle 20x, not 2x. Autoscaling helps but has limits and spin-up time. Either over-provision or explicitly plan for graceful degradation at peak.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Reject approaches that sound good in general but do not reduce concrete reliability risk. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 2x and 20x in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-071",
      "type": "multiple-choice",
      "question": "Assumption: 'Timestamps are unique identifiers.' When does this fail?",
      "options": [
        "Never, with nanosecond precision",
        "Multiple events in same millisecond",
        "Only with distributed systems",
        "Only without synchronized clocks"
      ],
      "correct": 1,
      "explanation": "At high throughput, multiple events occur in the same millisecond (or even nanosecond with concurrent threads). Timestamps need additional disambiguation: sequence numbers, random components, or UUIDs.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Reject approaches that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-072",
      "type": "multiple-choice",
      "question": "Estimate: 'With 1000 database connections, we can handle 1000 concurrent queries.' Actual effective parallelism?",
      "options": [
        "1000 parallel queries",
        "Limited by CPU cores (typically 8-64)",
        "500 due to overhead",
        "Depends on query type"
      ],
      "correct": 1,
      "explanation": "Database can only execute as many queries in parallel as it has CPU cores. 1000 connections mostly means 1000 queries can wait simultaneously, not execute simultaneously. IO-bound queries may achieve more concurrency.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 1000 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-073",
      "type": "multiple-choice",
      "question": "Cost projection: 'Traffic grows 10%/month, costs grow 10%/month.' Hidden assumption?",
      "options": [
        "Correct proportional scaling",
        "Assumes no efficiency improvements",
        "Assumes no volume discounts",
        "Assumes no tier pricing (costs often sublinear with scale)"
      ],
      "correct": 3,
      "explanation": "Cloud pricing often has tiers: cost/unit decreases at higher volumes. Also, fixed costs (baseline infrastructure) don't scale with traffic. Actual cost growth is often sublinear with traffic growth.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Reject approaches that rely on linear intuition for compounding workloads. Compounding effects should drive planning windows, not linear intuition. If values like 10 appear, convert them into one unit basis before comparison. Common pitfall: treating compounding as linear change.",
      "references": [
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        },
        {
          "title": "Rule of 72",
          "url": "https://www.investopedia.com/terms/r/ruleof72.asp"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-074",
      "type": "multiple-choice",
      "question": "Design: 'Saga pattern for distributed transactions with 10 services.' Failure at step 7 requires:",
      "options": [
        "Rollback steps 1-7",
        "Compensating transactions for steps 1-6",
        "Only retry step 7",
        "No action needed with eventual consistency"
      ],
      "correct": 1,
      "explanation": "Sagas use compensating transactions, not rollback. Steps 1-6 completed and committed. Step 7 failure requires running compensation for 6, 5, 4, 3, 2, 1 in reverse. Complex to implement correctly.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 10 and 7 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-075",
      "type": "multiple-choice",
      "question": "Estimate: 'Encrypting at rest is free with modern CPUs (AES-NI).' Storage performance impact?",
      "options": [
        "Near zero (<1%)",
        "~5-10% overhead",
        "~25-50% overhead",
        "Depends on block size"
      ],
      "correct": 0,
      "explanation": "AES-NI achieves ~5-10 GB/s encryption, faster than most storage. Encryption at rest with modern CPUs adds <1% overhead for storage-bound workloads. But key management adds operational complexity.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Numbers such as 5 and 10 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-076",
      "type": "multiple-choice",
      "question": "QA asks: 'Why does staging not match production?' Staging has 10% of production data. Missing concern?",
      "options": [
        "Missing data variety",
        "Database query plans differ with different data sizes",
        "Missing edge cases",
        "All of the above"
      ],
      "correct": 3,
      "explanation": "10% data affects: query plans (optimizer chooses differently), caching behavior, pagination edge cases, and missing data variety/edge cases. Performance tests on small data don't reflect production.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Discard options that weaken contract clarity or compatibility over time. Good API choices balance client ergonomics, compatibility, and long-term evolvability. If values like 10 appear, convert them into one unit basis before comparison. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-077",
      "type": "multiple-choice",
      "question": "Team plans to store 'unlimited message history.' At 1M users × 100 messages/day × 1 KB each, daily growth?",
      "options": ["~100 MB", "~1 GB", "~100 GB", "~1 TB"],
      "correct": 2,
      "explanation": "1M × 100 × 1 KB = 100M KB = 100 GB/day = 36 TB/year. 'Unlimited' history at this rate becomes expensive fast. Consider archival tiers, compression, or retention limits.",
      "detailedExplanation": "Generalize from team plans to store 'unlimited message history to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Reject approaches that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 1M and 100 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-078",
      "type": "multiple-choice",
      "question": "Design: 'We'll use UUIDs as primary keys for global uniqueness.' Performance consideration?",
      "options": [
        "No concerns with UUIDs",
        "Random UUIDs cause index fragmentation and slower inserts",
        "UUIDs are slower to compare",
        "UUID storage size is the only concern"
      ],
      "correct": 1,
      "explanation": "Random UUIDs (v4) scatter inserts across index pages, causing fragmentation and slower writes. Solutions: UUID v7 (time-sorted), ULID, or sequential IDs with sharding for global uniqueness.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer the schema/index decision that minimizes query and write amplification for this workload. Schema and index choices should follow access patterns and write/read amplification constraints. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-079",
      "type": "multiple-choice",
      "question": "Estimate: 'Moving to ARM instances saves 40% on compute costs.' When might savings not materialize?",
      "options": [
        "Always saves money if workload runs on ARM",
        "When dependencies don't support ARM",
        "When compute isn't the primary cost",
        "Both B and C"
      ],
      "correct": 3,
      "explanation": "ARM savings require: 1) all dependencies have ARM builds, 2) compute is a significant cost (if database or bandwidth dominates, 40% compute savings is minor). Rebuild/testing effort also has costs.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer the answer that correctly handles unit conversion and link-capacity limits. Treat network capacity as a steady-state constraint, then test against peak windows. If values like 40 and 1 appear, convert them into one unit basis before comparison. Common pitfall: bits-vs-bytes conversion mistakes.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-080",
      "type": "multiple-choice",
      "question": "Load test: 'System handles 10K QPS with 50ms p50 latency.' What additional metric is critical for capacity?",
      "options": [
        "p99 latency",
        "Error rate",
        "CPU utilization",
        "All of the above"
      ],
      "correct": 3,
      "explanation": "p50 hides tail latency (p99 might be 5 seconds). Error rate shows if 10K QPS is actually successful. CPU utilization shows headroom. All three are needed to assess true capacity.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prioritize the approach that best protects reliability objectives under stated failure conditions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Numbers such as 10K and 50ms should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-081",
      "type": "multiple-choice",
      "question": "Plan: 'Shard by user_id for even distribution.' User with 1M followers posts. Impact?",
      "options": [
        "Even distribution handles this fine",
        "Fan-out to 1M follower shards creates hotspot",
        "No impact with good sharding",
        "Impacts only write performance"
      ],
      "correct": 1,
      "explanation": "User-ID sharding distributes users evenly, but a celebrity post fans out to millions of followers across many shards. This creates read/write amplification and hotspots in the fan-out path.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 1M in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-082",
      "type": "multiple-choice",
      "question": "Estimate: 'Connection pool of 100 handles all load.' Each request holds connection for 50ms. Max sustainable QPS?",
      "options": ["100 QPS", "1,000 QPS", "2,000 QPS", "10,000 QPS"],
      "correct": 2,
      "explanation": "Each connection handles 1000ms/50ms = 20 requests/second. 100 connections × 20 req/sec = 2,000 QPS maximum. Beyond this, requests wait for connections, increasing latency.",
      "detailedExplanation": "Generalize from estimate: 'Connection pool of 100 handles all load to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 100 and 50ms in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-083",
      "type": "multiple-choice",
      "question": "Design assumes 'DynamoDB handles any scale.' What requires additional planning?",
      "options": [
        "Nothing, DynamoDB auto-scales",
        "Hot partitions still cause throttling",
        "Only write capacity needs planning",
        "Only read capacity needs planning"
      ],
      "correct": 1,
      "explanation": "DynamoDB auto-scales total capacity but has per-partition limits (~3K RCU, 1K WCU). Hot keys hitting one partition get throttled regardless of total capacity. Partition key design is critical.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Reject designs that improve throughput while weakening reliability guarantees. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Numbers such as 3K and 1K should be normalized first so downstream reasoning stays consistent. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-084",
      "type": "multiple-choice",
      "question": "Test environment has 100% automated test coverage. 'No bugs will reach production.' Issue with this claim?",
      "options": [
        "No issue with 100% coverage",
        "Coverage measures lines, not logic paths or edge cases",
        "Only integration tests matter",
        "Manual testing is still needed"
      ],
      "correct": 1,
      "explanation": "100% line coverage doesn't mean 100% tested scenarios. Edge cases, timing issues, integration problems, and unexpected inputs aren't caught by coverage metrics. Coverage is necessary but not sufficient.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 100 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-085",
      "type": "multiple-choice",
      "question": "Estimate: 'JWT tokens are stateless, so auth scales infinitely.' Hidden state?",
      "options": [
        "No hidden state with JWTs",
        "Token revocation requires state (blocklist)",
        "Only refresh tokens have state",
        "State is in the token itself"
      ],
      "correct": 1,
      "explanation": "JWTs are stateless for validation, but revocation requires checking a blocklist. Logout, password change, or security incidents need immediate invalidation, requiring shared state (Redis blocklist, etc.).",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Discard cache tactics that hide consistency bugs under high load. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-086",
      "type": "multiple-choice",
      "question": "Design: 'Multi-tenant with shared database, isolated by tenant_id column.' Security concern?",
      "options": [
        "No concern with proper access control",
        "One missing WHERE clause exposes all tenants",
        "Only performance is concerning",
        "Only backup/restore is affected"
      ],
      "correct": 1,
      "explanation": "Shared-database multi-tenancy relies on every query having correct tenant_id filter. One bug (missing WHERE, wrong join) can expose or corrupt other tenants' data. Defense in depth recommended.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Reject approaches that conflict with the primary access pattern or index strategy. Choose data shape based on workload paths, not on normalization dogma alone. Common pitfall: indexing that over-amplifies writes.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-087",
      "type": "multiple-choice",
      "question": "Teammate: 'We don't need rate limiting, we trust our clients.' Service is internal API. Gap?",
      "options": [
        "No gap for internal services",
        "Bugs/loops in clients can create self-inflicted DDoS",
        "Rate limiting only needed externally",
        "Trust but verify is overkill internally"
      ],
      "correct": 1,
      "explanation": "Internal clients have bugs: infinite loops, retry storms, batch jobs gone wrong. Rate limiting protects against both malicious and accidental overload. Internal != safe.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that directly address failure mode, recovery path, and blast radius. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-088",
      "type": "multiple-choice",
      "question": "Estimate: 'Switching from PostgreSQL to MongoDB will improve performance.' When is this likely false?",
      "options": [
        "When data is relational with complex joins",
        "When transactions span multiple documents",
        "When current issues are query optimization, not database type",
        "All of the above"
      ],
      "correct": 3,
      "explanation": "Database switches rarely fix performance issues caused by bad schema design, missing indexes, or unoptimized queries. The same problems often follow. Identify root cause before switching databases.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Discard modeling choices that look clean but perform poorly for the target queries. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-089",
      "type": "multiple-choice",
      "question": "Plan: 'Use client-side caching to reduce server load by 80%.' What happens during cache stampede?",
      "options": [
        "80% reduction maintained",
        "All clients simultaneously hit server when cache expires",
        "Cache naturally spreads load",
        "Server handles gracefully"
      ],
      "correct": 1,
      "explanation": "If all clients cache the same data with same TTL, cache expires simultaneously for everyone. Instant spike to server. Use jitter in TTL, staggered refresh, or lock-based refresh strategies.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Keep quantities like 80 in aligned units before deciding on an implementation approach. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-090",
      "type": "multiple-choice",
      "question": "Capacity: 'Peak is 3x average, so provision for 3x.' Average is 10K QPS. What's wrong with provisioning for exactly 30K QPS?",
      "options": [
        "Nothing wrong, correct calculation",
        "No headroom for growth or unexpected spikes",
        "3x is usually overprovisioned",
        "Should use p99 not average"
      ],
      "correct": 1,
      "explanation": "Provisioning exactly at expected peak leaves no margin for: growth, unexpected spikes beyond forecast, or handling failover from other instances. Typically provision for 1.5-2x expected peak.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer approaches that directly address failure mode, recovery path, and blast radius. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 3x and 10K appear, convert them into one unit basis before comparison. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-091",
      "type": "multiple-choice",
      "question": "Design: 'Async processing via job queue. Jobs complete in ~1 minute.' Queue depth alert set at 1,000 jobs. At 100 jobs/second ingest, how fast does alert trigger?",
      "options": [
        "~10 seconds",
        "~100 seconds",
        "Never triggers if processing keeps up",
        "Depends on worker count"
      ],
      "correct": 3,
      "explanation": "If workers process 100 jobs/sec (matching ingest), queue stays near zero. If workers process 90 jobs/sec, queue grows 10 jobs/sec, hitting 1000 in 100 seconds. Worker capacity determines queue growth.",
      "detailedExplanation": "Generalize from design: 'Async processing via job queue to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Reject designs that improve throughput while weakening reliability guarantees. A good message-system answer defines guarantees clearly for both producer and consumer paths. Keep quantities like 1 minute and 1,000 in aligned units before deciding on an implementation approach. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-092",
      "type": "multiple-choice",
      "question": "Estimate: 'Feature takes 1 sprint to build, 0 sprints to maintain.' Realistic for a new microservice?",
      "options": [
        "Realistic for simple features",
        "Unrealistic - maintenance is ongoing (20-40% of dev time)",
        "Realistic with good testing",
        "Depends on service complexity"
      ],
      "correct": 1,
      "explanation": "Maintenance is never zero: bug fixes, dependency updates, scaling, on-call support, documentation. Industry average is 20-40% of engineering time on maintenance. Plan for it.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 1 and 0 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-093",
      "type": "multiple-choice",
      "question": "Teammate claims: 'Our p50 latency is 20ms, so user experience is good.' What's missing?",
      "options": [
        "p50 is the right metric for UX",
        "p95/p99 - half of users experience worse than p50",
        "Only average matters for UX",
        "Need p50 for each endpoint"
      ],
      "correct": 1,
      "explanation": "p50 means 50% of requests are faster. But 50% are slower - potentially much slower. Users notice the slow requests. p99 (99th percentile) better represents worst-case user experience.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Reject approaches that sound good in general but do not reduce concrete reliability risk. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. If values like 20ms and 50 appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-094",
      "type": "multiple-choice",
      "question": "Design: 'Store images as base64 in database for simplicity.' At 1M images × 1 MB each, base64 storage?",
      "options": ["~1 TB", "~1.33 TB", "~4 TB (with DB overhead)", "~10 TB"],
      "correct": 2,
      "explanation": "1 MB × 1.33 (base64) × 1M = 1.33 TB raw. But databases add overhead: row storage, indexes, WAL logs, TOAST tables. Actual DB footprint can be 2-3x. Also kills query performance. Use object storage.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer the approach that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. If values like 1M and 1 MB appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-095",
      "type": "multiple-choice",
      "question": "Reliability: 'We have 3 replicas, so we can lose 2 and stay up.' With consensus (Raft/Paxos), what's actually tolerable?",
      "options": [
        "Lose 2, keep 1 running",
        "Lose 1, need 2 for quorum",
        "Lose any number, 1 is enough",
        "Depends on configuration"
      ],
      "correct": 1,
      "explanation": "Consensus requires majority quorum. With 3 nodes, quorum is 2. Lose 1 node: 2 remain (can reach consensus). Lose 2 nodes: 1 remains (no quorum, cluster unavailable). For 2 failure tolerance, need 5 nodes.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Discard choices that violate required invariants during concurrent or failed states. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. If values like 3 and 2 appear, convert them into one unit basis before comparison. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-096",
      "type": "multiple-choice",
      "question": "Cost model: 'Reserved instances save 60%, so reserve everything.' Downside?",
      "options": [
        "No downside if you can predict usage",
        "Locked to instance type; can't optimize later",
        "Locked to capacity even if needs decrease",
        "Both B and C"
      ],
      "correct": 3,
      "explanation": "Reserved instances commit you to specific instance types and capacity. If better instances launch, needs change, or architecture shifts, you're stuck paying for unused capacity. Reserve baseline, use on-demand for variable.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 60 in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-097",
      "type": "multiple-choice",
      "question": "Design: 'Daily batch job at midnight.' Global users. Issue?",
      "options": [
        "No issue, midnight is low-traffic",
        "Midnight differs by timezone - always peak somewhere",
        "Only affects reporting freshness",
        "Batch timing doesn't impact users"
      ],
      "correct": 1,
      "explanation": "For global services, there's no universal 'off-hours.' Midnight PST is 8AM in London, 5PM in Tokyo. Batch jobs may hit users' peak hours. Also, batch completion time affects different regions differently.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-098",
      "type": "multiple-choice",
      "question": "Estimate: 'We need 99.99% availability. Budget: $10K/month for infrastructure.' Achievable?",
      "options": [
        "Achievable with smart architecture",
        "Likely insufficient - 4 nines requires significant redundancy",
        "Achievable with managed services",
        "Depends entirely on traffic"
      ],
      "correct": 1,
      "explanation": "99.99% (52 min/year downtime) needs: multi-AZ/region redundancy, automated failover, redundant databases, monitoring, and on-call support. $10K/month is tight for meaningful redundancy at most scales.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prioritize the approach that best protects reliability objectives under stated failure conditions. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 99.99 and 10K should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-099",
      "type": "multiple-choice",
      "question": "Log analysis: 'Error rate is 0.01%, system is healthy.' 10M requests/day. Daily error count?",
      "options": [
        "~10 errors",
        "~100 errors",
        "~1,000 errors",
        "~10,000 errors"
      ],
      "correct": 2,
      "explanation": "0.01% of 10M = 1,000 errors/day. That's 1000 potentially frustrated users or hidden bugs. Low percentage can still mean high absolute numbers. Always look at both rate and count.",
      "detailedExplanation": "Generalize from log analysis: 'Error rate is 0 to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 0.01 and 10M appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "sanity-100",
      "type": "multiple-choice",
      "question": "Final check: teammate's estimate has 10 assumptions, each 90% likely to be correct. Probability all are correct?",
      "options": ["~90%", "~65%", "~35%", "~50%"],
      "correct": 2,
      "explanation": "0.9^10 = 0.349 ≈ 35%. With 10 independent assumptions at 90% confidence each, you have only 35% confidence in the combined estimate. Small uncertainties compound. Validate critical assumptions.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prefer the answer that survives a sanity check against known anchor numbers. A harsh sanity check should identify which assumption is most likely wrong. If values like 10 and 90 appear, convert them into one unit basis before comparison. Common pitfall: propagating an early bad assumption through all steps.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n001",
      "type": "numeric-input",
      "question": "A proposal claims 1 million QPS from a single PostgreSQL instance. Typical single-instance max QPS?",
      "answer": 10000,
      "tolerance": 0.5,
      "explanation": "Single PostgreSQL typically maxes around 5K-15K QPS. 1M QPS is ~100× too high.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 1 and 5K should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n002",
      "type": "numeric-input",
      "question": "Estimate claims 10 TB/day for 1M users sending 10 messages/day at 100 bytes each. Actual TB/day?",
      "answer": 0.001,
      "unit": "TB",
      "tolerance": 0.2,
      "explanation": "1M × 10 × 100 bytes = 1 billion bytes = 1 GB, not 10 TB. Off by 10,000×.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Keep every transformation in one unit system and check order of magnitude at the end. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 10 TB and 1M in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n003",
      "type": "numeric-input",
      "question": "Proposal: 99.999% availability with single server, monthly restarts. Realistic availability %?",
      "answer": 99.9,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "Monthly restarts (~15 min each) alone consume more than 5.26 min/year budget for 5 nines.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Keep every transformation in one unit system and check order of magnitude at the end. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 99.999 and 15 min in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n004",
      "type": "numeric-input",
      "question": "Claim: 100 servers for 100K DAU, 10 requests/user/day. Reasonable server count?",
      "answer": 1,
      "tolerance": 0.5,
      "explanation": "100K × 10 / 86400 ≈ 12 QPS. One server can easily handle this. 100 servers is 100× overprovisioned.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Keep every transformation in one unit system and check order of magnitude at the end. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 100 and 100K in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n005",
      "type": "numeric-input",
      "question": "Estimate says 1 PB storage for 10M user profiles at 1 KB each. Actual storage in GB?",
      "answer": 10,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "10M × 1 KB = 10 GB. 1 PB is 100,000× too high.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep every transformation in one unit system and check order of magnitude at the end. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 1 and 10M in aligned units before deciding on an implementation approach. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n006",
      "type": "numeric-input",
      "question": "Proposal: 50ms latency for a request making 20 sequential DB queries at 5ms each. Minimum possible latency in ms?",
      "answer": 100,
      "unit": "ms",
      "tolerance": 0.1,
      "explanation": "20 × 5ms = 100ms minimum. 50ms is physically impossible.",
      "detailedExplanation": "Generalize from proposal: 50ms latency for a request making 20 sequential DB queries at 5ms each to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 50ms and 20 should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n007",
      "type": "numeric-input",
      "question": "Claim: transfer 1 TB in 1 minute over 1 Gbps link. Actual minimum time in minutes?",
      "answer": 133,
      "unit": "minutes",
      "tolerance": 0.15,
      "explanation": "1 Gbps = 125 MB/s. 1 TB / 125 MB/s = 8,000 sec = 133 min. Claim is off by 133×.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Keep every transformation in one unit system and check order of magnitude at the end. Bandwidth planning should account for protocol overhead and burst behavior, not raw payload only. Keep quantities like 1 TB and 1 minute in aligned units before deciding on an implementation approach. Common pitfall: planning on average transfer while peak bursts dominate.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n008",
      "type": "numeric-input",
      "question": "Design proposes 1 billion rows in a 10 GB database at 1 KB per row. Max rows that fit?",
      "answer": 10000000,
      "tolerance": 0.1,
      "explanation": "10 GB / 1 KB = 10 million rows max, not 1 billion.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Keep every transformation in one unit system and check order of magnitude at the end. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 1 and 10 GB in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n009",
      "type": "numeric-input",
      "question": "Claim: handle 1M WebSocket connections per server. Realistic connections per server (thousands)?",
      "answer": 100,
      "unit": "K",
      "tolerance": 0.5,
      "explanation": "With tuning, 50K-200K connections per server is achievable. 1M per server is aggressive.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Keep every transformation in one unit system and check order of magnitude at the end. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 1M and 50K in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n010",
      "type": "numeric-input",
      "question": "Proposal says 10ms RTT for US-to-Europe request. Realistic RTT in ms?",
      "answer": 100,
      "unit": "ms",
      "tolerance": 0.3,
      "explanation": "Speed of light limits: ~80-150ms for transatlantic RTT. 10ms is physically impossible.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Keep every transformation in one unit system and check order of magnitude at the end. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 10ms and 80 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n011",
      "type": "numeric-input",
      "question": "Claim: 1 developer can write 10,000 lines of production code per day. Realistic lines/day?",
      "answer": 100,
      "tolerance": 0.5,
      "explanation": "Industry average is 50-200 lines of quality code per day. 10K is unrealistic.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Normalize units before computing so conversion mistakes do not propagate. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 1 and 10,000 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n012",
      "type": "numeric-input",
      "question": "Estimate: 1 GB RAM to cache 100 million 1 KB objects. Required RAM in GB?",
      "answer": 100,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "100M × 1 KB = 100 GB. Estimate is off by 100×.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Normalize units before computing so conversion mistakes do not propagate. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. If values like 1 GB and 100 appear, convert them into one unit basis before comparison. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n013",
      "type": "numeric-input",
      "question": "Proposal: daily backup of 10 TB in 1-hour window at 100 Mbps. Required bandwidth in Gbps?",
      "answer": 22.2,
      "unit": "Gbps",
      "tolerance": 0.15,
      "explanation": "10 TB / 3600 sec = 2.78 GB/s = 22.2 Gbps. 100 Mbps is ~200× too slow.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Keep every transformation in one unit system and check order of magnitude at the end. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 10 TB and 1 in aligned units before deciding on an implementation approach. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n014",
      "type": "numeric-input",
      "question": "Design claims 1μs network latency between servers. Realistic same-rack latency in μs?",
      "answer": 100,
      "unit": "μs",
      "tolerance": 0.5,
      "explanation": "Same-rack: 100-500μs. Same-DC: 500μs-1ms. 1μs is unrealistic except for specialized hardware.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Treat network capacity as a steady-state constraint, then test against peak windows. Numbers such as 1 and 100 should be normalized first so downstream reasoning stays consistent. Common pitfall: planning on average transfer while peak bursts dominate.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n015",
      "type": "numeric-input",
      "question": "Estimate: 100 engineers can build and maintain a 10M LOC codebase. Typical LOC per engineer (thousands)?",
      "answer": 10,
      "unit": "K",
      "tolerance": 0.5,
      "explanation": "Industry heuristic: 5-15K LOC per engineer for maintenance. 100K LOC/engineer is too high.",
      "detailedExplanation": "Generalize from estimate: 100 engineers can build and maintain a 10M LOC codebase to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Normalize units before computing so conversion mistakes do not propagate. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 100 and 10M appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n016",
      "type": "numeric-input",
      "question": "Proposal: 10ms p99 latency for a service calling 5 downstream services sequentially (each 5ms p99). Minimum p99 in ms?",
      "answer": 25,
      "unit": "ms",
      "tolerance": 0.2,
      "explanation": "5 sequential calls at 5ms each = 25ms minimum. 10ms is impossible.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep every transformation in one unit system and check order of magnitude at the end. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Keep quantities like 10ms and 5 in aligned units before deciding on an implementation approach. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n017",
      "type": "numeric-input",
      "question": "Claim: single SSD can sustain 1 million IOPS. Typical high-end SSD IOPS (thousands)?",
      "answer": 500,
      "unit": "K",
      "tolerance": 0.5,
      "explanation": "High-end NVMe SSDs achieve 200K-800K IOPS. 1M is at the upper extreme.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Keep every transformation in one unit system and check order of magnitude at the end. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 1 and 200K in aligned units before deciding on an implementation approach. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-n018",
      "type": "numeric-input",
      "question": "Design says 100 Kafka partitions needed for 100 msg/sec. Reasonable partition count?",
      "answer": 1,
      "tolerance": 0.5,
      "explanation": "Single Kafka partition handles 10K+ msg/sec. 100 partitions for 100 msg/sec is massive over-provisioning.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Keep every transformation in one unit system and check order of magnitude at the end. Throughput is only one part; replay behavior and consumer lag handling matter equally. Keep quantities like 100 and 10K in aligned units before deciding on an implementation approach. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o001",
      "type": "ordering",
      "question": "Rank these estimates by how overestimated they are (least to most).",
      "items": [
        "10 servers for 1000 QPS",
        "100 GB for 1M user profiles",
        "1ms cross-DC latency",
        "1B rows in 10 GB"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "10 servers (2-5× over) < 100GB (10× over) < 1ms latency (50× under) < 1B rows (100× over).",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Order by relative scale and bottleneck effect, then validate neighboring items. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 10 and 2 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o002",
      "type": "ordering",
      "question": "Rank by plausibility for a startup MVP (most to least plausible).",
      "items": [
        "99.9% availability",
        "10ms global latency",
        "1M QPS day one",
        "10K daily active users"
      ],
      "correctOrder": [3, 0, 1, 2],
      "explanation": "10K DAU is realistic. 99.9% is achievable. 10ms global and 1M QPS are unrealistic for MVP.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Place obvious extremes first, then sort the middle by pairwise comparison. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 10K and 99.9 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o003",
      "type": "ordering",
      "question": "Rank these latencies by how realistic they are (most to least realistic).",
      "items": [
        "100ms API response",
        "1ms database query",
        "10μs network hop",
        "1ns disk read"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "100ms API is normal. 1ms DB query is fast but possible. 10μs network is aggressive. 1ns disk is impossible.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Place obvious extremes first, then sort the middle by pairwise comparison. Interface decisions should be justified by contract stability and client impact over time. Keep quantities like 100ms and 1ms in aligned units before deciding on an implementation approach. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o004",
      "type": "ordering",
      "question": "Rank by accuracy of estimate for 1M users (most to least accurate).",
      "items": [
        "1 TB photo storage",
        "100 GB metadata",
        "10 servers",
        "1 PB total storage"
      ],
      "correctOrder": [1, 2, 0, 3],
      "explanation": "100 GB metadata (~100B/user) reasonable. 10 servers reasonable. 1 TB photos (1 MB/user) low. 1 PB way too high.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Order by relative scale and bottleneck effect, then validate neighboring items. A harsh sanity check should identify which assumption is most likely wrong. Numbers such as 1M and 100 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: accepting implausible outputs because arithmetic is clean.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o005",
      "type": "ordering",
      "question": "Rank these claims by red-flag severity (least to most concerning).",
      "items": [
        "Linear scaling to 10×",
        "Zero downtime deployments",
        "1μs P99 latency",
        "Infinite horizontal scaling"
      ],
      "correctOrder": [1, 0, 2, 3],
      "explanation": "Zero-downtime is achievable. Linear 10× is optimistic but possible. 1μs P99 is unrealistic. Infinite scaling is impossible.",
      "detailedExplanation": "Generalize from rank these claims by red-flag severity (least to most concerning) to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Place obvious extremes first, then sort the middle by pairwise comparison. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. If values like 10 and 1 appear, convert them into one unit basis before comparison. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o006",
      "type": "ordering",
      "question": "Rank by how much the estimate misses by (smallest to largest miss).",
      "items": [
        "'1 server for 1M users'",
        "'10ms cross-continent'",
        "'1 GB for 1B records'",
        "'100% cache hit rate'"
      ],
      "correctOrder": [1, 0, 3, 2],
      "explanation": "10ms cross-continent (10× off). 1 server/1M users (10-100× off). 100% cache (impossible). 1 GB/1B records (1000× off).",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Build the rank from biggest differences first, then refine with adjacent checks. Treat freshness policy and invalidation paths as first-class constraints. Keep quantities like 10ms and 10 in aligned units before deciding on an implementation approach. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o007",
      "type": "ordering",
      "question": "Rank infrastructure costs by how underestimated they typically are (least to most underestimated).",
      "items": [
        "Compute costs",
        "Data transfer costs",
        "Storage costs",
        "Operational costs"
      ],
      "correctOrder": [2, 0, 1, 3],
      "explanation": "Storage is predictable. Compute is understood. Data transfer surprises people. Operations (people, tooling) often massively underestimated.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Build the rank from biggest differences first, then refine with adjacent checks. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-o008",
      "type": "ordering",
      "question": "Rank by typical accuracy of back-of-envelope estimates (most to least accurate).",
      "items": [
        "Storage calculations",
        "Latency estimates",
        "Cost projections",
        "Availability targets"
      ],
      "correctOrder": [0, 1, 3, 2],
      "explanation": "Storage math is straightforward. Latency can be measured. Availability is complex. Costs have many hidden factors.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Order by relative scale and bottleneck effect, then validate neighboring items. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m001",
      "type": "multi-select",
      "question": "Which estimates are reasonable for a social media app with 10M DAU?",
      "options": [
        "100 TB storage",
        "10,000 QPS average",
        "99.9% availability",
        "1 engineer team"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "100 TB (10KB/user), 10K QPS (86 req/user/day), 99.9% all reasonable. 1 engineer can't maintain at this scale.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 10M and 100 TB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m002",
      "type": "multi-select",
      "question": "Which are red flags in a system design proposal?",
      "options": [
        "Ignoring network latency",
        "Assuming 100% cache hit rate",
        "Planning for 2× peak capacity",
        "Using eventually consistent storage"
      ],
      "correctIndices": [0, 1],
      "explanation": "Ignoring latency and 100% cache are unrealistic. 2× headroom and eventual consistency are valid choices.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Treat freshness policy and invalidation paths as first-class constraints. If values like 100 and 2 appear, convert them into one unit basis before comparison. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m003",
      "type": "multi-select",
      "question": "Which claims should trigger sanity check questions?",
      "options": [
        "1ms response time for any request",
        "Horizontal scaling to any load",
        "Zero data loss guarantee",
        "All operations are idempotent"
      ],
      "correctIndices": [0, 1, 2, 3],
      "explanation": "All of these are extreme claims that need verification. Even idempotency should be confirmed.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Validate each proposed control independently and avoid partially true claims that fail under realistic load. Cross-check with anchor numbers to test plausibility before finalizing. Common pitfall: propagating an early bad assumption through all steps.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m004",
      "type": "multi-select",
      "question": "Which are physically plausible for a single server?",
      "options": [
        "500K WebSocket connections",
        "1 million IOPS",
        "10 Gbps network throughput",
        "1 TB RAM"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "500K connections (with tuning), 10 Gbps NIC, 1 TB RAM are possible. 1M IOPS is at the extreme limit.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Validate each proposed control independently and avoid partially true claims that fail under realistic load. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 500K and 10 in aligned units before deciding on an implementation approach. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m005",
      "type": "multi-select",
      "question": "An estimate claims 1 PB/year data growth. Which user bases could justify this?",
      "options": [
        "1M users, text only",
        "10M users with photos",
        "100M users with video",
        "1B users, text only"
      ],
      "correctIndices": [2, 3],
      "explanation": "1 PB/year ≈ 3 TB/day. 100M × 30KB/day ✓ or 1B × 3KB/day ✓. 1M text or 10M photos is way under.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Evaluate each candidate approach independently under the same constraints. Growth answers improve when tied to a concrete capacity decision threshold. If values like 1 and 3 TB appear, convert them into one unit basis before comparison. Common pitfall: treating compounding as linear change.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m006",
      "type": "multi-select",
      "question": "Which indicate an estimate may be off by orders of magnitude?",
      "options": [
        "Unusually round numbers",
        "No consideration of overhead",
        "Latency under speed-of-light limits",
        "Linear extrapolation of exponential process"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "Missing overhead, physics violations, and wrong growth model cause large errors. Round numbers alone aren't red flags.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Validate each proposed control independently and avoid partially true claims that fail under realistic load. Show present and projected demand side by side so scaling deadlines are visible early. Common pitfall: treating compounding as linear change.",
      "references": [
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        },
        {
          "title": "Rule of 72",
          "url": "https://www.investopedia.com/terms/r/ruleof72.asp"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m007",
      "type": "multi-select",
      "question": "Which are valid simplifications in back-of-envelope estimates?",
      "options": [
        "Ignore metadata overhead",
        "Round to nearest power of 10",
        "Assume uniform distribution",
        "Ignore network latency"
      ],
      "correctIndices": [1, 2],
      "explanation": "Rounding and uniform distribution are acceptable simplifications. Ignoring overhead and latency can cause significant errors.",
      "detailedExplanation": "Generalize from valid simplifications in back-of-envelope estimates to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Evaluate each candidate approach independently under the same constraints. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-m008",
      "type": "multi-select",
      "question": "Which capacity claims need immediate verification?",
      "options": [
        "Single DB handles all writes",
        "Cache hit rate above 99%",
        "Zero message loss",
        "Sub-second failover"
      ],
      "correctIndices": [0, 1, 2, 3],
      "explanation": "All of these are strong claims that need evidence. They're possible but shouldn't be assumed.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Evaluate each candidate approach independently under the same constraints. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-t001",
      "type": "two-stage",
      "stages": [
        {
          "question": "A proposal claims 10ms average latency for a request that crosses 3 services. Is this reasonable if each service is 5ms?",
          "options": [
            "Yes, services run in parallel",
            "No, minimum is 15ms sequential",
            "Yes, if caching is used",
            "Depends on network latency"
          ],
          "correct": 1,
          "explanation": "3 sequential services × 5ms = 15ms minimum. 10ms is impossible without parallelization.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Solve this as chained reasoning where stage two must respect stage one assumptions. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Keep quantities like 10ms and 3 in aligned units before deciding on an implementation approach. Common pitfall: propagating an early bad assumption through all steps."
        },
        {
          "question": "What additional time should you budget for network hops between services?",
          "options": [
            "~0.1ms per hop",
            "~1ms per hop",
            "~10ms per hop",
            "~100ms per hop"
          ],
          "correct": 1,
          "explanation": "Same-datacenter network hops are typically 0.5-2ms each.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. Convert bits/bytes carefully and include sustained peak assumptions in transfer planning. Keep quantities like 0.5 and 2ms in aligned units before deciding on an implementation approach. Common pitfall: planning on average transfer while peak bursts dominate."
        }
      ],
      "explanation": "Always account for network latency between services.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat network capacity as a steady-state constraint, then test against peak windows. Common pitfall: missing protocol/compression overhead in capacity math.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-t002",
      "type": "two-stage",
      "stages": [
        {
          "question": "Proposal claims 1 GB storage for 1 million user sessions at 10 KB each. Is this correct?",
          "options": [
            "Yes, math checks out",
            "No, need 10 GB",
            "No, need 100 MB",
            "Depends on compression"
          ],
          "correct": 1,
          "explanation": "1M × 10 KB = 10 GB, not 1 GB. Off by 10×.",
          "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Solve this as chained reasoning where stage two must respect stage one assumptions. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 1 GB and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints."
        },
        {
          "question": "If sessions also need 20% overhead for indexes, actual storage needed?",
          "options": ["10 GB", "12 GB", "15 GB", "20 GB"],
          "correct": 1,
          "explanation": "10 GB × 1.2 = 12 GB with index overhead.",
          "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Solve this as chained reasoning where stage two must respect stage one assumptions. Modeling quality is measured by query fit, cardinality behavior, and operational cost. If values like 20 and 10 GB appear, convert them into one unit basis before comparison. Common pitfall: unbounded cardinality in joins or fan-out."
        }
      ],
      "explanation": "Always verify arithmetic and add overhead factors.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-t003",
      "type": "two-stage",
      "stages": [
        {
          "question": "Design claims 99.99% availability with monthly maintenance windows of 4 hours. What's the actual max availability?",
          "options": ["99.99%", "99.95%", "99.5%", "99%"],
          "correct": 2,
          "explanation": "4 hours/month = 48 hours/year. 48/8760 = 0.55% downtime = 99.45% availability max.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Numbers such as 99.99 and 4 hours should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "To achieve 99.99% (52 min/year), max maintenance window per month?",
          "options": ["~1 minute", "~4 minutes", "~15 minutes", "~1 hour"],
          "correct": 1,
          "explanation": "52 min/year ÷ 12 months = 4.3 minutes per month max.",
          "detailedExplanation": "Generalize from to achieve 99 to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 99.99 and 52 min in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization."
        }
      ],
      "explanation": "Planned downtime counts against availability SLAs.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Do not reset assumptions between stages; carry forward prior constraints directly. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "AWS Pricing Calculator",
          "url": "https://calculator.aws/#/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    },
    {
      "id": "reason-t004",
      "type": "two-stage",
      "stages": [
        {
          "question": "Estimate claims 100 Mbps sufficient for 1000 concurrent video streams at 5 Mbps each. Actual bandwidth needed?",
          "options": ["100 Mbps", "500 Mbps", "5 Gbps", "50 Gbps"],
          "correct": 2,
          "explanation": "1000 × 5 Mbps = 5000 Mbps = 5 Gbps. Estimate is 50× too low.",
          "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Convert bits/bytes carefully and include sustained peak assumptions in transfer planning. If values like 100 and 1000 appear, convert them into one unit basis before comparison. Common pitfall: bits-vs-bytes conversion mistakes."
        },
        {
          "question": "How many concurrent streams can 100 Mbps actually support at 5 Mbps each?",
          "options": ["2 streams", "10 streams", "20 streams", "100 streams"],
          "correct": 2,
          "explanation": "100 Mbps ÷ 5 Mbps = 20 streams max.",
          "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 100 and 5 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks."
        }
      ],
      "explanation": "Bandwidth requirements scale linearly with concurrent streams.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat network capacity as a steady-state constraint, then test against peak windows. Common pitfall: planning on average transfer while peak bursts dominate.",
      "references": [
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "Azure bandwidth pricing",
          "url": "https://azure.microsoft.com/pricing/details/bandwidth/"
        }
      ],
      "tags": ["estimation", "reasonableness-checks"],
      "difficulty": "senior"
    }
  ]
}
