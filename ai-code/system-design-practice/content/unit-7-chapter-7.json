{
  "unit": 7,
  "unitTitle": "Scaling Compute",
  "chapter": 7,
  "chapterTitle": "Compute Selection & Platform Trade-offs",
  "chapterDescription": "Choosing between VMs, containers, serverless, and managed runtimes using workload shape, reliability goals, and operations/cost trade-offs.",
  "problems": [
    {
      "id": "sc-pt-001",
      "type": "multiple-choice",
      "question": "A team runs a latency-sensitive API gateway. Their main concern is cold-start latency penalties. Which compute-platform decision is strongest? Recent incident data shows rollback speed is now a top requirement.",
      "options": [
        "For this workload, prefer containers on orchestrator with autoscaling and pod-level isolation controls.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Given the observed bottleneck and guardrails, compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a latency-sensitive API gateway, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that directly address failure mode, recovery path, and blast radius. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-002",
      "type": "multiple-choice",
      "question": "A team runs a spiky image thumbnail endpoint. Their main concern is bin-packing efficiency vs noisy neighbors. Which compute-platform decision is strongest? Latency and cost both regressed after the last platform change.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer serverless for burst-heavy short-lived handlers with strict timeout fit."
      ],
      "correct": 3,
      "explanation": "From an incident-first perspective, compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a spiky image thumbnail endpoint, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-003",
      "type": "multiple-choice",
      "question": "A team runs a steady background ETL workers. Their main concern is ops overhead and patching burden. Which compute-platform decision is strongest? On-call load rose due to weak operational ergonomics.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer VMs when host-level control/compliance and stable workloads dominate.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Under the stated reliability and cost constraints, compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a steady background ETL workers, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-004",
      "type": "multiple-choice",
      "question": "A team runs a event-driven notification fanout. Their main concern is deployment velocity and rollback control. Which compute-platform decision is strongest? Tail latency sensitivity increased after product growth.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, use mixed model: serverless ingress + containerized core services.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Prioritizing blast-radius reduction first, compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a event-driven notification fanout, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Reject approaches that ignore delivery semantics or backpressure behavior. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-005",
      "type": "multiple-choice",
      "question": "A team runs a GPU-bound inference service. Their main concern is portability vs managed-service lock-in. Which compute-platform decision is strongest? Compliance review added stronger tenancy-isolation constraints.",
      "options": [
        "For this workload, choose managed runtime for speed, but enforce portability seams at boundaries.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "With latency and correctness objectives explicit, compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a GPU-bound inference service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-006",
      "type": "multiple-choice",
      "question": "A team runs a long-running media transcoding jobs. Their main concern is cost predictability under burst load. Which compute-platform decision is strongest? Traffic burstiness is higher than prior capacity assumptions.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, use dedicated node pools for noisy-neighbor-sensitive workloads."
      ],
      "correct": 3,
      "explanation": "Looking at rollback safety and operational load, compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a long-running media transcoding jobs, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-007",
      "type": "multiple-choice",
      "question": "A team runs a stateful websocket chat service. Their main concern is runtime limits for long-lived tasks. Which compute-platform decision is strongest? Dependency startup overhead dominates low-traffic periods.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, shift long-running jobs off strict serverless limits into container workers.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a stateful websocket chat service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Generalize from team runs a stateful websocket chat service to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-008",
      "type": "multiple-choice",
      "question": "A team runs a bursty webhook processor. Their main concern is debugging/observability depth requirements. Which compute-platform decision is strongest? Regional expansion exposed portability gaps in runtime choices.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, opt for containers with canary/blue-green rollout automation.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a bursty webhook processor, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-009",
      "type": "multiple-choice",
      "question": "A team runs a compliance batch scanner. Their main concern is per-tenant isolation requirements. Which compute-platform decision is strongest? Noisy-neighbor contention appears in peak-hour traces.",
      "options": [
        "For this workload, segment tenants with per-workload isolation tiers.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a compliance batch scanner, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-010",
      "type": "multiple-choice",
      "question": "A team runs a high-QPS key-value read API. Their main concern is compliance boundary and host control. Which compute-platform decision is strongest? Team capacity for infrastructure operations is currently limited.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, adopt managed platform where undifferentiated ops cost exceeds lock-in risk."
      ],
      "correct": 3,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a high-QPS key-value read API, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Generalize from team runs a high-QPS key-value read API to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-011",
      "type": "multiple-choice",
      "question": "A team runs a multi-tenant cron execution service. Their main concern is cold-start latency penalties. Which compute-platform decision is strongest? Feature rollout cadence is blocked by environment drift.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer containers on orchestrator with autoscaling and pod-level isolation controls.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a multi-tenant cron execution service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-012",
      "type": "multiple-choice",
      "question": "A team runs a search query frontend. Their main concern is bin-packing efficiency vs noisy neighbors. Which compute-platform decision is strongest? Workload duration moved beyond prior runtime limits.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer serverless for burst-heavy short-lived handlers with strict timeout fit.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a search query frontend, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject approaches that fail under peak load or saturation conditions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-013",
      "type": "multiple-choice",
      "question": "A team runs a document rendering service. Their main concern is ops overhead and patching burden. Which compute-platform decision is strongest? Observability needs now require deeper runtime controls.",
      "options": [
        "For this workload, prefer VMs when host-level control/compliance and stable workloads dominate.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a document rendering service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-014",
      "type": "multiple-choice",
      "question": "A team runs a fraud scoring microservice. Their main concern is deployment velocity and rollback control. Which compute-platform decision is strongest? Cost per request became unpredictable under seasonal spikes.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, use mixed model: serverless ingress + containerized core services."
      ],
      "correct": 3,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a fraud scoring microservice, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-015",
      "type": "multiple-choice",
      "question": "A team runs a scheduled billing pipeline. Their main concern is portability vs managed-service lock-in. Which compute-platform decision is strongest? Platform lock-in risk was raised in architecture review.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, choose managed runtime for speed, but enforce portability seams at boundaries.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a scheduled billing pipeline, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-016",
      "type": "multiple-choice",
      "question": "A team runs a control-plane reconciliation loop. Their main concern is cost predictability under burst load. Which compute-platform decision is strongest? Failure drills revealed weak fallback behavior on cutover.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, use dedicated node pools for noisy-neighbor-sensitive workloads.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a control-plane reconciliation loop, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-017",
      "type": "multiple-choice",
      "question": "A team runs a ML feature extraction workers. Their main concern is runtime limits for long-lived tasks. Which compute-platform decision is strongest? Service startup profile makes cold paths user-visible.",
      "options": [
        "For this workload, shift long-running jobs off strict serverless limits into container workers.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a ML feature extraction workers, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-018",
      "type": "multiple-choice",
      "question": "A team runs a tenant-isolated report generation. Their main concern is debugging/observability depth requirements. Which compute-platform decision is strongest? The same workload class now needs stricter performance guarantees.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, opt for containers with canary/blue-green rollout automation."
      ],
      "correct": 3,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a tenant-isolated report generation, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Generalize from team runs a tenant-isolated report generation to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-019",
      "type": "multiple-choice",
      "question": "A team runs a internal admin API. Their main concern is per-tenant isolation requirements. Which compute-platform decision is strongest? Migration plan requires safer phased rollout behavior.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, segment tenants with per-workload isolation tiers.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a internal admin API, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-020",
      "type": "multiple-choice",
      "question": "A team runs a global edge request validator. Their main concern is compliance boundary and host control. Which compute-platform decision is strongest? Cross-team ownership boundaries now affect platform fit.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, adopt managed platform where undifferentiated ops cost exceeds lock-in risk.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a global edge request validator, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-021",
      "type": "multiple-choice",
      "question": "A team runs a latency-sensitive API gateway. Their main concern is cold-start latency penalties. Which compute-platform decision is strongest? Infrastructure patch burden is competing with product work.",
      "options": [
        "For this workload, prefer containers on orchestrator with autoscaling and pod-level isolation controls.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a latency-sensitive API gateway, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Discard options that weaken contract clarity or compatibility over time. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-022",
      "type": "multiple-choice",
      "question": "A team runs a spiky image thumbnail endpoint. Their main concern is bin-packing efficiency vs noisy neighbors. Which compute-platform decision is strongest? Model size growth stressed existing deployment assumptions.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer serverless for burst-heavy short-lived handlers with strict timeout fit."
      ],
      "correct": 3,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a spiky image thumbnail endpoint, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Discard options that weaken contract clarity or compatibility over time. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-023",
      "type": "multiple-choice",
      "question": "A team runs a steady background ETL workers. Their main concern is ops overhead and patching burden. Which compute-platform decision is strongest? Connection-heavy paths require stricter graceful-shutdown behavior.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer VMs when host-level control/compliance and stable workloads dominate.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a steady background ETL workers, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-024",
      "type": "multiple-choice",
      "question": "A team runs a event-driven notification fanout. Their main concern is deployment velocity and rollback control. Which compute-platform decision is strongest? Batch windows are tightening against current runtime ceilings.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, use mixed model: serverless ingress + containerized core services.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a event-driven notification fanout, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer the approach that keeps ordering/acknowledgment behavior predictable under failure. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-025",
      "type": "multiple-choice",
      "question": "A team runs a GPU-bound inference service. Their main concern is portability vs managed-service lock-in. Which compute-platform decision is strongest? Canary data showed heterogeneous workload fit across teams.",
      "options": [
        "For this workload, choose managed runtime for speed, but enforce portability seams at boundaries.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a GPU-bound inference service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Generalize from team runs a GPU-bound inference service to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-026",
      "type": "multiple-choice",
      "question": "A team runs a long-running media transcoding jobs. Their main concern is cost predictability under burst load. Which compute-platform decision is strongest? Managed-service boundaries changed after vendor update.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, use dedicated node pools for noisy-neighbor-sensitive workloads."
      ],
      "correct": 3,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a long-running media transcoding jobs, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-027",
      "type": "multiple-choice",
      "question": "A team runs a stateful websocket chat service. Their main concern is runtime limits for long-lived tasks. Which compute-platform decision is strongest? Container density gains came with intermittent latency spikes.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, shift long-running jobs off strict serverless limits into container workers.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a stateful websocket chat service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-028",
      "type": "multiple-choice",
      "question": "A team runs a bursty webhook processor. Their main concern is debugging/observability depth requirements. Which compute-platform decision is strongest? Unexpected timeout rates increased under concurrent bursts.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, opt for containers with canary/blue-green rollout automation.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a bursty webhook processor, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that directly address failure mode, recovery path, and blast radius. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-029",
      "type": "multiple-choice",
      "question": "A team runs a compliance batch scanner. Their main concern is per-tenant isolation requirements. Which compute-platform decision is strongest? Long-tail jobs now dominate compute spend variance.",
      "options": [
        "For this workload, segment tenants with per-workload isolation tiers.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a compliance batch scanner, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-030",
      "type": "multiple-choice",
      "question": "A team runs a high-QPS key-value read API. Their main concern is compliance boundary and host control. Which compute-platform decision is strongest? Governance requires clearer change control and auditability.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, adopt managed platform where undifferentiated ops cost exceeds lock-in risk."
      ],
      "correct": 3,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a high-QPS key-value read API, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-031",
      "type": "multiple-choice",
      "question": "A team runs a multi-tenant cron execution service. Their main concern is cold-start latency penalties. Which compute-platform decision is strongest? SLOs are now stricter for customer-facing request paths.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer containers on orchestrator with autoscaling and pod-level isolation controls.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a multi-tenant cron execution service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-032",
      "type": "multiple-choice",
      "question": "A team runs a search query frontend. Their main concern is bin-packing efficiency vs noisy neighbors. Which compute-platform decision is strongest? Platform standardization is clashing with workload diversity.",
      "options": [
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, prefer serverless for burst-heavy short-lived handlers with strict timeout fit.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase."
      ],
      "correct": 1,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a search query frontend, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-033",
      "type": "multiple-choice",
      "question": "A team runs a document rendering service. Their main concern is ops overhead and patching burden. Which compute-platform decision is strongest? Release velocity targets now require safer progressive delivery.",
      "options": [
        "For this workload, prefer VMs when host-level control/compliance and stable workloads dominate.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization."
      ],
      "correct": 0,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a document rendering service, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-034",
      "type": "multiple-choice",
      "question": "A team runs a fraud scoring microservice. Their main concern is deployment velocity and rollback control. Which compute-platform decision is strongest? Cost optimization must avoid sacrificing reliability posture.",
      "options": [
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later.",
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, use mixed model: serverless ingress + containerized core services."
      ],
      "correct": 3,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a fraud scoring microservice, this is the strongest fit in Compute Selection & Platform Trade-offs. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-035",
      "type": "multiple-choice",
      "question": "A team runs a scheduled billing pipeline. Their main concern is portability vs managed-service lock-in. Which compute-platform decision is strongest? Legacy runtime constraints are blocking architecture simplification.",
      "options": [
        "Prioritize cross-platform portability first, deferring operational-efficiency tuning to a later phase.",
        "Hold the cost model constant during remediation and postpone runtime cost/efficiency measurement until after stabilization.",
        "For this workload, choose managed runtime for speed, but enforce portability seams at boundaries.",
        "Converge workloads onto one compute platform to reduce operational complexity, then tune per-service exceptions later."
      ],
      "correct": 2,
      "explanation": "Compute selection should match workload shape, operational constraints, and economic behavior rather than forcing a single platform. For A team runs a scheduled billing pipeline, this is the strongest fit in Compute Selection & Platform Trade-offs.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a long-running media transcoding jobs, incident reviews show repeated issues tied to deployment velocity and rollback control. What is the most likely diagnosis?",
          "options": [
            "Current platform choice mismatches long-running media transcoding jobs constraints around deployment velocity and rollback control.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability."
          ],
          "correct": 0,
          "explanation": "long-running media transcoding jobs is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for long-running media transcoding jobs, what is the strongest next platform move while preserving rollback speed?",
          "options": [
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: choose managed runtime for speed, but enforce portability seams at boundaries, then validate latency/cost/operability before broad rollout."
          ],
          "correct": 3,
          "explanation": "Adopt the targeted fit correction for long-running media transcoding jobs: Implement this next: choose managed runtime for speed, but enforce portability seams at boundaries, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Cross-check with anchor numbers to test plausibility before finalizing. Common pitfall: propagating an early bad assumption through all steps."
        }
      ],
      "detailedExplanation": "Generalize from compute Selection & Platform Trade-offs to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a stateful websocket chat service, incident reviews show repeated issues tied to portability vs managed-service lock-in. What is the most likely diagnosis?",
          "options": [
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches stateful websocket chat service constraints around portability vs managed-service lock-in."
          ],
          "correct": 3,
          "explanation": "stateful websocket chat service is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Solve this as chained reasoning where stage two must respect stage one assumptions. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for stateful websocket chat service, what is the strongest next platform move under tighter latency SLOs?",
          "options": [
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: use dedicated node pools for noisy-neighbor-sensitive workloads, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged."
          ],
          "correct": 2,
          "explanation": "Adopt the targeted fit correction for stateful websocket chat service: Implement this next: use dedicated node pools for noisy-neighbor-sensitive workloads, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Common pitfall: propagating an early bad assumption through all steps."
        }
      ],
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a bursty webhook processor, incident reviews show repeated issues tied to cost predictability under burst load. What is the most likely diagnosis?",
          "options": [
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches bursty webhook processor constraints around cost predictability under burst load.",
            "Cloud region selection is always the root cause of platform fit issues."
          ],
          "correct": 2,
          "explanation": "bursty webhook processor is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Generalize from for a bursty webhook processor, incident reviews show repeated issues tied to cost to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming diagnosis for bursty webhook processor, what is the strongest next platform move with constrained ops bandwidth?",
          "options": [
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: shift long-running jobs off strict serverless limits into container workers, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding."
          ],
          "correct": 1,
          "explanation": "Adopt the targeted fit correction for bursty webhook processor: Implement this next: shift long-running jobs off strict serverless limits into container workers, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Solve this as chained reasoning where stage two must respect stage one assumptions. Bandwidth planning should account for protocol overhead and burst behavior, not raw payload only. Common pitfall: missing protocol/compression overhead in capacity math."
        }
      ],
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a compliance batch scanner, incident reviews show repeated issues tied to runtime limits for long-lived tasks. What is the most likely diagnosis?",
          "options": [
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches compliance batch scanner constraints around runtime limits for long-lived tasks.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless."
          ],
          "correct": 1,
          "explanation": "compliance batch scanner is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Do not reset assumptions between stages; carry forward prior constraints directly. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for compliance batch scanner, what is the strongest next platform move without worsening lock-in exposure?",
          "options": [
            "Implement this next: opt for containers with canary/blue-green rollout automation, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing."
          ],
          "correct": 0,
          "explanation": "Adopt the targeted fit correction for compliance batch scanner: Implement this next: opt for containers with canary/blue-green rollout automation, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Do not reset assumptions between stages; carry forward prior constraints directly. A harsh sanity check should identify which assumption is most likely wrong. Common pitfall: accepting implausible outputs because arithmetic is clean."
        }
      ],
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a high-QPS key-value read API, incident reviews show repeated issues tied to debugging/observability depth requirements. What is the most likely diagnosis?",
          "options": [
            "Current platform choice mismatches high-QPS key-value read API constraints around debugging/observability depth requirements.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability."
          ],
          "correct": 0,
          "explanation": "high-QPS key-value read API is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Do not reset assumptions between stages; carry forward prior constraints directly. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for high-QPS key-value read API, what is the strongest next platform move while controlling noisy-neighbor risk?",
          "options": [
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: segment tenants with per-workload isolation tiers, then validate latency/cost/operability before broad rollout."
          ],
          "correct": 3,
          "explanation": "Adopt the targeted fit correction for high-QPS key-value read API: Implement this next: segment tenants with per-workload isolation tiers, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Generalize from after confirming diagnosis for high-QPS key-value read API, what is the strongest next to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Solve this as chained reasoning where stage two must respect stage one assumptions. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: ambiguous contracts that hide behavior changes."
        }
      ],
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Do not reset assumptions between stages; carry forward prior constraints directly. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a multi-tenant cron execution service, incident reviews show repeated issues tied to per-tenant isolation requirements. What is the most likely diagnosis?",
          "options": [
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches multi-tenant cron execution service constraints around per-tenant isolation requirements."
          ],
          "correct": 3,
          "explanation": "multi-tenant cron execution service is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Do not reset assumptions between stages; carry forward prior constraints directly. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for multi-tenant cron execution service, what is the strongest next platform move with predictable burst-cost behavior?",
          "options": [
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: adopt managed platform where undifferentiated ops cost exceeds lock-in risk, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged."
          ],
          "correct": 2,
          "explanation": "Adopt the targeted fit correction for multi-tenant cron execution service: Implement this next: adopt managed platform where undifferentiated ops cost exceeds lock-in risk, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Solve this as chained reasoning where stage two must respect stage one assumptions. Cross-check with anchor numbers to test plausibility before finalizing. Common pitfall: skipping anchor checks against known scale."
        }
      ],
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a search query frontend, incident reviews show repeated issues tied to compliance boundary and host control. What is the most likely diagnosis?",
          "options": [
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches search query frontend constraints around compliance boundary and host control.",
            "Cloud region selection is always the root cause of platform fit issues."
          ],
          "correct": 2,
          "explanation": "search query frontend is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Do not reset assumptions between stages; carry forward prior constraints directly. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for search query frontend, what is the strongest next platform move under stricter compliance boundaries?",
          "options": [
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: prefer containers on orchestrator with autoscaling and pod-level isolation controls, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding."
          ],
          "correct": 1,
          "explanation": "Adopt the targeted fit correction for search query frontend: Implement this next: prefer containers on orchestrator with autoscaling and pod-level isolation controls, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Common pitfall: accepting implausible outputs because arithmetic is clean."
        }
      ],
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a document rendering service, incident reviews show repeated issues tied to cold-start latency penalties. What is the most likely diagnosis?",
          "options": [
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches document rendering service constraints around cold-start latency penalties.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless."
          ],
          "correct": 1,
          "explanation": "document rendering service is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Solve this as chained reasoning where stage two must respect stage one assumptions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for document rendering service, what is the strongest next platform move while keeping deployment velocity high?",
          "options": [
            "Implement this next: prefer serverless for burst-heavy short-lived handlers with strict timeout fit, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing."
          ],
          "correct": 0,
          "explanation": "Adopt the targeted fit correction for document rendering service: Implement this next: prefer serverless for burst-heavy short-lived handlers with strict timeout fit, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "Generalize from compute Selection & Platform Trade-offs to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a fraud scoring microservice, incident reviews show repeated issues tied to bin-packing efficiency vs noisy neighbors. What is the most likely diagnosis?",
          "options": [
            "Current platform choice mismatches fraud scoring microservice constraints around bin-packing efficiency vs noisy neighbors.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability."
          ],
          "correct": 0,
          "explanation": "fraud scoring microservice is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Do not reset assumptions between stages; carry forward prior constraints directly. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for fraud scoring microservice, what is the strongest next platform move before broad migration rollout?",
          "options": [
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: prefer VMs when host-level control/compliance and stable workloads dominate, then validate latency/cost/operability before broad rollout."
          ],
          "correct": 3,
          "explanation": "Adopt the targeted fit correction for fraud scoring microservice: Implement this next: prefer VMs when host-level control/compliance and stable workloads dominate, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Do not reset assumptions between stages; carry forward prior constraints directly. Cross-check with anchor numbers to test plausibility before finalizing. Common pitfall: skipping anchor checks against known scale."
        }
      ],
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a scheduled billing pipeline, incident reviews show repeated issues tied to ops overhead and patching burden. What is the most likely diagnosis?",
          "options": [
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches scheduled billing pipeline constraints around ops overhead and patching burden."
          ],
          "correct": 3,
          "explanation": "scheduled billing pipeline is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Generalize from for a scheduled billing pipeline, incident reviews show repeated issues tied to ops to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming diagnosis for scheduled billing pipeline, what is the strongest next platform move under long-running workload pressure?",
          "options": [
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: use mixed model: serverless ingress + containerized core services, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged."
          ],
          "correct": 2,
          "explanation": "Adopt the targeted fit correction for scheduled billing pipeline: Implement this next: use mixed model: serverless ingress + containerized core services, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Bandwidth planning should account for protocol overhead and burst behavior, not raw payload only. Common pitfall: bits-vs-bytes conversion mistakes."
        }
      ],
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a control-plane reconciliation loop, incident reviews show repeated issues tied to deployment velocity and rollback control. What is the most likely diagnosis?",
          "options": [
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches control-plane reconciliation loop constraints around deployment velocity and rollback control.",
            "Cloud region selection is always the root cause of platform fit issues."
          ],
          "correct": 2,
          "explanation": "control-plane reconciliation loop is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Do not reset assumptions between stages; carry forward prior constraints directly. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for control-plane reconciliation loop, what is the strongest next platform move with production observability requirements?",
          "options": [
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: choose managed runtime for speed, but enforce portability seams at boundaries, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding."
          ],
          "correct": 1,
          "explanation": "Adopt the targeted fit correction for control-plane reconciliation loop: Implement this next: choose managed runtime for speed, but enforce portability seams at boundaries, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Common pitfall: accepting implausible outputs because arithmetic is clean."
        }
      ],
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Do not reset assumptions between stages; carry forward prior constraints directly. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a ML feature extraction workers, incident reviews show repeated issues tied to portability vs managed-service lock-in. What is the most likely diagnosis?",
          "options": [
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches ML feature extraction workers constraints around portability vs managed-service lock-in.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless."
          ],
          "correct": 1,
          "explanation": "ML feature extraction workers is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for ML feature extraction workers, what is the strongest next platform move while minimizing platform sprawl?",
          "options": [
            "Implement this next: use dedicated node pools for noisy-neighbor-sensitive workloads, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing."
          ],
          "correct": 0,
          "explanation": "Adopt the targeted fit correction for ML feature extraction workers: Implement this next: use dedicated node pools for noisy-neighbor-sensitive workloads, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Common pitfall: propagating an early bad assumption through all steps."
        }
      ],
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a tenant-isolated report generation, incident reviews show repeated issues tied to cost predictability under burst load. What is the most likely diagnosis?",
          "options": [
            "Current platform choice mismatches tenant-isolated report generation constraints around cost predictability under burst load.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability."
          ],
          "correct": 0,
          "explanation": "tenant-isolated report generation is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Solve this as chained reasoning where stage two must respect stage one assumptions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming diagnosis for tenant-isolated report generation, what is the strongest next platform move with explicit fallback expectations?",
          "options": [
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: shift long-running jobs off strict serverless limits into container workers, then validate latency/cost/operability before broad rollout."
          ],
          "correct": 3,
          "explanation": "Adopt the targeted fit correction for tenant-isolated report generation: Implement this next: shift long-running jobs off strict serverless limits into container workers, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Generalize from after confirming diagnosis for tenant-isolated report generation, what is the strongest to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. A harsh sanity check should identify which assumption is most likely wrong. Common pitfall: accepting implausible outputs because arithmetic is clean."
        }
      ],
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a internal admin API, incident reviews show repeated issues tied to runtime limits for long-lived tasks. What is the most likely diagnosis?",
          "options": [
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches internal admin API constraints around runtime limits for long-lived tasks."
          ],
          "correct": 3,
          "explanation": "internal admin API is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Do not reset assumptions between stages; carry forward prior constraints directly. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for internal admin API, what is the strongest next platform move during peak seasonal load?",
          "options": [
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: opt for containers with canary/blue-green rollout automation, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged."
          ],
          "correct": 2,
          "explanation": "Adopt the targeted fit correction for internal admin API: Implement this next: opt for containers with canary/blue-green rollout automation, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Solve this as chained reasoning where stage two must respect stage one assumptions. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: interface design coupled too tightly to internal implementation."
        }
      ],
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a global edge request validator, incident reviews show repeated issues tied to debugging/observability depth requirements. What is the most likely diagnosis?",
          "options": [
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches global edge request validator constraints around debugging/observability depth requirements.",
            "Cloud region selection is always the root cause of platform fit issues."
          ],
          "correct": 2,
          "explanation": "global edge request validator is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for global edge request validator, what is the strongest next platform move under tenant-isolation constraints?",
          "options": [
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: segment tenants with per-workload isolation tiers, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding."
          ],
          "correct": 1,
          "explanation": "Adopt the targeted fit correction for global edge request validator: Implement this next: segment tenants with per-workload isolation tiers, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. A harsh sanity check should identify which assumption is most likely wrong. Common pitfall: skipping anchor checks against known scale."
        }
      ],
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a latency-sensitive API gateway, incident reviews show repeated issues tied to per-tenant isolation requirements. What is the most likely diagnosis?",
          "options": [
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches latency-sensitive API gateway constraints around per-tenant isolation requirements.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless."
          ],
          "correct": 1,
          "explanation": "latency-sensitive API gateway is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for latency-sensitive API gateway, what is the strongest next platform move while reducing incident toil?",
          "options": [
            "Implement this next: adopt managed platform where undifferentiated ops cost exceeds lock-in risk, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing."
          ],
          "correct": 0,
          "explanation": "Adopt the targeted fit correction for latency-sensitive API gateway: Implement this next: adopt managed platform where undifferentiated ops cost exceeds lock-in risk, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a spiky image thumbnail endpoint, incident reviews show repeated issues tied to compliance boundary and host control. What is the most likely diagnosis?",
          "options": [
            "Current platform choice mismatches spiky image thumbnail endpoint constraints around compliance boundary and host control.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability."
          ],
          "correct": 0,
          "explanation": "spiky image thumbnail endpoint is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Generalize from for a spiky image thumbnail endpoint, incident reviews show repeated issues tied to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for spiky image thumbnail endpoint, what is the strongest next platform move for mixed short/long job profiles?",
          "options": [
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: prefer containers on orchestrator with autoscaling and pod-level isolation controls, then validate latency/cost/operability before broad rollout."
          ],
          "correct": 3,
          "explanation": "Adopt the targeted fit correction for spiky image thumbnail endpoint: Implement this next: prefer containers on orchestrator with autoscaling and pod-level isolation controls, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Solve this as chained reasoning where stage two must respect stage one assumptions. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: breaking clients during version evolution."
        }
      ],
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a steady background ETL workers, incident reviews show repeated issues tied to cold-start latency penalties. What is the most likely diagnosis?",
          "options": [
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches steady background ETL workers constraints around cold-start latency penalties."
          ],
          "correct": 3,
          "explanation": "steady background ETL workers is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "After confirming diagnosis for steady background ETL workers, what is the strongest next platform move with clear ownership boundaries?",
          "options": [
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: prefer serverless for burst-heavy short-lived handlers with strict timeout fit, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged."
          ],
          "correct": 2,
          "explanation": "Adopt the targeted fit correction for steady background ETL workers: Implement this next: prefer serverless for burst-heavy short-lived handlers with strict timeout fit, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a event-driven notification fanout, incident reviews show repeated issues tied to bin-packing efficiency vs noisy neighbors. What is the most likely diagnosis?",
          "options": [
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches event-driven notification fanout constraints around bin-packing efficiency vs noisy neighbors.",
            "Cloud region selection is always the root cause of platform fit issues."
          ],
          "correct": 2,
          "explanation": "event-driven notification fanout is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for event-driven notification fanout, what is the strongest next platform move under evolving workload shape?",
          "options": [
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: prefer VMs when host-level control/compliance and stable workloads dominate, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding."
          ],
          "correct": 1,
          "explanation": "Adopt the targeted fit correction for event-driven notification fanout: Implement this next: prefer VMs when host-level control/compliance and stable workloads dominate, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency."
        }
      ],
      "detailedExplanation": "Generalize from compute Selection & Platform Trade-offs to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a GPU-bound inference service, incident reviews show repeated issues tied to ops overhead and patching burden. What is the most likely diagnosis?",
          "options": [
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches GPU-bound inference service constraints around ops overhead and patching burden.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless."
          ],
          "correct": 1,
          "explanation": "GPU-bound inference service is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Do not reset assumptions between stages; carry forward prior constraints directly. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for GPU-bound inference service, what is the strongest next platform move while avoiding cold-path regressions?",
          "options": [
            "Implement this next: use mixed model: serverless ingress + containerized core services, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing."
          ],
          "correct": 0,
          "explanation": "Adopt the targeted fit correction for GPU-bound inference service: Implement this next: use mixed model: serverless ingress + containerized core services, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat network capacity as a steady-state constraint, then test against peak windows. Common pitfall: missing protocol/compression overhead in capacity math."
        }
      ],
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a long-running media transcoding jobs, incident reviews show repeated issues tied to deployment velocity and rollback control. What is the most likely diagnosis?",
          "options": [
            "Current platform choice mismatches long-running media transcoding jobs constraints around deployment velocity and rollback control.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability."
          ],
          "correct": 0,
          "explanation": "long-running media transcoding jobs is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for long-running media transcoding jobs, what is the strongest next platform move with measured cost guardrails?",
          "options": [
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: choose managed runtime for speed, but enforce portability seams at boundaries, then validate latency/cost/operability before broad rollout."
          ],
          "correct": 3,
          "explanation": "Adopt the targeted fit correction for long-running media transcoding jobs: Implement this next: choose managed runtime for speed, but enforce portability seams at boundaries, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Solve this as chained reasoning where stage two must respect stage one assumptions. Treat plausibility validation as mandatory, even when the arithmetic is internally consistent. Common pitfall: skipping anchor checks against known scale."
        }
      ],
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a stateful websocket chat service, incident reviews show repeated issues tied to portability vs managed-service lock-in. What is the most likely diagnosis?",
          "options": [
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches stateful websocket chat service constraints around portability vs managed-service lock-in."
          ],
          "correct": 3,
          "explanation": "stateful websocket chat service is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming diagnosis for stateful websocket chat service, what is the strongest next platform move during phased adoption?",
          "options": [
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: use dedicated node pools for noisy-neighbor-sensitive workloads, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged."
          ],
          "correct": 2,
          "explanation": "Adopt the targeted fit correction for stateful websocket chat service: Implement this next: use dedicated node pools for noisy-neighbor-sensitive workloads, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Generalize from after confirming diagnosis for stateful websocket chat service, what is the strongest to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A harsh sanity check should identify which assumption is most likely wrong. Common pitfall: propagating an early bad assumption through all steps."
        }
      ],
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a bursty webhook processor, incident reviews show repeated issues tied to cost predictability under burst load. What is the most likely diagnosis?",
          "options": [
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches bursty webhook processor constraints around cost predictability under burst load.",
            "Cloud region selection is always the root cause of platform fit issues."
          ],
          "correct": 2,
          "explanation": "bursty webhook processor is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming diagnosis for bursty webhook processor, what is the strongest next platform move without sacrificing reliability?",
          "options": [
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: shift long-running jobs off strict serverless limits into container workers, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding."
          ],
          "correct": 1,
          "explanation": "Adopt the targeted fit correction for bursty webhook processor: Implement this next: shift long-running jobs off strict serverless limits into container workers, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. A harsh sanity check should identify which assumption is most likely wrong. Common pitfall: accepting implausible outputs because arithmetic is clean."
        }
      ],
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a compliance batch scanner, incident reviews show repeated issues tied to runtime limits for long-lived tasks. What is the most likely diagnosis?",
          "options": [
            "Compute model never affects rollout speed or reliability.",
            "Current platform choice mismatches compliance batch scanner constraints around runtime limits for long-lived tasks.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless."
          ],
          "correct": 1,
          "explanation": "compliance batch scanner is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After confirming diagnosis for compliance batch scanner, what is the strongest next platform move under migration time pressure?",
          "options": [
            "Implement this next: opt for containers with canary/blue-green rollout automation, then validate latency/cost/operability before broad rollout.",
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing."
          ],
          "correct": 0,
          "explanation": "Adopt the targeted fit correction for compliance batch scanner: Implement this next: opt for containers with canary/blue-green rollout automation, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Do not reset assumptions between stages; carry forward prior constraints directly. A harsh sanity check should identify which assumption is most likely wrong. Common pitfall: skipping anchor checks against known scale."
        }
      ],
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "For a high-QPS key-value read API, incident reviews show repeated issues tied to debugging/observability depth requirements. What is the most likely diagnosis?",
          "options": [
            "Current platform choice mismatches high-QPS key-value read API constraints around debugging/observability depth requirements.",
            "Cloud region selection is always the root cause of platform fit issues.",
            "Noisy neighbors only happen on VMs, never containers/serverless.",
            "Compute model never affects rollout speed or reliability."
          ],
          "correct": 0,
          "explanation": "high-QPS key-value read API is showing a platform-fit mismatch where runtime model and operational constraints are misaligned.",
          "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Solve this as chained reasoning where stage two must respect stage one assumptions. Tie decisions to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "After confirming diagnosis for high-QPS key-value read API, what is the strongest next platform move with strict change-control requirements?",
          "options": [
            "Add retries everywhere and keep current platform unchanged.",
            "Disable observability to reduce overhead before deciding.",
            "Choose the cheapest hourly price without performance testing.",
            "Implement this next: segment tenants with per-workload isolation tiers, then validate latency/cost/operability before broad rollout."
          ],
          "correct": 3,
          "explanation": "Adopt the targeted fit correction for high-QPS key-value read API: Implement this next: segment tenants with per-workload isolation tiers, then validate latency/cost/operability before broad rollout.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: ambiguous contracts that hide behavior changes."
        }
      ],
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-061",
      "type": "multi-select",
      "question": "When is serverless usually a strong fit? (Select all that apply)",
      "options": [
        "Spiky event-driven workloads",
        "Short-lived handlers with clear timeout bounds",
        "Always-on heavy jobs with long execution windows",
        "Teams optimizing for low ops overhead"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Serverless excels for bursty short tasks and reduced ops burden.",
      "detailedExplanation": "Generalize from serverless usually a strong fit? (Select all that apply) to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-062",
      "type": "multi-select",
      "question": "Common container-platform advantages include which? (Select all that apply)",
      "options": [
        "Fine-grained rollout control",
        "Portable packaging across environments",
        "Zero noisy-neighbor risk by default",
        "Flexible runtime/resource tuning"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Containers offer strong deployment and runtime control, but isolation still needs policy.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Validate each proposed control independently and avoid partially true claims that fail under realistic load. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-063",
      "type": "multi-select",
      "question": "Reasons to choose VMs for a workload include which? (Select all that apply)",
      "options": [
        "Host-level control and custom kernel/runtime needs",
        "Predictable long-running workload shape",
        "Guaranteed fastest deployment velocity always",
        "Strict compliance boundaries requiring stronger tenancy control"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "VMs are useful where host control, compliance, and stable long-running profiles dominate.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-064",
      "type": "multi-select",
      "question": "Which practices reduce serverless cold-start impact? (Select all that apply)",
      "options": [
        "Provisioned concurrency/warm pools",
        "Smaller deployment artifacts",
        "Unbounded startup dependencies",
        "Split latency-critical path from heavy init tasks"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Cold starts improve with warm capacity, lightweight init, and path separation.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Validate each proposed control independently and avoid partially true claims that fail under realistic load. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-065",
      "type": "multi-select",
      "question": "What helps control noisy-neighbor effects in containerized environments? (Select all that apply)",
      "options": [
        "Resource requests/limits and QoS classes",
        "Dedicated node pools for sensitive workloads",
        "Ignoring throttling and steal-time metrics",
        "Pod anti-affinity and placement rules"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Isolation requires scheduling/resource controls plus observability.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Evaluate each candidate approach independently under the same constraints. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-066",
      "type": "multi-select",
      "question": "Portability-vs-lock-in tradeoff handling should include which? (Select all that apply)",
      "options": [
        "Define abstraction seams around managed dependencies",
        "Document exit cost and migration paths",
        "Avoid all managed services categorically",
        "Use capability-driven adoption with explicit constraints"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Pragmatic lock-in management is about explicit seams and migration planning.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-067",
      "type": "multi-select",
      "question": "Which signals suggest a workload is a poor fit for strict serverless execution limits? (Select all that apply)",
      "options": [
        "Frequent timeout near platform max duration",
        "Large in-memory working set and long warmup",
        "Short burst processing under 100ms",
        "Need for persistent long-lived connections"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Long-lived/stateful/heavy-init workloads often exceed serverless sweet spot.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Validate each proposed control independently and avoid partially true claims that fail under realistic load. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-068",
      "type": "multi-select",
      "question": "Strong compute-platform migration guardrails include which? (Select all that apply)",
      "options": [
        "Canary rollout with rollback thresholds",
        "Baseline vs post-change cost and latency comparison",
        "Big-bang migration with no fallback",
        "Operational readiness checklist for on-call/support"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Migration safety depends on staged rollout and explicit operational readiness.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Evaluate each candidate approach independently under the same constraints. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-069",
      "type": "multi-select",
      "question": "Which factors matter most when picking managed runtime vs self-managed orchestration? (Select all that apply)",
      "options": [
        "Team ops bandwidth",
        "Required control depth over runtime/networking",
        "Popularity on social media only",
        "SLA/responsibility boundaries"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Decision should reflect control needs, ops capacity, and responsibility split.",
      "detailedExplanation": "Generalize from factors matter most when picking managed runtime vs self-managed orchestration? (Select to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-070",
      "type": "multi-select",
      "question": "Hybrid compute strategies are useful when which conditions hold? (Select all that apply)",
      "options": [
        "Workloads have distinct latency/duration profiles",
        "One team can own platform complexity appropriately",
        "Uniform workload pattern across all services",
        "Cost and reliability targets differ by path"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Hybrid models work when workload classes have materially different constraints.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-071",
      "type": "multi-select",
      "question": "For deployment velocity, which compute characteristics help? (Select all that apply)",
      "options": [
        "Immutable artifact pipelines",
        "Progressive delivery controls",
        "Manual snowflake host edits",
        "Fast rollback primitives"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Velocity improves with automation, progressive rollout, and quick rollback paths.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Evaluate each candidate approach independently under the same constraints. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-072",
      "type": "multi-select",
      "question": "Which anti-patterns often increase compute TCO unexpectedly? (Select all that apply)",
      "options": [
        "Choosing platform by list price only",
        "Ignoring observability and incident toil costs",
        "Measuring end-to-end cost per request/job",
        "Overprovisioning for unmanaged cold-start risk"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Total cost includes toil, overprovisioning, and reliability effects, not just hourly price.",
      "detailedExplanation": "Generalize from anti-patterns often increase compute TCO unexpectedly? (Select all that apply) to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Evaluate each candidate approach independently under the same constraints. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-073",
      "type": "multi-select",
      "question": "When evaluating platform fit for compliance-heavy systems, which are relevant? (Select all that apply)",
      "options": [
        "Tenant isolation model",
        "Auditability and change controls",
        "Whether stack is trendy this quarter",
        "Boundary control over data residency and hosts"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Compliance depends on isolation, auditability, and boundary control.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Validate each proposed control independently and avoid partially true claims that fail under realistic load. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-074",
      "type": "multi-select",
      "question": "Which indicators suggest container bin packing is too aggressive? (Select all that apply)",
      "options": [
        "Frequent CPU throttling on critical pods",
        "Latency spikes correlated with co-location",
        "Stable p99 and low contention variance",
        "Memory pressure evictions under peak"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Contention and evictions indicate overpacked nodes for sensitive workloads.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-075",
      "type": "multi-select",
      "question": "For platform portability planning, useful actions include which? (Select all that apply)",
      "options": [
        "Minimize proprietary assumptions in core domain code",
        "Track managed API usage inventory",
        "Treat migration feasibility as unknowable",
        "Prototype critical fallback path periodically"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Portability improves when dependencies are explicit and fallback paths are tested.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Evaluate each candidate approach independently under the same constraints. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-076",
      "type": "multi-select",
      "question": "Which are valid reasons to keep some workloads on VMs while others move to containers/serverless? (Select all that apply)",
      "options": [
        "Different runtime/control requirements by workload class",
        "Phased migration risk management",
        "Need to maximize accidental platform sprawl",
        "Legacy constraints with clear retirement path"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Mixed estates can be rational when bounded by clear constraints and migration plans.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Validate each proposed control independently and avoid partially true claims that fail under realistic load. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-077",
      "type": "multi-select",
      "question": "For stateful long-lived connection services, which compute concerns are critical? (Select all that apply)",
      "options": [
        "Connection draining and graceful shutdown behavior",
        "Session/state externalization strategy",
        "Assuming instant migration with zero disruption",
        "Capacity planning for reconnect storms"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Stateful connection services need controlled drain/reconnect and state handling.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Validate each proposed control independently and avoid partially true claims that fail under realistic load. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-078",
      "type": "numeric-input",
      "question": "A serverless function runs 8,000,000 times/day at 180ms average. Total compute seconds/day?",
      "answer": 1440000,
      "unit": "seconds",
      "tolerance": 0.01,
      "explanation": "8,000,000 * 0.18 = 1,440,000 seconds.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 8,000 and 000 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-079",
      "type": "numeric-input",
      "question": "A container worker handles 250 jobs/min. You need 10,000 jobs/min with 20% headroom. Minimum workers?",
      "answer": 50,
      "unit": "workers",
      "tolerance": 0,
      "explanation": "Required capacity = 10,000 / 0.8 = 12,500 jobs/min. 12,500 / 250 = 50 workers.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep every transformation in one unit system and check order of magnitude at the end. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 250 and 10,000 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-080",
      "type": "numeric-input",
      "question": "A VM pool serves 48,000 rps at 65% target utilization. Forecast is +30% traffic. What rps capacity is needed at same target?",
      "answer": 62400,
      "unit": "rps",
      "tolerance": 0.02,
      "explanation": "48,000 * 1.3 = 62,400 rps required.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Keep every transformation in one unit system and check order of magnitude at the end. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 48,000 rps and 65 in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-081",
      "type": "numeric-input",
      "question": "Cold start adds 350ms to 4% of requests on a serverless endpoint. Average added latency across all requests?",
      "answer": 14,
      "unit": "ms",
      "tolerance": 0.2,
      "explanation": "0.04 * 350ms = 14ms average added latency.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Keep every transformation in one unit system and check order of magnitude at the end. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Keep quantities like 350ms and 4 in aligned units before deciding on an implementation approach. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-082",
      "type": "numeric-input",
      "question": "Container node has 32 vCPU. Policy reserves 25% for system overhead. Usable vCPU per node?",
      "answer": 24,
      "unit": "vCPU",
      "tolerance": 0,
      "explanation": "32 * 0.75 = 24 usable vCPU.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 32 and 25 should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-083",
      "type": "numeric-input",
      "question": "A managed runtime costs $0.000002 per request. At 140 million requests/day, daily request cost?",
      "answer": 280,
      "unit": "USD",
      "tolerance": 0.02,
      "explanation": "140,000,000 * 0.000002 = $280/day.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 0.000002 and 140 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-084",
      "type": "numeric-input",
      "question": "A VM instance costs $0.84/hour and handles 3,600 rps at target. Cost per 1,000 rps-hour?",
      "answer": 0.2333,
      "unit": "USD",
      "tolerance": 0.03,
      "explanation": "$0.84 / 3.6 = $0.2333 per 1,000 rps-hour.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Normalize units before computing so conversion mistakes do not propagate. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 0.84 and 3,600 rps appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-085",
      "type": "numeric-input",
      "question": "Autoscaled container fleet has 36 pods, each 2 vCPU request. Cluster allocatable CPU is 96 vCPU. Requested utilization percent?",
      "answer": 75,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "(36*2)/96 = 72/96 = 75% requested.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 36 and 2 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-086",
      "type": "numeric-input",
      "question": "A long-running job takes 25 minutes. Serverless max duration is 15 minutes. Minimum chained invocations needed?",
      "answer": 2,
      "unit": "invocations",
      "tolerance": 0,
      "explanation": "25/15 = 1.67, so at least 2 chained invocations.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Keep every transformation in one unit system and check order of magnitude at the end. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 25 minutes and 15 minutes in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-087",
      "type": "numeric-input",
      "question": "Platform migration reduced deployment rollback time from 18 minutes to 6 minutes. Percent reduction?",
      "answer": 66.67,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "(18-6)/18 = 66.67% reduction.",
      "detailedExplanation": "Generalize from platform migration reduced deployment rollback time from 18 minutes to 6 minutes to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Keep every transformation in one unit system and check order of magnitude at the end. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 18 minutes and 6 minutes in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-088",
      "type": "numeric-input",
      "question": "A service needs 12,000 persistent connections. One pod safely handles 750 connections. Minimum pods?",
      "answer": 16,
      "unit": "pods",
      "tolerance": 0,
      "explanation": "12,000 / 750 = 16 pods.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 12,000 and 750 should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-089",
      "type": "numeric-input",
      "question": "A serverless app keeps 30 provisioned instances warm at $0.012/hour each. Daily warm cost?",
      "answer": 8.64,
      "unit": "USD",
      "tolerance": 0.02,
      "explanation": "30 * 0.012 * 24 = $8.64/day.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Keep every transformation in one unit system and check order of magnitude at the end. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 30 and 0.012 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-090",
      "type": "ordering",
      "question": "Order a pragmatic compute-platform selection flow.",
      "items": [
        "Characterize workload/runtime constraints",
        "Map candidate platforms to constraints",
        "Run cost/performance/operability experiments",
        "Adopt with rollout guardrails and review loop"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Select platform from measured fit, not assumptions.",
      "detailedExplanation": "Generalize from order a pragmatic compute-platform selection flow to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Place obvious extremes first, then sort the middle by pairwise comparison. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-091",
      "type": "ordering",
      "question": "Order by increasing host-control depth.",
      "items": [
        "Fully managed serverless",
        "Managed container runtime",
        "Self-managed container orchestration",
        "VM-based host-managed deployment"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Control generally increases from managed abstractions to host-managed compute.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Build the rank from biggest differences first, then refine with adjacent checks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-092",
      "type": "ordering",
      "question": "Order migration rollout from safest to riskiest.",
      "items": [
        "Canary migration",
        "Incremental service-by-service migration",
        "Large batch migration",
        "Big-bang cutover"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Risk grows with blast radius and reduced rollback options.",
      "detailedExplanation": "Anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Order by relative scale and bottleneck effect, then validate neighboring items. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-093",
      "type": "ordering",
      "question": "Order by likely cold-start sensitivity (least to most).",
      "items": [
        "Always-on VM fleet",
        "Always-on container service",
        "Autoscaled container scale-to-zero path",
        "On-demand serverless with infrequent traffic"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Intermittent on-demand paths typically experience highest cold-start impact.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Place obvious extremes first, then sort the middle by pairwise comparison. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-094",
      "type": "ordering",
      "question": "Order by increasing lock-in risk (typical case).",
      "items": [
        "Portable containers with open standards",
        "Managed containers with provider-specific addons",
        "Provider-specific managed runtime",
        "Deeply coupled proprietary workflow stack"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Coupling depth and proprietary dependencies drive lock-in risk.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Order by relative scale and bottleneck effect, then validate neighboring items. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-095",
      "type": "ordering",
      "question": "Order by increasing deployment velocity potential.",
      "items": [
        "Manual VM patch workflow",
        "Scripted VM image rollout",
        "Container CI/CD with progressive delivery",
        "Managed platform with built-in progressive deploy controls"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Automation and built-in rollout primitives usually improve velocity.",
      "detailedExplanation": "Begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Place obvious extremes first, then sort the middle by pairwise comparison. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-096",
      "type": "ordering",
      "question": "Order by strongest isolation for noisy-neighbor mitigation (default posture).",
      "items": [
        "Shared serverless concurrency pool",
        "Shared container nodes",
        "Dedicated container nodes",
        "Dedicated VM hosts"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Isolation typically improves with dedicated resource boundaries.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Build the rank from biggest differences first, then refine with adjacent checks. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-097",
      "type": "ordering",
      "question": "Order by increasing suitability for very long-running tasks.",
      "items": [
        "Strict-duration serverless handlers",
        "Managed short-job runtime",
        "Container workers",
        "VM-based long-lived workers"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Long-running support grows as runtime limits relax and control increases.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Order by relative scale and bottleneck effect, then validate neighboring items. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-098",
      "type": "ordering",
      "question": "Order by increasing ops burden on the application team.",
      "items": [
        "Fully managed serverless",
        "Managed containers",
        "Self-managed containers",
        "Self-managed VM fleet"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Operational burden increases with infrastructure control responsibility.",
      "detailedExplanation": "Generalize from order by increasing ops burden on the application team to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Build the rank from biggest differences first, then refine with adjacent checks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-099",
      "type": "ordering",
      "question": "Order by strongest evidence quality for platform-fit decision.",
      "items": [
        "Anecdotal team preference",
        "Benchmark on developer laptop",
        "Staging benchmark with synthetic load",
        "Production-like canary with SLO and cost telemetry"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Decision confidence grows with realistic telemetry and production-like validation.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Place obvious extremes first, then sort the middle by pairwise comparison. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    },
    {
      "id": "sc-pt-100",
      "type": "ordering",
      "question": "Order fallback planning maturity from weakest to strongest.",
      "items": [
        "No fallback documented",
        "Fallback idea in wiki only",
        "Fallback runbook with owners",
        "Fallback runbook tested in drills"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Operational resilience requires owned and tested fallback paths.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Place obvious extremes first, then sort the middle by pairwise comparison. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ],
      "tags": ["scaling-compute", "compute-selection-and-platform-trade-offs"],
      "difficulty": "senior"
    }
  ]
}
