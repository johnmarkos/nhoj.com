{
  "unit": 12,
  "unitTitle": "Interview Execution & Design Communication",
  "chapter": 6,
  "chapterTitle": "Failure-Mode Discussion Quality",
  "chapterDescription": "Improve depth and clarity when discussing outages, degradation behavior, and mitigation sequencing in interviews.",
  "problems": [
    {
      "id": "int-fm-001",
      "type": "multiple-choice",
      "question": "For profile graph service, primary risk is happy-path architecture with no failure analysis with frequent schema evolution. Which response is strongest?",
      "options": [
        "identify top failure modes and likely blast radius early",
        "ignore partial failures and focus only hard outages",
        "skip rollback discussion to save time",
        "assume one team owns all incident actions"
      ],
      "correct": 0,
      "explanation": "identify top failure modes and likely blast radius early is preferred because it directly reduces happy-path architecture and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In profile graph service, identify top failure modes and likely blast radius early should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-002",
      "type": "multiple-choice",
      "question": "While reviewing media transcoding pipeline, highest-risk gap is mitigation sequencing unclear during outages under aggressive latency targets. Which choice best improves the design?",
      "options": [
        "defer degradation behavior to implementation phase",
        "declare solution complete without verification plan",
        "sequence mitigation by risk reduction and reversibility",
        "treat monitoring as separate from design"
      ],
      "correct": 2,
      "explanation": "sequence mitigation by risk reduction and reversibility is highest leverage because it mitigates mitigation sequencing unclear and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In media transcoding pipeline, sequence mitigation by risk reduction and reversibility should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-003",
      "type": "multiple-choice",
      "question": "During a design review for Experiment assignment service, you suspect degradation plan missing user-impact prioritization during bot-driven traffic spikes. Which action should be prioritized first?",
      "options": [
        "assume one team owns all incident actions",
        "hand-wave cross-region failure impact",
        "define graceful degradation by user impact tier",
        "skip rollback discussion to save time"
      ],
      "correct": 2,
      "explanation": "define graceful degradation by user impact tier is strongest because it directly addresses degradation plan missing user-impact prioritization and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Good L6 reasoning names both immediate impact and downstream tradeoffs. In Experiment assignment service, define graceful degradation by user impact tier should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-004",
      "type": "multiple-choice",
      "question": "In feature flag control plane, the dominant concern is incomplete blast-radius reasoning while operating across two regions. What is the best next move?",
      "options": [
        "declare solution complete without verification plan",
        "assume retries fix most failures",
        "treat monitoring as separate from design",
        "state rollback and failback criteria explicitly"
      ],
      "correct": 3,
      "explanation": "state rollback and failback criteria explicitly is highest leverage because it mitigates incomplete blast-radius reasoning and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Treat this as a leverage decision: small change, large risk reduction. In feature flag control plane, state rollback and failback criteria explicitly should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-005",
      "type": "multiple-choice",
      "question": "For analytics ingestion pipeline, primary risk is no rollback or failback strategy articulated under peak traffic. Which response is strongest?",
      "options": [
        "add observability signals mapped to hypotheses",
        "assume one team owns all incident actions",
        "hand-wave cross-region failure impact",
        "ignore partial failures and focus only hard outages"
      ],
      "correct": 0,
      "explanation": "add observability signals mapped to hypotheses works best because it targets no rollback or failback strategy articulated and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In analytics ingestion pipeline, add observability signals mapped to hypotheses should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-006",
      "type": "multiple-choice",
      "question": "During incident preparation for webhook processing service, highest-risk gap is dependency failure handling left implicit during a regional failover drill. Which choice best improves the design?",
      "options": [
        "declare solution complete without verification plan",
        "defer degradation behavior to implementation phase",
        "protect critical invariants during degraded operation",
        "assume retries fix most failures"
      ],
      "correct": 2,
      "explanation": "protect critical invariants during degraded operation is the best first move because it directly mitigates dependency failure handling left implicit and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In webhook processing service, protect critical invariants during degraded operation should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-007",
      "type": "multiple-choice",
      "question": "During a design review for partner integration gateway, you suspect missing observability signals for diagnosis while deployment velocity is high. Which action should be prioritized first?",
      "options": [
        "ignore partial failures and focus only hard outages",
        "skip rollback discussion to save time",
        "limit retry amplification with bounded controls",
        "hand-wave cross-region failure impact"
      ],
      "correct": 2,
      "explanation": "limit retry amplification with bounded controls is preferred because it directly reduces missing observability signals for diagnosis and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In partner integration gateway, limit retry amplification with bounded controls should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-008",
      "type": "multiple-choice",
      "question": "In admin operations console, the dominant concern is unclear ownership during incident response when one dependency is degraded. What is the best next move?",
      "options": [
        "defer degradation behavior to implementation phase",
        "treat monitoring as separate from design",
        "assume retries fix most failures",
        "clarify ownership and communication paths in incidents"
      ],
      "correct": 3,
      "explanation": "clarify ownership and communication paths in incidents is the right choice because it closes unclear ownership and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Treat this as a leverage decision: small change, large risk reduction. In admin operations console, clarify ownership and communication paths in incidents should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-009",
      "type": "multiple-choice",
      "question": "For model inference endpoint, primary risk is weak resilience story for cross-region faults with strict compliance scope. Which response is strongest?",
      "options": [
        "validate recovery with post-incident checks",
        "ignore partial failures and focus only hard outages",
        "skip rollback discussion to save time",
        "assume one team owns all incident actions"
      ],
      "correct": 0,
      "explanation": "validate recovery with post-incident checks is preferred because it directly reduces weak resilience story for cross-region faults and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In model inference endpoint, validate recovery with post-incident checks should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-010",
      "type": "multiple-choice",
      "question": "During incident preparation for session gateway, highest-risk gap is no plan for partial data corruption scenarios while supporting multi-tenant isolation. Which choice best improves the design?",
      "options": [
        "defer degradation behavior to implementation phase",
        "connect resilience choices to SLO implications",
        "declare solution complete without verification plan",
        "treat monitoring as separate from design"
      ],
      "correct": 1,
      "explanation": "connect resilience choices to SLO implications is strongest because it directly addresses no plan for partial data corruption scenarios and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In session gateway, connect resilience choices to SLO implications should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-011",
      "type": "multiple-choice",
      "question": "In billing reconciliation batch, the dominant concern is overconfidence in retries without safeguards with frequent schema evolution. What is the best next move?",
      "options": [
        "assume one team owns all incident actions",
        "hand-wave cross-region failure impact",
        "skip rollback discussion to save time",
        "rehearse failure handling assumptions via game-days"
      ],
      "correct": 3,
      "explanation": "rehearse failure handling assumptions via game-days is the right choice because it closes overconfidence in retries and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In billing reconciliation batch, rehearse failure handling assumptions via game-days should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-012",
      "type": "multiple-choice",
      "question": "During a design review for support workflow automation, you suspect insufficient validation after incident fixes under aggressive latency targets. Which action should be prioritized first?",
      "options": [
        "declare solution complete without verification plan",
        "assume retries fix most failures",
        "explain residual risk after proposed mitigations",
        "treat monitoring as separate from design"
      ],
      "correct": 2,
      "explanation": "explain residual risk after proposed mitigations works best because it targets insufficient validation after incident fixes and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In support workflow automation, explain residual risk after proposed mitigations should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-013",
      "type": "multiple-choice",
      "question": "During incident preparation for checkout API gateway, highest-risk gap is happy-path architecture with no failure analysis during bot-driven traffic spikes. Which choice best improves the design?",
      "options": [
        "assume one team owns all incident actions",
        "ignore partial failures and focus only hard outages",
        "identify top failure modes and likely blast radius early",
        "hand-wave cross-region failure impact"
      ],
      "correct": 2,
      "explanation": "identify top failure modes and likely blast radius early is the right choice because it closes happy-path architecture and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Treat this as a leverage decision: small change, large risk reduction. In checkout API gateway, identify top failure modes and likely blast radius early should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-014",
      "type": "multiple-choice",
      "question": "For identity token service, primary risk is mitigation sequencing unclear during outages while operating across two regions. Which response is strongest?",
      "options": [
        "sequence mitigation by risk reduction and reversibility",
        "declare solution complete without verification plan",
        "assume retries fix most failures",
        "defer degradation behavior to implementation phase"
      ],
      "correct": 0,
      "explanation": "sequence mitigation by risk reduction and reversibility is strongest because it directly addresses mitigation sequencing unclear and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Good L6 reasoning names both immediate impact and downstream tradeoffs. In identity token service, sequence mitigation by risk reduction and reversibility should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-015",
      "type": "multiple-choice",
      "question": "In search indexing pipeline, the dominant concern is degradation plan missing user-impact prioritization under peak traffic. What is the best next move?",
      "options": [
        "ignore partial failures and focus only hard outages",
        "skip rollback discussion to save time",
        "hand-wave cross-region failure impact",
        "define graceful degradation by user impact tier"
      ],
      "correct": 3,
      "explanation": "define graceful degradation by user impact tier is the right choice because it closes degradation plan missing user-impact prioritization and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In search indexing pipeline, define graceful degradation by user impact tier should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-016",
      "type": "multiple-choice",
      "question": "During a design review for recommendation ranking service, you suspect incomplete blast-radius reasoning during a regional failover drill. Which action should be prioritized first?",
      "options": [
        "defer degradation behavior to implementation phase",
        "treat monitoring as separate from design",
        "state rollback and failback criteria explicitly",
        "assume retries fix most failures"
      ],
      "correct": 2,
      "explanation": "state rollback and failback criteria explicitly works best because it targets incomplete blast-radius reasoning and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In recommendation ranking service, state rollback and failback criteria explicitly should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-017",
      "type": "multiple-choice",
      "question": "During incident preparation for chat delivery workers, highest-risk gap is no rollback or failback strategy articulated while deployment velocity is high. Which choice best improves the design?",
      "options": [
        "ignore partial failures and focus only hard outages",
        "add observability signals mapped to hypotheses",
        "assume one team owns all incident actions",
        "skip rollback discussion to save time"
      ],
      "correct": 1,
      "explanation": "add observability signals mapped to hypotheses is the best first move because it directly mitigates no rollback or failback strategy articulated and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In chat delivery workers, add observability signals mapped to hypotheses should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-018",
      "type": "multiple-choice",
      "question": "Notification fanout dispatcher is under case; primary risk is dependency failure handling left implicit when one dependency is degraded. Which response is strongest?",
      "options": [
        "protect critical invariants during degraded operation",
        "defer degradation behavior to implementation phase",
        "treat monitoring as separate from design",
        "declare solution complete without verification plan"
      ],
      "correct": 0,
      "explanation": "protect critical invariants during degraded operation is strongest because it directly addresses dependency failure handling left implicit and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In Notification fanout dispatcher, protect critical invariants during degraded operation should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-019",
      "type": "multiple-choice",
      "question": "A scenario of fraud scoring engine surfaced this issue: the dominant concern is missing observability signals for diagnosis with strict compliance scope. What is the best next move?",
      "options": [
        "assume one team owns all incident actions",
        "hand-wave cross-region failure impact",
        "skip rollback discussion to save time",
        "limit retry amplification with bounded controls"
      ],
      "correct": 3,
      "explanation": "limit retry amplification with bounded controls is the best first move because it directly mitigates missing observability signals for diagnosis and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Focus on what you can deploy first without painting the team into a corner. In this system, limit retry amplification with bounded controls should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-020",
      "type": "multiple-choice",
      "question": "During a design review for ad auction edge service, you suspect unclear ownership during incident response while supporting multi-tenant isolation. Which action should be prioritized first?",
      "options": [
        "clarify ownership and communication paths in incidents",
        "declare solution complete without verification plan",
        "assume retries fix most failures",
        "treat monitoring as separate from design"
      ],
      "correct": 0,
      "explanation": "clarify ownership and communication paths in incidents is highest leverage because it mitigates unclear ownership and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In ad auction edge service, clarify ownership and communication paths in incidents should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-021",
      "type": "multiple-choice",
      "question": "During a design review for document collaboration backend, you suspect weak resilience story for cross-region faults with frequent schema evolution. Which action should be prioritized first?",
      "options": [
        "validate recovery with post-incident checks",
        "hand-wave cross-region failure impact",
        "ignore partial failures and focus only hard outages",
        "assume one team owns all incident actions"
      ],
      "correct": 0,
      "explanation": "validate recovery with post-incident checks is preferred because it directly reduces weak resilience story for cross-region faults and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In document collaboration backend, validate recovery with post-incident checks should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-022",
      "type": "multiple-choice",
      "question": "In payments orchestration service, the dominant concern is no plan for partial data corruption scenarios under aggressive latency targets. What is the best next move?",
      "options": [
        "declare solution complete without verification plan",
        "defer degradation behavior to implementation phase",
        "assume retries fix most failures",
        "connect resilience choices to SLO implications"
      ],
      "correct": 3,
      "explanation": "connect resilience choices to SLO implications is the right choice because it closes no plan for partial data corruption scenarios and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In payments orchestration service, connect resilience choices to SLO implications should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-023",
      "type": "multiple-choice",
      "question": "For inventory reservation service, primary risk is overconfidence in retries without safeguards during bot-driven traffic spikes. Which response is strongest?",
      "options": [
        "rehearse failure handling assumptions via game-days",
        "hand-wave cross-region failure impact",
        "ignore partial failures and focus only hard outages",
        "skip rollback discussion to save time"
      ],
      "correct": 0,
      "explanation": "rehearse failure handling assumptions via game-days is strongest because it directly addresses overconfidence in retries and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In inventory reservation service, rehearse failure handling assumptions via game-days should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-024",
      "type": "multiple-choice",
      "question": "During incident preparation for catalog read API, highest-risk gap is insufficient validation after incident fixes while operating across two regions. Which choice best improves the design?",
      "options": [
        "assume retries fix most failures",
        "treat monitoring as separate from design",
        "explain residual risk after proposed mitigations",
        "defer degradation behavior to implementation phase"
      ],
      "correct": 2,
      "explanation": "explain residual risk after proposed mitigations is highest leverage because it mitigates insufficient validation after incident fixes and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Focus on what you can deploy first without painting the team into a corner. In catalog read API, explain residual risk after proposed mitigations should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-025",
      "type": "multiple-choice",
      "question": "During a design review for profile graph service, you suspect happy-path architecture with no failure analysis under peak traffic. Which action should be prioritized first?",
      "options": [
        "identify top failure modes and likely blast radius early",
        "skip rollback discussion to save time",
        "assume one team owns all incident actions",
        "ignore partial failures and focus only hard outages"
      ],
      "correct": 0,
      "explanation": "identify top failure modes and likely blast radius early is strongest because it directly addresses happy-path architecture and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In profile graph service, identify top failure modes and likely blast radius early should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-026",
      "type": "multiple-choice",
      "question": "In media transcoding pipeline, the dominant concern is mitigation sequencing unclear during outages during a regional failover drill. What is the best next move?",
      "options": [
        "defer degradation behavior to implementation phase",
        "declare solution complete without verification plan",
        "treat monitoring as separate from design",
        "sequence mitigation by risk reduction and reversibility"
      ],
      "correct": 3,
      "explanation": "sequence mitigation by risk reduction and reversibility is the best first move because it directly mitigates mitigation sequencing unclear and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In media transcoding pipeline, sequence mitigation by risk reduction and reversibility should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-027",
      "type": "multiple-choice",
      "question": "For experiment assignment service, primary risk is degradation plan missing user-impact prioritization while deployment velocity is high. Which response is strongest?",
      "options": [
        "define graceful degradation by user impact tier",
        "skip rollback discussion to save time",
        "assume one team owns all incident actions",
        "hand-wave cross-region failure impact"
      ],
      "correct": 0,
      "explanation": "define graceful degradation by user impact tier works best because it targets degradation plan missing user-impact prioritization and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In experiment assignment service, define graceful degradation by user impact tier should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-028",
      "type": "multiple-choice",
      "question": "During incident preparation for feature flag control plane, highest-risk gap is incomplete blast-radius reasoning when one dependency is degraded. Which choice best improves the design?",
      "options": [
        "treat monitoring as separate from design",
        "assume retries fix most failures",
        "state rollback and failback criteria explicitly",
        "declare solution complete without verification plan"
      ],
      "correct": 2,
      "explanation": "state rollback and failback criteria explicitly is highest leverage because it mitigates incomplete blast-radius reasoning and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Focus on what you can deploy first without painting the team into a corner. In feature flag control plane, state rollback and failback criteria explicitly should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-029",
      "type": "multiple-choice",
      "question": "During a design review for analytics ingestion pipeline, you suspect no rollback or failback strategy articulated with strict compliance scope. Which action should be prioritized first?",
      "options": [
        "hand-wave cross-region failure impact",
        "ignore partial failures and focus only hard outages",
        "add observability signals mapped to hypotheses",
        "assume one team owns all incident actions"
      ],
      "correct": 2,
      "explanation": "add observability signals mapped to hypotheses is strongest because it directly addresses no rollback or failback strategy articulated and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In analytics ingestion pipeline, add observability signals mapped to hypotheses should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-030",
      "type": "multiple-choice",
      "question": "In webhook processing service, the dominant concern is dependency failure handling left implicit while supporting multi-tenant isolation. What is the best next move?",
      "options": [
        "assume retries fix most failures",
        "defer degradation behavior to implementation phase",
        "declare solution complete without verification plan",
        "protect critical invariants during degraded operation"
      ],
      "correct": 3,
      "explanation": "protect critical invariants during degraded operation is preferred because it directly reduces dependency failure handling left implicit and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In webhook processing service, protect critical invariants during degraded operation should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-031",
      "type": "multiple-choice",
      "question": "During incident preparation for partner integration gateway, highest-risk gap is missing observability signals for diagnosis with frequent schema evolution. Which choice best improves the design?",
      "options": [
        "hand-wave cross-region failure impact",
        "skip rollback discussion to save time",
        "limit retry amplification with bounded controls",
        "ignore partial failures and focus only hard outages"
      ],
      "correct": 2,
      "explanation": "limit retry amplification with bounded controls is highest leverage because it mitigates missing observability signals for diagnosis and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In partner integration gateway, limit retry amplification with bounded controls should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-032",
      "type": "multiple-choice",
      "question": "For admin operations console, primary risk is unclear ownership during incident response under aggressive latency targets. Which response is strongest?",
      "options": [
        "defer degradation behavior to implementation phase",
        "assume retries fix most failures",
        "clarify ownership and communication paths in incidents",
        "treat monitoring as separate from design"
      ],
      "correct": 2,
      "explanation": "clarify ownership and communication paths in incidents is strongest because it directly addresses unclear ownership and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In admin operations console, clarify ownership and communication paths in incidents should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-033",
      "type": "multiple-choice",
      "question": "While reviewing model inference endpoint, the dominant concern is weak resilience story for cross-region faults during bot-driven traffic spikes. What is the best next move?",
      "options": [
        "ignore partial failures and focus only hard outages",
        "assume one team owns all incident actions",
        "skip rollback discussion to save time",
        "validate recovery with post-incident checks"
      ],
      "correct": 3,
      "explanation": "validate recovery with post-incident checks is the right choice because it closes weak resilience story for cross-region faults and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In model inference endpoint, validate recovery with post-incident checks should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-034",
      "type": "multiple-choice",
      "question": "During a design review for session gateway, you suspect no plan for partial data corruption scenarios while operating across two regions. Which action should be prioritized first?",
      "options": [
        "connect resilience choices to SLO implications",
        "treat monitoring as separate from design",
        "declare solution complete without verification plan",
        "defer degradation behavior to implementation phase"
      ],
      "correct": 0,
      "explanation": "connect resilience choices to SLO implications works best because it targets no plan for partial data corruption scenarios and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Strong answers connect one decision to one observable outcome. In session gateway, connect resilience choices to SLO implications should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-035",
      "type": "multiple-choice",
      "question": "While reviewing billing reconciliation batch, highest-risk gap is overconfidence in retries without safeguards under peak traffic. Which choice best improves the design?",
      "options": [
        "skip rollback discussion to save time",
        "hand-wave cross-region failure impact",
        "rehearse failure handling assumptions via game-days",
        "assume one team owns all incident actions"
      ],
      "correct": 2,
      "explanation": "rehearse failure handling assumptions via game-days is highest leverage because it mitigates overconfidence in retries and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In billing reconciliation batch, rehearse failure handling assumptions via game-days should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "For fraud scoring engine, what is the most likely core problem behind happy-path architecture with no failure analysis with frequent schema evolution?",
          "options": [
            "happy-path architecture with no failure analysis",
            "degradation plan missing user-impact prioritization",
            "no rollback or failback strategy articulated",
            "missing observability signals for diagnosis"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is happy-path architecture because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In fraud scoring engine, happy-path architecture best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in fraud scoring engine, which adjustment gives the best risk reduction?",
          "options": [
            "ignore partial failures and focus only hard outages",
            "identify top failure modes and likely blast radius early",
            "assume one team owns all incident actions",
            "skip rollback discussion to save time"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, identify top failure modes and likely blast radius early is the strongest first change because it reduces happy-path architecture quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In fraud scoring engine, identify top failure modes and likely blast radius early is high leverage because it lowers happy-path architecture without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. A strong stage-2 answer balances immediate impact with operational safety. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of document collaboration backend, which diagnosis is most defensible for mitigation sequencing unclear during outages while operating across two regions?",
          "options": [
            "incomplete blast-radius reasoning",
            "unclear ownership during incident response",
            "mitigation sequencing unclear during outages",
            "dependency failure handling left implicit"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is mitigation sequencing unclear because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In this system, mitigation sequencing unclear best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for document collaboration backend, what is the strongest immediate response?",
          "options": [
            "sequence mitigation by risk reduction and reversibility",
            "defer degradation behavior to implementation phase",
            "treat monitoring as separate from design",
            "declare solution complete without verification plan"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, sequence mitigation by risk reduction and reversibility is the strongest first change because it reduces mitigation sequencing unclear quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In this system, sequence mitigation by risk reduction and reversibility is high leverage because it lowers mitigation sequencing unclear without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. Choose the action that creates momentum for subsequent hardening work. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "In inventory reservation service, what is the highest-priority diagnosis given degradation plan missing user-impact prioritization while deployment velocity is high?",
          "options": [
            "missing observability signals for diagnosis",
            "weak resilience story for cross-region faults",
            "degradation plan missing user-impact prioritization",
            "no rollback or failback strategy articulated"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is degradation plan missing user-impact prioritization because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. In inventory reservation service, degradation plan missing user-impact prioritization best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in inventory reservation service, which next change should be prioritized first?",
          "options": [
            "assume one team owns all incident actions",
            "hand-wave cross-region failure impact",
            "skip rollback discussion to save time",
            "define graceful degradation by user impact tier"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, define graceful degradation by user impact tier is the strongest first change because it reduces degradation plan missing user-impact prioritization quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A good stage-2 answer includes rollout guardrails and success criteria. In inventory reservation service, define graceful degradation by user impact tier is high leverage because it lowers degradation plan missing user-impact prioritization without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. This phase checks whether your mitigation plan is practical, not theoretical. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "In profile graph service, the strongest diagnosis is needed. Which primary issue best explains incomplete blast-radius reasoning while supporting multi-tenant isolation?",
          "options": [
            "unclear ownership during incident response",
            "no plan for partial data corruption scenarios",
            "dependency failure handling left implicit",
            "incomplete blast-radius reasoning"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is incomplete blast-radius reasoning because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In profile graph service, incomplete blast-radius reasoning best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        },
        {
          "question": "After diagnosing profile graph service, what should change first before broad rollout?",
          "options": [
            "declare solution complete without verification plan",
            "assume retries fix most failures",
            "state rollback and failback criteria explicitly",
            "treat monitoring as separate from design"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, state rollback and failback criteria explicitly is the strongest first change because it reduces incomplete blast-radius reasoning quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In profile graph service, state rollback and failback criteria explicitly is high leverage because it lowers incomplete blast-radius reasoning without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. The right first step should be high ROI and low coordination overhead. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "For experiment assignment service, what is the most likely core problem behind no rollback or failback strategy articulated during bot-driven traffic spikes?",
          "options": [
            "no rollback or failback strategy articulated",
            "missing observability signals for diagnosis",
            "weak resilience story for cross-region faults",
            "overconfidence in retries without safeguards"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is no rollback or failback strategy articulated because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. In experiment assignment service, no rollback or failback strategy articulated best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in experiment assignment service, which adjustment gives the best risk reduction?",
          "options": [
            "assume one team owns all incident actions",
            "add observability signals mapped to hypotheses",
            "ignore partial failures and focus only hard outages",
            "hand-wave cross-region failure impact"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, add observability signals mapped to hypotheses is the strongest first change because it reduces no rollback or failback strategy articulated quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Now the signal is whether you can choose the highest-leverage next action. In experiment assignment service, add observability signals mapped to hypotheses is high leverage because it lowers no rollback or failback strategy articulated without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. The best response reduces exposure quickly without destabilizing the system. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of analytics ingestion pipeline, which diagnosis is most defensible for dependency failure handling left implicit during a regional failover drill?",
          "options": [
            "unclear ownership during incident response",
            "insufficient validation after incident fixes",
            "dependency failure handling left implicit",
            "no plan for partial data corruption scenarios"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is dependency failure handling left implicit because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. In this system, dependency failure handling left implicit best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for analytics ingestion pipeline, what is the strongest immediate response?",
          "options": [
            "protect critical invariants during degraded operation",
            "declare solution complete without verification plan",
            "assume retries fix most failures",
            "defer degradation behavior to implementation phase"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, protect critical invariants during degraded operation is the strongest first change because it reduces dependency failure handling left implicit quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 rewards changes that are effective, measurable, and rollout-safe. In this system, protect critical invariants during degraded operation is high leverage because it lowers dependency failure handling left implicit without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "In partner integration gateway, what is the highest-priority diagnosis given missing observability signals for diagnosis with strict compliance scope?",
          "options": [
            "overconfidence in retries without safeguards",
            "happy-path architecture with no failure analysis",
            "missing observability signals for diagnosis",
            "weak resilience story for cross-region faults"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is missing observability signals for diagnosis because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. In partner integration gateway, missing observability signals for diagnosis best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in partner integration gateway, which next change should be prioritized first?",
          "options": [
            "ignore partial failures and focus only hard outages",
            "skip rollback discussion to save time",
            "hand-wave cross-region failure impact",
            "limit retry amplification with bounded controls"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, limit retry amplification with bounded controls is the strongest first change because it reduces missing observability signals for diagnosis quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "The right first step should be high ROI and low coordination overhead. In partner integration gateway, limit retry amplification with bounded controls is high leverage because it lowers missing observability signals for diagnosis without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. Prioritize the smallest change that closes the largest risk gap. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "In model inference endpoint, the strongest diagnosis is needed. Which primary issue best explains unclear ownership during incident response under aggressive latency targets?",
          "options": [
            "insufficient validation after incident fixes",
            "mitigation sequencing unclear during outages",
            "no plan for partial data corruption scenarios",
            "unclear ownership during incident response"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is unclear ownership during incident response because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In model inference endpoint, unclear ownership during incident response best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        },
        {
          "question": "After diagnosing model inference endpoint, what should change first before broad rollout?",
          "options": [
            "defer degradation behavior to implementation phase",
            "treat monitoring as separate from design",
            "clarify ownership and communication paths in incidents",
            "assume retries fix most failures"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, clarify ownership and communication paths in incidents is the strongest first change because it reduces unclear ownership during incident response quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In model inference endpoint, clarify ownership and communication paths in incidents is high leverage because it lowers unclear ownership during incident response without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. A good stage-2 answer includes rollout guardrails and success criteria. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "For billing reconciliation batch, what is the most likely core problem behind weak resilience story for cross-region faults under peak traffic?",
          "options": [
            "weak resilience story for cross-region faults",
            "overconfidence in retries without safeguards",
            "happy-path architecture with no failure analysis",
            "degradation plan missing user-impact prioritization"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is weak resilience story for cross-region faults because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In billing reconciliation batch, weak resilience story for cross-region faults best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in billing reconciliation batch, which adjustment gives the best risk reduction?",
          "options": [
            "ignore partial failures and focus only hard outages",
            "validate recovery with post-incident checks",
            "assume one team owns all incident actions",
            "skip rollback discussion to save time"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, validate recovery with post-incident checks is the strongest first change because it reduces weak resilience story for cross-region faults quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In billing reconciliation batch, validate recovery with post-incident checks is high leverage because it lowers weak resilience story for cross-region faults without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. Stage 2 is first-move prioritization under real delivery constraints. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of checkout API gateway, which diagnosis is most defensible for no plan for partial data corruption scenarios when one dependency is degraded?",
          "options": [
            "insufficient validation after incident fixes",
            "incomplete blast-radius reasoning",
            "no plan for partial data corruption scenarios",
            "mitigation sequencing unclear during outages"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is no plan for partial data corruption scenarios because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. In this system, no plan for partial data corruption scenarios best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for checkout API gateway, what is the strongest immediate response?",
          "options": [
            "connect resilience choices to SLO implications",
            "treat monitoring as separate from design",
            "defer degradation behavior to implementation phase",
            "declare solution complete without verification plan"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, connect resilience choices to SLO implications is the strongest first change because it reduces no plan for partial data corruption scenarios quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A good stage-2 answer includes rollout guardrails and success criteria. In this system, connect resilience choices to SLO implications is high leverage because it lowers no plan for partial data corruption scenarios without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. This is a prioritization question: what should ship first and why. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of search indexing pipeline, which diagnosis is most defensible for overconfidence in retries without safeguards with frequent schema evolution?",
          "options": [
            "happy-path architecture with no failure analysis",
            "degradation plan missing user-impact prioritization",
            "no rollback or failback strategy articulated",
            "overconfidence in retries without safeguards"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is overconfidence in retries because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. In this system, overconfidence in retries best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "After diagnosing search indexing pipeline, what should change first before broad rollout?",
          "options": [
            "rehearse failure handling assumptions via game-days",
            "skip rollback discussion to save time",
            "assume one team owns all incident actions",
            "hand-wave cross-region failure impact"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, rehearse failure handling assumptions via game-days is the strongest first change because it reduces overconfidence in retries quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "The best response reduces exposure quickly without destabilizing the system. In this system, rehearse failure handling assumptions via game-days is high leverage because it lowers overconfidence in retries without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. Now the signal is whether you can choose the highest-leverage next action. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "For chat delivery workers, what is the most likely core problem behind insufficient validation after incident fixes while operating across two regions?",
          "options": [
            "insufficient validation after incident fixes",
            "dependency failure handling left implicit",
            "incomplete blast-radius reasoning",
            "mitigation sequencing unclear during outages"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is insufficient validation after incident fixes because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "The goal here is precise problem framing before intervention design. In chat delivery workers, insufficient validation after incident fixes best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in chat delivery workers, which next change should be prioritized first?",
          "options": [
            "treat monitoring as separate from design",
            "assume retries fix most failures",
            "explain residual risk after proposed mitigations",
            "declare solution complete without verification plan"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, explain residual risk after proposed mitigations is the strongest first change because it reduces insufficient validation after incident fixes quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "With diagnosis set, this step tests execution sequencing quality. In chat delivery workers, explain residual risk after proposed mitigations is high leverage because it lowers insufficient validation after incident fixes without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "In fraud scoring engine, the strongest diagnosis is needed. Which primary issue best explains happy-path architecture with no failure analysis while deployment velocity is high?",
          "options": [
            "degradation plan missing user-impact prioritization",
            "happy-path architecture with no failure analysis",
            "missing observability signals for diagnosis",
            "no rollback or failback strategy articulated"
          ],
          "correct": 1,
          "explanation": "The best diagnosis is happy-path architecture with no failure analysis because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. In fraud scoring engine, happy-path architecture with no failure analysis best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for fraud scoring engine, what is the strongest immediate response?",
          "options": [
            "identify top failure modes and likely blast radius early",
            "hand-wave cross-region failure impact",
            "ignore partial failures and focus only hard outages",
            "assume one team owns all incident actions"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, identify top failure modes and likely blast radius early is the strongest first change because it reduces happy-path architecture with no failure analysis quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Choose the action that creates momentum for subsequent hardening work. In fraud scoring engine, identify top failure modes and likely blast radius early is high leverage because it lowers happy-path architecture with no failure analysis without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. Stage 2 is first-move prioritization under real delivery constraints. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "In document collaboration backend, what is the highest-priority diagnosis given mitigation sequencing unclear during outages while supporting multi-tenant isolation?",
          "options": [
            "mitigation sequencing unclear during outages",
            "dependency failure handling left implicit",
            "incomplete blast-radius reasoning",
            "unclear ownership during incident response"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is mitigation sequencing unclear because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In document collaboration backend, mitigation sequencing unclear best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in document collaboration backend, which adjustment gives the best risk reduction?",
          "options": [
            "assume retries fix most failures",
            "defer degradation behavior to implementation phase",
            "declare solution complete without verification plan",
            "sequence mitigation by risk reduction and reversibility"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, sequence mitigation by risk reduction and reversibility is the strongest first change because it reduces mitigation sequencing unclear quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In document collaboration backend, sequence mitigation by risk reduction and reversibility is high leverage because it lowers mitigation sequencing unclear without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. This is a prioritization question: what should ship first and why. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of inventory reservation service, which diagnosis is most defensible for degradation plan missing user-impact prioritization during bot-driven traffic spikes?",
          "options": [
            "no rollback or failback strategy articulated",
            "missing observability signals for diagnosis",
            "weak resilience story for cross-region faults",
            "degradation plan missing user-impact prioritization"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is degradation plan missing user-impact prioritization because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "The goal here is precise problem framing before intervention design. In this system, degradation plan missing user-impact prioritization best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        },
        {
          "question": "After diagnosing inventory reservation service, what should change first before broad rollout?",
          "options": [
            "define graceful degradation by user impact tier",
            "hand-wave cross-region failure impact",
            "ignore partial failures and focus only hard outages",
            "skip rollback discussion to save time"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, define graceful degradation by user impact tier is the strongest first change because it reduces degradation plan missing user-impact prioritization quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "With diagnosis set, this step tests execution sequencing quality. In this system, define graceful degradation by user impact tier is high leverage because it lowers degradation plan missing user-impact prioritization without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "For profile graph service, what is the most likely core problem behind incomplete blast-radius reasoning during a regional failover drill?",
          "options": [
            "incomplete blast-radius reasoning",
            "no plan for partial data corruption scenarios",
            "unclear ownership during incident response",
            "dependency failure handling left implicit"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is incomplete blast-radius reasoning because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In profile graph service, incomplete blast-radius reasoning best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in profile graph service, which next change should be prioritized first?",
          "options": [
            "assume retries fix most failures",
            "treat monitoring as separate from design",
            "state rollback and failback criteria explicitly",
            "defer degradation behavior to implementation phase"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, state rollback and failback criteria explicitly is the strongest first change because it reduces incomplete blast-radius reasoning quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In profile graph service, state rollback and failback criteria explicitly is high leverage because it lowers incomplete blast-radius reasoning without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. Choose the action that creates momentum for subsequent hardening work. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "In experiment assignment service, the strongest diagnosis is needed. Which primary issue best explains no rollback or failback strategy articulated with strict compliance scope?",
          "options": [
            "overconfidence in retries without safeguards",
            "no rollback or failback strategy articulated",
            "missing observability signals for diagnosis",
            "weak resilience story for cross-region faults"
          ],
          "correct": 1,
          "explanation": "The best diagnosis is no rollback or failback strategy articulated because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In experiment assignment service, no rollback or failback strategy articulated best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for experiment assignment service, what is the strongest immediate response?",
          "options": [
            "add observability signals mapped to hypotheses",
            "skip rollback discussion to save time",
            "assume one team owns all incident actions",
            "ignore partial failures and focus only hard outages"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, add observability signals mapped to hypotheses is the strongest first change because it reduces no rollback or failback strategy articulated quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In experiment assignment service, add observability signals mapped to hypotheses is high leverage because it lowers no rollback or failback strategy articulated without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. This phase checks whether your mitigation plan is practical, not theoretical. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "In analytics ingestion pipeline, what is the highest-priority diagnosis given dependency failure handling left implicit under aggressive latency targets?",
          "options": [
            "dependency failure handling left implicit",
            "no plan for partial data corruption scenarios",
            "unclear ownership during incident response",
            "insufficient validation after incident fixes"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is dependency failure handling left implicit because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In analytics ingestion pipeline, dependency failure handling left implicit best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in analytics ingestion pipeline, which adjustment gives the best risk reduction?",
          "options": [
            "treat monitoring as separate from design",
            "declare solution complete without verification plan",
            "defer degradation behavior to implementation phase",
            "protect critical invariants during degraded operation"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, protect critical invariants during degraded operation is the strongest first change because it reduces dependency failure handling left implicit quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In analytics ingestion pipeline, protect critical invariants during degraded operation is high leverage because it lowers dependency failure handling left implicit without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. The right first step should be high ROI and low coordination overhead. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of partner integration gateway, which diagnosis is most defensible for missing observability signals for diagnosis under peak traffic?",
          "options": [
            "weak resilience story for cross-region faults",
            "overconfidence in retries without safeguards",
            "happy-path architecture with no failure analysis",
            "missing observability signals for diagnosis"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is missing observability signals for diagnosis because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. In this system, missing observability signals for diagnosis best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        },
        {
          "question": "After diagnosing partner integration gateway, what should change first before broad rollout?",
          "options": [
            "limit retry amplification with bounded controls",
            "skip rollback discussion to save time",
            "assume one team owns all incident actions",
            "hand-wave cross-region failure impact"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, limit retry amplification with bounded controls is the strongest first change because it reduces missing observability signals for diagnosis quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This is a prioritization question: what should ship first and why. In this system, limit retry amplification with bounded controls is high leverage because it lowers missing observability signals for diagnosis without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. A good stage-2 answer includes rollout guardrails and success criteria. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "For model inference endpoint, what is the most likely core problem behind unclear ownership during incident response when one dependency is degraded?",
          "options": [
            "unclear ownership during incident response",
            "mitigation sequencing unclear during outages",
            "insufficient validation after incident fixes",
            "no plan for partial data corruption scenarios"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is unclear ownership because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. In model inference endpoint, unclear ownership best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in model inference endpoint, which next change should be prioritized first?",
          "options": [
            "treat monitoring as separate from design",
            "assume retries fix most failures",
            "clarify ownership and communication paths in incidents",
            "declare solution complete without verification plan"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, clarify ownership and communication paths in incidents is the strongest first change because it reduces unclear ownership quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "The right first step should be high ROI and low coordination overhead. In model inference endpoint, clarify ownership and communication paths in incidents is high leverage because it lowers unclear ownership without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. Choose the action that creates momentum for subsequent hardening work. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "For billing reconciliation batch, what is the most likely core problem behind weak resilience story for cross-region faults with frequent schema evolution?",
          "options": [
            "happy-path architecture with no failure analysis",
            "degradation plan missing user-impact prioritization",
            "weak resilience story for cross-region faults",
            "overconfidence in retries without safeguards"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is weak resilience story for cross-region faults because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. In billing reconciliation batch, weak resilience story for cross-region faults best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in billing reconciliation batch, which next change should be prioritized first?",
          "options": [
            "assume one team owns all incident actions",
            "ignore partial failures and focus only hard outages",
            "validate recovery with post-incident checks",
            "hand-wave cross-region failure impact"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, validate recovery with post-incident checks is the strongest first change because it reduces weak resilience story for cross-region faults quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 rewards changes that are effective, measurable, and rollout-safe. In billing reconciliation batch, validate recovery with post-incident checks is high leverage because it lowers weak resilience story for cross-region faults without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. This phase checks whether your mitigation plan is practical, not theoretical. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of checkout API gateway, which diagnosis is most defensible for no plan for partial data corruption scenarios while operating across two regions?",
          "options": [
            "mitigation sequencing unclear during outages",
            "incomplete blast-radius reasoning",
            "insufficient validation after incident fixes",
            "no plan for partial data corruption scenarios"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is no plan for partial data corruption scenarios because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. In this system, no plan for partial data corruption scenarios best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        },
        {
          "question": "After diagnosing checkout API gateway, what should change first before broad rollout?",
          "options": [
            "connect resilience choices to SLO implications",
            "declare solution complete without verification plan",
            "assume retries fix most failures",
            "defer degradation behavior to implementation phase"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, connect resilience choices to SLO implications is the strongest first change because it reduces no plan for partial data corruption scenarios quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Now the signal is whether you can choose the highest-leverage next action. In this system, connect resilience choices to SLO implications is high leverage because it lowers no plan for partial data corruption scenarios without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. Stage 2 is first-move prioritization under real delivery constraints. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "In search indexing pipeline, what is the highest-priority diagnosis given overconfidence in retries without safeguards while deployment velocity is high?",
          "options": [
            "overconfidence in retries without safeguards",
            "happy-path architecture with no failure analysis",
            "degradation plan missing user-impact prioritization",
            "no rollback or failback strategy articulated"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is overconfidence in retries because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In search indexing pipeline, overconfidence in retries best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in search indexing pipeline, which adjustment gives the best risk reduction?",
          "options": [
            "ignore partial failures and focus only hard outages",
            "skip rollback discussion to save time",
            "hand-wave cross-region failure impact",
            "rehearse failure handling assumptions via game-days"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, rehearse failure handling assumptions via game-days is the strongest first change because it reduces overconfidence in retries quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In search indexing pipeline, rehearse failure handling assumptions via game-days is high leverage because it lowers overconfidence in retries without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Service Level Objectives",
              "url": "https://sre.google/sre-book/service-level-objectives/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. A good stage-2 answer includes rollout guardrails and success criteria. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "In chat delivery workers, the strongest diagnosis is needed. Which primary issue best explains insufficient validation after incident fixes while supporting multi-tenant isolation?",
          "options": [
            "mitigation sequencing unclear during outages",
            "insufficient validation after incident fixes",
            "dependency failure handling left implicit",
            "incomplete blast-radius reasoning"
          ],
          "correct": 1,
          "explanation": "The best diagnosis is insufficient validation after incident fixes because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. In chat delivery workers, insufficient validation after incident fixes best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for chat delivery workers, what is the strongest immediate response?",
          "options": [
            "defer degradation behavior to implementation phase",
            "treat monitoring as separate from design",
            "explain residual risk after proposed mitigations",
            "assume retries fix most failures"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, explain residual risk after proposed mitigations is the strongest first change because it reduces insufficient validation after incident fixes quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "The best response reduces exposure quickly without destabilizing the system. In chat delivery workers, explain residual risk after proposed mitigations is high leverage because it lowers insufficient validation after incident fixes without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. Prioritize the smallest change that closes the largest risk gap. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "For fraud scoring engine, what is the most likely core problem behind happy-path architecture with no failure analysis during bot-driven traffic spikes?",
          "options": [
            "no rollback or failback strategy articulated",
            "missing observability signals for diagnosis",
            "happy-path architecture with no failure analysis",
            "degradation plan missing user-impact prioritization"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is happy-path architecture because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In fraud scoring engine, happy-path architecture best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in fraud scoring engine, which next change should be prioritized first?",
          "options": [
            "ignore partial failures and focus only hard outages",
            "assume one team owns all incident actions",
            "identify top failure modes and likely blast radius early",
            "skip rollback discussion to save time"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, identify top failure modes and likely blast radius early is the strongest first change because it reduces happy-path architecture quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In fraud scoring engine, identify top failure modes and likely blast radius early is high leverage because it lowers happy-path architecture without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
              "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
            },
            {
              "title": "Google SRE Book: Managing Incidents",
              "url": "https://sre.google/sre-book/managing-incidents/"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for failure analysis depth and mitigation sequencing. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. Prioritize the smallest change that closes the largest risk gap. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-061",
      "type": "multi-select",
      "question": "In fraud scoring engine, which actions should be combined to improve failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "add observability signals mapped to hypotheses",
        "identify top failure modes and likely blast radius early",
        "assume retries fix most failures",
        "defer degradation behavior to implementation phase",
        "clarify ownership and communication paths in incidents"
      ],
      "correctIndices": [0, 1, 4],
      "explanation": "The selected options are correct because together they reduce incomplete blast-radius reasoning through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In fraud scoring engine, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-062",
      "type": "multi-select",
      "question": "Which measures are most valuable for failure-mode reasoning quality in inventory reservation service? (Select all that apply)",
      "options": [
        "validate recovery with post-incident checks",
        "ignore partial failures and focus only hard outages",
        "skip rollback discussion to save time",
        "protect critical invariants during degraded operation",
        "sequence mitigation by risk reduction and reversibility"
      ],
      "correctIndices": [0, 3, 4],
      "explanation": "The selected options are correct because together they reduce no rollback or failback strategy articulated through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Your selected options should reduce bypass potential across different attack paths. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-063",
      "type": "multi-select",
      "question": "For experiment assignment service, select the controls that most directly improve failure-mode reasoning quality. (Select all that apply)",
      "options": [
        "limit retry amplification with bounded controls",
        "connect resilience choices to SLO implications",
        "treat monitoring as separate from design",
        "define graceful degradation by user impact tier",
        "defer degradation behavior to implementation phase"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The selected options are correct because together they reduce dependency failure handling left implicit through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "This item rewards layered reasoning and explicit residual-risk thinking. In experiment assignment service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-064",
      "type": "multi-select",
      "question": "For partner integration gateway, which controls best strengthen failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "rehearse failure handling assumptions via game-days",
        "assume one team owns all incident actions",
        "state rollback and failback criteria explicitly",
        "skip rollback discussion to save time",
        "clarify ownership and communication paths in incidents"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce missing observability signals for diagnosis through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The interview signal is whether your chosen controls still hold under stress. In partner integration gateway, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-065",
      "type": "multi-select",
      "question": "In billing reconciliation batch, which actions should be combined to improve failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "declare solution complete without verification plan",
        "treat monitoring as separate from design",
        "add observability signals mapped to hypotheses",
        "explain residual risk after proposed mitigations",
        "validate recovery with post-incident checks"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "The selected options are correct because together they reduce unclear ownership during incident response through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In billing reconciliation batch, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-066",
      "type": "multi-select",
      "question": "Which measures are most valuable for failure-mode reasoning quality in search indexing pipeline? (Select all that apply)",
      "options": [
        "protect critical invariants during degraded operation",
        "identify top failure modes and likely blast radius early",
        "assume one team owns all incident actions",
        "connect resilience choices to SLO implications",
        "hand-wave cross-region failure impact"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The selected options are correct because together they reduce weak resilience story for cross-region faults through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Your selected options should reduce bypass potential across different attack paths. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-067",
      "type": "multi-select",
      "question": "For fraud scoring engine, select the controls that most directly improve failure-mode reasoning quality. (Select all that apply)",
      "options": [
        "assume retries fix most failures",
        "declare solution complete without verification plan",
        "rehearse failure handling assumptions via game-days",
        "limit retry amplification with bounded controls",
        "sequence mitigation by risk reduction and reversibility"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "The selected options are correct because together they reduce no plan for partial data corruption scenarios through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "This item rewards layered reasoning and explicit residual-risk thinking. In fraud scoring engine, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-068",
      "type": "multi-select",
      "question": "For inventory reservation service, which controls best strengthen failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "ignore partial failures and focus only hard outages",
        "explain residual risk after proposed mitigations",
        "define graceful degradation by user impact tier",
        "hand-wave cross-region failure impact",
        "clarify ownership and communication paths in incidents"
      ],
      "correctIndices": [1, 2, 4],
      "explanation": "The selected options are correct because together they reduce overconfidence in retries without safeguards through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best selections should complement each other rather than overlap. In inventory reservation service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-069",
      "type": "multi-select",
      "question": "In experiment assignment service, which actions should be combined to improve failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "assume retries fix most failures",
        "defer degradation behavior to implementation phase",
        "identify top failure modes and likely blast radius early",
        "state rollback and failback criteria explicitly",
        "validate recovery with post-incident checks"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "The selected options are correct because together they reduce insufficient validation after incident fixes through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "A strong set combines prevention, detection, and recovery readiness. In experiment assignment service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-070",
      "type": "multi-select",
      "question": "Which measures are most valuable for failure-mode reasoning quality in partner integration gateway? (Select all that apply)",
      "options": [
        "connect resilience choices to SLO implications",
        "skip rollback discussion to save time",
        "add observability signals mapped to hypotheses",
        "sequence mitigation by risk reduction and reversibility",
        "ignore partial failures and focus only hard outages"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The selected options are correct because together they reduce happy-path architecture with no failure analysis through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "You are being tested on mitigation composition, not checkbox coverage. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-071",
      "type": "multi-select",
      "question": "Which measures are most valuable for failure-mode reasoning quality in billing reconciliation batch? (Select all that apply)",
      "options": [
        "protect critical invariants during degraded operation",
        "define graceful degradation by user impact tier",
        "rehearse failure handling assumptions via game-days",
        "treat monitoring as separate from design",
        "defer degradation behavior to implementation phase"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "The selected options are correct because together they reduce mitigation sequencing unclear during outages through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Your selected options should reduce bypass potential across different attack paths. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-072",
      "type": "multi-select",
      "question": "In search indexing pipeline, which actions should be combined to improve failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "state rollback and failback criteria explicitly",
        "skip rollback discussion to save time",
        "limit retry amplification with bounded controls",
        "assume one team owns all incident actions",
        "explain residual risk after proposed mitigations"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce degradation plan missing user-impact prioritization through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "A strong set combines prevention, detection, and recovery readiness. In search indexing pipeline, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-073",
      "type": "multi-select",
      "question": "For fraud scoring engine, which controls best strengthen failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "identify top failure modes and likely blast radius early",
        "treat monitoring as separate from design",
        "declare solution complete without verification plan",
        "add observability signals mapped to hypotheses",
        "clarify ownership and communication paths in incidents"
      ],
      "correctIndices": [0, 3, 4],
      "explanation": "The selected options are correct because together they reduce incomplete blast-radius reasoning through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The interview signal is whether your chosen controls still hold under stress. In fraud scoring engine, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-074",
      "type": "multi-select",
      "question": "For inventory reservation service, select the controls that most directly improve failure-mode reasoning quality. (Select all that apply)",
      "options": [
        "assume one team owns all incident actions",
        "hand-wave cross-region failure impact",
        "protect critical invariants during degraded operation",
        "validate recovery with post-incident checks",
        "sequence mitigation by risk reduction and reversibility"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "The selected options are correct because together they reduce no rollback or failback strategy articulated through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "These options should form a coherent plan, not a random collection of good ideas. In inventory reservation service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-075",
      "type": "multi-select",
      "question": "Which measures are most valuable for failure-mode reasoning quality in experiment assignment service? (Select all that apply)",
      "options": [
        "define graceful degradation by user impact tier",
        "assume retries fix most failures",
        "limit retry amplification with bounded controls",
        "declare solution complete without verification plan",
        "connect resilience choices to SLO implications"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce dependency failure handling left implicit through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Select controls that improve both correctness and day-2 operability. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-076",
      "type": "multi-select",
      "question": "In partner integration gateway, which actions should be combined to improve failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "clarify ownership and communication paths in incidents",
        "rehearse failure handling assumptions via game-days",
        "hand-wave cross-region failure impact",
        "state rollback and failback criteria explicitly",
        "ignore partial failures and focus only hard outages"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The selected options are correct because together they reduce missing observability signals for diagnosis through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In partner integration gateway, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-077",
      "type": "multi-select",
      "question": "For billing reconciliation batch, which controls best strengthen failure-mode reasoning quality? (Select all that apply)",
      "options": [
        "explain residual risk after proposed mitigations",
        "assume retries fix most failures",
        "add observability signals mapped to hypotheses",
        "defer degradation behavior to implementation phase",
        "validate recovery with post-incident checks"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce unclear ownership during incident response through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The interview signal is whether your chosen controls still hold under stress. In billing reconciliation batch, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-078",
      "type": "numeric-input",
      "question": "In a 45-minute interview, you allocate 15% to requirements and scoping. How many minutes is that?",
      "answer": 6.75,
      "unit": "minutes",
      "tolerance": 0.15,
      "explanation": "45  15% = 6.75 minutes. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in a 45-minute interview, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-079",
      "type": "numeric-input",
      "question": "While whiteboarding recommendation ranking service, you estimate 860 QPS and 140ms average latency. Using Little's Law, how many in-flight requests are expected?",
      "answer": 120.4,
      "unit": "requests",
      "tolerance": 0.15,
      "explanation": "L = W = 860  0.14 = 120.40 in-flight requests. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Keep the arithmetic simple, then explain the operational implication. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-080",
      "type": "numeric-input",
      "question": "After interview feedback, design explanation time dropped from 20 to 14 minutes while preserving coverage. What is the percent reduction?",
      "answer": 30,
      "unit": "percent",
      "tolerance": 0.15,
      "explanation": "(20-14)/20  100 = 30.00%. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Back-of-envelope math should be auditable and tied to thresholds. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-081",
      "type": "numeric-input",
      "question": "You discuss 9 serial dependencies each at 99.9% monthly reliability assumptions in an interview drill. Approximate combined downtime-hours/year if failures are independent and additive by rough estimate?",
      "answer": 78.84,
      "unit": "hours/year",
      "tolerance": 0.2,
      "explanation": "Back-of-envelope additive approximation: 9  8.76  78.84 hours/year. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "The calculation matters only if you map it to capacity or reliability actions. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-082",
      "type": "numeric-input",
      "question": "For a live design walkthrough, you estimate 380,000 DAU and 10 requests/user/day. What is average QPS?",
      "answer": 44,
      "unit": "qps",
      "tolerance": 0.15,
      "explanation": "380,000  10  86,400  44 QPS. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "The value of this number is in how it changes the design choice. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in a live design walkthrough, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-083",
      "type": "numeric-input",
      "question": "In a mock interview retro, your design suffered 8 incidents/month with 17 min MTTR each. Total monthly downtime minutes?",
      "answer": 136,
      "unit": "minutes/month",
      "tolerance": 0.15,
      "explanation": "8  17 = 136 minutes/month. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Numeric prompts test whether your reasoning survives unit pressure. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in a mock interview retro, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-084",
      "type": "numeric-input",
      "question": "In a 45-minute interview, you allocate 15% to requirements and scoping. How many minutes is that?",
      "answer": 6.75,
      "unit": "minutes",
      "tolerance": 0.15,
      "explanation": "45  15% = 6.75 minutes. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Back-of-envelope math should be auditable and tied to thresholds. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in a 45-minute interview, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-085",
      "type": "numeric-input",
      "question": "While whiteboarding session gateway, you estimate 1220 QPS and 260ms average latency. Using Little's Law, how many in-flight requests are expected?",
      "answer": 317.2,
      "unit": "requests",
      "tolerance": 0.15,
      "explanation": "L = W = 1220  0.26 = 317.20 in-flight requests. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-086",
      "type": "numeric-input",
      "question": "After interview feedback, design explanation time dropped from 26 to 22 minutes while preserving coverage. What is the percent reduction?",
      "answer": 15.38,
      "unit": "percent",
      "tolerance": 0.15,
      "explanation": "(26-22)/26  100 = 15.38%. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "A good estimate closes with an actionable design consequence. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-087",
      "type": "numeric-input",
      "question": "You discuss 8 serial dependencies each at 99.9% monthly reliability assumptions in an interview drill. Approximate combined downtime-hours/year if failures are independent and additive by rough estimate?",
      "answer": 70.08,
      "unit": "hours/year",
      "tolerance": 0.2,
      "explanation": "Back-of-envelope additive approximation: 8  8.76  70.08 hours/year. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Numeric prompts test whether your reasoning survives unit pressure. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-088",
      "type": "numeric-input",
      "question": "For a live design walkthrough, you estimate 500,000 DAU and 6 requests/user/day. What is average QPS?",
      "answer": 35,
      "unit": "qps",
      "tolerance": 0.15,
      "explanation": "500,000  6  86,400  35 QPS. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "This is a decision-support estimate, not just arithmetic. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in a live design walkthrough, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-089",
      "type": "numeric-input",
      "question": "In a mock interview retro, your design suffered 8 incidents/month with 15 min MTTR each. Total monthly downtime minutes?",
      "answer": 120,
      "unit": "minutes/month",
      "tolerance": 0.15,
      "explanation": "8  15 = 120 minutes/month. This estimate should drive a concrete failure analysis depth and mitigation sequencing decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete failure analysis depth and mitigation sequencing decision.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In failure analysis depth and mitigation sequencing, show units, assumptions, and headroom explicitly. Then map the result to a decision in a mock interview retro, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-090",
      "type": "ordering",
      "question": "Order these from lowest to highest effectiveness for failure-mode reasoning quality.",
      "items": [
        "Define rollout guardrails",
        "Define post-rollout validation",
        "Set success constraint",
        "Choose highest-leverage control",
        "Identify primary risk"
      ],
      "correctOrder": [4, 2, 3, 0, 1],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Good ordering protects both delivery speed and system reliability. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-091",
      "type": "ordering",
      "question": "Order by increasing maturity for failure-mode reasoning quality.",
      "items": [
        "Capture current signal",
        "Iterate controls",
        "Pick first mitigation",
        "Form diagnosis hypothesis",
        "Measure impact"
      ],
      "correctOrder": [0, 3, 2, 4, 1],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "This ranking is about dependency awareness between decisions. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-092",
      "type": "ordering",
      "question": "Arrange these controls from least to most robust for failure-mode reasoning quality.",
      "items": [
        "State assumptions",
        "Evaluate tradeoffs",
        "Propose design",
        "Summarize risks",
        "Clarify requirement"
      ],
      "correctOrder": [4, 0, 2, 1, 3],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Prioritize steps that improve decision confidence before hard commitment. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-093",
      "type": "ordering",
      "question": "Rank these from weakest to strongest for failure-mode reasoning quality.",
      "items": [
        "Prioritize failure/abuse paths",
        "Map trust/flow boundaries",
        "List assets or users",
        "Verify with drills",
        "Implement controls"
      ],
      "correctOrder": [2, 1, 0, 4, 3],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "A mature order avoids premature optimization and late-stage surprises. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-094",
      "type": "ordering",
      "question": "Order these from lowest to highest effectiveness for failure-mode reasoning quality.",
      "items": [
        "Review residual risk",
        "Plan migration",
        "Define objective",
        "Select approach",
        "Compare alternatives"
      ],
      "correctOrder": [2, 4, 3, 1, 0],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "The wrong sequence often causes rework and hidden residual risk. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-095",
      "type": "ordering",
      "question": "Order by increasing maturity for failure-mode reasoning quality.",
      "items": [
        "Capture baseline metrics",
        "Apply constraints",
        "Choose architecture change",
        "Estimate capacity or risk envelope",
        "Monitor outcomes"
      ],
      "correctOrder": [0, 3, 1, 2, 4],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "This ranking is about dependency awareness between decisions. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-096",
      "type": "ordering",
      "question": "Arrange these controls from least to most robust for failure-mode reasoning quality.",
      "items": [
        "Define post-rollout validation",
        "Define rollout guardrails",
        "Set success constraint",
        "Identify primary risk",
        "Choose highest-leverage control"
      ],
      "correctOrder": [3, 2, 4, 1, 0],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "A solid sequence reduces uncertainty before committing to expensive changes. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    },
    {
      "id": "int-fm-097",
      "type": "ordering",
      "question": "Rank these from weakest to strongest for failure-mode reasoning quality.",
      "items": [
        "Capture current signal",
        "Form diagnosis hypothesis",
        "Pick first mitigation",
        "Measure impact",
        "Iterate controls"
      ],
      "correctOrder": [0, 1, 2, 3, 4],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "A mature order avoids premature optimization and late-stage surprises. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        }
      ]
    },
    {
      "id": "int-fm-098",
      "type": "ordering",
      "question": "Order these from lowest to highest effectiveness for failure-mode reasoning quality.",
      "items": [
        "State assumptions",
        "Clarify requirement",
        "Evaluate tradeoffs",
        "Summarize risks",
        "Propose design"
      ],
      "correctOrder": [1, 0, 4, 2, 3],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "The wrong sequence often causes rework and hidden residual risk. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        }
      ]
    },
    {
      "id": "int-fm-099",
      "type": "ordering",
      "question": "Order by increasing maturity for failure-mode reasoning quality.",
      "items": [
        "Prioritize failure/abuse paths",
        "Implement controls",
        "Verify with drills",
        "Map trust/flow boundaries",
        "List assets or users"
      ],
      "correctOrder": [4, 3, 0, 1, 2],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Ordering items measure execution discipline more than terminology recall. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "NIST SP 800-61 Rev.2 Incident Handling Guide",
          "url": "https://csrc.nist.gov/pubs/sp/800/61/r2/final"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-fm-100",
      "type": "ordering",
      "question": "Rank these from weakest to strongest for failure-mode reasoning quality.",
      "items": [
        "Select approach",
        "Compare alternatives",
        "Define objective",
        "Review residual risk",
        "Plan migration"
      ],
      "correctOrder": [2, 1, 0, 4, 3],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In failure analysis depth and mitigation sequencing, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "A defensible order keeps learning cheap early and rollout safer later. In failure analysis depth and mitigation sequencing, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Google SRE Book: Managing Incidents",
          "url": "https://sre.google/sre-book/managing-incidents/"
        }
      ]
    }
  ]
}
