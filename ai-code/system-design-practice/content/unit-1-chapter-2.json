{
  "unit": 1,
  "unitTitle": "Estimation",
  "chapter": 2,
  "chapterTitle": "Time Math",
  "chapterDescription": "Seconds per day, requests to QPS, SLA percentages to downtime",
  "problems": [
    {
      "id": "time-002",
      "type": "multiple-choice",
      "question": "A service receives 10 million requests per day. What's the average QPS?",
      "options": ["~12", "~120", "~1,200", "~12,000"],
      "correct": 1,
      "explanation": "10M requests ÷ 86,400 seconds ≈ 116 QPS. Quick trick: divide daily requests by 100K to estimate QPS.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-003",
      "type": "multiple-choice",
      "question": "Your service handles 500 QPS. How many requests per day is that?",
      "options": [
        "~4.3 million",
        "~43 million",
        "~430 million",
        "~4.3 billion"
      ],
      "correct": 1,
      "explanation": "500 × 86,400 = 43.2 million. Quick trick: multiply QPS by 100K to estimate daily requests.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-004",
      "type": "multiple-choice",
      "question": "A 99.9% SLA means how much downtime per year?",
      "options": ["~53 minutes", "~8.7 hours", "~3.6 days", "~36.5 days"],
      "correct": 1,
      "explanation": "0.1% of a year = 0.001 × 365 × 24 = 8.76 hours. Three nines = ~9 hours/year downtime.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-005",
      "type": "multiple-choice",
      "question": "A 99.99% SLA (four nines) allows how much downtime per year?",
      "options": ["~5 minutes", "~52 minutes", "~8.7 hours", "~87 hours"],
      "correct": 1,
      "explanation": "0.01% of a year = 0.0001 × 365 × 24 × 60 = 52.6 minutes. Four nines = ~52 minutes/year.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-007",
      "type": "multiple-choice",
      "question": "Your batch job runs every hour. How many times does it run per month (30 days)?",
      "options": ["~72", "~720", "~7,200", "~72,000"],
      "correct": 1,
      "explanation": "24 hours × 30 days = 720 runs per month.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-008",
      "type": "multiple-choice",
      "question": "A cron job runs every 5 minutes. How many executions per day?",
      "options": ["~29", "~288", "~1,440", "~2,880"],
      "correct": 1,
      "explanation": "60 minutes ÷ 5 = 12 per hour. 12 × 24 = 288 executions per day.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-009",
      "type": "multiple-choice",
      "question": "You need 99.95% uptime. What's your monthly downtime budget?",
      "options": ["~2 minutes", "~22 minutes", "~3.6 hours", "~36 hours"],
      "correct": 1,
      "explanation": "0.05% of 30 days = 0.0005 × 30 × 24 × 60 = 21.6 minutes per month.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-010",
      "type": "multiple-choice",
      "question": "Peak traffic is 3× average. If average QPS is 1,000 and peak lasts 4 hours, how many total requests occur during that peak period?",
      "options": [
        "~4.3 million",
        "~43 million",
        "~430 million",
        "~4.3 billion"
      ],
      "correct": 1,
      "explanation": "Peak QPS = 3,000. Total requests = 3,000 × 4 hours × 3,600 sec/hr = 43.2 million requests during the peak window.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-011",
      "type": "multiple-choice",
      "question": "A service processes 1 billion requests per month. What's the average QPS?",
      "options": ["~39", "~390", "~3,900", "~39,000"],
      "correct": 1,
      "explanation": "1B ÷ (30 × 86,400) = 1B ÷ 2.6M ≈ 385 QPS. Quick estimate: 1B/month ÷ 2.5M seconds/month ≈ 400 QPS.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-012",
      "type": "multiple-choice",
      "question": "Your p99 latency target is 200ms. If you handle 10,000 requests, how many can exceed 200ms while still meeting the target?",
      "options": ["1", "10", "100", "1,000"],
      "correct": 2,
      "explanation": "p99 means 99% of requests must be under 200ms. 1% can exceed it. 1% of 10,000 = 100 requests.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-013",
      "type": "multiple-choice",
      "question": "A cache TTL is 5 minutes. How many times will a popular item be refreshed per day?",
      "options": ["~29", "~288", "~1,440", "~2,880"],
      "correct": 1,
      "explanation": "24 hours × 60 minutes ÷ 5 minutes = 288 refreshes per day.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-014",
      "type": "multiple-choice",
      "question": "You're designing a rate limiter: 100 requests per user per minute. What's the per-second limit?",
      "options": ["~0.6", "~1.7", "~10", "~100"],
      "correct": 1,
      "explanation": "100 ÷ 60 ≈ 1.67 requests per second. In practice, you'd use a token bucket that refills at this rate.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-017",
      "type": "multiple-choice",
      "question": "A 99% SLA means how much downtime per month (30 days)?",
      "options": ["~43 minutes", "~7.2 hours", "~3 days", "~7.2 days"],
      "correct": 1,
      "explanation": "1% of 30 days = 0.01 × 30 × 24 = 7.2 hours per month. Two nines is not very reliable!",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-018",
      "type": "multiple-choice",
      "question": "Your API handles 50 million requests per week. What's the average QPS?",
      "options": ["~8", "~83", "~830", "~8,300"],
      "correct": 1,
      "explanation": "50M ÷ (7 × 86,400) = 50M ÷ 604,800 ≈ 83 QPS.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-019",
      "type": "multiple-choice",
      "question": "A heartbeat is sent every 30 seconds. How many heartbeats per day?",
      "options": ["~288", "~2,880", "~28,800", "~288,000"],
      "correct": 1,
      "explanation": "86,400 seconds ÷ 30 seconds = 2,880 heartbeats per day.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-020",
      "type": "multiple-choice",
      "question": "Your service runs at 10,000 QPS. How many requests per hour?",
      "options": [
        "~3.6 million",
        "~36 million",
        "~360 million",
        "~3.6 billion"
      ],
      "correct": 1,
      "explanation": "10,000 × 3,600 = 36 million requests per hour.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-021",
      "type": "multiple-choice",
      "question": "A 99.999% SLA (five nines) allows how much downtime per year?",
      "options": ["~5 seconds", "~5 minutes", "~52 minutes", "~8.7 hours"],
      "correct": 1,
      "explanation": "0.001% of a year = 0.00001 × 365 × 24 × 60 = 5.26 minutes. Five nines = ~5 minutes/year.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-023",
      "type": "multiple-choice",
      "question": "A job processes 1,000 items per second. How long to process 1 million items?",
      "options": ["~1.7 minutes", "~17 minutes", "~1.7 hours", "~17 hours"],
      "correct": 1,
      "explanation": "1,000,000 ÷ 1,000 = 1,000 seconds = 16.7 minutes.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-024",
      "type": "multiple-choice",
      "question": "Your monitoring samples metrics every 10 seconds. How many data points per day per metric?",
      "options": ["~864", "~8,640", "~86,400", "~864,000"],
      "correct": 1,
      "explanation": "86,400 seconds ÷ 10 = 8,640 samples per day per metric.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-025",
      "type": "multiple-choice",
      "question": "A user session timeout is 30 minutes. If a user is active 8 hours/day, how many sessions?",
      "options": ["~4", "~16", "~32", "~64"],
      "correct": 1,
      "explanation": "8 hours × 60 minutes ÷ 30 minutes = 16 sessions (assuming continuous activity requiring re-auth).",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-027",
      "type": "multiple-choice",
      "question": "Your database handles 100 writes per second. How many writes per day?",
      "options": ["~864,000", "~8.64 million", "~86.4 million", "~864 million"],
      "correct": 1,
      "explanation": "100 × 86,400 = 8.64 million writes per day.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-028",
      "type": "multiple-choice",
      "question": "A retry has exponential backoff: 1s, 2s, 4s, 8s, 16s. Total time if all 5 retries fail?",
      "options": ["~15 seconds", "~31 seconds", "~63 seconds", "~127 seconds"],
      "correct": 1,
      "explanation": "1 + 2 + 4 + 8 + 16 = 31 seconds total wait time across all retries.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-029",
      "type": "multiple-choice",
      "question": "A log rotates every 6 hours. How many log files per month?",
      "options": ["~12", "~120", "~1,200", "~12,000"],
      "correct": 1,
      "explanation": "24 hours ÷ 6 = 4 files per day. 4 × 30 = 120 files per month.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-030",
      "type": "multiple-choice",
      "question": "Your p95 latency is 100ms. Out of 1 million requests, how many exceed 100ms?",
      "options": ["~5,000", "~50,000", "~500,000", "~950,000"],
      "correct": 1,
      "explanation": "5% of requests exceed p95. 5% of 1,000,000 = 50,000 requests.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-032",
      "type": "multiple-choice",
      "question": "A task queue processes jobs at 50/second. How long to clear a backlog of 100,000 jobs?",
      "options": ["~3 minutes", "~33 minutes", "~3.3 hours", "~33 hours"],
      "correct": 1,
      "explanation": "100,000 ÷ 50 = 2,000 seconds = 33.3 minutes.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-033",
      "type": "multiple-choice",
      "question": "Your API rate limit is 1,000 requests per hour. What's that per minute?",
      "options": ["~1.7", "~17", "~167", "~1,670"],
      "correct": 1,
      "explanation": "1,000 ÷ 60 ≈ 16.7 requests per minute.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-034",
      "type": "multiple-choice",
      "question": "A 99.9% SLA allows how much downtime per month (30 days)?",
      "options": ["~4 minutes", "~43 minutes", "~7 hours", "~43 hours"],
      "correct": 1,
      "explanation": "0.1% of 30 days = 0.001 × 30 × 24 × 60 = 43.2 minutes per month.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-035",
      "type": "multiple-choice",
      "question": "A daily backup takes 2 hours. What percentage of the day is spent backing up?",
      "options": ["~4%", "~8%", "~12%", "~20%"],
      "correct": 1,
      "explanation": "2 hours ÷ 24 hours = 8.3% of the day.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-036",
      "type": "multiple-choice",
      "question": "Your service receives 1 request per second. How many per year?",
      "options": [
        "~3.2 million",
        "~32 million",
        "~320 million",
        "~3.2 billion"
      ],
      "correct": 1,
      "explanation": "1 × 86,400 × 365 = 31.5 million requests per year.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-037",
      "type": "multiple-choice",
      "question": "A health check runs every 15 seconds. How many checks per hour?",
      "options": ["~24", "~240", "~2,400", "~24,000"],
      "correct": 1,
      "explanation": "3,600 seconds ÷ 15 = 240 health checks per hour.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. A good sanity check compares against anchor numbers and names which assumption must change if the result looks implausible.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-038",
      "type": "multiple-choice",
      "question": "An event processes in 50ms average. What's the theoretical max throughput?",
      "options": ["~2/sec", "~20/sec", "~200/sec", "~2,000/sec"],
      "correct": 1,
      "explanation": "1,000ms ÷ 50ms = 20 events per second maximum (single-threaded).",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-039",
      "type": "multiple-choice",
      "question": "Your token expires in 1 hour. A user is active 10 hours/day. How many token refreshes?",
      "options": ["~5", "~10", "~20", "~100"],
      "correct": 1,
      "explanation": "10 hours of activity ÷ 1 hour token lifetime = 10 refreshes (one per hour of activity).",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-041",
      "type": "multiple-choice",
      "question": "A message queue has 5ms processing time per message. Max messages per second (single consumer)?",
      "options": ["~20", "~200", "~2,000", "~20,000"],
      "correct": 1,
      "explanation": "1,000ms ÷ 5ms = 200 messages per second maximum.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-042",
      "type": "multiple-choice",
      "question": "Your CI pipeline runs 50 times per day, averaging 10 minutes each. Total CI time per day?",
      "options": ["~83 minutes", "~8.3 hours", "~83 hours", "~8.3 days"],
      "correct": 1,
      "explanation": "50 × 10 = 500 minutes = 8.3 hours of CI time per day.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-043",
      "type": "multiple-choice",
      "question": "A lease expires in 30 seconds and needs renewal 5 seconds before expiry. How often to renew?",
      "options": [
        "Every 5 seconds",
        "Every 25 seconds",
        "Every 30 seconds",
        "Every 35 seconds"
      ],
      "correct": 1,
      "explanation": "Renew 5 seconds before the 30-second expiry = renew every 25 seconds.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-044",
      "type": "multiple-choice",
      "question": "100 million daily active users, each makes 10 requests/day. What's the QPS?",
      "options": ["~1,200", "~12,000", "~120,000", "~1.2 million"],
      "correct": 1,
      "explanation": "100M × 10 = 1 billion requests/day. 1B ÷ 86,400 ≈ 11,574 QPS.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-045",
      "type": "multiple-choice",
      "question": "A DNS TTL is 5 minutes. Your app caches DNS. How many DNS lookups per day per domain?",
      "options": ["~29", "~288", "~2,880", "~28,800"],
      "correct": 1,
      "explanation": "1,440 minutes/day ÷ 5 minutes = 288 lookups per day.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "RFC 1035: Domain names - implementation and specification",
          "url": "https://www.rfc-editor.org/rfc/rfc1035"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-046",
      "type": "multiple-choice",
      "question": "Your database connection pool refreshes connections every 10 minutes. Connections refreshed per day?",
      "options": ["~14", "~144", "~1,440", "~14,400"],
      "correct": 1,
      "explanation": "1,440 minutes ÷ 10 = 144 connection refreshes per day.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-047",
      "type": "multiple-choice",
      "question": "An SLO targets 99.5% success rate. Out of 10,000 requests, how many failures are allowed?",
      "options": ["5", "50", "500", "5,000"],
      "correct": 1,
      "explanation": "0.5% failure rate allowed. 0.5% of 10,000 = 50 failures.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-048",
      "type": "multiple-choice",
      "question": "A weekly batch job runs for 3 hours. What percentage of the week is it running?",
      "options": ["~0.2%", "~1.8%", "~4.2%", "~12.5%"],
      "correct": 1,
      "explanation": "3 hours ÷ 168 hours/week = 1.8% of the week.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-049",
      "type": "multiple-choice",
      "question": "Your p50 latency is 20ms. What does this mean?",
      "options": [
        "20ms is the minimum latency",
        "50% of requests are under 20ms",
        "50% of requests are over 20ms",
        "Average latency is 20ms"
      ],
      "correct": 1,
      "explanation": "p50 (median) means 50% of requests complete in 20ms or less.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-051",
      "type": "multiple-choice",
      "question": "A circuit breaker opens for 30 seconds after 5 failures. Max breaker trips per hour?",
      "options": ["~12", "~60", "~120", "~600"],
      "correct": 2,
      "explanation": "3,600 seconds ÷ 30 = 120 possible trips per hour (if it keeps failing and resetting).",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Circuit Breaker",
          "url": "https://martinfowler.com/bliki/CircuitBreaker.html"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-052",
      "type": "multiple-choice",
      "question": "Your deploy takes 15 minutes with 0 downtime. You deploy 4 times daily. Total deploy time?",
      "options": ["~15 minutes", "~1 hour", "~4 hours", "~15 hours"],
      "correct": 1,
      "explanation": "15 minutes × 4 deploys = 60 minutes = 1 hour of deploy time per day.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        }
      ]
    },
    {
      "id": "time-053",
      "type": "multiple-choice",
      "question": "A user's JWT expires in 15 minutes. How many tokens issued per 8-hour session?",
      "options": ["~8", "~32", "~128", "~480"],
      "correct": 1,
      "explanation": "8 hours × 60 minutes ÷ 15 minutes = 32 tokens per session.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-054",
      "type": "multiple-choice",
      "question": "1,000 QPS with 100ms average latency. Requests in-flight at any moment (Little's Law)?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 1,
      "explanation": "Little's Law: L = λW. 1,000 req/sec × 0.1 sec = 100 concurrent requests.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-055",
      "type": "multiple-choice",
      "question": "A scraper fetches 10 pages/second. How long to scrape 1 million pages?",
      "options": ["~2.8 hours", "~28 hours", "~280 hours", "~2,800 hours"],
      "correct": 1,
      "explanation": "1,000,000 ÷ 10 = 100,000 seconds = 27.8 hours.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-056",
      "type": "multiple-choice",
      "question": "Logs are retained for 90 days. If you write 1GB/day, total storage needed?",
      "options": ["~9 GB", "~90 GB", "~900 GB", "~9 TB"],
      "correct": 1,
      "explanation": "90 days × 1 GB/day = 90 GB of log storage.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-057",
      "type": "multiple-choice",
      "question": "A cron runs at */15 (every 15 minutes). Executions per week?",
      "options": ["~67", "~672", "~6,720", "~67,200"],
      "correct": 1,
      "explanation": "4 per hour × 24 hours × 7 days = 672 executions per week.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-058",
      "type": "multiple-choice",
      "question": "Your timeout is 5 seconds. With 3 retries (no backoff), max wait per request?",
      "options": ["~5 seconds", "~15 seconds", "~20 seconds", "~25 seconds"],
      "correct": 2,
      "explanation": "Original attempt + 3 retries = 4 attempts × 5 seconds = 20 seconds max.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-059",
      "type": "multiple-choice",
      "question": "200 QPS average, but traffic doubles during a 2-hour lunch rush. Requests during lunch?",
      "options": [
        "~144,000",
        "~1.44 million",
        "~2.88 million",
        "~14.4 million"
      ],
      "correct": 2,
      "explanation": "400 QPS × 2 hours × 3,600 sec/hr = 2.88 million requests during lunch.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-061",
      "type": "multiple-choice",
      "question": "A canary deployment runs for 30 minutes with 5% traffic. Normal QPS is 1,000. Canary requests?",
      "options": ["~9,000", "~90,000", "~900,000", "~9 million"],
      "correct": 1,
      "explanation": "5% of 1,000 = 50 QPS to canary. 50 × 30 × 60 = 90,000 requests.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-062",
      "type": "multiple-choice",
      "question": "99.99% of requests succeed. You serve 10 million requests/day. Daily failures?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 2,
      "explanation": "0.01% failure rate. 0.0001 × 10,000,000 = 1,000 failures per day.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-063",
      "type": "multiple-choice",
      "question": "Your GC pause is 50ms and happens every 10 seconds. What % of time is paused?",
      "options": ["~0.05%", "~0.5%", "~5%", "~50%"],
      "correct": 1,
      "explanation": "50ms pause every 10,000ms = 50/10,000 = 0.5% time paused.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-064",
      "type": "multiple-choice",
      "question": "A connection has a 60-second idle timeout. Active connections drop to 0. Max time until all connections close?",
      "options": ["~30 seconds", "~60 seconds", "~120 seconds", "~600 seconds"],
      "correct": 1,
      "explanation": "After traffic stops, connections idle out in 60 seconds (the timeout value).",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-065",
      "type": "multiple-choice",
      "question": "You process 1TB of data at 100MB/second. How long?",
      "options": ["~17 minutes", "~2.8 hours", "~17 hours", "~2.8 days"],
      "correct": 1,
      "explanation": "1TB = 1,000GB = 1,000,000MB. 1,000,000 ÷ 100 = 10,000 seconds = 2.8 hours.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-066",
      "type": "multiple-choice",
      "question": "A feature flag check takes 1ms. You check 100 flags per request at 1,000 QPS. Time spent on flags per second?",
      "options": ["~0.1 seconds", "~1 second", "~10 seconds", "~100 seconds"],
      "correct": 3,
      "explanation": "1ms × 100 flags × 1,000 requests = 100,000ms = 100 seconds of flag-checking time per second (need parallelism!).",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-067",
      "type": "multiple-choice",
      "question": "Your SLI shows 99.8% success this month. Budget was 99.9%. How much error budget did you burn?",
      "options": ["~80%", "~100%", "~200%", "~800%"],
      "correct": 2,
      "explanation": "Budget allowed 0.1% errors. You had 0.2% errors. 0.2/0.1 = 200% of budget burned.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-068",
      "type": "multiple-choice",
      "question": "A mutex lock is held for 100μs on average. Max locks per second (single thread)?",
      "options": ["~100", "~1,000", "~10,000", "~100,000"],
      "correct": 2,
      "explanation": "1,000,000μs per second ÷ 100μs per lock = 10,000 locks per second max.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-069",
      "type": "multiple-choice",
      "question": "Your API client retries 3 times with 1-second delays. Total time if all fail (including initial)?",
      "options": ["~3 seconds", "~4 seconds", "~6 seconds", "~7 seconds"],
      "correct": 0,
      "explanation": "Initial attempt + 3 retries = 4 attempts. 3 delays of 1 second = 3 seconds (delays happen between attempts).",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-070",
      "type": "multiple-choice",
      "question": "A video is transcoded at 2× realtime speed. How long to transcode a 2-hour movie?",
      "options": ["~30 minutes", "~1 hour", "~2 hours", "~4 hours"],
      "correct": 1,
      "explanation": "2× realtime means 1 hour of video takes 30 minutes. 2-hour movie = 1 hour to transcode.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-071",
      "type": "multiple-choice",
      "question": "How many 100ms requests can you serve per second with 10 threads?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 1,
      "explanation": "Each thread serves 10 requests/second (1000ms ÷ 100ms). 10 threads × 10 = 100 requests/second.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-072",
      "type": "multiple-choice",
      "question": "A queue drains at 100/second but receives 120/second. Backlog after 1 hour?",
      "options": ["~7,200", "~72,000", "~720,000", "~7.2 million"],
      "correct": 1,
      "explanation": "Net backlog rate = 20/second. 20 × 3,600 = 72,000 items backed up after 1 hour.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-073",
      "type": "multiple-choice",
      "question": "Election timeout is 150ms. Heartbeat interval should be roughly?",
      "options": ["~15ms", "~50ms", "~150ms", "~300ms"],
      "correct": 1,
      "explanation": "Heartbeat should be significantly less than election timeout. Rule of thumb: 1/3 to 1/10 of timeout.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-074",
      "type": "multiple-choice",
      "question": "Your endpoint averages 25ms latency. Max QPS from a single connection (sequential requests)?",
      "options": ["~4", "~40", "~400", "~4,000"],
      "correct": 1,
      "explanation": "1,000ms ÷ 25ms = 40 sequential requests per second per connection.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-075",
      "type": "multiple-choice",
      "question": "A billing cycle is monthly. You have 100,000 customers. Average bills processed per day?",
      "options": ["~333", "~3,333", "~33,333", "~333,333"],
      "correct": 1,
      "explanation": "100,000 bills spread over 30 days = 3,333 bills per day on average.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Growth planning should show today vs horizon requirements side by side because compounding makes small percentages material quickly.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-076",
      "type": "multiple-choice",
      "question": "A cache warm-up fetches 10,000 keys at 100/second. How long until warm?",
      "options": [
        "~10 seconds",
        "~100 seconds",
        "~1,000 seconds",
        "~10,000 seconds"
      ],
      "correct": 1,
      "explanation": "10,000 ÷ 100 = 100 seconds to warm up the cache.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-077",
      "type": "multiple-choice",
      "question": "Peak hours are 6 PM - 10 PM (4 hours). What percentage of daily traffic if peak is 3× average?",
      "options": ["~25%", "~37%", "~50%", "~75%"],
      "correct": 1,
      "explanation": "4 hours at 3× + 20 hours at 1× = 12 + 20 = 32 units. Peak portion = 12/32 = 37.5%.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-078",
      "type": "multiple-choice",
      "question": "Kafka retention is 7 days. Messages/second is 1,000. Total messages retained?",
      "options": ["~60 million", "~600 million", "~6 billion", "~60 billion"],
      "correct": 1,
      "explanation": "1,000 × 86,400 × 7 = 604.8 million messages retained.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka Documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-079",
      "type": "multiple-choice",
      "question": "A request travels through 5 services, each adding 10ms latency. Total added latency?",
      "options": ["~5ms", "~50ms", "~500ms", "~5,000ms"],
      "correct": 1,
      "explanation": "5 services × 10ms each = 50ms total added latency (assuming sequential calls).",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-081",
      "type": "multiple-choice",
      "question": "An A/B test needs 10,000 users per variant. At 1,000 new users/day, how long for 2 variants?",
      "options": ["~10 days", "~20 days", "~100 days", "~200 days"],
      "correct": 1,
      "explanation": "Need 20,000 total users. 20,000 ÷ 1,000 per day = 20 days.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-082",
      "type": "multiple-choice",
      "question": "A pod restarts in 30 seconds. You have 10 pods. Full rolling restart takes?",
      "options": ["~30 seconds", "~5 minutes", "~30 minutes", "~5 hours"],
      "correct": 1,
      "explanation": "10 pods × 30 seconds = 300 seconds = 5 minutes (sequential rolling restart).",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-083",
      "type": "multiple-choice",
      "question": "Your CDN cache hit rate is 95%. Origin gets 5% of traffic. If CDN QPS is 10,000, origin QPS?",
      "options": ["~50", "~500", "~5,000", "~9,500"],
      "correct": 1,
      "explanation": "5% of 10,000 = 500 QPS hitting the origin server.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-084",
      "type": "multiple-choice",
      "question": "A microservice calls 3 downstream services in parallel, each taking 50ms. Total added latency?",
      "options": ["~17ms", "~50ms", "~100ms", "~150ms"],
      "correct": 1,
      "explanation": "Parallel calls: latency = max(50, 50, 50) = 50ms, not the sum.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-085",
      "type": "multiple-choice",
      "question": "Your on-call rotation is weekly, team of 6. How many weeks between your on-call shifts?",
      "options": ["~3 weeks", "~5 weeks", "~6 weeks", "~12 weeks"],
      "correct": 1,
      "explanation": "6 people rotating weekly = each person on-call every 6 weeks. 5 weeks gap between shifts.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-086",
      "type": "multiple-choice",
      "question": "Rate limit: 10,000 requests per day. Steady usage requires what average QPS?",
      "options": ["~0.01", "~0.12", "~1.2", "~12"],
      "correct": 1,
      "explanation": "10,000 ÷ 86,400 = 0.116 QPS average to stay under the limit.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-087",
      "type": "multiple-choice",
      "question": "A leader election happens every 10 seconds. Elections per year?",
      "options": ["~3.2 million", "~320,000", "~32,000", "~3,200"],
      "correct": 0,
      "explanation": "31.5 million seconds/year ÷ 10 = 3.15 million elections per year.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-088",
      "type": "multiple-choice",
      "question": "Your mobile app polls every 30 seconds. 1 million active users. QPS from polling?",
      "options": ["~3,300", "~33,000", "~330,000", "~3.3 million"],
      "correct": 1,
      "explanation": "1,000,000 users ÷ 30 seconds = 33,333 QPS from polling.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-089",
      "type": "multiple-choice",
      "question": "A database query takes 5ms. You need to run 1,000 queries. Single-threaded time?",
      "options": ["~0.5 seconds", "~5 seconds", "~50 seconds", "~500 seconds"],
      "correct": 1,
      "explanation": "1,000 queries × 5ms = 5,000ms = 5 seconds.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-090",
      "type": "multiple-choice",
      "question": "Retention policy: delete data older than 2 years. Data grows 10GB/month. Max storage?",
      "options": ["~24 GB", "~240 GB", "~2.4 TB", "~24 TB"],
      "correct": 1,
      "explanation": "2 years = 24 months × 10 GB/month = 240 GB max storage under this policy.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-091",
      "type": "multiple-choice",
      "question": "A websocket heartbeat is every 20 seconds. 50,000 connections. Heartbeat messages/second?",
      "options": ["~250", "~2,500", "~25,000", "~250,000"],
      "correct": 1,
      "explanation": "50,000 connections ÷ 20 seconds = 2,500 heartbeat messages per second.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-092",
      "type": "multiple-choice",
      "question": "Your SLO is p99 < 500ms. You had 100 requests > 500ms out of 1,000. Did you meet SLO?",
      "options": [
        "Yes, 10% is under 11%",
        "No, 10% exceeds 1%",
        "Yes, 100 is under 500",
        "Need more data"
      ],
      "correct": 1,
      "explanation": "p99 means only 1% can exceed threshold. 10% (100/1000) exceeded it. SLO violated.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ]
    },
    {
      "id": "time-093",
      "type": "multiple-choice",
      "question": "Batch ingestion runs for 2 hours every night. What's the daily processing window utilization?",
      "options": ["~2%", "~8%", "~25%", "~50%"],
      "correct": 1,
      "explanation": "2 hours ÷ 24 hours = 8.3% of the day spent on batch ingestion.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-094",
      "type": "multiple-choice",
      "question": "Network RTT is 50ms between datacenters. Synchronous cross-DC call adds how much latency?",
      "options": ["~25ms", "~50ms", "~100ms", "~200ms"],
      "correct": 1,
      "explanation": "RTT already means round-trip time. A single synchronous request-response call adds roughly one RTT, so about 50ms.",
      "detailedExplanation": "RTT is already end-to-end request plus response for one exchange, so you should not double it again for a single call. The call adds roughly one RTT (~50ms), then any application/server processing on top. This distinction matters when estimating cross-region overhead and tail latency impact.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-095",
      "type": "multiple-choice",
      "question": "Your deploy freezes start Dec 15 and end Jan 2. How many freeze days?",
      "options": ["~15 days", "~19 days", "~30 days", "~45 days"],
      "correct": 1,
      "explanation": "Dec 15-31 = 17 days + Jan 1-2 = 2 days = 19 days of freeze.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-096",
      "type": "multiple-choice",
      "question": "You have 99.9% availability and serve 1 million requests/day. Expected daily failures?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 2,
      "explanation": "0.1% failure rate. 0.001 × 1,000,000 = 1,000 failed requests per day.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-097",
      "type": "multiple-choice",
      "question": "A rate limiter allows 60 requests/minute with no bursting. Max requests in 10 seconds?",
      "options": ["~1", "~6", "~10", "~60"],
      "correct": 2,
      "explanation": "60/minute = 1/second. In 10 seconds, max 10 requests (no bursting allowed).",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-098",
      "type": "multiple-choice",
      "question": "Sprint is 2 weeks. Release is every sprint. Releases per year?",
      "options": ["~12", "~26", "~52", "~104"],
      "correct": 1,
      "explanation": "52 weeks per year ÷ 2 weeks per sprint = 26 releases per year.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-099",
      "type": "multiple-choice",
      "question": "Your export job handles 10,000 records/minute. Time for 5 million records?",
      "options": ["~83 minutes", "~8.3 hours", "~83 hours", "~8.3 days"],
      "correct": 1,
      "explanation": "5,000,000 ÷ 10,000 per minute = 500 minutes = 8.3 hours.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-100",
      "type": "multiple-choice",
      "question": "A TTL is 1 hour. You have 1 million cached items uniformly distributed. Expirations per second?",
      "options": ["~28", "~278", "~2,780", "~27,800"],
      "correct": 1,
      "explanation": "1 million items expire over 3,600 seconds = 278 expirations per second.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-101",
      "type": "multiple-choice",
      "question": "Your service has 99.9% success rate, handles 10,000 QPS, and failed requests retry twice on average. What's the actual QPS including retries?",
      "options": ["~10,010", "~10,020", "~10,100", "~10,200"],
      "correct": 1,
      "explanation": "0.1% of 10,000 = 10 failures/sec. Each failure retries twice = 20 extra QPS. Total = 10,020 QPS.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "time-102",
      "type": "multiple-choice",
      "question": "Cache hit rate is 95%, cache latency is 5ms, cache miss adds a 50ms DB lookup. What's the average request latency?",
      "options": ["~5.25ms", "~7.5ms", "~27.5ms", "~52.5ms"],
      "correct": 1,
      "explanation": "Hits (95%): 5ms. Misses (5%): 5ms + 50ms = 55ms. Average = 0.95(5) + 0.05(55) = 4.75 + 2.75 = 7.5ms.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-103",
      "type": "multiple-choice",
      "question": "You're at 2,000 QPS with 10% monthly traffic growth. Capacity is 10,000 QPS. Approximately when do you need to scale?",
      "options": ["~8 months", "~12 months", "~17 months", "~24 months"],
      "correct": 2,
      "explanation": "Need 5× growth (2K to 10K). 1.1^n = 5, so n = ln(5)/ln(1.1) ≈ 16.9 months. You'd want to scale before hitting capacity.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-104",
      "type": "multiple-choice",
      "question": "An engineer proposes 50GB storage for a year of access logs: 500 QPS average, 200 bytes per log entry. Is this estimate reasonable?",
      "options": [
        "About right",
        "Too high by ~10×",
        "Too low by ~10×",
        "Too low by ~50×"
      ],
      "correct": 3,
      "explanation": "500 QPS × 200 bytes × 86,400 sec/day × 365 days = 3.15 TB. Proposal is 50GB—off by ~63×, so too low by ~50×.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-105",
      "type": "multiple-choice",
      "question": "Your p50 is 20ms, p99 is 200ms. A request makes 3 sequential calls to this service. What's the p99 of the combined request?",
      "options": [
        "~200ms",
        "~400ms",
        "~600ms",
        "Cannot determine from this data"
      ],
      "correct": 3,
      "explanation": "p99 of a sum ≠ sum of p99s. The 99th percentile of each call rarely aligns. You need the full latency distribution or must measure the combined path directly.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-106",
      "type": "multiple-choice",
      "question": "You deploy 4× daily, each with 0.1% chance of causing a 15-minute incident. What's the expected monthly downtime from deploy incidents?",
      "options": [
        "~0.18 minutes",
        "~1.8 minutes",
        "~18 minutes",
        "~180 minutes"
      ],
      "correct": 1,
      "explanation": "4 deploys × 30 days = 120/month. Expected incidents = 120 × 0.001 = 0.12. Expected downtime = 0.12 × 15 min = 1.8 minutes.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        }
      ]
    },
    {
      "id": "time-107",
      "type": "multiple-choice",
      "question": "Leader election takes 5 seconds. Your leader fails once per month on average. What's the availability impact from leader failures alone?",
      "options": ["~99.9998%", "~99.998%", "~99.98%", "~99.8%"],
      "correct": 0,
      "explanation": "5 sec downtime per month. Month = 30 × 86,400 = 2.59M sec. Availability = 1 - (5/2,590,000) = 99.9998%.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        }
      ]
    },
    {
      "id": "time-108",
      "type": "multiple-choice",
      "question": "You need 99.95% availability. MTBF (mean time between failures) is 720 hours. What's the maximum MTTR (mean time to recovery) you can tolerate?",
      "options": ["~5 minutes", "~22 minutes", "~2.2 hours", "~5 hours"],
      "correct": 1,
      "explanation": "Availability = MTBF/(MTBF+MTTR). 0.9995 = 720/(720+MTTR). Solving: MTTR = 720 × 0.0005/0.9995 ≈ 0.36 hours = 21.6 minutes.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-109",
      "type": "multiple-choice",
      "question": "A batch job took 2 hours before optimization, 12 minutes after. It runs daily. How much compute time is saved per year?",
      "options": ["~66 hours", "~660 hours", "~1,320 hours", "~6,600 hours"],
      "correct": 1,
      "explanation": "Saved per run = 120 - 12 = 108 min = 1.8 hours. Per year = 1.8 × 365 = 657 hours ≈ 660 hours.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n001",
      "type": "numeric-input",
      "question": "A service handles 5,000 QPS. How many requests does it receive per hour?",
      "answer": 18000000,
      "tolerance": 0.1,
      "explanation": "5,000 QPS × 3,600 seconds/hour = 18 million requests per hour.",
      "detailedExplanation": "Use base-unit arithmetic plus a magnitude check to keep the estimate robust under time pressure. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n002",
      "type": "numeric-input",
      "question": "Your API receives 50 million requests per day. What's the average QPS?",
      "answer": 579,
      "tolerance": 0.15,
      "explanation": "50M ÷ 86,400 seconds = 579 QPS.",
      "detailedExplanation": "Anchor the math in base units and check each transformation to avoid compounding conversion errors. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n003",
      "type": "numeric-input",
      "question": "A cache TTL is 10 minutes. How many times will a hot key be refreshed per day?",
      "answer": 144,
      "tolerance": 0.1,
      "explanation": "1,440 minutes/day ÷ 10 minutes = 144 refreshes.",
      "detailedExplanation": "Normalize units before calculating, and keep order-of-magnitude checks explicit throughout. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n004",
      "type": "numeric-input",
      "question": "A cron job runs every 2 minutes. How many executions per week?",
      "answer": 5040,
      "tolerance": 0.1,
      "explanation": "60÷2 = 30 per hour × 24 hours × 7 days = 5,040 executions.",
      "detailedExplanation": "Reduce the problem to base units, compute, and sanity-check the output scale before finalizing. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n005",
      "type": "numeric-input",
      "question": "99.99% availability allows how many minutes of downtime per month (30 days)?",
      "answer": 4.32,
      "unit": "minutes",
      "tolerance": 0.15,
      "explanation": "0.01% of 30 days = 0.0001 × 30 × 24 × 60 = 4.32 minutes.",
      "detailedExplanation": "Start with unit normalization, then verify that the final magnitude passes a quick sanity check. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n006",
      "type": "numeric-input",
      "question": "A job processes 500 items/second. How many seconds to process 2 million items?",
      "answer": 4000,
      "unit": "seconds",
      "tolerance": 0.1,
      "explanation": "2,000,000 ÷ 500 = 4,000 seconds.",
      "detailedExplanation": "Convert to base units first, then track powers of ten so arithmetic mistakes are easier to catch. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n007",
      "type": "numeric-input",
      "question": "With 1 billion requests/month, what's the average QPS?",
      "answer": 386,
      "tolerance": 0.15,
      "explanation": "1B ÷ (30 × 86,400) = 1B ÷ 2.59M ≈ 386 QPS.",
      "detailedExplanation": "Make the units explicit at every step, then validate the resulting magnitude against known anchors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n008",
      "type": "numeric-input",
      "question": "A heartbeat is sent every 45 seconds. How many heartbeats per day?",
      "answer": 1920,
      "tolerance": 0.1,
      "explanation": "86,400 ÷ 45 = 1,920 heartbeats per day.",
      "detailedExplanation": "Do the conversion step first and maintain unit labels to prevent silent math errors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n009",
      "type": "numeric-input",
      "question": "You have 10 million DAU, each making 20 requests/day. What's the QPS?",
      "answer": 2315,
      "tolerance": 0.15,
      "explanation": "10M × 20 = 200M requests/day ÷ 86,400 = 2,315 QPS.",
      "detailedExplanation": "Use base-unit arithmetic plus a magnitude check to keep the estimate robust under time pressure. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n010",
      "type": "numeric-input",
      "question": "A rate limit is 5,000 requests/hour. What's that per second?",
      "answer": 1.39,
      "tolerance": 0.2,
      "explanation": "5,000 ÷ 3,600 = 1.39 requests per second.",
      "detailedExplanation": "Make the units explicit at every step, then validate the resulting magnitude against known anchors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n011",
      "type": "numeric-input",
      "question": "A batch job runs every 4 hours. How many runs per month (30 days)?",
      "answer": 180,
      "tolerance": 0.1,
      "explanation": "24 ÷ 4 = 6 per day × 30 days = 180 runs.",
      "detailedExplanation": "Convert to base units first, then track powers of ten so arithmetic mistakes are easier to catch. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n012",
      "type": "numeric-input",
      "question": "Your p99 latency is 300ms. Out of 50,000 requests, how many can exceed 300ms?",
      "answer": 500,
      "tolerance": 0.1,
      "explanation": "1% of 50,000 = 500 requests can exceed the p99 threshold.",
      "detailedExplanation": "Start with unit normalization, then verify that the final magnitude passes a quick sanity check. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n013",
      "type": "numeric-input",
      "question": "A 99.5% SLA allows how many hours of downtime per year?",
      "answer": 43.8,
      "unit": "hours",
      "tolerance": 0.15,
      "explanation": "0.5% of 365 × 24 = 0.005 × 8,760 = 43.8 hours.",
      "detailedExplanation": "Reduce the problem to base units, compute, and sanity-check the output scale before finalizing. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n014",
      "type": "numeric-input",
      "question": "A queue drains at 200/second but receives 180/second. After 10 minutes, what's the backlog cleared?",
      "answer": 12000,
      "tolerance": 0.1,
      "explanation": "Net drain rate = 20/second. 20 × 600 seconds = 12,000 items cleared.",
      "detailedExplanation": "Normalize units before calculating, and keep order-of-magnitude checks explicit throughout. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n015",
      "type": "numeric-input",
      "question": "2,000 QPS at 50ms average latency. Using Little's Law, how many requests are in-flight?",
      "answer": 100,
      "tolerance": 0.1,
      "explanation": "L = λW. 2,000 × 0.05 = 100 concurrent requests.",
      "detailedExplanation": "Anchor the math in base units and check each transformation to avoid compounding conversion errors. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n016",
      "type": "numeric-input",
      "question": "A video transcodes at 4× realtime. How many minutes to transcode a 3-hour movie?",
      "answer": 45,
      "unit": "minutes",
      "tolerance": 0.1,
      "explanation": "3 hours ÷ 4 = 0.75 hours = 45 minutes.",
      "detailedExplanation": "Use base-unit arithmetic plus a magnitude check to keep the estimate robust under time pressure. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n017",
      "type": "numeric-input",
      "question": "A database handles 50 writes/second. How many million writes per day?",
      "answer": 4.32,
      "unit": "million",
      "tolerance": 0.15,
      "explanation": "50 × 86,400 = 4.32 million writes per day.",
      "detailedExplanation": "Do the conversion step first and maintain unit labels to prevent silent math errors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-n018",
      "type": "numeric-input",
      "question": "Cache has 2 million items with 30-minute TTL, uniformly distributed. Expirations per second?",
      "answer": 1111,
      "tolerance": 0.15,
      "explanation": "2M items ÷ 1,800 seconds = 1,111 expirations per second.",
      "detailedExplanation": "Make the units explicit at every step, then validate the resulting magnitude against known anchors. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o001",
      "type": "ordering",
      "question": "Rank these SLA levels from most to least downtime allowed per year.",
      "items": ["99%", "99.99%", "99.9%", "99.999%"],
      "correctOrder": [0, 2, 1, 3],
      "explanation": "99% (3.65 days) > 99.9% (8.76 hrs) > 99.99% (52.6 min) > 99.999% (5.26 min).",
      "detailedExplanation": "Rank by dominant bottleneck or magnitude, then validate adjacent transitions for consistency. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o002",
      "type": "ordering",
      "question": "Rank these from most to fewest executions per day.",
      "items": [
        "Every 5 minutes",
        "Every hour",
        "Every 30 seconds",
        "Every 15 minutes"
      ],
      "correctOrder": [2, 0, 3, 1],
      "explanation": "30s (2,880) > 5min (288) > 15min (96) > 1hr (24).",
      "detailedExplanation": "Compare relative scale first, then confirm neighboring items pairwise to lock in the order. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o003",
      "type": "ordering",
      "question": "Rank these time periods from shortest to longest.",
      "items": ["1 week", "10,000 seconds", "1 month", "1 million seconds"],
      "correctOrder": [1, 0, 3, 2],
      "explanation": "10K sec (2.8 hrs) < 1 week (604K sec) < 1M sec (11.6 days) < 1 month (2.6M sec).",
      "detailedExplanation": "10K sec (2.8 hrs) < 1 week (604K sec) < 1 month (2.6M sec) < 1M sec (11.6 days). Treat this as a reference-number anchor you can reuse in larger back-of-envelope estimates. In interviews, state the formula, compute an order-of-magnitude result, and tie it back to a concrete system decision.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o004",
      "type": "ordering",
      "question": "Rank these QPS values from lowest to highest.",
      "items": ["1M req/day", "100 req/sec", "1B req/month", "10M req/week"],
      "correctOrder": [0, 3, 1, 2],
      "explanation": "1M/day (12 QPS) < 10M/week (17 QPS) < 100 QPS < 1B/month (386 QPS).",
      "detailedExplanation": "Establish the extremes first and fill the middle with pairwise comparisons. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o005",
      "type": "ordering",
      "question": "Rank these retry strategies by total wait time if all retries fail (initial + retries).",
      "items": [
        "3 retries, 2s each",
        "2 retries, 5s each",
        "Exponential 1-2-4s",
        "4 retries, 1s each"
      ],
      "correctOrder": [3, 0, 2, 1],
      "explanation": "4×1=4s < 3×2=6s < 1+2+4=7s < 2×5=10s (assuming immediate failures).",
      "detailedExplanation": "Use relative magnitude to draft the order and confirm it with local adjacency checks. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o006",
      "type": "ordering",
      "question": "Rank these scenarios by expected latency (lowest to highest).",
      "items": [
        "Sequential: 3 calls × 50ms each",
        "Parallel: max of 3 calls × 50ms",
        "1 call × 100ms",
        "Sequential: 2 calls × 30ms each"
      ],
      "correctOrder": [1, 3, 2, 0],
      "explanation": "Parallel 50ms < Sequential 60ms < Single 100ms < Sequential 150ms.",
      "detailedExplanation": "Start with the clear smallest/largest anchors, then place intermediate items by pairwise checks. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o007",
      "type": "ordering",
      "question": "Rank by number of executions per year (fewest to most).",
      "items": [
        "Weekly batch",
        "Daily backup",
        "Hourly sync",
        "Monthly report"
      ],
      "correctOrder": [3, 0, 1, 2],
      "explanation": "Monthly (12) < Weekly (52) < Daily (365) < Hourly (8,760).",
      "detailedExplanation": "Prioritize ratio-based comparisons and validate each neighboring step to avoid inversion mistakes. Growth planning should show today vs horizon requirements side by side because compounding makes small percentages material quickly.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-o008",
      "type": "ordering",
      "question": "Rank these percentile measurements by how many requests they represent (out of 1M).",
      "items": ["p50", "p99.9", "p99", "p95"],
      "correctOrder": [1, 2, 3, 0],
      "explanation": "p99.9 (1K exceed) < p99 (10K) < p95 (50K) < p50 (500K exceed the threshold).",
      "detailedExplanation": "Build the ordering from major scale differences first, then refine with adjacent comparisons. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m001",
      "type": "multi-select",
      "question": "Which represent approximately 1,000 QPS?",
      "options": [
        "86.4 million requests/day",
        "2.6 billion requests/month",
        "604 million requests/week",
        "3.6 million requests/hour"
      ],
      "correctIndices": [0, 1, 2, 3],
      "explanation": "All of these convert to approximately 1,000 QPS: 86.4M/day, 2.6B/month, 604M/week, 3.6M/hour.",
      "detailedExplanation": "Avoid grouped guessing: test every option directly against the system boundary condition. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m002",
      "type": "multi-select",
      "question": "Which SLA levels allow more than 1 hour of downtime per year?",
      "options": ["99%", "99.9%", "99.99%", "99.999%"],
      "correctIndices": [0, 1],
      "explanation": "99% allows ~3.65 days/year and 99.9% allows ~8.76 hours/year, both above 1 hour. 99.99% (~52.6 min) and 99.999% (~5.26 min) are below 1 hour.",
      "detailedExplanation": "Map each SLA to yearly downtime before choosing answers: 99% (~3.65 days) and 99.9% (~8.76 hours) are both greater than one hour. 99.99% and 99.999% are under one hour, so they do not qualify. This conversion prevents common \"extra nines\" mistakes in reliability interviews.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m003",
      "type": "multi-select",
      "question": "Which intervals result in more than 100 executions per day?",
      "options": [
        "Every 5 minutes",
        "Every 30 minutes",
        "Every 10 minutes",
        "Every hour"
      ],
      "correctIndices": [0, 2],
      "explanation": "5 min → 288/day, 10 min → 144/day. 30 min → 48/day, 1 hr → 24/day.",
      "detailedExplanation": "Treat each candidate as a separate true/false check against the same governing requirement. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m008",
      "type": "multi-select",
      "question": "A token expires in 1 hour. A user is active for 8 hours. Which are true?",
      "options": [
        "8 tokens will be issued",
        "7 token refreshes will occur",
        "Token refresh happens every 60 minutes",
        "User needs ~8 authentications"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "8 hours ÷ 1 hour = 8 tokens needed. Refresh happens hourly (every 60 min). 8 total tokens issued throughout the session.",
      "detailedExplanation": "Run a one-by-one validity check and discard options that depend on unstated conditions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m005",
      "type": "multi-select",
      "question": "Which batch frequencies run more than 500 times per month?",
      "options": [
        "Every 2 hours",
        "Every 30 minutes",
        "Every 4 hours",
        "Hourly"
      ],
      "correctIndices": [1, 3],
      "explanation": "30min: 48/day × 30 = 1,440/mo ✓, Hourly: 24 × 30 = 720/mo ✓. 2hr: 12 × 30 = 360/mo ✗, 4hr: 6 × 30 = 180/mo ✗.",
      "detailedExplanation": "Evaluate each option independently against the constraint instead of looking for a pattern across choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m006",
      "type": "multi-select",
      "question": "Which correctly describe a p99 latency of 200ms?",
      "options": [
        "99% of requests complete in ≤200ms",
        "1% of requests exceed 200ms",
        "Average latency is 200ms",
        "Maximum latency is 200ms"
      ],
      "correctIndices": [0, 1],
      "explanation": "p99 means 99% are under the threshold and 1% exceed it. It's not the average or maximum.",
      "detailedExplanation": "Use independent validation per option to prevent partial truths from slipping into the final set. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m007",
      "type": "multi-select",
      "question": "Which are approximately 1 million seconds?",
      "options": ["11.5 days", "1.5 weeks", "About 2 weeks", "About 1 month"],
      "correctIndices": [0],
      "explanation": "1M seconds = 1M ÷ 86,400 = 11.57 days. 1.5 weeks = 10.5 days, 2 weeks = 14 days, 1 month = 30 days.",
      "detailedExplanation": "Assess each option separately and keep answers that hold across the full problem context. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-m009",
      "type": "multi-select",
      "question": "If you deploy 4× daily with 0.1% incident probability per deploy, which are true?",
      "options": [
        "~1.5 incidents expected per year",
        "~12 incidents expected per year",
        "Less than 1% chance of incident each month",
        "About 0.4% daily incident probability"
      ],
      "correctIndices": [0, 3],
      "explanation": "Expected incidents/year = 4 deploys/day × 365 × 0.001 = 1.46 (~1.5). Daily probability of at least one incident is 1 - 0.999^4 ≈ 0.4%.",
      "detailedExplanation": "This combines expected-value math with probability-of-at-least-one-event math. Expected yearly incidents are 1.46, while the daily chance of seeing any incident is about 0.4%; these are different metrics and both are useful in risk discussions. In interviews, separate expected count, daily probability, and monthly probability explicitly.",
      "references": [
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-t001",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your service receives 100 million requests per day. What's the approximate QPS?",
          "options": ["~100 QPS", "~1,000 QPS", "~10,000 QPS", "~100,000 QPS"],
          "correct": 1,
          "explanation": "100M ÷ 86,400 ≈ 1,157 QPS ≈ 1,000 QPS.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        },
        {
          "question": "At this QPS with 50ms average latency, how many concurrent requests using Little's Law?",
          "options": ["~5", "~50", "~500", "~5,000"],
          "correct": 1,
          "explanation": "L = λW = 1,000 × 0.05 = 50 concurrent requests.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        }
      ],
      "explanation": "Converting daily requests to QPS, then applying Little's Law for concurrency estimation.",
      "detailedExplanation": "Think of this as staged reasoning: outcome one becomes input constraint for outcome two. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-t002",
      "type": "two-stage",
      "stages": [
        {
          "question": "You need 99.99% availability. How many minutes of downtime per month is your budget?",
          "options": [
            "~4 minutes",
            "~44 minutes",
            "~440 minutes",
            "~4,400 minutes"
          ],
          "correct": 0,
          "explanation": "0.01% of 30 days = 0.0001 × 30 × 24 × 60 = 4.32 minutes.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        },
        {
          "question": "If your average incident takes 30 minutes to resolve, how do you achieve this target?",
          "options": [
            "Never have incidents",
            "Have fewer than 1 incident per 7 months",
            "Have at most 1 incident per month",
            "Use redundancy to reduce incident duration"
          ],
          "correct": 3,
          "explanation": "30 min/incident exceeds 4 min budget. You need redundancy/failover to reduce actual downtime per incident.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        }
      ],
      "explanation": "High availability targets often require redundancy because incident resolution takes longer than the allowed downtime.",
      "detailedExplanation": "Solve stage one, freeze its implications, then use them as hard bounds for stage two. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-t003",
      "type": "two-stage",
      "stages": [
        {
          "question": "A batch job processes 1,000 items/second. You have 10 million items to process. How long?",
          "options": ["~17 minutes", "~2.8 hours", "~28 hours", "~2.8 days"],
          "correct": 1,
          "explanation": "10M ÷ 1,000 = 10,000 seconds = 2.78 hours.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        },
        {
          "question": "If you need to finish in under 1 hour, how many parallel workers do you need?",
          "options": ["2 workers", "3 workers", "4 workers", "5 workers"],
          "correct": 1,
          "explanation": "2.78 hours ÷ 1 hour target = 2.78, round up to 3 workers minimum.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "explanation": "Estimating processing time and scaling horizontally to meet time constraints.",
      "detailedExplanation": "Handle this as a sequential constraint problem where each stage narrows the feasible design space. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    },
    {
      "id": "time-t004",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your cache TTL is 5 minutes. You have 1 million cached items uniformly distributed. Expirations per second?",
          "options": ["~33", "~333", "~3,333", "~33,333"],
          "correct": 2,
          "explanation": "1M items ÷ 300 seconds = 3,333 expirations per second.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee."
        },
        {
          "question": "If each cache miss causes a 10ms database query, what's the added DB load from expirations?",
          "options": [
            "~33 concurrent queries",
            "~333 QPS to DB",
            "~3,333 QPS to DB",
            "~10% of DB capacity"
          ],
          "correct": 2,
          "explanation": "3,333 expirations/sec = 3,333 cache misses = 3,333 QPS hitting the database.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee."
        }
      ],
      "explanation": "Cache expiration storms can cause significant database load spikes.",
      "detailedExplanation": "This format tests handoff quality between steps: carry forward results and avoid context drift. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ]
    }
  ]
}
