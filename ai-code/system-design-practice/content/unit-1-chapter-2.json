{
  "unit": 1,
  "unitTitle": "Estimation",
  "chapter": 2,
  "chapterTitle": "Time Math",
  "chapterDescription": "Seconds per day, requests to QPS, SLA percentages to downtime",
  "problems": [
    {
      "id": "time-002",
      "type": "multiple-choice",
      "question": "A service receives 10 million requests per day. What's the average QPS?",
      "options": ["~12", "~120", "~1,200", "~12,000"],
      "correct": 1,
      "explanation": "10M requests ÷ 86,400 seconds ≈ 116 QPS. Quick trick: divide daily requests by 100K to estimate QPS.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 10 and 10M appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-003",
      "type": "multiple-choice",
      "question": "Your service handles 500 QPS. How many requests per day is that?",
      "options": [
        "~4.3 million",
        "~43 million",
        "~430 million",
        "~4.3 billion"
      ],
      "correct": 1,
      "explanation": "500 × 86,400 = 43.2 million. Quick trick: multiply QPS by 100K to estimate daily requests.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. In real systems, reject approaches that fail under peak load or saturation conditions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 500 QPS and 500 in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-004",
      "type": "multiple-choice",
      "question": "A 99.9% SLA means how much downtime per year?",
      "options": ["~53 minutes", "~8.7 hours", "~3.6 days", "~36.5 days"],
      "correct": 1,
      "explanation": "0.1% of a year = 0.001 × 365 × 24 = 8.76 hours. Three nines = ~9 hours/year downtime.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Numbers such as 99.9 and 0.1 should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-005",
      "type": "multiple-choice",
      "question": "A 99.99% SLA (four nines) allows how much downtime per year?",
      "options": ["~5 minutes", "~52 minutes", "~8.7 hours", "~87 hours"],
      "correct": 1,
      "explanation": "0.01% of a year = 0.0001 × 365 × 24 × 60 = 52.6 minutes. Four nines = ~52 minutes/year.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 99.99 and 0.01 appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-007",
      "type": "multiple-choice",
      "question": "Your batch job runs every hour. How many times does it run per month (30 days)?",
      "options": ["~72", "~720", "~7,200", "~72,000"],
      "correct": 1,
      "explanation": "24 hours × 30 days = 720 runs per month.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 30 days and 24 hours appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-008",
      "type": "multiple-choice",
      "question": "A cron job runs every 5 minutes. How many executions per day?",
      "options": ["~29", "~288", "~1,440", "~2,880"],
      "correct": 1,
      "explanation": "60 minutes ÷ 5 = 12 per hour. 12 × 24 = 288 executions per day.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 5 minutes and 60 minutes should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-009",
      "type": "multiple-choice",
      "question": "You need 99.95% uptime. What's your monthly downtime budget?",
      "options": ["~2 minutes", "~22 minutes", "~3.6 hours", "~36 hours"],
      "correct": 1,
      "explanation": "0.05% of 30 days = 0.0005 × 30 × 24 × 60 = 21.6 minutes per month.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 99.95 and 0.05 in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-010",
      "type": "multiple-choice",
      "question": "Peak traffic is 3× average. If average QPS is 1,000 and peak lasts 4 hours, how many total requests occur during that peak period?",
      "options": [
        "~4.3 million",
        "~43 million",
        "~430 million",
        "~4.3 billion"
      ],
      "correct": 1,
      "explanation": "Peak QPS = 3,000. Total requests = 3,000 × 4 hours × 3,600 sec/hr = 43.2 million requests during the peak window.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 3 and 1,000 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-011",
      "type": "multiple-choice",
      "question": "A service processes 1 billion requests per month. What's the average QPS?",
      "options": ["~39", "~390", "~3,900", "~39,000"],
      "correct": 1,
      "explanation": "1B ÷ (30 × 86,400) = 1B ÷ 2.6M ≈ 385 QPS. Quick estimate: 1B/month ÷ 2.5M seconds/month ≈ 400 QPS.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 1 and 1B appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-012",
      "type": "multiple-choice",
      "question": "Your p99 latency target is 200ms. If you handle 10,000 requests, how many can exceed 200ms while still meeting the target?",
      "options": ["1", "10", "100", "1,000"],
      "correct": 2,
      "explanation": "p99 means 99% of requests must be under 200ms. 1% can exceed it. 1% of 10,000 = 100 requests.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that directly address failure mode, recovery path, and blast radius. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 200ms and 10,000 appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-013",
      "type": "multiple-choice",
      "question": "A cache TTL is 5 minutes. How many times will a popular item be refreshed per day?",
      "options": ["~29", "~288", "~1,440", "~2,880"],
      "correct": 1,
      "explanation": "24 hours × 60 minutes ÷ 5 minutes = 288 refreshes per day.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. Keep quantities like 5 minutes and 24 hours in aligned units before deciding on an implementation approach. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-014",
      "type": "multiple-choice",
      "question": "You're designing a rate limiter: 100 requests per user per minute. What's the per-second limit?",
      "options": ["~0.6", "~1.7", "~10", "~100"],
      "correct": 1,
      "explanation": "100 ÷ 60 ≈ 1.67 requests per second. In practice, you'd use a token bucket that refills at this rate.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 100 and 60 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-017",
      "type": "multiple-choice",
      "question": "A 99% SLA means how much downtime per month (30 days)?",
      "options": ["~43 minutes", "~7.2 hours", "~3 days", "~7.2 days"],
      "correct": 1,
      "explanation": "1% of 30 days = 0.01 × 30 × 24 = 7.2 hours per month. Two nines is not very reliable!",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prioritize the approach that best protects reliability objectives under stated failure conditions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Keep quantities like 99 and 30 days in aligned units before deciding on an implementation approach. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-018",
      "type": "multiple-choice",
      "question": "Your API handles 50 million requests per week. What's the average QPS?",
      "options": ["~8", "~83", "~830", "~8,300"],
      "correct": 1,
      "explanation": "50M ÷ (7 × 86,400) = 50M ÷ 604,800 ≈ 83 QPS.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Keep quantities like 50 and 50M in aligned units before deciding on an implementation approach. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-019",
      "type": "multiple-choice",
      "question": "A heartbeat is sent every 30 seconds. How many heartbeats per day?",
      "options": ["~288", "~2,880", "~28,800", "~288,000"],
      "correct": 1,
      "explanation": "86,400 seconds ÷ 30 seconds = 2,880 heartbeats per day.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 30 seconds and 86,400 seconds in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-020",
      "type": "multiple-choice",
      "question": "Your service runs at 10,000 QPS. How many requests per hour?",
      "options": [
        "~3.6 million",
        "~36 million",
        "~360 million",
        "~3.6 billion"
      ],
      "correct": 1,
      "explanation": "10,000 × 3,600 = 36 million requests per hour.",
      "detailedExplanation": "Generalize from your service runs at 10,000 QPS to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 10,000 QPS and 10,000 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-021",
      "type": "multiple-choice",
      "question": "A 99.999% SLA (five nines) allows how much downtime per year?",
      "options": ["~5 seconds", "~5 minutes", "~52 minutes", "~8.7 hours"],
      "correct": 1,
      "explanation": "0.001% of a year = 0.00001 × 365 × 24 × 60 = 5.26 minutes. Five nines = ~5 minutes/year.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer approaches that directly address failure mode, recovery path, and blast radius. Tie decisions to concrete operational outcomes, not abstract reliability language. If values like 99.999 and 0.001 appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-023",
      "type": "multiple-choice",
      "question": "A job processes 1,000 items per second. How long to process 1 million items?",
      "options": ["~1.7 minutes", "~17 minutes", "~1.7 hours", "~17 hours"],
      "correct": 1,
      "explanation": "1,000,000 ÷ 1,000 = 1,000 seconds = 16.7 minutes.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 1,000 and 1 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-024",
      "type": "multiple-choice",
      "question": "Your monitoring samples metrics every 10 seconds. How many data points per day per metric?",
      "options": ["~864", "~8,640", "~86,400", "~864,000"],
      "correct": 1,
      "explanation": "86,400 seconds ÷ 10 = 8,640 samples per day per metric.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 10 seconds and 86,400 seconds should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-025",
      "type": "multiple-choice",
      "question": "A user session timeout is 30 minutes. If a user is active 8 hours/day, how many sessions?",
      "options": ["~4", "~16", "~32", "~64"],
      "correct": 1,
      "explanation": "8 hours × 60 minutes ÷ 30 minutes = 16 sessions (assuming continuous activity requiring re-auth).",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that directly address failure mode, recovery path, and blast radius. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 30 minutes and 8 hours should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-027",
      "type": "multiple-choice",
      "question": "Your database handles 100 writes per second. How many writes per day?",
      "options": ["~864,000", "~8.64 million", "~86.4 million", "~864 million"],
      "correct": 1,
      "explanation": "100 × 86,400 = 8.64 million writes per day.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 100 and 86,400 in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-028",
      "type": "multiple-choice",
      "question": "A retry has exponential backoff: 1s, 2s, 4s, 8s, 16s. Total time if all 5 retries fail?",
      "options": ["~15 seconds", "~31 seconds", "~63 seconds", "~127 seconds"],
      "correct": 1,
      "explanation": "1 + 2 + 4 + 8 + 16 = 31 seconds total wait time across all retries.",
      "detailedExplanation": "Generalize from retry has exponential backoff: 1s, 2s, 4s, 8s, 16s to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that directly address failure mode, recovery path, and blast radius. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. If values like 1s and 2s appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-029",
      "type": "multiple-choice",
      "question": "A log rotates every 6 hours. How many log files per month?",
      "options": ["~12", "~120", "~1,200", "~12,000"],
      "correct": 1,
      "explanation": "24 hours ÷ 6 = 4 files per day. 4 × 30 = 120 files per month.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 6 hours and 24 hours in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-030",
      "type": "multiple-choice",
      "question": "Your p95 latency is 100ms. Out of 1 million requests, how many exceed 100ms?",
      "options": ["~5,000", "~50,000", "~500,000", "~950,000"],
      "correct": 1,
      "explanation": "5% of requests exceed p95. 5% of 1,000,000 = 50,000 requests.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that directly address failure mode, recovery path, and blast radius. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Numbers such as 100ms and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-032",
      "type": "multiple-choice",
      "question": "A task queue processes jobs at 50/second. How long to clear a backlog of 100,000 jobs?",
      "options": ["~3 minutes", "~33 minutes", "~3.3 hours", "~33 hours"],
      "correct": 1,
      "explanation": "100,000 ÷ 50 = 2,000 seconds = 33.3 minutes.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Reject designs that improve throughput while weakening reliability guarantees. A good message-system answer defines guarantees clearly for both producer and consumer paths. Numbers such as 50 and 100,000 should be normalized first so downstream reasoning stays consistent. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-033",
      "type": "multiple-choice",
      "question": "Your API rate limit is 1,000 requests per hour. What's that per minute?",
      "options": ["~1.7", "~17", "~167", "~1,670"],
      "correct": 1,
      "explanation": "1,000 ÷ 60 ≈ 16.7 requests per minute.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Numbers such as 1,000 and 60 should be normalized first so downstream reasoning stays consistent. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-034",
      "type": "multiple-choice",
      "question": "A 99.9% SLA allows how much downtime per month (30 days)?",
      "options": ["~4 minutes", "~43 minutes", "~7 hours", "~43 hours"],
      "correct": 1,
      "explanation": "0.1% of 30 days = 0.001 × 30 × 24 × 60 = 43.2 minutes per month.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 99.9 and 30 days appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-035",
      "type": "multiple-choice",
      "question": "A daily backup takes 2 hours. What percentage of the day is spent backing up?",
      "options": ["~4%", "~8%", "~12%", "~20%"],
      "correct": 1,
      "explanation": "2 hours ÷ 24 hours = 8.3% of the day.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prefer the approach that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 2 hours and 24 hours should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-036",
      "type": "multiple-choice",
      "question": "Your service receives 1 request per second. How many per year?",
      "options": [
        "~3.2 million",
        "~32 million",
        "~320 million",
        "~3.2 billion"
      ],
      "correct": 1,
      "explanation": "1 × 86,400 × 365 = 31.5 million requests per year.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 1 and 86,400 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-037",
      "type": "multiple-choice",
      "question": "A health check runs every 15 seconds. How many checks per hour?",
      "options": ["~24", "~240", "~2,400", "~24,000"],
      "correct": 1,
      "explanation": "3,600 seconds ÷ 15 = 240 health checks per hour.",
      "detailedExplanation": "Generalize from health check runs every 15 seconds to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer the answer that survives a sanity check against known anchor numbers. Cross-check with anchor numbers to test plausibility before finalizing. Numbers such as 15 seconds and 3,600 seconds should be normalized first so downstream reasoning stays consistent. Common pitfall: propagating an early bad assumption through all steps.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-038",
      "type": "multiple-choice",
      "question": "An event processes in 50ms average. What's the theoretical max throughput?",
      "options": ["~2/sec", "~20/sec", "~200/sec", "~2,000/sec"],
      "correct": 1,
      "explanation": "1,000ms ÷ 50ms = 20 events per second maximum (single-threaded).",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer the approach that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Keep quantities like 50ms and 1,000ms in aligned units before deciding on an implementation approach. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-039",
      "type": "multiple-choice",
      "question": "Your token expires in 1 hour. A user is active 10 hours/day. How many token refreshes?",
      "options": ["~5", "~10", "~20", "~100"],
      "correct": 1,
      "explanation": "10 hours of activity ÷ 1 hour token lifetime = 10 refreshes (one per hour of activity).",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 1 hour and 10 hours in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-041",
      "type": "multiple-choice",
      "question": "A message queue has 5ms processing time per message. Max messages per second (single consumer)?",
      "options": ["~20", "~200", "~2,000", "~20,000"],
      "correct": 1,
      "explanation": "1,000ms ÷ 5ms = 200 messages per second maximum.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Reject designs that improve throughput while weakening reliability guarantees. A good message-system answer defines guarantees clearly for both producer and consumer paths. Keep quantities like 5ms and 1,000ms in aligned units before deciding on an implementation approach. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-042",
      "type": "multiple-choice",
      "question": "Your CI pipeline runs 50 times per day, averaging 10 minutes each. Total CI time per day?",
      "options": ["~83 minutes", "~8.3 hours", "~83 hours", "~8.3 days"],
      "correct": 1,
      "explanation": "50 × 10 = 500 minutes = 8.3 hours of CI time per day.",
      "detailedExplanation": "Generalize from your CI pipeline runs 50 times per day, averaging 10 minutes each to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 50 and 10 minutes appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-043",
      "type": "multiple-choice",
      "question": "A lease expires in 30 seconds and needs renewal 5 seconds before expiry. How often to renew?",
      "options": [
        "Every 5 seconds",
        "Every 25 seconds",
        "Every 30 seconds",
        "Every 35 seconds"
      ],
      "correct": 1,
      "explanation": "Renew 5 seconds before the 30-second expiry = renew every 25 seconds.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 30 seconds and 5 seconds should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-044",
      "type": "multiple-choice",
      "question": "100 million daily active users, each makes 10 requests/day. What's the QPS?",
      "options": ["~1,200", "~12,000", "~120,000", "~1.2 million"],
      "correct": 1,
      "explanation": "100M × 10 = 1 billion requests/day. 1B ÷ 86,400 ≈ 11,574 QPS.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 100 and 10 in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-045",
      "type": "multiple-choice",
      "question": "A DNS TTL is 5 minutes. Your app caches DNS. How many DNS lookups per day per domain?",
      "options": ["~29", "~288", "~2,880", "~28,800"],
      "correct": 1,
      "explanation": "1,440 minutes/day ÷ 5 minutes = 288 lookups per day.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. If values like 5 minutes and 1,440 minutes appear, convert them into one unit basis before comparison. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "RFC 1035: Domain names - implementation and specification",
          "url": "https://www.rfc-editor.org/rfc/rfc1035"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-046",
      "type": "multiple-choice",
      "question": "Your database connection pool refreshes connections every 10 minutes. Connections refreshed per day?",
      "options": ["~14", "~144", "~1,440", "~14,400"],
      "correct": 1,
      "explanation": "1,440 minutes ÷ 10 = 144 connection refreshes per day.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 10 minutes and 1,440 minutes appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-047",
      "type": "multiple-choice",
      "question": "An SLO targets 99.5% success rate. Out of 10,000 requests, how many failures are allowed?",
      "options": ["5", "50", "500", "5,000"],
      "correct": 1,
      "explanation": "0.5% failure rate allowed. 0.5% of 10,000 = 50 failures.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prioritize the approach that best protects reliability objectives under stated failure conditions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Keep quantities like 99.5 and 10,000 in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-048",
      "type": "multiple-choice",
      "question": "A weekly batch job runs for 3 hours. What percentage of the week is it running?",
      "options": ["~0.2%", "~1.8%", "~4.2%", "~12.5%"],
      "correct": 1,
      "explanation": "3 hours ÷ 168 hours/week = 1.8% of the week.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 3 hours and 168 hours in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-049",
      "type": "multiple-choice",
      "question": "Your p50 latency is 20ms. What does this mean?",
      "options": [
        "20ms is the minimum latency",
        "50% of requests are under 20ms",
        "50% of requests are over 20ms",
        "Average latency is 20ms"
      ],
      "correct": 1,
      "explanation": "p50 (median) means 50% of requests complete in 20ms or less.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Reject approaches that sound good in general but do not reduce concrete reliability risk. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 20ms and 50 appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-051",
      "type": "multiple-choice",
      "question": "A circuit breaker opens for 30 seconds after 5 failures. Max breaker trips per hour?",
      "options": ["~12", "~60", "~120", "~600"],
      "correct": 2,
      "explanation": "3,600 seconds ÷ 30 = 120 possible trips per hour (if it keeps failing and resetting).",
      "detailedExplanation": "Generalize from circuit breaker opens for 30 seconds after 5 failures to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that directly address failure mode, recovery path, and blast radius. Tie decisions to concrete operational outcomes, not abstract reliability language. Keep quantities like 30 seconds and 5 in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Circuit Breaker",
          "url": "https://martinfowler.com/bliki/CircuitBreaker.html"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-052",
      "type": "multiple-choice",
      "question": "Your deploy takes 15 minutes with 0 downtime. You deploy 4 times daily. Total deploy time?",
      "options": ["~15 minutes", "~1 hour", "~4 hours", "~15 hours"],
      "correct": 1,
      "explanation": "15 minutes × 4 deploys = 60 minutes = 1 hour of deploy time per day.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prefer approaches that directly address failure mode, recovery path, and blast radius. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Numbers such as 15 minutes and 0 should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-053",
      "type": "multiple-choice",
      "question": "A user's JWT expires in 15 minutes. How many tokens issued per 8-hour session?",
      "options": ["~8", "~32", "~128", "~480"],
      "correct": 1,
      "explanation": "8 hours × 60 minutes ÷ 15 minutes = 32 tokens per session.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject approaches that fail under peak load or saturation conditions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 15 minutes and 8 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-054",
      "type": "multiple-choice",
      "question": "1,000 QPS with 100ms average latency. Requests in-flight at any moment (Little's Law)?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 1,
      "explanation": "Little's Law: L = λW. 1,000 req/sec × 0.1 sec = 100 concurrent requests.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 1,000 QPS and 100ms in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-055",
      "type": "multiple-choice",
      "question": "A scraper fetches 10 pages/second. How long to scrape 1 million pages?",
      "options": ["~2.8 hours", "~28 hours", "~280 hours", "~2,800 hours"],
      "correct": 1,
      "explanation": "1,000,000 ÷ 10 = 100,000 seconds = 27.8 hours.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 10 and 1 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-056",
      "type": "multiple-choice",
      "question": "Logs are retained for 90 days. If you write 1GB/day, total storage needed?",
      "options": ["~9 GB", "~90 GB", "~900 GB", "~9 TB"],
      "correct": 1,
      "explanation": "90 days × 1 GB/day = 90 GB of log storage.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer the approach that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 90 days and 1GB appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-057",
      "type": "multiple-choice",
      "question": "A cron runs at */15 (every 15 minutes). Executions per week?",
      "options": ["~67", "~672", "~6,720", "~67,200"],
      "correct": 1,
      "explanation": "4 per hour × 24 hours × 7 days = 672 executions per week.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 15 and 15 minutes should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-058",
      "type": "multiple-choice",
      "question": "Your timeout is 5 seconds. With 3 retries (no backoff), max wait per request?",
      "options": ["~5 seconds", "~15 seconds", "~20 seconds", "~25 seconds"],
      "correct": 2,
      "explanation": "Original attempt + 3 retries = 4 attempts × 5 seconds = 20 seconds max.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer approaches that directly address failure mode, recovery path, and blast radius. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 5 seconds and 3 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-059",
      "type": "multiple-choice",
      "question": "200 QPS average, but traffic doubles during a 2-hour lunch rush. Requests during lunch?",
      "options": [
        "~144,000",
        "~1.44 million",
        "~2.88 million",
        "~14.4 million"
      ],
      "correct": 2,
      "explanation": "400 QPS × 2 hours × 3,600 sec/hr = 2.88 million requests during lunch.",
      "detailedExplanation": "Generalize from 200 QPS average, but traffic doubles during a 2-hour lunch rush to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 200 QPS and 2 should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-061",
      "type": "multiple-choice",
      "question": "A canary deployment runs for 30 minutes with 5% traffic. Normal QPS is 1,000. Canary requests?",
      "options": ["~9,000", "~90,000", "~900,000", "~9 million"],
      "correct": 1,
      "explanation": "5% of 1,000 = 50 QPS to canary. 50 × 30 × 60 = 90,000 requests.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 30 minutes and 5 in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-062",
      "type": "multiple-choice",
      "question": "99.99% of requests succeed. You serve 10 million requests/day. Daily failures?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 2,
      "explanation": "0.01% failure rate. 0.0001 × 10,000,000 = 1,000 failures per day.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 99.99 and 10 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-063",
      "type": "multiple-choice",
      "question": "Your GC pause is 50ms and happens every 10 seconds. What % of time is paused?",
      "options": ["~0.05%", "~0.5%", "~5%", "~50%"],
      "correct": 1,
      "explanation": "50ms pause every 10,000ms = 50/10,000 = 0.5% time paused.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. In real systems, reject approaches that fail under peak load or saturation conditions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 50ms and 10 seconds should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-064",
      "type": "multiple-choice",
      "question": "A connection has a 60-second idle timeout. Active connections drop to 0. Max time until all connections close?",
      "options": ["~30 seconds", "~60 seconds", "~120 seconds", "~600 seconds"],
      "correct": 1,
      "explanation": "After traffic stops, connections idle out in 60 seconds (the timeout value).",
      "detailedExplanation": "Generalize from connection has a 60-second idle timeout to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 60 and 0 appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-065",
      "type": "multiple-choice",
      "question": "You process 1TB of data at 100MB/second. How long?",
      "options": ["~17 minutes", "~2.8 hours", "~17 hours", "~2.8 days"],
      "correct": 1,
      "explanation": "1TB = 1,000GB = 1,000,000MB. 1,000,000 ÷ 100 = 10,000 seconds = 2.8 hours.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 1TB and 100MB should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-066",
      "type": "multiple-choice",
      "question": "A feature flag check takes 1ms. You check 100 flags per request at 1,000 QPS. Time spent on flags per second?",
      "options": ["~0.1 seconds", "~1 second", "~10 seconds", "~100 seconds"],
      "correct": 3,
      "explanation": "1ms × 100 flags × 1,000 requests = 100,000ms = 100 seconds of flag-checking time per second (need parallelism!).",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 1ms and 100 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-067",
      "type": "multiple-choice",
      "question": "Your SLI shows 99.8% success this month. Budget was 99.9%. How much error budget did you burn?",
      "options": ["~80%", "~100%", "~200%", "~800%"],
      "correct": 2,
      "explanation": "Budget allowed 0.1% errors. You had 0.2% errors. 0.2/0.1 = 200% of budget burned.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prioritize the approach that best protects reliability objectives under stated failure conditions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. If values like 99.8 and 99.9 appear, convert them into one unit basis before comparison. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-068",
      "type": "multiple-choice",
      "question": "A mutex lock is held for 100μs on average. Max locks per second (single thread)?",
      "options": ["~100", "~1,000", "~10,000", "~100,000"],
      "correct": 2,
      "explanation": "1,000,000μs per second ÷ 100μs per lock = 10,000 locks per second max.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 100 and 1,000 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-069",
      "type": "multiple-choice",
      "question": "Your API client retries 3 times with 1-second delays. Total time if all fail (including initial)?",
      "options": ["~3 seconds", "~4 seconds", "~6 seconds", "~7 seconds"],
      "correct": 0,
      "explanation": "Initial attempt + 3 retries = 4 attempts. 3 delays of 1 second = 3 seconds (delays happen between attempts).",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer the approach that keeps client behavior explicit while preserving evolvability. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Keep quantities like 3 and 1 in aligned units before deciding on an implementation approach. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-070",
      "type": "multiple-choice",
      "question": "A video is transcoded at 2× realtime speed. How long to transcode a 2-hour movie?",
      "options": ["~30 minutes", "~1 hour", "~2 hours", "~4 hours"],
      "correct": 1,
      "explanation": "2× realtime means 1 hour of video takes 30 minutes. 2-hour movie = 1 hour to transcode.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 2 and 1 hour appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-071",
      "type": "multiple-choice",
      "question": "How many 100ms requests can you serve per second with 10 threads?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 1,
      "explanation": "Each thread serves 10 requests/second (1000ms ÷ 100ms). 10 threads × 10 = 100 requests/second.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 100ms and 10 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-072",
      "type": "multiple-choice",
      "question": "A queue drains at 100/second but receives 120/second. Backlog after 1 hour?",
      "options": ["~7,200", "~72,000", "~720,000", "~7.2 million"],
      "correct": 1,
      "explanation": "Net backlog rate = 20/second. 20 × 3,600 = 72,000 items backed up after 1 hour.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer the approach that keeps ordering/acknowledgment behavior predictable under failure. A good message-system answer defines guarantees clearly for both producer and consumer paths. If values like 100 and 120 appear, convert them into one unit basis before comparison. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-073",
      "type": "multiple-choice",
      "question": "Election timeout is 150ms. Heartbeat interval should be roughly?",
      "options": ["~15ms", "~50ms", "~150ms", "~300ms"],
      "correct": 1,
      "explanation": "Heartbeat should be significantly less than election timeout. Rule of thumb: 1/3 to 1/10 of timeout.",
      "detailedExplanation": "Generalize from election timeout is 150ms to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that directly address failure mode, recovery path, and blast radius. Tie decisions to concrete operational outcomes, not abstract reliability language. If values like 150ms and 1 appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-074",
      "type": "multiple-choice",
      "question": "Your endpoint averages 25ms latency. Max QPS from a single connection (sequential requests)?",
      "options": ["~4", "~40", "~400", "~4,000"],
      "correct": 1,
      "explanation": "1,000ms ÷ 25ms = 40 sequential requests per second per connection.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer the approach that keeps client behavior explicit while preserving evolvability. Prioritize explicit semantics and upgrade safety, not just short-term convenience. If values like 25ms and 1,000ms appear, convert them into one unit basis before comparison. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-075",
      "type": "multiple-choice",
      "question": "A billing cycle is monthly. You have 100,000 customers. Average bills processed per day?",
      "options": ["~333", "~3,333", "~33,333", "~333,333"],
      "correct": 1,
      "explanation": "100,000 bills spread over 30 days = 3,333 bills per day on average.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer the approach that remains viable across the planning horizon, not just today. Compounding effects should drive planning windows, not linear intuition. Keep quantities like 100,000 and 30 days in aligned units before deciding on an implementation approach. Common pitfall: forecasting volume without resource thresholds.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-076",
      "type": "multiple-choice",
      "question": "A cache warm-up fetches 10,000 keys at 100/second. How long until warm?",
      "options": [
        "~10 seconds",
        "~100 seconds",
        "~1,000 seconds",
        "~10,000 seconds"
      ],
      "correct": 1,
      "explanation": "10,000 ÷ 100 = 100 seconds to warm up the cache.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Discard cache tactics that hide consistency bugs under high load. Cache design quality is mostly about correctness boundaries, not only hit rate. If values like 10,000 and 100 appear, convert them into one unit basis before comparison. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-077",
      "type": "multiple-choice",
      "question": "Peak hours are 6 PM - 10 PM (4 hours). What percentage of daily traffic if peak is 3× average?",
      "options": ["~25%", "~37%", "~50%", "~75%"],
      "correct": 1,
      "explanation": "4 hours at 3× + 20 hours at 1× = 12 + 20 = 32 units. Peak portion = 12/32 = 37.5%.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 6 and 10 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-078",
      "type": "multiple-choice",
      "question": "Kafka retention is 7 days. Messages/second is 1,000. Total messages retained?",
      "options": ["~60 million", "~600 million", "~6 billion", "~60 billion"],
      "correct": 1,
      "explanation": "1,000 × 86,400 × 7 = 604.8 million messages retained.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prefer the approach that keeps ordering/acknowledgment behavior predictable under failure. A good message-system answer defines guarantees clearly for both producer and consumer paths. Keep quantities like 7 days and 1,000 in aligned units before deciding on an implementation approach. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka Documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-079",
      "type": "multiple-choice",
      "question": "A request travels through 5 services, each adding 10ms latency. Total added latency?",
      "options": ["~5ms", "~50ms", "~500ms", "~5,000ms"],
      "correct": 1,
      "explanation": "5 services × 10ms each = 50ms total added latency (assuming sequential calls).",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 5 and 10ms in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-081",
      "type": "multiple-choice",
      "question": "An A/B test needs 10,000 users per variant. At 1,000 new users/day, how long for 2 variants?",
      "options": ["~10 days", "~20 days", "~100 days", "~200 days"],
      "correct": 1,
      "explanation": "Need 20,000 total users. 20,000 ÷ 1,000 per day = 20 days.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 10,000 and 1,000 in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-082",
      "type": "multiple-choice",
      "question": "A pod restarts in 30 seconds. You have 10 pods. Full rolling restart takes?",
      "options": ["~30 seconds", "~5 minutes", "~30 minutes", "~5 hours"],
      "correct": 1,
      "explanation": "10 pods × 30 seconds = 300 seconds = 5 minutes (sequential rolling restart).",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 30 seconds and 10 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-083",
      "type": "multiple-choice",
      "question": "Your CDN cache hit rate is 95%. Origin gets 5% of traffic. If CDN QPS is 10,000, origin QPS?",
      "options": ["~50", "~500", "~5,000", "~9,500"],
      "correct": 1,
      "explanation": "5% of 10,000 = 500 QPS hitting the origin server.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. If values like 95 and 5 appear, convert them into one unit basis before comparison. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-084",
      "type": "multiple-choice",
      "question": "A microservice calls 3 downstream services in parallel, each taking 50ms. Total added latency?",
      "options": ["~17ms", "~50ms", "~100ms", "~150ms"],
      "correct": 1,
      "explanation": "Parallel calls: latency = max(50, 50, 50) = 50ms, not the sum.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 3 and 50ms should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-085",
      "type": "multiple-choice",
      "question": "Your on-call rotation is weekly, team of 6. How many weeks between your on-call shifts?",
      "options": ["~3 weeks", "~5 weeks", "~6 weeks", "~12 weeks"],
      "correct": 1,
      "explanation": "6 people rotating weekly = each person on-call every 6 weeks. 5 weeks gap between shifts.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 6 and 5 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-086",
      "type": "multiple-choice",
      "question": "Rate limit: 10,000 requests per day. Steady usage requires what average QPS?",
      "options": ["~0.01", "~0.12", "~1.2", "~12"],
      "correct": 1,
      "explanation": "10,000 ÷ 86,400 = 0.116 QPS average to stay under the limit.",
      "detailedExplanation": "Generalize from rate limit: 10,000 requests per day to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Discard options that weaken contract clarity or compatibility over time. Interface decisions should be justified by contract stability and client impact over time. Numbers such as 10,000 and 86,400 should be normalized first so downstream reasoning stays consistent. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-087",
      "type": "multiple-choice",
      "question": "A leader election happens every 10 seconds. Elections per year?",
      "options": ["~3.2 million", "~320,000", "~32,000", "~3,200"],
      "correct": 0,
      "explanation": "31.5 million seconds/year ÷ 10 = 3.15 million elections per year.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prefer the approach that preserves correctness guarantees for the stated consistency boundary. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Numbers such as 10 seconds and 31.5 should be normalized first so downstream reasoning stays consistent. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-088",
      "type": "multiple-choice",
      "question": "Your mobile app polls every 30 seconds. 1 million active users. QPS from polling?",
      "options": ["~3,300", "~33,000", "~330,000", "~3.3 million"],
      "correct": 1,
      "explanation": "1,000,000 users ÷ 30 seconds = 33,333 QPS from polling.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 30 seconds and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-089",
      "type": "multiple-choice",
      "question": "A database query takes 5ms. You need to run 1,000 queries. Single-threaded time?",
      "options": ["~0.5 seconds", "~5 seconds", "~50 seconds", "~500 seconds"],
      "correct": 1,
      "explanation": "1,000 queries × 5ms = 5,000ms = 5 seconds.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 5ms and 1,000 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-090",
      "type": "multiple-choice",
      "question": "Retention policy: delete data older than 2 years. Data grows 10GB/month. Max storage?",
      "options": ["~24 GB", "~240 GB", "~2.4 TB", "~24 TB"],
      "correct": 1,
      "explanation": "2 years = 24 months × 10 GB/month = 240 GB max storage under this policy.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Discard storage decisions that optimize one dimension while violating another core requirement. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 2 and 10GB in aligned units before deciding on an implementation approach. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-091",
      "type": "multiple-choice",
      "question": "A websocket heartbeat is every 20 seconds. 50,000 connections. Heartbeat messages/second?",
      "options": ["~250", "~2,500", "~25,000", "~250,000"],
      "correct": 1,
      "explanation": "50,000 connections ÷ 20 seconds = 2,500 heartbeat messages per second.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. If values like 20 seconds and 50,000 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-092",
      "type": "multiple-choice",
      "question": "Your SLO is p99 < 500ms. You had 100 requests > 500ms out of 1,000. Did you meet SLO?",
      "options": [
        "Yes, 10% is under 11%",
        "No, 10% exceeds 1%",
        "Yes, 100 is under 500",
        "Need more data"
      ],
      "correct": 1,
      "explanation": "p99 means only 1% can exceed threshold. 10% (100/1000) exceeded it. SLO violated.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that directly address failure mode, recovery path, and blast radius. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 500ms and 100 appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-093",
      "type": "multiple-choice",
      "question": "Batch ingestion runs for 2 hours every night. What's the daily processing window utilization?",
      "options": ["~2%", "~8%", "~25%", "~50%"],
      "correct": 1,
      "explanation": "2 hours ÷ 24 hours = 8.3% of the day spent on batch ingestion.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. In real systems, reject plans that assume linear scaling across shared bottlenecks. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 2 hours and 24 hours in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-094",
      "type": "multiple-choice",
      "question": "Network RTT is 50ms between datacenters. Synchronous cross-DC call adds how much latency?",
      "options": ["~25ms", "~50ms", "~100ms", "~200ms"],
      "correct": 1,
      "explanation": "RTT already means round-trip time. A single synchronous request-response call adds roughly one RTT, so about 50ms.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Discard bandwidth plans that omit overhead and burst behavior. Bandwidth planning should account for protocol overhead and burst behavior, not raw payload only. Numbers such as 50ms should be normalized first so downstream reasoning stays consistent. Common pitfall: bits-vs-bytes conversion mistakes.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-095",
      "type": "multiple-choice",
      "question": "Your deploy freezes start Dec 15 and end Jan 2. How many freeze days?",
      "options": ["~15 days", "~19 days", "~30 days", "~45 days"],
      "correct": 1,
      "explanation": "Dec 15-31 = 17 days + Jan 1-2 = 2 days = 19 days of freeze.",
      "detailedExplanation": "Generalize from your deploy freezes start Dec 15 and end Jan 2 to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 15 and 2 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-096",
      "type": "multiple-choice",
      "question": "You have 99.9% availability and serve 1 million requests/day. Expected daily failures?",
      "options": ["~10", "~100", "~1,000", "~10,000"],
      "correct": 2,
      "explanation": "0.1% failure rate. 0.001 × 1,000,000 = 1,000 failed requests per day.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 99.9 and 1 in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-097",
      "type": "multiple-choice",
      "question": "A rate limiter allows 60 requests/minute with no bursting. Max requests in 10 seconds?",
      "options": ["~1", "~6", "~10", "~60"],
      "correct": 2,
      "explanation": "60/minute = 1/second. In 10 seconds, max 10 requests (no bursting allowed).",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 60 and 10 seconds in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-098",
      "type": "multiple-choice",
      "question": "Sprint is 2 weeks. Release is every sprint. Releases per year?",
      "options": ["~12", "~26", "~52", "~104"],
      "correct": 1,
      "explanation": "52 weeks per year ÷ 2 weeks per sprint = 26 releases per year.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. In real systems, reject plans that assume linear scaling across shared bottlenecks. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 2 and 52 appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-099",
      "type": "multiple-choice",
      "question": "Your export job handles 10,000 records/minute. Time for 5 million records?",
      "options": ["~83 minutes", "~8.3 hours", "~83 hours", "~8.3 days"],
      "correct": 1,
      "explanation": "5,000,000 ÷ 10,000 per minute = 500 minutes = 8.3 hours.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject approaches that fail under peak load or saturation conditions. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 10,000 and 5 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-100",
      "type": "multiple-choice",
      "question": "A TTL is 1 hour. You have 1 million cached items uniformly distributed. Expirations per second?",
      "options": ["~28", "~278", "~2,780", "~27,800"],
      "correct": 1,
      "explanation": "1 million items expire over 3,600 seconds = 278 expirations per second.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. Keep quantities like 1 hour and 1 in aligned units before deciding on an implementation approach. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-101",
      "type": "multiple-choice",
      "question": "Your service has 99.9% success rate, handles 10,000 QPS, and failed requests retry twice on average. What's the actual QPS including retries?",
      "options": ["~10,010", "~10,020", "~10,100", "~10,200"],
      "correct": 1,
      "explanation": "0.1% of 10,000 = 10 failures/sec. Each failure retries twice = 20 extra QPS. Total = 10,020 QPS.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Reject approaches that sound good in general but do not reduce concrete reliability risk. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 99.9 and 10,000 QPS should be normalized first so downstream reasoning stays consistent. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-102",
      "type": "multiple-choice",
      "question": "Cache hit rate is 95%, cache latency is 5ms, cache miss adds a 50ms DB lookup. What's the average request latency?",
      "options": ["~5.25ms", "~7.5ms", "~27.5ms", "~52.5ms"],
      "correct": 1,
      "explanation": "Hits (95%): 5ms. Misses (5%): 5ms + 50ms = 55ms. Average = 0.95(5) + 0.05(55) = 4.75 + 2.75 = 7.5ms.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Prefer approaches that balance hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. If values like 95 and 5ms appear, convert them into one unit basis before comparison. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-103",
      "type": "multiple-choice",
      "question": "You're at 2,000 QPS with 10% monthly traffic growth. Capacity is 10,000 QPS. Approximately when do you need to scale?",
      "options": ["~8 months", "~12 months", "~17 months", "~24 months"],
      "correct": 2,
      "explanation": "Need 5× growth (2K to 10K). 1.1^n = 5, so n = ln(5)/ln(1.1) ≈ 16.9 months. You'd want to scale before hitting capacity.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. In real systems, reject plans that assume linear scaling across shared bottlenecks. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 2,000 QPS and 10 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-104",
      "type": "multiple-choice",
      "question": "An engineer proposes 50GB storage for a year of access logs: 500 QPS average, 200 bytes per log entry. Is this estimate reasonable?",
      "options": [
        "About right",
        "Too high by ~10×",
        "Too low by ~10×",
        "Too low by ~50×"
      ],
      "correct": 3,
      "explanation": "500 QPS × 200 bytes × 86,400 sec/day × 365 days = 3.15 TB. Proposal is 50GB—off by ~63×, so too low by ~50×.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Reject approaches that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 50GB and 500 QPS in aligned units before deciding on an implementation approach. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-105",
      "type": "multiple-choice",
      "question": "Your p50 is 20ms, p99 is 200ms. A request makes 3 sequential calls to this service. What's the p99 of the combined request?",
      "options": [
        "~200ms",
        "~400ms",
        "~600ms",
        "Cannot determine from this data"
      ],
      "correct": 3,
      "explanation": "p99 of a sum ≠ sum of p99s. The 99th percentile of each call rarely aligns. You need the full latency distribution or must measure the combined path directly.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Prefer approaches that directly address failure mode, recovery path, and blast radius. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Numbers such as 20ms and 200ms should be normalized first so downstream reasoning stays consistent. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-106",
      "type": "multiple-choice",
      "question": "You deploy 4× daily, each with 0.1% chance of causing a 15-minute incident. What's the expected monthly downtime from deploy incidents?",
      "options": [
        "~0.18 minutes",
        "~1.8 minutes",
        "~18 minutes",
        "~180 minutes"
      ],
      "correct": 1,
      "explanation": "4 deploys × 30 days = 120/month. Expected incidents = 120 × 0.001 = 0.12. Expected downtime = 0.12 × 15 min = 1.8 minutes.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Prioritize the approach that best protects reliability objectives under stated failure conditions. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 4 and 0.1 appear, convert them into one unit basis before comparison. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-107",
      "type": "multiple-choice",
      "question": "Leader election takes 5 seconds. Your leader fails once per month on average. What's the availability impact from leader failures alone?",
      "options": ["~99.9998%", "~99.998%", "~99.98%", "~99.8%"],
      "correct": 0,
      "explanation": "5 sec downtime per month. Month = 30 × 86,400 = 2.59M sec. Availability = 1 - (5/2,590,000) = 99.9998%.",
      "detailedExplanation": "Generalize from leader election takes 5 seconds to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Reject approaches that sound good in general but do not reduce concrete reliability risk. Tie decisions to concrete operational outcomes, not abstract reliability language. Keep quantities like 5 seconds and 5 sec in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-108",
      "type": "multiple-choice",
      "question": "You need 99.95% availability. MTBF (mean time between failures) is 720 hours. What's the maximum MTTR (mean time to recovery) you can tolerate?",
      "options": ["~5 minutes", "~22 minutes", "~2.2 hours", "~5 hours"],
      "correct": 1,
      "explanation": "Availability = MTBF/(MTBF+MTTR). 0.9995 = 720/(720+MTTR). Solving: MTTR = 720 × 0.0005/0.9995 ≈ 0.36 hours = 21.6 minutes.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Prefer approaches that directly address failure mode, recovery path, and blast radius. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 99.95 and 720 hours appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-109",
      "type": "multiple-choice",
      "question": "A batch job took 2 hours before optimization, 12 minutes after. It runs daily. How much compute time is saved per year?",
      "options": ["~66 hours", "~660 hours", "~1,320 hours", "~6,600 hours"],
      "correct": 1,
      "explanation": "Saved per run = 120 - 12 = 108 min = 1.8 hours. Per year = 1.8 × 365 = 657 hours ≈ 660 hours.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Prefer approaches that map cleanly to throughput, concurrency, and scaling limits. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 2 hours and 12 minutes should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n001",
      "type": "numeric-input",
      "question": "A service handles 5,000 QPS. How many requests does it receive per hour?",
      "answer": 18000000,
      "tolerance": 0.1,
      "explanation": "5,000 QPS × 3,600 seconds/hour = 18 million requests per hour.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 5,000 QPS and 3,600 seconds should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n002",
      "type": "numeric-input",
      "question": "Your API receives 50 million requests per day. What's the average QPS?",
      "answer": 579,
      "tolerance": 0.15,
      "explanation": "50M ÷ 86,400 seconds = 579 QPS.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Normalize units before computing so conversion mistakes do not propagate. Prioritize explicit semantics and upgrade safety, not just short-term convenience. If values like 50 and 50M appear, convert them into one unit basis before comparison. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n003",
      "type": "numeric-input",
      "question": "A cache TTL is 10 minutes. How many times will a hot key be refreshed per day?",
      "answer": 144,
      "tolerance": 0.1,
      "explanation": "1,440 minutes/day ÷ 10 minutes = 144 refreshes.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Normalize units before computing so conversion mistakes do not propagate. Treat freshness policy and invalidation paths as first-class constraints. If values like 10 minutes and 1,440 minutes appear, convert them into one unit basis before comparison. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n004",
      "type": "numeric-input",
      "question": "A cron job runs every 2 minutes. How many executions per week?",
      "answer": 5040,
      "tolerance": 0.1,
      "explanation": "60÷2 = 30 per hour × 24 hours × 7 days = 5,040 executions.",
      "detailedExplanation": "Generalize from cron job runs every 2 minutes to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Normalize units before computing so conversion mistakes do not propagate. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 2 minutes and 60 appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n005",
      "type": "numeric-input",
      "question": "99.99% availability allows how many minutes of downtime per month (30 days)?",
      "answer": 4.32,
      "unit": "minutes",
      "tolerance": 0.15,
      "explanation": "0.01% of 30 days = 0.0001 × 30 × 24 × 60 = 4.32 minutes.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Keep every transformation in one unit system and check order of magnitude at the end. Tie decisions to concrete operational outcomes, not abstract reliability language. Keep quantities like 99.99 and 30 days in aligned units before deciding on an implementation approach. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n006",
      "type": "numeric-input",
      "question": "A job processes 500 items/second. How many seconds to process 2 million items?",
      "answer": 4000,
      "unit": "seconds",
      "tolerance": 0.1,
      "explanation": "2,000,000 ÷ 500 = 4,000 seconds.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Keep every transformation in one unit system and check order of magnitude at the end. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 500 and 2 in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n007",
      "type": "numeric-input",
      "question": "With 1 billion requests/month, what's the average QPS?",
      "answer": 386,
      "tolerance": 0.15,
      "explanation": "1B ÷ (30 × 86,400) = 1B ÷ 2.59M ≈ 386 QPS.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 1 and 1B should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n008",
      "type": "numeric-input",
      "question": "A heartbeat is sent every 45 seconds. How many heartbeats per day?",
      "answer": 1920,
      "tolerance": 0.1,
      "explanation": "86,400 ÷ 45 = 1,920 heartbeats per day.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Normalize units before computing so conversion mistakes do not propagate. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 45 seconds and 86,400 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "RFC 6455: The WebSocket Protocol",
          "url": "https://www.rfc-editor.org/rfc/rfc6455"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n009",
      "type": "numeric-input",
      "question": "You have 10 million DAU, each making 20 requests/day. What's the QPS?",
      "answer": 2315,
      "tolerance": 0.15,
      "explanation": "10M × 20 = 200M requests/day ÷ 86,400 = 2,315 QPS.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Normalize units before computing so conversion mistakes do not propagate. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 10 and 20 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n010",
      "type": "numeric-input",
      "question": "A rate limit is 5,000 requests/hour. What's that per second?",
      "answer": 1.39,
      "tolerance": 0.2,
      "explanation": "5,000 ÷ 3,600 = 1.39 requests per second.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Normalize units before computing so conversion mistakes do not propagate. Interface decisions should be justified by contract stability and client impact over time. If values like 5,000 and 3,600 appear, convert them into one unit basis before comparison. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "Token bucket",
          "url": "https://en.wikipedia.org/wiki/Token_bucket"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n011",
      "type": "numeric-input",
      "question": "A batch job runs every 4 hours. How many runs per month (30 days)?",
      "answer": 180,
      "tolerance": 0.1,
      "explanation": "24 ÷ 4 = 6 per day × 30 days = 180 runs.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 4 hours and 30 days should be normalized first so downstream reasoning stays consistent. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n012",
      "type": "numeric-input",
      "question": "Your p99 latency is 300ms. Out of 50,000 requests, how many can exceed 300ms?",
      "answer": 500,
      "tolerance": 0.1,
      "explanation": "1% of 50,000 = 500 requests can exceed the p99 threshold.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Normalize units before computing so conversion mistakes do not propagate. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 300ms and 50,000 appear, convert them into one unit basis before comparison. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n013",
      "type": "numeric-input",
      "question": "A 99.5% SLA allows how many hours of downtime per year?",
      "answer": 43.8,
      "unit": "hours",
      "tolerance": 0.15,
      "explanation": "0.5% of 365 × 24 = 0.005 × 8,760 = 43.8 hours.",
      "detailedExplanation": "Generalize from 99 to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Numbers such as 99.5 and 0.5 should be normalized first so downstream reasoning stays consistent. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n014",
      "type": "numeric-input",
      "question": "A queue drains at 200/second but receives 180/second. After 10 minutes, what's the backlog cleared?",
      "answer": 12000,
      "tolerance": 0.1,
      "explanation": "Net drain rate = 20/second. 20 × 600 seconds = 12,000 items cleared.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Keep every transformation in one unit system and check order of magnitude at the end. A good message-system answer defines guarantees clearly for both producer and consumer paths. Keep quantities like 200 and 180 in aligned units before deciding on an implementation approach. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n015",
      "type": "numeric-input",
      "question": "2,000 QPS at 50ms average latency. Using Little's Law, how many requests are in-flight?",
      "answer": 100,
      "tolerance": 0.1,
      "explanation": "L = λW. 2,000 × 0.05 = 100 concurrent requests.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Normalize units before computing so conversion mistakes do not propagate. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 2,000 QPS and 50ms appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n016",
      "type": "numeric-input",
      "question": "A video transcodes at 4× realtime. How many minutes to transcode a 3-hour movie?",
      "answer": 45,
      "unit": "minutes",
      "tolerance": 0.1,
      "explanation": "3 hours ÷ 4 = 0.75 hours = 45 minutes.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Keep every transformation in one unit system and check order of magnitude at the end. A strong compute answer links throughput targets to concurrency and scaling triggers. Keep quantities like 4 and 3 in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n017",
      "type": "numeric-input",
      "question": "A database handles 50 writes/second. How many million writes per day?",
      "answer": 4.32,
      "unit": "million",
      "tolerance": 0.15,
      "explanation": "50 × 86,400 = 4.32 million writes per day.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Normalize units before computing so conversion mistakes do not propagate. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 50 and 86,400 appear, convert them into one unit basis before comparison. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-n018",
      "type": "numeric-input",
      "question": "Cache has 2 million items with 30-minute TTL, uniformly distributed. Expirations per second?",
      "answer": 1111,
      "tolerance": 0.15,
      "explanation": "2M items ÷ 1,800 seconds = 1,111 expirations per second.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Numbers such as 2 and 30 should be normalized first so downstream reasoning stays consistent. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Redis EXPIRE command",
          "url": "https://redis.io/docs/latest/commands/expire/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o001",
      "type": "ordering",
      "question": "Rank these SLA levels from most to least downtime allowed per year.",
      "items": ["99%", "99.99%", "99.9%", "99.999%"],
      "correctOrder": [0, 2, 1, 3],
      "explanation": "99% (3.65 days) > 99.9% (8.76 hrs) > 99.99% (52.6 min) > 99.999% (5.26 min).",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Place obvious extremes first, then sort the middle by pairwise comparison. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. If values like 99 and 3.65 days appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o002",
      "type": "ordering",
      "question": "Rank these from most to fewest executions per day.",
      "items": [
        "Every 5 minutes",
        "Every hour",
        "Every 30 seconds",
        "Every 15 minutes"
      ],
      "correctOrder": [2, 0, 3, 1],
      "explanation": "30s (2,880) > 5min (288) > 15min (96) > 1hr (24).",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Order by relative scale and bottleneck effect, then validate neighboring items. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 30s and 2,880 appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o003",
      "type": "ordering",
      "question": "Rank these time periods from shortest to longest.",
      "items": ["1 week", "10,000 seconds", "1 month", "1 million seconds"],
      "correctOrder": [1, 0, 3, 2],
      "explanation": "10K sec (2.8 hrs) < 1 week (604K sec) < 1M sec (11.6 days) < 1 month (2.6M sec).",
      "detailedExplanation": "Generalize from rank these time periods from shortest to longest to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Place obvious extremes first, then sort the middle by pairwise comparison. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Numbers such as 10K and 2.8 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o004",
      "type": "ordering",
      "question": "Rank these QPS values from lowest to highest.",
      "items": ["1M req/day", "100 req/sec", "1B req/month", "10M req/week"],
      "correctOrder": [0, 3, 1, 2],
      "explanation": "1M/day (12 QPS) < 10M/week (17 QPS) < 100 QPS < 1B/month (386 QPS).",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Place obvious extremes first, then sort the middle by pairwise comparison. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 1M and 12 QPS in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o005",
      "type": "ordering",
      "question": "Rank these retry strategies by total wait time if all retries fail (initial + retries).",
      "items": [
        "3 retries, 2s each",
        "2 retries, 5s each",
        "Exponential 1-2-4s",
        "4 retries, 1s each"
      ],
      "correctOrder": [3, 0, 2, 1],
      "explanation": "4×1=4s < 3×2=6s < 1+2+4=7s < 2×5=10s (assuming immediate failures).",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Order by relative scale and bottleneck effect, then validate neighboring items. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Keep quantities like 4 and 1 in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o006",
      "type": "ordering",
      "question": "Rank these scenarios by expected latency (lowest to highest).",
      "items": [
        "Sequential: 3 calls × 50ms each",
        "Parallel: max of 3 calls × 50ms",
        "1 call × 100ms",
        "Sequential: 2 calls × 30ms each"
      ],
      "correctOrder": [1, 3, 2, 0],
      "explanation": "Parallel 50ms < Sequential 60ms < Single 100ms < Sequential 150ms.",
      "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Build the rank from biggest differences first, then refine with adjacent checks. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 50ms and 60ms should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o007",
      "type": "ordering",
      "question": "Rank by number of executions per year (fewest to most).",
      "items": [
        "Weekly batch",
        "Daily backup",
        "Hourly sync",
        "Monthly report"
      ],
      "correctOrder": [3, 0, 1, 2],
      "explanation": "Monthly (12) < Weekly (52) < Daily (365) < Hourly (8,760).",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Order by relative scale and bottleneck effect, then validate neighboring items. Show present and projected demand side by side so scaling deadlines are visible early. If values like 12 and 52 appear, convert them into one unit basis before comparison. Common pitfall: postponing scaling work until after constraint breach.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-o008",
      "type": "ordering",
      "question": "Rank these percentile measurements by how many requests they represent (out of 1M).",
      "items": ["p50", "p99.9", "p99", "p95"],
      "correctOrder": [1, 2, 3, 0],
      "explanation": "p99.9 (1K exceed) < p99 (10K) < p95 (50K) < p50 (500K exceed the threshold).",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Order by relative scale and bottleneck effect, then validate neighboring items. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. If values like 1M and 9 appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m001",
      "type": "multi-select",
      "question": "Which represent approximately 1,000 QPS?",
      "options": [
        "86.4 million requests/day",
        "2.6 billion requests/month",
        "604 million requests/week",
        "3.6 million requests/hour"
      ],
      "correctIndices": [0, 1, 2, 3],
      "explanation": "All of these convert to approximately 1,000 QPS: 86.4M/day, 2.6B/month, 604M/week, 3.6M/hour.",
      "detailedExplanation": "Generalize from represent approximately 1,000 QPS to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Evaluate each candidate approach independently under the same constraints. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 1,000 QPS and 86.4M in aligned units before deciding on an implementation approach. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m002",
      "type": "multi-select",
      "question": "Which SLA levels allow more than 1 hour of downtime per year?",
      "options": ["99%", "99.9%", "99.99%", "99.999%"],
      "correctIndices": [0, 1],
      "explanation": "99% allows ~3.65 days/year and 99.9% allows ~8.76 hours/year, both above 1 hour. 99.99% (~52.6 min) and 99.999% (~5.26 min) are below 1 hour.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 1 hour and 99 in aligned units before deciding on an implementation approach. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m003",
      "type": "multi-select",
      "question": "Which intervals result in more than 100 executions per day?",
      "options": [
        "Every 5 minutes",
        "Every 30 minutes",
        "Every 10 minutes",
        "Every hour"
      ],
      "correctIndices": [0, 2],
      "explanation": "5 min → 288/day, 10 min → 144/day. 30 min → 48/day, 1 hr → 24/day.",
      "detailedExplanation": "In interviews and real systems work, anchor on the dominant constraint and evaluate approaches by blast radius, reversibility, and operational cost. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Keep quantities like 100 and 5 min in aligned units before deciding on an implementation approach. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m008",
      "type": "multi-select",
      "question": "A token expires in 1 hour. A user is active for 8 hours. Which are true?",
      "options": [
        "8 tokens will be issued",
        "7 token refreshes will occur",
        "Token refresh happens every 60 minutes",
        "User needs ~8 authentications"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "8 hours ÷ 1 hour = 8 tokens needed. Refresh happens hourly (every 60 min). 8 total tokens issued throughout the session.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Evaluate each candidate approach independently under the same constraints. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Keep quantities like 1 hour and 8 hours in aligned units before deciding on an implementation approach. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m005",
      "type": "multi-select",
      "question": "Which batch frequencies run more than 500 times per month?",
      "options": [
        "Every 2 hours",
        "Every 30 minutes",
        "Every 4 hours",
        "Hourly"
      ],
      "correctIndices": [1, 3],
      "explanation": "30min: 48/day × 30 = 1,440/mo ✓, Hourly: 24 × 30 = 720/mo ✓. 2hr: 12 × 30 = 360/mo ✗, 4hr: 6 × 30 = 180/mo ✗.",
      "detailedExplanation": "For related interview or production problems, identify the highest-signal symptom early and map it to the smallest high-leverage control change. Validate each proposed control independently and avoid partially true claims that fail under realistic load. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. Numbers such as 500 and 30min should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming linear scaling through shared bottlenecks.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m006",
      "type": "multi-select",
      "question": "Which correctly describe a p99 latency of 200ms?",
      "options": [
        "99% of requests complete in ≤200ms",
        "1% of requests exceed 200ms",
        "Average latency is 200ms",
        "Maximum latency is 200ms"
      ],
      "correctIndices": [0, 1],
      "explanation": "p99 means 99% are under the threshold and 1% exceed it. It's not the average or maximum.",
      "detailedExplanation": "For related interview and production incidents, classify the dominant failure mode first, then choose the earliest intervention that materially reduces user-facing risk. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Numbers such as 200ms and 99 should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m007",
      "type": "multiple-choice",
      "question": "Which option is approximately 1 million seconds?",
      "options": ["11.5 days", "1.5 weeks", "About 2 weeks", "About 1 month"],
      "explanation": "1M seconds = 1M ÷ 86,400 = 11.57 days. 1.5 weeks = 10.5 days, 2 weeks = 14 days, 1 month = 30 days.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Anchor decisions in explicit constraints, invariants, and observable failure signals rather than intuition. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 1 and 1M appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "correct": 0,
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-m009",
      "type": "multi-select",
      "question": "If you deploy 4× daily with 0.1% incident probability per deploy, which are true?",
      "options": [
        "~1.5 incidents expected per year",
        "~12 incidents expected per year",
        "Less than 1% chance of incident each month",
        "About 0.4% daily incident probability"
      ],
      "correctIndices": [0, 3],
      "explanation": "Expected incidents/year = 4 deploys/day × 365 × 0.001 = 1.46 (~1.5). Daily probability of at least one incident is 1 - 0.999^4 ≈ 0.4%.",
      "detailedExplanation": "Generalize from if you deploy 4× daily with 0 to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Evaluate each candidate approach independently under the same constraints. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 4 and 0.1 should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Release Engineering",
          "url": "https://sre.google/sre-book/release-engineering/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-t001",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your service receives 100 million requests per day. What's the approximate QPS?",
          "options": ["~100 QPS", "~1,000 QPS", "~10,000 QPS", "~100,000 QPS"],
          "correct": 1,
          "explanation": "100M ÷ 86,400 ≈ 1,157 QPS ≈ 1,000 QPS.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Solve this as chained reasoning where stage two must respect stage one assumptions. A strong compute answer links throughput targets to concurrency and scaling triggers. Numbers such as 100 and 100M should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring queueing effects at high utilization."
        },
        {
          "question": "At this QPS with 50ms average latency, how many concurrent requests using Little's Law?",
          "options": ["~5", "~50", "~500", "~5,000"],
          "correct": 1,
          "explanation": "L = λW = 1,000 × 0.05 = 50 concurrent requests.",
          "detailedExplanation": "Generalize from at this QPS with 50ms average latency, how many concurrent requests using Little's Law to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Solve this as chained reasoning where stage two must respect stage one assumptions. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 50ms and 1,000 appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak."
        }
      ],
      "explanation": "Converting daily requests to QPS, then applying Little's Law for concurrency estimation.",
      "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong compute answer links throughput targets to concurrency and scaling triggers. Common pitfall: sizing to average and failing at peak.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-t002",
      "type": "two-stage",
      "stages": [
        {
          "question": "You need 99.99% availability. How many minutes of downtime per month is your budget?",
          "options": [
            "~4 minutes",
            "~44 minutes",
            "~440 minutes",
            "~4,400 minutes"
          ],
          "correct": 0,
          "explanation": "0.01% of 30 days = 0.0001 × 30 × 24 × 60 = 4.32 minutes.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Solve this as chained reasoning where stage two must respect stage one assumptions. Map the approach to measurable reliability impact such as error-budget burn and recovery behavior. Keep quantities like 99.99 and 0.01 in aligned units before deciding on an implementation approach. Common pitfall: retry storms during partial failure."
        },
        {
          "question": "If your average incident takes 30 minutes to resolve, how do you achieve this target?",
          "options": [
            "Never have incidents",
            "Have fewer than 1 incident per 7 months",
            "Have at most 1 incident per month",
            "Use redundancy to reduce incident duration"
          ],
          "correct": 3,
          "explanation": "30 min/incident exceeds 4 min budget. You need redundancy/failover to reduce actual downtime per incident.",
          "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie decisions to concrete operational outcomes, not abstract reliability language. Numbers such as 30 minutes and 30 min should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "explanation": "High availability targets often require redundancy because incident resolution takes longer than the allowed downtime.",
      "detailedExplanation": "Generalize from high availability targets often require redundancy because incident resolution takes to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong real-world approach explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-t003",
      "type": "two-stage",
      "stages": [
        {
          "question": "A batch job processes 1,000 items/second. You have 10 million items to process. How long?",
          "options": ["~17 minutes", "~2.8 hours", "~28 hours", "~2.8 days"],
          "correct": 1,
          "explanation": "10M ÷ 1,000 = 10,000 seconds = 2.78 hours.",
          "detailedExplanation": "In interviews and real systems work, begin by naming the dominant constraint, then pressure-test candidate approaches against reliability, latency, and operability trade-offs. Solve this as chained reasoning where stage two must respect stage one assumptions. Capacity reasoning should separate average and peak demand, then map both to saturation limits. If values like 1,000 and 10 appear, convert them into one unit basis before comparison. Common pitfall: sizing to average and failing at peak."
        },
        {
          "question": "If you need to finish in under 1 hour, how many parallel workers do you need?",
          "options": ["2 workers", "3 workers", "4 workers", "5 workers"],
          "correct": 1,
          "explanation": "2.78 hours ÷ 1 hour target = 2.78, round up to 3 workers minimum.",
          "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Do not reset assumptions between stages; carry forward prior constraints directly. Sizing decisions are better when headroom and bottleneck behavior are stated explicitly. If values like 1 hour and 2.78 hours appear, convert them into one unit basis before comparison. Common pitfall: ignoring queueing effects at high utilization."
        }
      ],
      "explanation": "Estimating processing time and scaling horizontally to meet time constraints.",
      "detailedExplanation": "Generalize this scenario to the underlying systems skill: identify the invariant to protect, the load/failure pattern, and the first control that changes outcomes. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity reasoning should separate average and peak demand, then map both to saturation limits. Common pitfall: ignoring queueing effects at high utilization.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    },
    {
      "id": "time-t004",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your cache TTL is 5 minutes. You have 1 million cached items uniformly distributed. Expirations per second?",
          "options": ["~33", "~333", "~3,333", "~33,333"],
          "correct": 2,
          "explanation": "1M items ÷ 300 seconds = 3,333 expirations per second.",
          "detailedExplanation": "Generalize from your cache TTL is 5 minutes to the underlying invariant and failure mode, then compare approaches by risk reduction, reversibility, and operational cost. Solve this as chained reasoning where stage two must respect stage one assumptions. Cache design quality is mostly about correctness boundaries, not only hit rate. Numbers such as 5 minutes and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: hot-key skew causing uneven load."
        },
        {
          "question": "If each cache miss causes a 10ms database query, what's the added DB load from expirations?",
          "options": [
            "~33 concurrent queries",
            "~333 QPS to DB",
            "~3,333 QPS to DB",
            "~10% of DB capacity"
          ],
          "correct": 2,
          "explanation": "3,333 expirations/sec = 3,333 cache misses = 3,333 QPS hitting the database.",
          "detailedExplanation": "For related interview or production problems, distinguish core signal from background noise before selecting mitigations. Do not reset assumptions between stages; carry forward prior constraints directly. Cache design quality is mostly about correctness boundaries, not only hit rate. Numbers such as 10ms and 3,333 should be normalized first so downstream reasoning stays consistent. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "explanation": "Cache expiration storms can cause significant database load spikes.",
      "detailedExplanation": "For related interview or production problems, make the decision around the dominant constraint instead of broad platform-wide changes. Solve this as chained reasoning where stage two must respect stage one assumptions. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "System Design Primer: Numbers Every Programmer Should Know",
          "url": "https://github.com/donnemartin/system-design-primer#numbers-every-programmer-should-know"
        }
      ],
      "tags": ["estimation", "time-math"],
      "difficulty": "senior"
    }
  ]
}
