{
  "unit": 4,
  "unitTitle": "Storage Selection",
  "chapter": 4,
  "chapterTitle": "Wide-Column & Time-Series",
  "chapterDescription": "Cassandra, HBase, and time-series databases for write-heavy and time-ordered workloads.",
  "problems": [
    {
      "id": "wc-001",
      "type": "multiple-choice",
      "question": "What is a wide-column store?",
      "options": [
        "A database with many columns per table",
        "A database where rows can have different columns, organized by row key and column families",
        "A columnar analytics database",
        "A spreadsheet application"
      ],
      "correct": 1,
      "explanation": "Wide-column stores (Cassandra, HBase) organize data by row key, with columns grouped into column families. Unlike relational tables, each row can have different columns. It's a sparse, distributed structure optimized for scale and write performance.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-002",
      "type": "multi-select",
      "question": "Which are wide-column databases?",
      "options": ["Cassandra", "HBase", "MongoDB", "Google Bigtable"],
      "correctIndices": [0, 1, 3],
      "explanation": "Cassandra, HBase, and Google Bigtable are wide-column stores. MongoDB is a document database. Bigtable was the original wide-column store; Cassandra and HBase are inspired by it.",
      "detailedExplanation": "Treat each candidate as a separate true/false check against the same governing requirement. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-003",
      "type": "multiple-choice",
      "question": "What is a column family in wide-column stores?",
      "options": [
        "A group of related tables",
        "A container for columns that are typically accessed together",
        "A family of database servers",
        "A backup of columns"
      ],
      "correct": 1,
      "explanation": "A column family groups related columns stored together on disk. In Cassandra, a table is a column family. Columns within a family are stored together, so group columns that are queried together. This optimizes read performance.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        }
      ]
    },
    {
      "id": "wc-004",
      "type": "multiple-choice",
      "question": "How do wide-column stores differ from relational databases?",
      "options": [
        "They have fixed schemas",
        "Rows can have different columns, and data is stored by column family for efficient access",
        "They don't support any queries",
        "They only store numbers"
      ],
      "correct": 1,
      "explanation": "Wide-column stores have flexible schemas: each row can have different columns. Data is organized by row key and column families, not normalized tables. This enables massive scale and fast writes, but queries are limited to row key patterns.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-005",
      "type": "multiple-choice",
      "question": "What is Apache Cassandra?",
      "options": [
        "A relational database",
        "A distributed wide-column store designed for high availability and linear scalability",
        "A message queue",
        "A search engine"
      ],
      "correct": 1,
      "explanation": "Cassandra is a distributed wide-column database. Key features: masterless architecture (no single point of failure), linear scalability (add nodes for more capacity), tunable consistency, and excellent write performance. Used by Netflix, Apple, and others at scale.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "wc-006",
      "type": "multi-select",
      "question": "What are key features of Cassandra?",
      "options": [
        "Masterless architecture — no single point of failure",
        "Linear horizontal scalability",
        "Strong ACID transactions by default",
        "Tunable consistency levels"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Cassandra is masterless (any node can handle requests), scales linearly (add nodes for capacity), and has tunable consistency (trade consistency for availability). It's not strongly ACID by default — it prioritizes availability and partition tolerance.",
      "detailedExplanation": "Assess each option separately and keep answers that hold across the full problem context. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "wc-007",
      "type": "multiple-choice",
      "question": "What is a partition key in Cassandra?",
      "options": [
        "A key that partitions the network",
        "The primary key component that determines which node stores the data",
        "An encryption key",
        "A foreign key"
      ],
      "correct": 1,
      "explanation": "The partition key determines data placement. Cassandra hashes it to assign data to nodes. All rows with the same partition key are stored together on the same nodes. Choosing a good partition key (high cardinality, even distribution) is critical.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-008",
      "type": "multiple-choice",
      "question": "What is a clustering key in Cassandra?",
      "options": [
        "A key for cluster management",
        "Columns that determine the sort order of rows within a partition",
        "A key for joining clusters",
        "The primary key"
      ],
      "correct": 1,
      "explanation": "Clustering columns define the sort order within a partition. For PRIMARY KEY ((user_id), created_at), user_id is the partition key, created_at is the clustering key. Rows for a user are sorted by created_at, enabling efficient range queries within the partition.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-009",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're storing user activity logs. Each user has thousands of events. What's a good primary key design?",
          "options": [
            "PRIMARY KEY (event_id)",
            "PRIMARY KEY ((user_id), event_timestamp)",
            "PRIMARY KEY (event_timestamp)",
            "PRIMARY KEY ((event_id), user_id)"
          ],
          "correct": 1,
          "explanation": "((user_id), event_timestamp): user_id is the partition key (groups all events for a user), event_timestamp is the clustering key (sorts events chronologically). You can efficiently query 'all events for user X' or 'events for user X after time Y'.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        },
        {
          "question": "A user has 10 years of activity (millions of events). What problem might occur?",
          "options": [
            "No problem",
            "Partition too large — 'wide row' or 'hot partition' issues",
            "Too many clustering keys",
            "Cassandra can't store that much data"
          ],
          "correct": 1,
          "explanation": "Millions of events per partition creates a 'wide row' that's slow to read and can exceed recommended partition size (~100MB). Solutions: add a time bucket to the partition key ((user_id, year_month)) to split data into manageable partitions.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-010",
      "type": "multiple-choice",
      "question": "What is CQL (Cassandra Query Language)?",
      "options": [
        "A programming language",
        "SQL-like query language for Cassandra, but with different capabilities",
        "A configuration language",
        "A compression algorithm"
      ],
      "correct": 1,
      "explanation": "CQL looks like SQL (SELECT, INSERT, CREATE TABLE) but has different semantics. No JOINs, limited WHERE clauses (must include partition key), no ad-hoc queries. CQL queries must match the data model you designed.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-011",
      "type": "multiple-choice",
      "question": "Why can't you do arbitrary WHERE clauses in Cassandra like in SQL?",
      "options": [
        "CQL syntax doesn't support WHERE",
        "Queries must use the partition key; Cassandra doesn't scan all partitions for arbitrary filters",
        "Cassandra is write-only",
        "WHERE is deprecated"
      ],
      "correct": 1,
      "explanation": "Cassandra is designed for key-based lookups, not full scans. Queries must include the partition key to route to the right nodes. Arbitrary WHERE without partition key would require scanning all nodes — that's an anti-pattern. Design your keys for your queries.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-012",
      "type": "multi-select",
      "question": "What queries are efficient in Cassandra?",
      "options": [
        "Query by full partition key",
        "Query by partition key with clustering key range",
        "Query by non-key column across all partitions",
        "Query by partition key prefix in a composite key"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Efficient: full partition key (routes to nodes), partition key + clustering range (sorted within partition), composite partition key prefix. Inefficient: queries without partition key require ALLOW FILTERING (full scan) — avoid in production.",
      "detailedExplanation": "Check every option on its own merits and reject statements that are only true under hidden assumptions. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-013",
      "type": "multiple-choice",
      "question": "What is ALLOW FILTERING in Cassandra?",
      "options": [
        "Enables optimized filtering",
        "A directive that allows inefficient queries scanning many partitions — generally avoid",
        "Allows filtering null values",
        "A security permission"
      ],
      "correct": 1,
      "explanation": "ALLOW FILTERING tells Cassandra to scan partitions for your query. It's required when the query doesn't match the primary key. It's slow and expensive at scale — queries without ALLOW FILTERING are efficient by design.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-014",
      "type": "two-stage",
      "stages": [
        {
          "question": "You have a users table with partition key user_id. You want to query users by email. What's the challenge?",
          "options": [
            "No challenge — just WHERE email = ...",
            "email is not part of the primary key, so you can't query efficiently by email",
            "Cassandra doesn't support email fields",
            "You need to JOIN with another table"
          ],
          "correct": 1,
          "explanation": "Cassandra queries must include the partition key. Querying by email without user_id requires scanning all partitions (ALLOW FILTERING). This is slow and not scalable. You need a different approach.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        },
        {
          "question": "How do you enable efficient email lookups?",
          "options": [
            "Add ALLOW FILTERING to every query",
            "Create a secondary table (email → user_id) or use a secondary index",
            "Store email as the partition key instead",
            "Use a relational database for this query"
          ],
          "correct": 1,
          "explanation": "Two options: (1) Secondary index on email (Cassandra manages it, but has limitations at scale). (2) Denormalized lookup table: users_by_email with partition key email. Insert into both tables. Option 2 is more performant for high-scale reads.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        }
      ],
      "detailedExplanation": "Start from the governing formula, keep units visible, and validate the final magnitude. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-015",
      "type": "multiple-choice",
      "question": "What is a secondary index in Cassandra?",
      "options": [
        "A backup index",
        "An index on a non-primary-key column, enabling queries on that column",
        "The second column in the primary key",
        "An index on a secondary cluster"
      ],
      "correct": 1,
      "explanation": "Secondary indexes let you query by non-key columns. Cassandra maintains the index automatically. But they have limits: low-cardinality columns work best, high-cardinality can be slow. For high-scale, denormalized tables are often better.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "wc-016",
      "type": "multi-select",
      "question": "What are limitations of Cassandra secondary indexes?",
      "options": [
        "Can be slow for high-cardinality columns",
        "May require querying all nodes",
        "Not suitable for columns with very few unique values",
        "Can't be used with partition keys"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Secondary indexes can be slow for high-cardinality (many unique values) because lookups may hit many nodes. Very low cardinality (boolean) is also problematic — each value maps to many rows, making queries expensive. They work best for medium cardinality.",
      "detailedExplanation": "Run a one-by-one validity check and discard options that depend on unstated conditions. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "wc-017",
      "type": "multiple-choice",
      "question": "What is Cassandra's approach to consistency?",
      "options": [
        "Always strongly consistent",
        "Always eventually consistent",
        "Tunable consistency — you choose per query",
        "No consistency guarantees"
      ],
      "correct": 2,
      "explanation": "Cassandra offers tunable consistency. For each read/write, you specify a consistency level: ONE (fastest, least consistent), QUORUM (majority of replicas), ALL (slowest, strongest). You can trade latency for consistency per operation.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-018",
      "type": "ordering",
      "question": "Rank these Cassandra consistency levels from weakest to strongest:",
      "items": ["ONE", "ALL", "QUORUM", "LOCAL_QUORUM"],
      "correctOrder": [0, 3, 2, 1],
      "explanation": "ONE (1 replica) < LOCAL_QUORUM (majority in local datacenter) < QUORUM (majority across all datacenters) < ALL (all replicas). Stronger consistency means more nodes must respond, increasing latency and reducing availability during partitions.",
      "detailedExplanation": "Establish the extremes first and fill the middle with pairwise comparisons. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "wc-019",
      "type": "two-stage",
      "stages": [
        {
          "question": "You write with consistency level QUORUM (replication factor 3, so 2 nodes). You read with ONE. Could you get stale data?",
          "options": [
            "No — QUORUM write guarantees consistency",
            "Yes — reading from 1 replica might hit the node that didn't receive the write yet",
            "Cassandra prevents this automatically",
            "Only if nodes are down"
          ],
          "correct": 1,
          "explanation": "QUORUM write goes to 2/3 replicas. Reading with ONE might hit the third replica that doesn't have the write yet. For guaranteed read-your-writes, use QUORUM for both reads and writes, or use sticky sessions.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "What combination guarantees strong consistency in Cassandra?",
          "options": [
            "Write ONE, Read ONE",
            "Write ALL, Read ONE",
            "Write QUORUM, Read QUORUM (where W + R > N)",
            "Any combination works"
          ],
          "correct": 2,
          "explanation": "For strong consistency: W + R > N (replication factor). With RF=3 and QUORUM (2), W(2) + R(2) = 4 > 3. At least one replica in the read set received the write. This is the standard pattern for consistent reads.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        }
      ],
      "detailedExplanation": "Anchor on the base formula, preserve unit integrity, and then run a reasonableness check. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-020",
      "type": "multiple-choice",
      "question": "What happens when you write to Cassandra?",
      "options": [
        "Data goes directly to disk",
        "Write to commit log (durability) and memtable (memory), later flushed to SSTables on disk",
        "Data is queued for batch processing",
        "Write to primary replica only"
      ],
      "correct": 1,
      "explanation": "Cassandra writes are fast: append to commit log (sequential disk write for durability) and update memtable (in-memory). Later, memtables flush to immutable SSTables on disk. This write path is optimized for high throughput.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-021",
      "type": "multiple-choice",
      "question": "What is an SSTable in Cassandra?",
      "options": [
        "A SQL table",
        "Sorted String Table — an immutable, sorted file of key-value data on disk",
        "A session state table",
        "A secondary storage table"
      ],
      "correct": 1,
      "explanation": "SSTables are immutable, sorted files. When memtables flush, they become SSTables. Reads may check multiple SSTables and merge results. Compaction merges SSTables, removing deleted data (tombstones) and consolidating updates.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. A good sanity check compares against anchor numbers and names which assumption must change if the result looks implausible.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-022",
      "type": "multiple-choice",
      "question": "What is compaction in Cassandra?",
      "options": [
        "Compressing data",
        "Merging SSTables to remove tombstones and consolidate data",
        "Compacting the cluster",
        "Reducing replication factor"
      ],
      "correct": 1,
      "explanation": "Compaction merges SSTables: combines rows, applies updates, removes tombstones (deleted data markers). This reclaims space and improves read performance (fewer files to check). Compaction runs in the background but consumes I/O.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. A good sanity check compares against anchor numbers and names which assumption must change if the result looks implausible.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-023",
      "type": "multi-select",
      "question": "What workloads is Cassandra particularly good for?",
      "options": [
        "Write-heavy workloads (time-series, IoT, logging)",
        "High availability requirements (no single point of failure)",
        "Complex ad-hoc queries with JOINs",
        "Global distribution with multi-datacenter replication"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Cassandra excels at: write-heavy (append-optimized), high availability (masterless, survives node failures), multi-datacenter (built-in replication across regions). It's not for ad-hoc queries or JOINs — design your data model for your queries.",
      "detailedExplanation": "Check every option on its own merits and reject statements that are only true under hidden assumptions. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-024",
      "type": "multiple-choice",
      "question": "What is Apache HBase?",
      "options": [
        "A SQL database on Hadoop",
        "A wide-column store modeled after Bigtable, running on HDFS/Hadoop",
        "A hive for data bees",
        "A key-value cache"
      ],
      "correct": 1,
      "explanation": "HBase is a wide-column store inspired by Google Bigtable. It runs on Hadoop/HDFS. Key features: strong consistency (unlike Cassandra's tunable), random read/write access to HDFS data, integration with Hadoop ecosystem.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-025",
      "type": "multi-select",
      "question": "How does HBase differ from Cassandra?",
      "options": [
        "HBase uses master nodes; Cassandra is masterless",
        "HBase provides strong consistency; Cassandra has tunable consistency",
        "HBase runs on HDFS; Cassandra has its own storage",
        "HBase is better for ad-hoc analytics"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Key differences: HBase has master nodes (HMaster, ZooKeeper) vs. Cassandra's masterless. HBase is strongly consistent vs. Cassandra's tunable. HBase runs on HDFS. Both are limited for ad-hoc analytics — use Spark/Hive on top.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-026",
      "type": "multiple-choice",
      "question": "When would you choose HBase over Cassandra?",
      "options": [
        "When you need tunable consistency",
        "When you need strong consistency and Hadoop ecosystem integration",
        "When you need masterless architecture",
        "When you need the simplest operations"
      ],
      "correct": 1,
      "explanation": "Choose HBase for: strong consistency requirements, existing Hadoop/HDFS investment, need to run MapReduce/Spark on stored data. Choose Cassandra for: masterless HA, tunable consistency, easier operations, multi-datacenter.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-027",
      "type": "multiple-choice",
      "question": "What is Google Cloud Bigtable?",
      "options": [
        "An open-source database",
        "Google's managed wide-column store, the original inspiration for HBase",
        "A relational database",
        "A file storage service"
      ],
      "correct": 1,
      "explanation": "Cloud Bigtable is Google's managed wide-column store. The original Bigtable paper inspired HBase and Cassandra. Bigtable offers: fully managed, massive scale, low latency, integration with Google Cloud services. Used internally by Google for Search, Maps, etc.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-028",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're designing a row key for Bigtable/HBase storing user events. Key = user_id + timestamp. What's a potential problem?",
          "options": [
            "No problem",
            "Sequential timestamps create hot spots — all recent writes go to the same region",
            "User IDs are too long",
            "Timestamps aren't supported"
          ],
          "correct": 1,
          "explanation": "Sequential keys (like timestamps) cause hot spotting: all writes go to the region handling the current time range. This overloads that region while others are idle. Wide-column stores prefer random or distributed key patterns.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        },
        {
          "question": "How do you avoid this hot spotting?",
          "options": [
            "Use shorter timestamps",
            "Prefix with user_id or hash, or reverse the timestamp",
            "Use a different database",
            "Increase region count"
          ],
          "correct": 1,
          "explanation": "Solutions: (1) Prefix with high-cardinality field (user_id) so writes spread across users. (2) Hash prefix to randomize. (3) Reverse timestamp (newest = smallest) spreads writes across regions. Key design is critical for wide-column performance.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead."
        }
      ],
      "detailedExplanation": "Anchor on the base formula, preserve unit integrity, and then run a reasonableness check. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-029",
      "type": "multiple-choice",
      "question": "What is a time-series database?",
      "options": [
        "Any database that stores timestamps",
        "A database optimized for time-stamped data: efficient writes, time-range queries, downsampling",
        "A database that tracks time spent",
        "A scheduling database"
      ],
      "correct": 1,
      "explanation": "Time-series databases (InfluxDB, TimescaleDB, Prometheus) are optimized for: append-heavy writes (metrics, events), time-range queries (last 24 hours), aggregation (downsample to hourly), and automatic data retention (delete old data).",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-030",
      "type": "multi-select",
      "question": "What are characteristics of time-series workloads?",
      "options": [
        "Data is append-only or append-mostly",
        "Queries are typically by time range",
        "Recent data is accessed more than old data",
        "Data requires frequent random updates"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Time-series workloads: append-mostly (new data points, rarely update old), time-range queries (metrics from 2-3pm), recency bias (today's data accessed more than last year's). Random updates are rare — if common, consider a different database.",
      "detailedExplanation": "Check every option on its own merits and reject statements that are only true under hidden assumptions. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-031",
      "type": "multiple-choice",
      "question": "What is InfluxDB?",
      "options": [
        "A relational database",
        "A purpose-built time-series database with its own query language (InfluxQL/Flux)",
        "An influence tracking database",
        "A graph database"
      ],
      "correct": 1,
      "explanation": "InfluxDB is a popular time-series database. Features: high write throughput, time-range queries, built-in downsampling, retention policies. Query languages: InfluxQL (SQL-like) and Flux (functional). Part of the TICK stack (Telegraf, InfluxDB, Chronograf, Kapacitor).",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-032",
      "type": "multi-select",
      "question": "What features do time-series databases typically provide?",
      "options": [
        "Automatic data retention (delete data older than X days)",
        "Downsampling (aggregate old data to save space)",
        "Optimized time-range queries",
        "ACID transactions across time ranges"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Time-series databases offer: retention policies (auto-delete old data), downsampling (keep hourly averages instead of per-second), optimized time queries. They typically don't provide strong ACID transactions — they prioritize write throughput.",
      "detailedExplanation": "Use independent validation per option to prevent partial truths from slipping into the final set. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-033",
      "type": "multiple-choice",
      "question": "What is downsampling in time-series databases?",
      "options": [
        "Reducing the sample rate of new data",
        "Aggregating old fine-grained data into coarser summaries (e.g., per-second → per-hour)",
        "Downloading samples",
        "Reducing database size by compression"
      ],
      "correct": 1,
      "explanation": "Downsampling reduces storage for old data: keep per-second metrics for 7 days, then aggregate to per-minute for 30 days, per-hour for 1 year. You lose precision but save massive storage. Most time-series DBs automate this.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-034",
      "type": "two-stage",
      "stages": [
        {
          "question": "You collect 1 data point per second per sensor. You have 10,000 sensors. How many points per day?",
          "options": ["864,000", "86,400,000", "864,000,000", "8,640,000,000"],
          "correct": 2,
          "explanation": "86,400 seconds/day × 10,000 sensors = 864,000,000 (864 million) points per day. At 100 bytes per point, that's 86GB/day. Time-series scale gets big fast — compression and downsampling are essential.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        },
        {
          "question": "You want to keep 1 year of data. Raw data is 86GB/day = ~31TB/year. How do you make this feasible?",
          "options": [
            "Buy 31TB of storage",
            "Downsample: keep raw for 7 days, per-minute for 30 days, per-hour for 1 year",
            "Delete all data after 30 days",
            "Sample fewer sensors"
          ],
          "correct": 1,
          "explanation": "Downsampling dramatically reduces storage: raw 7 days (~600GB), then per-minute 30 days (60x reduction), per-hour 1 year (3600x reduction). Total storage becomes manageable. You can still query historical trends, just not per-second detail.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-035",
      "type": "multiple-choice",
      "question": "What is TimescaleDB?",
      "options": [
        "A time management app",
        "A time-series database built as a PostgreSQL extension, combining SQL power with time-series optimization",
        "A scheduling database",
        "A proprietary Oracle feature"
      ],
      "correct": 1,
      "explanation": "TimescaleDB is PostgreSQL with time-series superpowers. It's a PostgreSQL extension, so you get full SQL, JOINs, and the Postgres ecosystem. Under the hood, it automatically partitions data by time (hypertables) for performance.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-036",
      "type": "multi-select",
      "question": "What are advantages of TimescaleDB over pure time-series databases?",
      "options": [
        "Full SQL support including JOINs",
        "Familiar PostgreSQL tooling and ecosystem",
        "Can store relational data alongside time-series",
        "Always faster than InfluxDB for pure time-series"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "TimescaleDB advantages: full SQL (JOINs, subqueries), PostgreSQL ecosystem (tools, ORMs, extensions), relational + time-series in one DB. It's not always faster than InfluxDB for pure time-series — choose based on your needs.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-037",
      "type": "multiple-choice",
      "question": "What is a hypertable in TimescaleDB?",
      "options": [
        "A very large table",
        "An abstraction that automatically partitions data by time into chunks",
        "A table with hyperlinks",
        "A compressed table"
      ],
      "correct": 1,
      "explanation": "A hypertable looks like a regular table but is automatically partitioned into chunks by time (and optionally other dimensions). TimescaleDB manages chunks transparently — you query the hypertable, and it handles partition pruning.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-038",
      "type": "multiple-choice",
      "question": "What is Prometheus?",
      "options": [
        "A Greek god",
        "A monitoring system with a time-series database, focused on metrics and alerting",
        "A message queue",
        "A log aggregator"
      ],
      "correct": 1,
      "explanation": "Prometheus is a monitoring system with a built-in time-series database. It pulls metrics from targets, stores them, provides PromQL for queries, and supports alerting. Designed for reliability (simple, local storage) over long-term storage.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "wc-039",
      "type": "multi-select",
      "question": "What are characteristics of Prometheus?",
      "options": [
        "Pull-based metrics collection",
        "PromQL query language",
        "Designed for long-term storage of years of data",
        "Built-in alerting"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Prometheus: pull-based (scrapes targets), PromQL (powerful query language), built-in alerting. It's NOT designed for long-term storage — it's optimized for recent data. For long-term, use remote storage (Thanos, Cortex, or a time-series DB).",
      "detailedExplanation": "Evaluate each option independently against the constraint instead of looking for a pattern across choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're storing IoT sensor data: device_id, timestamp, temperature, humidity. Writes are 100K/second. Which database type fits best?",
          "options": [
            "Relational database (PostgreSQL)",
            "Document database (MongoDB)",
            "Time-series or wide-column database",
            "Key-value store (Redis)"
          ],
          "correct": 2,
          "explanation": "100K writes/second of time-stamped sensor data is a classic time-series workload. Time-series DBs (InfluxDB, TimescaleDB) or wide-column (Cassandra) handle this well. Relational DBs struggle at this write rate without significant tuning.",
          "detailedExplanation": "Advance from the first-stage output, then verify that this decision still respects the same limits. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        },
        {
          "question": "Your primary query is 'average temperature for device X over the last hour.' Which database feature helps?",
          "options": [
            "Foreign keys",
            "Time-range queries with aggregation, optimized for time-series",
            "Full-text search",
            "Graph traversal"
          ],
          "correct": 1,
          "explanation": "Time-series databases optimize exactly this: partition by time for fast range scans, built-in aggregation functions (AVG, MAX, MIN over time windows). TimescaleDB: SELECT AVG(temperature) FROM sensors WHERE device_id = X AND time > now() - interval '1 hour'.",
          "detailedExplanation": "Treat this as a continuation step: preserve earlier constraints and recheck feasibility. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        }
      ],
      "detailedExplanation": "Use the core equation with explicit unit tracking before committing to an answer. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-041",
      "type": "multiple-choice",
      "question": "What is a tombstone in Cassandra?",
      "options": [
        "A gravestone-shaped data structure",
        "A marker indicating deleted data, removed during compaction",
        "A failed node",
        "An index entry"
      ],
      "correct": 1,
      "explanation": "When you delete in Cassandra, it writes a tombstone (deletion marker) rather than immediately removing data. This is needed for distributed consistency. Tombstones are removed during compaction. Too many tombstones hurt read performance.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-042",
      "type": "multiple-choice",
      "question": "Why do tombstones exist in Cassandra instead of immediate deletion?",
      "options": [
        "Cassandra can't delete data",
        "Distributed consistency — tombstones propagate to ensure all replicas know about the delete",
        "Storage efficiency",
        "To preserve history"
      ],
      "correct": 1,
      "explanation": "In a distributed system, a delete must propagate to all replicas. If you immediately removed data and a replica was down, it might 'resurrect' the data when it syncs. Tombstones are markers that propagate and persist until compaction.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-043",
      "type": "multi-select",
      "question": "What problems can excessive tombstones cause in Cassandra?",
      "options": [
        "Slow reads — must skip over many tombstones",
        "Increased storage usage",
        "Possible query failures if tombstone limit is exceeded",
        "Faster writes"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Tombstone problems: slow reads (scan through tombstones to find live data), storage (tombstones take space until compaction), query failures (Cassandra has a tombstone_failure_threshold). Design to minimize tombstones — avoid patterns with heavy deletes.",
      "detailedExplanation": "Use independent validation per option to prevent partial truths from slipping into the final set. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-044",
      "type": "multiple-choice",
      "question": "What is a common anti-pattern that causes tombstone issues in Cassandra?",
      "options": [
        "Using too many columns",
        "Using TTLs or frequent deletes with wide partitions",
        "Having too many tables",
        "Using batch inserts"
      ],
      "correct": 1,
      "explanation": "Wide partitions with TTL or frequent deletes create many tombstones. Example: storing the last 1000 events by deleting old ones. Each delete = tombstone. Better: use separate partitions per time bucket, drop entire buckets when old.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "You want to keep only the last 30 days of events in Cassandra. Approach A: Delete old events with TTL. What's the issue?",
          "options": [
            "No issue",
            "TTL creates tombstones for every expired event",
            "TTL doesn't work in Cassandra",
            "TTL is too slow"
          ],
          "correct": 1,
          "explanation": "TTL expiration creates tombstones. With millions of events expiring daily, you get millions of tombstones. Reads slow down scanning through them. Compaction eventually removes them but takes time.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee."
        },
        {
          "question": "Better approach: partition by date (event_date as part of partition key). To remove old data:",
          "options": [
            "DELETE with TTL",
            "DROP the old partitions or let entire SSTables age out",
            "TRUNCATE the table",
            "Manual row-by-row deletion"
          ],
          "correct": 1,
          "explanation": "If each partition = one day, dropping 30+ day old data is efficient. You can drop entire partitions (no individual tombstones) or configure compaction to ignore old SSTables (they age out). Much more efficient than TTL per row.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-046",
      "type": "multiple-choice",
      "question": "What is lightweight transactions (LWT) in Cassandra?",
      "options": [
        "Fast transactions",
        "Paxos-based conditional writes (IF NOT EXISTS, IF column = value)",
        "Transactions with small data",
        "Read-only transactions"
      ],
      "correct": 1,
      "explanation": "LWT provides linearizable consistency using Paxos: INSERT IF NOT EXISTS, UPDATE IF column = value. Use for compare-and-set operations. But LWT is 4x slower than regular writes (Paxos rounds), so use sparingly.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-047",
      "type": "multi-select",
      "question": "When would you use Cassandra lightweight transactions?",
      "options": [
        "Ensuring unique usernames (INSERT IF NOT EXISTS)",
        "Compare-and-set for distributed locks",
        "All write operations for safety",
        "Conditional updates based on current value"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Use LWT for: uniqueness (IF NOT EXISTS), conditional updates (IF status = 'pending'), distributed locks. Don't use for all writes — 4x overhead adds up. Most writes don't need linearizability.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-048",
      "type": "multiple-choice",
      "question": "What is Cassandra's approach to handling node failures?",
      "options": [
        "Stop the cluster until the node recovers",
        "Continue operating — replicas on other nodes serve requests, hinted handoff queues writes",
        "Immediately replace the node",
        "Fail all requests"
      ],
      "correct": 1,
      "explanation": "Cassandra is designed for failure: other replicas serve reads/writes, hinted handoff queues writes for the failed node. When it recovers, it catches up. No single point of failure — the cluster degrades gracefully.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-049",
      "type": "multiple-choice",
      "question": "What is hinted handoff in Cassandra?",
      "options": [
        "A hint for query optimization",
        "When a replica is down, other nodes store 'hints' (writes) to replay when it recovers",
        "A handshake protocol",
        "A failover mechanism"
      ],
      "correct": 1,
      "explanation": "Hinted handoff: if a write's target replica is down, another node stores a 'hint.' When the target recovers, the hint is replayed. This helps nodes catch up after short outages. For long outages, repair is needed.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-050",
      "type": "multiple-choice",
      "question": "What is repair in Cassandra?",
      "options": [
        "Fixing corrupt data",
        "Synchronizing data across replicas to ensure consistency",
        "Repairing hardware",
        "A backup operation"
      ],
      "correct": 1,
      "explanation": "Repair compares data across replicas and synchronizes differences. It's necessary to maintain consistency, especially after node outages. Run repair regularly (weekly/monthly depending on cluster size). Without repair, replicas can drift.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "wc-051",
      "type": "ordering",
      "question": "Rank these consistency levels for Cassandra writes from fastest to slowest:",
      "items": ["ANY", "ONE", "QUORUM", "ALL"],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "ANY (write succeeds even if only hint is stored) is fastest but least durable. ONE (1 replica) is fast. QUORUM (majority) adds latency. ALL (all replicas) is slowest — must wait for every replica. Speed vs. consistency trade-off.",
      "detailedExplanation": "Rank by dominant bottleneck or magnitude, then validate adjacent transitions for consistency. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-052",
      "type": "multiple-choice",
      "question": "What is ClickHouse?",
      "options": [
        "A web analytics tool",
        "A column-oriented OLAP database designed for real-time analytics on large datasets",
        "A click tracking service",
        "A housing search engine"
      ],
      "correct": 1,
      "explanation": "ClickHouse is a columnar OLAP database. Extremely fast for analytical queries on large datasets. Used for: web analytics, monitoring, ad tech. It's not a wide-column store in the Cassandra sense — it's columnar for analytics.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-053",
      "type": "multi-select",
      "question": "What's the difference between wide-column stores and columnar databases?",
      "options": [
        "Wide-column: rows can have different columns, organized by row key",
        "Columnar: stores data by column for analytics (read efficiency for aggregations)",
        "Wide-column is for OLTP-like workloads; columnar is for OLAP",
        "They're the same thing"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Different concepts: Wide-column (Cassandra) has flexible schema, keyed access, write-optimized. Columnar (ClickHouse, Redshift) stores columns together for scan-heavy analytics. Wide-column = transactional NoSQL; columnar = analytical.",
      "detailedExplanation": "Avoid grouped guessing: test every option directly against the system boundary condition. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "wc-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "You need to run analytics: 'SELECT product_id, SUM(revenue) GROUP BY product_id' on billions of rows. Which is better: Cassandra or ClickHouse?",
          "options": [
            "Cassandra — it's designed for big data",
            "ClickHouse — columnar storage is optimized for aggregation queries",
            "They're equally good",
            "Neither — use PostgreSQL"
          ],
          "correct": 1,
          "explanation": "ClickHouse is columnar: it reads only the product_id and revenue columns, skipping others. Aggregations are vectorized. Cassandra would need to read full rows and isn't optimized for GROUP BY across partitions. Use the right tool for the job.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        },
        {
          "question": "For the same dataset, you need fast lookups: 'Get order details by order_id.' Which is better?",
          "options": [
            "ClickHouse — it can do everything",
            "Cassandra — designed for key-based lookups",
            "They're equally good",
            "Neither — use Redis"
          ],
          "correct": 1,
          "explanation": "Cassandra is designed for key-based lookups: get a specific row by partition key. ClickHouse is optimized for scans, not point lookups. Cassandra (or a key-value store) wins for this access pattern. Choose based on workload.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        }
      ],
      "detailedExplanation": "Follow the canonical calculation path and check both units and magnitude before finalizing. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-055",
      "type": "multiple-choice",
      "question": "What is data locality in wide-column stores?",
      "options": [
        "Data stored locally on laptops",
        "Related data stored together on disk for efficient reads",
        "Geographic data location",
        "Local variable storage"
      ],
      "correct": 1,
      "explanation": "Data locality means related data is physically stored together. In Cassandra, rows with the same partition key are stored together, sorted by clustering key. Reading a user's last 10 events is one disk read, not 10. This is why data modeling matters.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-056",
      "type": "multi-select",
      "question": "What use cases are wide-column stores well-suited for?",
      "options": [
        "IoT sensor data",
        "User activity timelines",
        "Messaging inboxes",
        "Complex relational queries with JOINs"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Wide-column stores excel at: IoT (high write volume, time-series), timelines (partition by user, sort by time), messaging (partition by user, sort by timestamp). JOINs are not supported — use relational databases for complex queries.",
      "detailedExplanation": "Check every option on its own merits and reject statements that are only true under hidden assumptions. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-057",
      "type": "multiple-choice",
      "question": "What is the CAP theorem positioning of Cassandra?",
      "options": [
        "CA (Consistent and Available)",
        "CP (Consistent and Partition-tolerant)",
        "AP (Available and Partition-tolerant)",
        "Cassandra ignores CAP"
      ],
      "correct": 2,
      "explanation": "Cassandra is AP: it prioritizes Availability and Partition tolerance over Consistency. During a network partition, Cassandra remains available (with tunable consistency). With QUORUM writes/reads, you get strong consistency — but it's opt-in.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "wc-058",
      "type": "multiple-choice",
      "question": "What is the CAP theorem positioning of HBase?",
      "options": [
        "CA (Consistent and Available)",
        "CP (Consistent and Partition-tolerant)",
        "AP (Available and Partition-tolerant)",
        "HBase ignores CAP"
      ],
      "correct": 1,
      "explanation": "HBase is CP: it prioritizes Consistency and Partition tolerance. HBase provides strong consistency (a read always returns the latest write). During partitions, unavailable regions may not serve requests. The trade-off: less availability than Cassandra.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "wc-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're building a metrics collection system. Writes: 500K/second. Reads: time-range aggregations. What's a good database choice?",
          "options": [
            "PostgreSQL",
            "MongoDB",
            "InfluxDB or TimescaleDB",
            "Redis"
          ],
          "correct": 2,
          "explanation": "500K writes/second of metrics is a time-series workload. InfluxDB or TimescaleDB are purpose-built: high write throughput, time-range queries, aggregations, downsampling. PostgreSQL can work with TimescaleDB extension. Redis is for caching, not this.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee."
        },
        {
          "question": "You also need to JOIN metrics with relational data (user profiles, devices). What would help?",
          "options": [
            "Use InfluxDB for everything",
            "Use TimescaleDB — it's PostgreSQL, so you can JOIN with relational tables",
            "Export metrics to PostgreSQL for JOINs",
            "Either B or C works"
          ],
          "correct": 3,
          "explanation": "TimescaleDB lets you JOIN hypertables with regular PostgreSQL tables — metrics JOIN devices seamlessly. Alternatively, export aggregated metrics to a relational DB for combined analysis. Either approach works depending on query frequency.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead."
        }
      ],
      "detailedExplanation": "Apply the main relationship stepwise and verify unit consistency at each step. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-060",
      "type": "multiple-choice",
      "question": "What is a materialized view in Cassandra?",
      "options": [
        "A cached query result",
        "An automatically-maintained denormalized table for alternate query patterns",
        "A view stored on disk",
        "A backup of a table"
      ],
      "correct": 1,
      "explanation": "Cassandra materialized views create a new table with a different primary key, maintained by Cassandra. Write to base table, MV updates automatically. Enables alternate query patterns without manual denormalization. But MVs have limitations and consistency caveats.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-061",
      "type": "multi-select",
      "question": "What are concerns with Cassandra materialized views?",
      "options": [
        "Eventual consistency — view may lag behind base table",
        "Write amplification — each base write updates the view",
        "They're fully consistent and have no downsides",
        "Limited to simple transformations"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "MV concerns: eventual consistency (view lags), write amplification (extra writes per insert), limited transformations (primary key must include base table's partition key). Many teams prefer explicit denormalization with application-managed writes.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "wc-062",
      "type": "multiple-choice",
      "question": "What is the typical replication factor in Cassandra for production?",
      "options": [
        "1 — no replication needed",
        "3 — balance of durability, availability, and storage cost",
        "10 — maximum durability",
        "2 — minimum for HA"
      ],
      "correct": 1,
      "explanation": "RF=3 is common: survives 1 node failure with QUORUM consistency, 2 failures for availability. RF=1 means any node failure loses data. RF=2 is risky for QUORUM (need both nodes). Higher RF costs more storage. 3 is the sweet spot.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "wc-063",
      "type": "ordering",
      "question": "Rank these from most to least suitable for Cassandra:",
      "items": [
        "User activity timeline (query by user, sorted by time)",
        "Real-time fraud detection with complex rules",
        "Event sourcing log",
        "Ad-hoc reporting with arbitrary GROUP BY"
      ],
      "correctOrder": [0, 2, 1, 3],
      "explanation": "Timelines (partition by user, cluster by time) are perfect. Event logs (append-only, partition by entity) work well. Fraud detection can work if queries are key-based. Ad-hoc GROUP BY across partitions is an anti-pattern — use OLAP DB.",
      "detailedExplanation": "Compare relative scale first, then confirm neighboring items pairwise to lock in the order. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-064",
      "type": "multiple-choice",
      "question": "What is ScyllaDB?",
      "options": [
        "A Cassandra GUI",
        "A Cassandra-compatible database written in C++ for better performance",
        "A SQL database",
        "A backup tool for Cassandra"
      ],
      "correct": 1,
      "explanation": "ScyllaDB is a drop-in Cassandra replacement written in C++. It claims higher performance (up to 10x) due to: shared-nothing architecture, async I/O, avoiding JVM GC pauses. CQL compatible, so Cassandra applications can migrate.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-065",
      "type": "multi-select",
      "question": "What advantages does ScyllaDB claim over Cassandra?",
      "options": [
        "No JVM garbage collection pauses",
        "Better resource utilization (shared-nothing)",
        "Higher throughput per node",
        "Different query language"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "ScyllaDB uses C++ (no GC pauses), shared-nothing architecture (each core handles its own data), and optimized I/O. CQL is the same — applications migrate easily. Trade-off: Cassandra has larger community and ecosystem.",
      "detailedExplanation": "Use independent validation per option to prevent partial truths from slipping into the final set. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-066",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your team debates Cassandra vs. DynamoDB for a new project. What's a key operational difference?",
          "options": [
            "They're operationally identical",
            "Cassandra is self-managed; DynamoDB is fully managed by AWS",
            "DynamoDB is open source",
            "Cassandra only runs on AWS"
          ],
          "correct": 1,
          "explanation": "Cassandra: you manage the cluster (provisioning, scaling, repairs, upgrades). DynamoDB: fully managed — AWS handles everything. DynamoDB costs more but less ops burden. Cassandra gives more control but requires expertise.",
          "detailedExplanation": "Advance from the first-stage output, then verify that this decision still respects the same limits. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        },
        {
          "question": "What about query flexibility?",
          "options": [
            "DynamoDB has full SQL support",
            "Cassandra has more query flexibility (CQL) vs. DynamoDB's key-based access",
            "They're identical",
            "Neither supports queries"
          ],
          "correct": 1,
          "explanation": "Cassandra CQL is more SQL-like: clustering columns, range queries, secondary indexes. DynamoDB is more strictly key-based: partition key required, limited secondary indexes (GSI/LSI). Cassandra has more query flexibility; DynamoDB is simpler.",
          "detailedExplanation": "Treat this as a continuation step: preserve earlier constraints and recheck feasibility. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        }
      ],
      "detailedExplanation": "Use the core equation with explicit unit tracking before committing to an answer. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-067",
      "type": "multiple-choice",
      "question": "What is Apache Kudu?",
      "options": [
        "A message queue",
        "A columnar storage engine for fast analytics on fast-changing data (between HDFS and HBase)",
        "A Kafka alternative",
        "A graph database"
      ],
      "correct": 1,
      "explanation": "Kudu fills a gap: HDFS is good for batch analytics but slow updates; HBase is good for random access but weak analytics. Kudu provides: columnar storage for analytics + fast random access + real-time inserts. Good for fast-changing analytical data.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-068",
      "type": "multiple-choice",
      "question": "When storing time-series data in Cassandra, what's a good practice for the partition key?",
      "options": [
        "Use timestamp as partition key",
        "Include a time bucket (e.g., device_id + day) to prevent unbounded partition growth",
        "Use a random UUID",
        "Use no partition key"
      ],
      "correct": 1,
      "explanation": "Partition by entity + time bucket: ((sensor_id, day), timestamp). This bounds partition size (one day of data per sensor per partition). Pure timestamp creates hot partitions. Pure entity creates unbounded growth. Bucketing balances both.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-069",
      "type": "multi-select",
      "question": "What tools are commonly used with time-series databases for visualization?",
      "options": ["Grafana", "Kibana", "Chronograf", "Microsoft Excel"],
      "correctIndices": [0, 1, 2],
      "explanation": "Grafana is the most popular (works with many TSDBs). Kibana works with Elasticsearch (logs/metrics). Chronograf is InfluxDB's visualization tool. Excel can import data but isn't designed for real-time time-series dashboards.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-070",
      "type": "multiple-choice",
      "question": "What is continuous aggregation in TimescaleDB?",
      "options": [
        "Continuously adding data",
        "Materialized views that automatically refresh as new data arrives",
        "Aggregate functions that run continuously",
        "A backup process"
      ],
      "correct": 1,
      "explanation": "Continuous aggregates are materialized views that update incrementally as data arrives. Instead of re-computing 'hourly averages' each query, the aggregate updates in real-time. Great for dashboards — fast reads of pre-computed data.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-071",
      "type": "two-stage",
      "stages": [
        {
          "question": "You have a dashboard querying 'average temperature per hour for the last 7 days' — millions of data points. The query is slow. What optimization helps?",
          "options": [
            "Add more indexes",
            "Pre-aggregate hourly averages in a continuous aggregate / materialized view",
            "Query faster",
            "Cache in Redis"
          ],
          "correct": 1,
          "explanation": "Pre-aggregate: compute hourly averages as data arrives, store in a summary table. Dashboard queries the summary (168 rows for 7 days), not millions of raw points. TimescaleDB continuous aggregates, InfluxDB continuous queries, or manual summary tables.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead."
        },
        {
          "question": "What's the trade-off of pre-aggregation?",
          "options": [
            "No trade-offs",
            "Lose raw data precision for aggregated time periods",
            "Slower writes",
            "B and C — aggregation overhead on write, lose raw granularity after retention"
          ],
          "correct": 3,
          "explanation": "Trade-offs: (1) Write overhead to maintain aggregates. (2) If you delete raw data after aggregating, you lose per-second precision. (3) More storage for aggregates (though less than raw data). Usually worth it for dashboards.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        }
      ],
      "detailedExplanation": "Use a formula-first approach with explicit units to avoid hidden conversion mistakes. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-072",
      "type": "multiple-choice",
      "question": "What is VictoriaMetrics?",
      "options": [
        "A metrics about victories",
        "A fast, cost-effective time-series database and monitoring solution, Prometheus-compatible",
        "A game analytics platform",
        "A Roman database"
      ],
      "correct": 1,
      "explanation": "VictoriaMetrics is a high-performance time-series DB that's Prometheus-compatible. It can serve as Prometheus long-term storage or standalone TSDB. Claims 10x+ lower memory usage than Prometheus. Good for scaling Prometheus-based monitoring.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-073",
      "type": "multi-select",
      "question": "What are alternatives for Prometheus long-term storage?",
      "options": ["Thanos", "Cortex", "VictoriaMetrics", "MySQL"],
      "correctIndices": [0, 1, 2],
      "explanation": "Thanos, Cortex, and VictoriaMetrics all provide long-term storage for Prometheus metrics. They integrate with Prometheus via remote write. MySQL is not designed for time-series at Prometheus scale.",
      "detailedExplanation": "Treat each candidate as a separate true/false check against the same governing requirement. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-074",
      "type": "multiple-choice",
      "question": "What is QuestDB?",
      "options": [
        "A database for quests",
        "A high-performance time-series database optimized for SQL queries and real-time analytics",
        "A question-answer database",
        "A graph database"
      ],
      "correct": 1,
      "explanation": "QuestDB is a time-series database focusing on performance. It uses SQL (PostgreSQL wire protocol), optimized for time-series patterns. Claims millions of inserts per second. Good for real-time analytics where SQL familiarity is valued.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-075",
      "type": "ordering",
      "question": "Rank these from most to least specialized for time-series:",
      "items": [
        "InfluxDB (purpose-built TSDB)",
        "TimescaleDB (PostgreSQL extension)",
        "Cassandra (general wide-column)",
        "PostgreSQL (relational)"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "InfluxDB is purely time-series. TimescaleDB adds time-series to PostgreSQL. Cassandra handles time-series but isn't specialized. PostgreSQL can store time-series but isn't optimized for it. Specialization vs. generality trade-off.",
      "detailedExplanation": "Prioritize ratio-based comparisons and validate each neighboring step to avoid inversion mistakes. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-076",
      "type": "multiple-choice",
      "question": "What is data retention policy in time-series databases?",
      "options": [
        "How long to keep employees",
        "Rules defining how long data is kept before automatic deletion",
        "Data backup policy",
        "Policy on retaining customers"
      ],
      "correct": 1,
      "explanation": "Retention policies automatically delete old data: 'keep raw data for 30 days, then delete.' Most TSDBs support this natively. Combined with downsampling (keep aggregates longer), you manage storage costs while preserving historical trends.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-077",
      "type": "two-stage",
      "stages": [
        {
          "question": "You store metrics with 1-second granularity. After 90 days, you don't need per-second data, but you need 1-year trends. What strategy?",
          "options": [
            "Keep all raw data for 1 year",
            "Delete all data after 90 days",
            "Downsample: keep raw for 90 days, per-hour aggregates for 1 year",
            "Store everything in different database"
          ],
          "correct": 2,
          "explanation": "Downsample: raw data (expensive, detailed) for recent period; aggregates (cheap, summarized) for historical. 1-second for 90 days, hourly for 1 year. You can still see yearly trends; you just can't drill into per-second detail for last year.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Growth planning should show today vs horizon requirements side by side because compounding makes small percentages material quickly."
        },
        {
          "question": "How much storage does this save roughly? (Assume 1-second data = X bytes/day)",
          "options": [
            "No savings",
            "Approximately 3600x savings for the aggregated period (1 hour = 3600 seconds)",
            "10x savings",
            "Infinite savings"
          ],
          "correct": 1,
          "explanation": "Per-hour vs per-second: 3600x fewer data points for the same time span. If per-second is 86,400 points/day, per-hour is 24 points/day. For a year of hourly aggregates vs. raw seconds, savings are massive.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        }
      ],
      "detailedExplanation": "Anchor on the base formula, preserve unit integrity, and then run a reasonableness check. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-078",
      "type": "multiple-choice",
      "question": "What is Cassandra's read path?",
      "options": [
        "Read directly from disk",
        "Check memtable, then bloom filter, then key cache, then SSTables on disk",
        "Read from write-ahead log",
        "Query the master node"
      ],
      "correct": 1,
      "explanation": "Read path: check memtable (in-memory recent writes), then use bloom filter (quick 'definitely not here' check), key cache (index cache), then read SSTables from disk. Bloom filters prevent unnecessary disk reads for non-existent keys.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-079",
      "type": "multiple-choice",
      "question": "What is a bloom filter in Cassandra?",
      "options": [
        "A filter for blooming data",
        "A probabilistic data structure that quickly checks if a key might be in an SSTable",
        "A data compression filter",
        "A query filter"
      ],
      "correct": 1,
      "explanation": "Bloom filters give fast 'probably yes' or 'definitely no' answers about key existence. Before reading an SSTable, Cassandra checks its bloom filter. If 'definitely no,' skip the SSTable — saves disk I/O. False positives are possible but infrequent.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-080",
      "type": "multi-select",
      "question": "What configurations are important when tuning Cassandra for time-series?",
      "options": [
        "Partition key design (time bucketing)",
        "Compaction strategy (TimeWindowCompactionStrategy)",
        "Using ALLOW FILTERING for all queries",
        "TTL for automatic data expiration"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Time-series tuning: bucket partitions by time, use TWCS (compacts by time windows, efficient for TTL), set TTL for auto-expiration. ALLOW FILTERING is an anti-pattern — design keys for efficient queries instead.",
      "detailedExplanation": "Avoid grouped guessing: test every option directly against the system boundary condition. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-081",
      "type": "multiple-choice",
      "question": "What is TimeWindowCompactionStrategy (TWCS) in Cassandra?",
      "options": [
        "A strategy for windowed queries",
        "A compaction strategy that groups SSTables by time window, efficient for time-series with TTL",
        "A time-based backup strategy",
        "A query scheduling strategy"
      ],
      "correct": 1,
      "explanation": "TWCS compacts SSTables within time windows (e.g., 1 day). As data ages past TTL, entire windows can be dropped without expensive compaction. Ideal for time-series: write-heavy, TTL-based expiration, time-ordered data.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-082",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're writing 100K events/second to Cassandra. After a week, reads are slow. Likely cause?",
          "options": [
            "Too few nodes",
            "Too many SSTables — compaction can't keep up, reads scan many files",
            "Not enough RAM",
            "Slow network"
          ],
          "correct": 1,
          "explanation": "Heavy writes create many SSTables faster than compaction merges them. Reads must check multiple SSTables, slowing down. Solutions: tune compaction, add nodes (spread write load), ensure compaction throughput matches write rate.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        },
        {
          "question": "How can you verify this is the issue?",
          "options": [
            "Check application logs",
            "Monitor SSTable count per table with nodetool",
            "Restart Cassandra",
            "Check disk space"
          ],
          "correct": 1,
          "explanation": "nodetool tablestats shows SSTable count and other table metrics. High SSTable count (hundreds per table) confirms compaction isn't keeping up. Also check compaction pending tasks, latency percentiles.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        }
      ],
      "detailedExplanation": "Apply the main relationship stepwise and verify unit consistency at each step. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-083",
      "type": "multiple-choice",
      "question": "What is the snitch in Cassandra?",
      "options": [
        "A monitoring tool",
        "A component that determines node locations for replication and routing",
        "A security feature",
        "A data type"
      ],
      "correct": 1,
      "explanation": "The snitch tells Cassandra about network topology: which datacenter/rack each node is in. This affects: replica placement (spread across racks), query routing (prefer local datacenter). SimpleSnitch for testing, GossipingPropertyFileSnitch for production.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "wc-084",
      "type": "multi-select",
      "question": "What are strategies for multi-datacenter replication in Cassandra?",
      "options": [
        "NetworkTopologyStrategy — specify replication per datacenter",
        "SimpleStrategy — replicate equally everywhere",
        "LOCAL_QUORUM — ensure quorum within local datacenter",
        "Async replication to remote datacenter"
      ],
      "correctIndices": [0, 2],
      "explanation": "NetworkTopologyStrategy specifies RF per DC (e.g., 3 in US-East, 3 in EU-West). LOCAL_QUORUM ensures consistency within a DC without cross-DC latency. SimpleStrategy is for single-DC only. Cassandra replication is synchronous (within consistency level).",
      "detailedExplanation": "Evaluate each option independently against the constraint instead of looking for a pattern across choices. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-085",
      "type": "multiple-choice",
      "question": "What is the benefit of LOCAL_QUORUM over QUORUM in a multi-DC setup?",
      "options": [
        "Stronger consistency",
        "Lower latency — only waits for local datacenter replicas",
        "Higher availability",
        "Less storage"
      ],
      "correct": 1,
      "explanation": "LOCAL_QUORUM waits for quorum in the local datacenter only. Cross-DC replication happens async (for that request). This avoids inter-DC latency on the critical path. Trade-off: a DC could have stale data briefly; cross-DC failover needs QUORUM.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "wc-086",
      "type": "two-stage",
      "stages": [
        {
          "question": "You operate Cassandra in US-East and EU-West. A user in EU writes, then immediately reads. What consistency ensures they see their write?",
          "options": [
            "LOCAL_QUORUM write, LOCAL_QUORUM read",
            "LOCAL_ONE write, LOCAL_ONE read",
            "ONE write, ONE read",
            "ALL write, ONE read"
          ],
          "correct": 0,
          "explanation": "LOCAL_QUORUM write and LOCAL_QUORUM read ensures read-your-writes within the user's datacenter. The read quorum overlaps with write quorum in EU-West. Cross-DC consistency isn't guaranteed but local consistency is.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "The user then travels to US and reads. Might they see stale data?",
          "options": [
            "No — LOCAL_QUORUM guarantees global consistency",
            "Yes — their EU write might not have replicated to US yet",
            "Never — Cassandra is always consistent",
            "Only if nodes are down"
          ],
          "correct": 1,
          "explanation": "LOCAL_QUORUM is local to the datacenter. The write committed in EU, but replication to US is async. If they read in US immediately, the US replicas might not have the write yet. For global consistency, use QUORUM (cross-DC, higher latency).",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        }
      ],
      "detailedExplanation": "Anchor on the base formula, preserve unit integrity, and then run a reasonableness check. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-087",
      "type": "multiple-choice",
      "question": "What is the difference between time-series and event sourcing storage?",
      "options": [
        "They're the same",
        "Time-series is metrics (numeric, aggregatable); event sourcing is domain events (immutable facts, replayable)",
        "Time-series is for events; event sourcing is for metrics",
        "Event sourcing requires Kafka"
      ],
      "correct": 1,
      "explanation": "Time-series: metrics like CPU%, temperature — numeric, sampled, aggregated over time. Event sourcing: domain events like 'OrderPlaced', 'ItemAdded' — immutable facts that reconstruct state when replayed. Different patterns, sometimes overlapping storage.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "wc-088",
      "type": "multi-select",
      "question": "Which databases are commonly used for event sourcing?",
      "options": [
        "Cassandra (append-only, partitioned by aggregate ID)",
        "EventStoreDB (purpose-built for event sourcing)",
        "PostgreSQL (with append-only tables)",
        "Memcached"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Event sourcing can use: Cassandra (partition by aggregate, cluster by version), EventStoreDB (native event store), PostgreSQL (append-only, with NOTIFY for subscriptions). Memcached is a cache, not suitable for persistent event storage.",
      "detailedExplanation": "Avoid grouped guessing: test every option directly against the system boundary condition. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        }
      ]
    },
    {
      "id": "wc-089",
      "type": "multiple-choice",
      "question": "What is AWS Keyspaces?",
      "options": [
        "A key management service",
        "Amazon's managed Cassandra-compatible database service",
        "A key-value store",
        "An encryption service"
      ],
      "correct": 1,
      "explanation": "Amazon Keyspaces is a managed Cassandra-compatible service. Serverless, auto-scaling, CQL-compatible. You don't manage clusters. Trade-offs: not 100% Cassandra-compatible (some features missing), AWS-specific, pricing model differs from self-managed.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-090",
      "type": "ordering",
      "question": "Rank these from most to least operational overhead:",
      "items": [
        "Self-managed Cassandra",
        "AWS Keyspaces",
        "DataStax Astra (managed Cassandra)",
        "DynamoDB"
      ],
      "correctOrder": [0, 2, 1, 3],
      "explanation": "Self-managed Cassandra: you handle everything. DataStax Astra: managed but Cassandra complexity. AWS Keyspaces: serverless, less overhead. DynamoDB: fully serverless, simplest ops. Trade-off: flexibility vs. operational burden.",
      "detailedExplanation": "Establish the extremes first and fill the middle with pairwise comparisons. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-091",
      "type": "multiple-choice",
      "question": "What makes time-series workloads challenging for traditional databases?",
      "options": [
        "Time-series data is small",
        "High ingestion rate, time-range queries, data retention at scale",
        "Time-series data is relational",
        "Time-series requires JOINs"
      ],
      "correct": 1,
      "explanation": "Challenges: high write volume (thousands-millions/second), queries by time range (not point lookups), massive scale (years of data), retention management (delete old, downsample). Traditional DBs can handle some time-series but aren't optimized for all challenges.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-092",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're evaluating InfluxDB vs. TimescaleDB. What's a key decision factor?",
          "options": [
            "They're identical",
            "Whether you need pure time-series (InfluxDB) or SQL/JOINs with relational data (TimescaleDB)",
            "InfluxDB is always faster",
            "TimescaleDB doesn't support time-series"
          ],
          "correct": 1,
          "explanation": "InfluxDB: purpose-built, InfluxQL/Flux queries, simpler for pure time-series. TimescaleDB: PostgreSQL extension, full SQL, JOINs with relational tables. If you need SQL familiarity and relational integration, TimescaleDB. For standalone metrics, InfluxDB.",
          "detailedExplanation": "Treat this as a continuation step: preserve earlier constraints and recheck feasibility. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        },
        {
          "question": "You have an existing PostgreSQL application and want to add metrics. Which is easier to integrate?",
          "options": [
            "InfluxDB — it's faster",
            "TimescaleDB — it's a PostgreSQL extension, same tools and queries",
            "Neither — use Redis",
            "Cassandra"
          ],
          "correct": 1,
          "explanation": "TimescaleDB is PostgreSQL. Your existing connections, ORMs, tools work. Add the extension, create a hypertable, start inserting time-series data. InfluxDB would be a separate system with different query language and integration.",
          "detailedExplanation": "Advance from the first-stage output, then verify that this decision still respects the same limits. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early."
        }
      ],
      "detailedExplanation": "Work through the core math with unit labels attached, then verify scale plausibility. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-093",
      "type": "multiple-choice",
      "question": "What is Amazon Timestream?",
      "options": [
        "A streaming service",
        "AWS's managed time-series database",
        "A timestamp format",
        "A backup service"
      ],
      "correct": 1,
      "explanation": "Amazon Timestream is AWS's managed time-series database. Serverless, auto-scaling, built-in analytics. Features: tiered storage (hot/cold), automatic retention, SQL queries. Good for IoT, DevOps metrics when you want fully managed on AWS.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-094",
      "type": "multi-select",
      "question": "What are considerations when choosing between self-managed and managed wide-column/time-series databases?",
      "options": [
        "Operational expertise available",
        "Cost (managed often costs more but saves ops time)",
        "Specific feature requirements (managed may lack some)",
        "Vendor lock-in"
      ],
      "correctIndices": [0, 1, 2, 3],
      "explanation": "All are valid considerations. Self-managed: needs expertise, full control, potentially cheaper at scale. Managed: less ops, faster start, may lack features, vendor lock-in risk, costs can be higher. Evaluate based on team skills and requirements.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-095",
      "type": "multiple-choice",
      "question": "What is the ideal batch size for Cassandra writes?",
      "options": [
        "As large as possible",
        "Logged batches for atomicity on single partition; unlogged batches sparingly, only for related writes",
        "Always batch 1000 rows",
        "Never use batches"
      ],
      "correct": 1,
      "explanation": "Cassandra batches aren't for performance (unlike SQL). Logged batches ensure atomicity within a partition. Unlogged batches are faster but not atomic. Large batches to multiple partitions hurt coordinators. Use batches for atomicity, not performance.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-096",
      "type": "two-stage",
      "stages": [
        {
          "question": "A developer batches 10,000 writes to different partitions 'for performance.' What's the problem?",
          "options": [
            "No problem — batches are always faster",
            "Large multi-partition batches overload the coordinator node",
            "Batches can't span partitions",
            "10,000 is too few"
          ],
          "correct": 1,
          "explanation": "Multi-partition batches route through one coordinator, which must track all writes. Large batches stress the coordinator: memory, CPU, timeout risk. This is an anti-pattern — batches are for atomicity, not performance.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        },
        {
          "question": "What's the correct approach for high-throughput writes to many partitions?",
          "options": [
            "Larger batches",
            "Send individual writes in parallel from the client (async)",
            "Synchronous one-by-one writes",
            "Use a single partition for all data"
          ],
          "correct": 1,
          "explanation": "For throughput: send individual writes asynchronously. Cassandra drivers support async writes — send many in parallel, Cassandra routes each to its coordinator. This distributes load across nodes. Much better than coordinator-heavy batches.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Storage estimates are most useful when split into raw data, replication factor, metadata/index overhead, and retention horizon.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-097",
      "type": "multiple-choice",
      "question": "What is nodetool in Cassandra?",
      "options": [
        "A tool for managing nodes in general",
        "The command-line tool for managing and monitoring Cassandra clusters",
        "A node.js tool",
        "A network analysis tool"
      ],
      "correct": 1,
      "explanation": "nodetool is Cassandra's CLI for cluster management: status (node health), repair (sync replicas), compact (force compaction), cleanup, tablestats, and many more. Essential for Cassandra operations.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-098",
      "type": "multi-select",
      "question": "What are important nodetool commands to know?",
      "options": [
        "nodetool status — cluster health",
        "nodetool repair — synchronize replicas",
        "nodetool tablestats — table metrics",
        "nodetool query — run CQL queries"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "status shows cluster/node health. repair syncs replicas. tablestats shows table metrics (SSTable count, read/write latency). 'nodetool query' doesn't exist — use cqlsh for queries. Other useful: compact, cleanup, describecluster.",
      "detailedExplanation": "Use independent validation per option to prevent partial truths from slipping into the final set. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "wc-099",
      "type": "ordering",
      "question": "Rank these wide-column/time-series use cases from best to worst fit for Cassandra:",
      "items": [
        "User activity streams (partition by user)",
        "Real-time analytics with complex aggregations",
        "IoT sensor data with time-bucketed partitions",
        "Global messaging inbox"
      ],
      "correctOrder": [0, 2, 3, 1],
      "explanation": "Activity streams and IoT with time buckets are excellent (known partition keys, time ordering). Messaging inbox works but needs careful modeling. Real-time complex aggregations are a poor fit — Cassandra doesn't optimize for ad-hoc GROUP BY; use ClickHouse or similar.",
      "detailedExplanation": "Use relative magnitude to draft the order and confirm it with local adjacency checks. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "wc-100",
      "type": "multiple-choice",
      "question": "What's the most important principle when modeling data for wide-column stores?",
      "options": [
        "Normalize like in relational databases",
        "Model your tables around your query patterns — denormalize as needed",
        "Use as few tables as possible",
        "Always use auto-generated keys"
      ],
      "correct": 1,
      "explanation": "Query-first design: know your queries, then design tables to serve them. Each query pattern might need its own table (denormalization). This is opposite to relational normalization. Wide-column stores sacrifice write simplicity for read efficiency.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Data model choices are strongest when grounded in query paths, write amplification, and index/storage overhead.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    }
  ]
}
