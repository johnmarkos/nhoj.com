{
  "unit": 7,
  "unitTitle": "Scaling Compute",
  "chapter": 3,
  "chapterTitle": "Horizontal vs Vertical Scaling Decisions",
  "chapterDescription": "Choosing between bigger nodes and more nodes based on bottlenecks, coordination costs, reliability, and cost curves.",
  "problems": [
    {
      "id": "sc-hv-001",
      "type": "multiple-choice",
      "question": "A checkout API shows this signal: CPU is pinned at 92% while memory is stable at 45%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-002",
      "type": "multiple-choice",
      "question": "A search backend shows this signal: RSS keeps climbing to OOM while CPU is only 35%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose vertical scaling first because lower coordination overhead for stateful in-memory workloads.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "Memory pressure is the constraining resource, so larger nodes are the fastest immediate fix. Vertical scale buys time while you reduce memory footprint or redesign state handling."
    },
    {
      "id": "sc-hv-003",
      "type": "multiple-choice",
      "question": "A recommendation service shows this signal: network egress is capped at NIC limits while CPU is 40%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose horizontal scaling first because aggregate capacity growth without hard single-node limits.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-004",
      "type": "multiple-choice",
      "question": "A image processing worker shows this signal: lock contention and cross-node coordination dominate p99 latency. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose horizontal scaling first because safer rolling deploys with smaller blast radius per node."
      ],
      "correct": 3,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-005",
      "type": "multiple-choice",
      "question": "A stream metadata service shows this signal: one large node still has headroom but queueing spikes during deploys. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-006",
      "type": "multiple-choice",
      "question": "A inventory API shows this signal: CPU is pinned at 92% while memory is stable at 45%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose horizontal scaling first because better elasticity for bursty traffic patterns.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-007",
      "type": "multiple-choice",
      "question": "A payments service shows this signal: RSS keeps climbing to OOM while CPU is only 35%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose vertical scaling first because simple operational rollout when node count is small.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "Memory pressure is the constraining resource, so larger nodes are the fastest immediate fix. Vertical scale buys time while you reduce memory footprint or redesign state handling."
    },
    {
      "id": "sc-hv-008",
      "type": "multiple-choice",
      "question": "A notification dispatcher shows this signal: network egress is capped at NIC limits while CPU is 40%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose horizontal scaling first because safer rolling deploys with smaller blast radius per node."
      ],
      "correct": 3,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-009",
      "type": "multiple-choice",
      "question": "A profile API shows this signal: lock contention and cross-node coordination dominate p99 latency. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-010",
      "type": "multiple-choice",
      "question": "A analytics ingestion service shows this signal: one large node still has headroom but queueing spikes during deploys. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose horizontal scaling first because better elasticity for bursty traffic patterns.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-011",
      "type": "multiple-choice",
      "question": "A checkout API shows this signal: CPU is pinned at 92% while memory is stable at 45%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose horizontal scaling first because aggregate capacity growth without hard single-node limits.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-012",
      "type": "multiple-choice",
      "question": "A search backend shows this signal: RSS keeps climbing to OOM while CPU is only 35%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose vertical scaling first because better single-thread performance for CPU-bound hot paths."
      ],
      "correct": 3,
      "explanation": "Memory pressure is the constraining resource, so larger nodes are the fastest immediate fix. Vertical scale buys time while you reduce memory footprint or redesign state handling."
    },
    {
      "id": "sc-hv-013",
      "type": "multiple-choice",
      "question": "A recommendation service shows this signal: network egress is capped at NIC limits while CPU is 40%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-014",
      "type": "multiple-choice",
      "question": "A image processing worker shows this signal: lock contention and cross-node coordination dominate p99 latency. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose horizontal scaling first because better elasticity for bursty traffic patterns.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-015",
      "type": "multiple-choice",
      "question": "A stream metadata service shows this signal: one large node still has headroom but queueing spikes during deploys. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose horizontal scaling first because aggregate capacity growth without hard single-node limits.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-016",
      "type": "multiple-choice",
      "question": "A inventory API shows this signal: CPU is pinned at 92% while memory is stable at 45%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose horizontal scaling first because safer rolling deploys with smaller blast radius per node."
      ],
      "correct": 3,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-017",
      "type": "multiple-choice",
      "question": "A payments service shows this signal: RSS keeps climbing to OOM while CPU is only 35%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose vertical scaling first because minimal architecture change and fast short-term relief.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "Memory pressure is the constraining resource, so larger nodes are the fastest immediate fix. Vertical scale buys time while you reduce memory footprint or redesign state handling."
    },
    {
      "id": "sc-hv-018",
      "type": "multiple-choice",
      "question": "A notification dispatcher shows this signal: network egress is capped at NIC limits while CPU is 40%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose horizontal scaling first because better elasticity for bursty traffic patterns.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-019",
      "type": "multiple-choice",
      "question": "A profile API shows this signal: lock contention and cross-node coordination dominate p99 latency. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose horizontal scaling first because aggregate capacity growth without hard single-node limits.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-020",
      "type": "multiple-choice",
      "question": "A analytics ingestion service shows this signal: one large node still has headroom but queueing spikes during deploys. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose horizontal scaling first because safer rolling deploys with smaller blast radius per node."
      ],
      "correct": 3,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-021",
      "type": "multiple-choice",
      "question": "A checkout API shows this signal: CPU is pinned at 92% while memory is stable at 45%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-022",
      "type": "multiple-choice",
      "question": "A search backend shows this signal: RSS keeps climbing to OOM while CPU is only 35%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose vertical scaling first because lower coordination overhead for stateful in-memory workloads.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "Memory pressure is the constraining resource, so larger nodes are the fastest immediate fix. Vertical scale buys time while you reduce memory footprint or redesign state handling."
    },
    {
      "id": "sc-hv-023",
      "type": "multiple-choice",
      "question": "A recommendation service shows this signal: network egress is capped at NIC limits while CPU is 40%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose horizontal scaling first because aggregate capacity growth without hard single-node limits.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-024",
      "type": "multiple-choice",
      "question": "A image processing worker shows this signal: lock contention and cross-node coordination dominate p99 latency. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose horizontal scaling first because safer rolling deploys with smaller blast radius per node."
      ],
      "correct": 3,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-025",
      "type": "multiple-choice",
      "question": "A stream metadata service shows this signal: one large node still has headroom but queueing spikes during deploys. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-026",
      "type": "multiple-choice",
      "question": "A inventory API shows this signal: CPU is pinned at 92% while memory is stable at 45%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose horizontal scaling first because better elasticity for bursty traffic patterns.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-027",
      "type": "multiple-choice",
      "question": "A payments service shows this signal: RSS keeps climbing to OOM while CPU is only 35%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose vertical scaling first because simple operational rollout when node count is small.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "Memory pressure is the constraining resource, so larger nodes are the fastest immediate fix. Vertical scale buys time while you reduce memory footprint or redesign state handling."
    },
    {
      "id": "sc-hv-028",
      "type": "multiple-choice",
      "question": "A notification dispatcher shows this signal: network egress is capped at NIC limits while CPU is 40%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose horizontal scaling first because safer rolling deploys with smaller blast radius per node."
      ],
      "correct": 3,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-029",
      "type": "multiple-choice",
      "question": "A profile API shows this signal: lock contention and cross-node coordination dominate p99 latency. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-030",
      "type": "multiple-choice",
      "question": "A analytics ingestion service shows this signal: one large node still has headroom but queueing spikes during deploys. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose horizontal scaling first because better elasticity for bursty traffic patterns.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-031",
      "type": "multiple-choice",
      "question": "A checkout API shows this signal: CPU is pinned at 92% while memory is stable at 45%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose horizontal scaling first because aggregate capacity growth without hard single-node limits.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-032",
      "type": "multiple-choice",
      "question": "A search backend shows this signal: RSS keeps climbing to OOM while CPU is only 35%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is.",
        "Choose vertical scaling first because better single-thread performance for CPU-bound hot paths."
      ],
      "correct": 3,
      "explanation": "Memory pressure is the constraining resource, so larger nodes are the fastest immediate fix. Vertical scale buys time while you reduce memory footprint or redesign state handling."
    },
    {
      "id": "sc-hv-033",
      "type": "multiple-choice",
      "question": "A recommendation service shows this signal: network egress is capped at NIC limits while CPU is 40%. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Choose horizontal scaling first because higher fault tolerance by spreading load across nodes.",
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 0,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-034",
      "type": "multiple-choice",
      "question": "A image processing worker shows this signal: lock contention and cross-node coordination dominate p99 latency. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Choose horizontal scaling first because better elasticity for bursty traffic patterns.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 1,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-035",
      "type": "multiple-choice",
      "question": "A stream metadata service shows this signal: one large node still has headroom but queueing spikes during deploys. You need near-term capacity relief for the next quarter. What is the strongest primary move?",
      "options": [
        "Disable health checks so overloaded nodes keep receiving traffic evenly.",
        "Keep node count fixed and rely only on retries to absorb demand growth.",
        "Choose horizontal scaling first because aggregate capacity growth without hard single-node limits.",
        "Scale database replicas only, regardless of where the application bottleneck is."
      ],
      "correct": 2,
      "explanation": "The service is constrained by factors that improve with more nodes or reduced per-node contention. Horizontal scaling increases aggregate capacity and resilience while avoiding single-node ceilings."
    },
    {
      "id": "sc-hv-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a checkout API. Metrics show: CPU is pinned at 92% while memory is stable at 45%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "CPU saturation",
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 0,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "scale horizontally by adding more workers behind the load balancer",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 1,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally by adding more workers behind the load balancer."
        }
      ]
    },
    {
      "id": "sc-hv-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a search backend. Metrics show: RSS keeps climbing to OOM while CPU is only 35%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "memory saturation",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 1,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "scale vertically to larger-memory nodes first, then optimize memory hotspots",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 2,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale vertically to larger-memory nodes first, then optimize memory hotspots."
        }
      ]
    },
    {
      "id": "sc-hv-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a recommendation service. Metrics show: network egress is capped at NIC limits while CPU is 40%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "network bandwidth saturation",
            "TLS certificate chain depth"
          ],
          "correct": 2,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics",
            "scale horizontally to add aggregate network throughput across more nodes"
          ],
          "correct": 3,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally to add aggregate network throughput across more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a image processing worker. Metrics show: lock contention and cross-node coordination dominate p99 latency. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "TLS certificate chain depth",
            "DNS propagation delay in clients",
            "coordination overhead"
          ],
          "correct": 3,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "reduce shared coordination and rebalance partitions before adding more nodes",
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 0,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Reduce shared coordination and rebalance partitions before adding more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a stream metadata service. Metrics show: one large node still has headroom but queueing spikes during deploys. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "single-node fragility",
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 0,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "prefer horizontal scale for resilience and deployment safety",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 1,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Prefer horizontal scale for resilience and deployment safety."
        }
      ]
    },
    {
      "id": "sc-hv-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a inventory API. Metrics show: CPU is pinned at 92% while memory is stable at 45%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "CPU saturation",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 1,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "scale horizontally by adding more workers behind the load balancer",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 2,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally by adding more workers behind the load balancer."
        }
      ]
    },
    {
      "id": "sc-hv-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a payments service. Metrics show: RSS keeps climbing to OOM while CPU is only 35%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "memory saturation",
            "TLS certificate chain depth"
          ],
          "correct": 2,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics",
            "scale vertically to larger-memory nodes first, then optimize memory hotspots"
          ],
          "correct": 3,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale vertically to larger-memory nodes first, then optimize memory hotspots."
        }
      ]
    },
    {
      "id": "sc-hv-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a notification dispatcher. Metrics show: network egress is capped at NIC limits while CPU is 40%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "TLS certificate chain depth",
            "DNS propagation delay in clients",
            "network bandwidth saturation"
          ],
          "correct": 3,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "scale horizontally to add aggregate network throughput across more nodes",
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 0,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally to add aggregate network throughput across more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a profile API. Metrics show: lock contention and cross-node coordination dominate p99 latency. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "coordination overhead",
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 0,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "reduce shared coordination and rebalance partitions before adding more nodes",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 1,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Reduce shared coordination and rebalance partitions before adding more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a analytics ingestion service. Metrics show: one large node still has headroom but queueing spikes during deploys. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "single-node fragility",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 1,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "prefer horizontal scale for resilience and deployment safety",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 2,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Prefer horizontal scale for resilience and deployment safety."
        }
      ]
    },
    {
      "id": "sc-hv-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a checkout API. Metrics show: CPU is pinned at 92% while memory is stable at 45%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "CPU saturation",
            "TLS certificate chain depth"
          ],
          "correct": 2,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics",
            "scale horizontally by adding more workers behind the load balancer"
          ],
          "correct": 3,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally by adding more workers behind the load balancer."
        }
      ]
    },
    {
      "id": "sc-hv-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a search backend. Metrics show: RSS keeps climbing to OOM while CPU is only 35%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "TLS certificate chain depth",
            "DNS propagation delay in clients",
            "memory saturation"
          ],
          "correct": 3,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "scale vertically to larger-memory nodes first, then optimize memory hotspots",
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 0,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale vertically to larger-memory nodes first, then optimize memory hotspots."
        }
      ]
    },
    {
      "id": "sc-hv-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a recommendation service. Metrics show: network egress is capped at NIC limits while CPU is 40%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "network bandwidth saturation",
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 0,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "scale horizontally to add aggregate network throughput across more nodes",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 1,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally to add aggregate network throughput across more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a image processing worker. Metrics show: lock contention and cross-node coordination dominate p99 latency. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "coordination overhead",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 1,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "reduce shared coordination and rebalance partitions before adding more nodes",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 2,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Reduce shared coordination and rebalance partitions before adding more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a stream metadata service. Metrics show: one large node still has headroom but queueing spikes during deploys. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "single-node fragility",
            "TLS certificate chain depth"
          ],
          "correct": 2,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics",
            "prefer horizontal scale for resilience and deployment safety"
          ],
          "correct": 3,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Prefer horizontal scale for resilience and deployment safety."
        }
      ]
    },
    {
      "id": "sc-hv-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a inventory API. Metrics show: CPU is pinned at 92% while memory is stable at 45%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "TLS certificate chain depth",
            "DNS propagation delay in clients",
            "CPU saturation"
          ],
          "correct": 3,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "scale horizontally by adding more workers behind the load balancer",
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 0,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally by adding more workers behind the load balancer."
        }
      ]
    },
    {
      "id": "sc-hv-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a payments service. Metrics show: RSS keeps climbing to OOM while CPU is only 35%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "memory saturation",
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 0,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "scale vertically to larger-memory nodes first, then optimize memory hotspots",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 1,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale vertically to larger-memory nodes first, then optimize memory hotspots."
        }
      ]
    },
    {
      "id": "sc-hv-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a notification dispatcher. Metrics show: network egress is capped at NIC limits while CPU is 40%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "network bandwidth saturation",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 1,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "scale horizontally to add aggregate network throughput across more nodes",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 2,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally to add aggregate network throughput across more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a profile API. Metrics show: lock contention and cross-node coordination dominate p99 latency. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "coordination overhead",
            "TLS certificate chain depth"
          ],
          "correct": 2,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics",
            "reduce shared coordination and rebalance partitions before adding more nodes"
          ],
          "correct": 3,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Reduce shared coordination and rebalance partitions before adding more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a analytics ingestion service. Metrics show: one large node still has headroom but queueing spikes during deploys. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "TLS certificate chain depth",
            "DNS propagation delay in clients",
            "single-node fragility"
          ],
          "correct": 3,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "prefer horizontal scale for resilience and deployment safety",
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 0,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Prefer horizontal scale for resilience and deployment safety."
        }
      ]
    },
    {
      "id": "sc-hv-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a checkout API. Metrics show: CPU is pinned at 92% while memory is stable at 45%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "CPU saturation",
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 0,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "scale horizontally by adding more workers behind the load balancer",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 1,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally by adding more workers behind the load balancer."
        }
      ]
    },
    {
      "id": "sc-hv-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a search backend. Metrics show: RSS keeps climbing to OOM while CPU is only 35%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "memory saturation",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 1,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "scale vertically to larger-memory nodes first, then optimize memory hotspots",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 2,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale vertically to larger-memory nodes first, then optimize memory hotspots."
        }
      ]
    },
    {
      "id": "sc-hv-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a recommendation service. Metrics show: network egress is capped at NIC limits while CPU is 40%. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "network bandwidth saturation",
            "TLS certificate chain depth"
          ],
          "correct": 2,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics",
            "scale horizontally to add aggregate network throughput across more nodes"
          ],
          "correct": 3,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Scale horizontally to add aggregate network throughput across more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a image processing worker. Metrics show: lock contention and cross-node coordination dominate p99 latency. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "Read amplification from replicas is the only issue",
            "TLS certificate chain depth",
            "DNS propagation delay in clients",
            "coordination overhead"
          ],
          "correct": 3,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "reduce shared coordination and rebalance partitions before adding more nodes",
            "Double log verbosity in production and wait one week",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 0,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Reduce shared coordination and rebalance partitions before adding more nodes."
        }
      ]
    },
    {
      "id": "sc-hv-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "You are on call for a stream metadata service. Metrics show: one large node still has headroom but queueing spikes during deploys. What is the best diagnosis to drive a scaling decision?",
          "options": [
            "single-node fragility",
            "Read amplification from replicas is the only issue",
            "DNS propagation delay in clients",
            "TLS certificate chain depth"
          ],
          "correct": 0,
          "explanation": "You should identify the limiting resource first. Scaling choice should match the observed saturation pattern instead of applying a generic one-size-fits-all answer."
        },
        {
          "question": "Given that diagnosis, what is the best immediate scaling action?",
          "options": [
            "Double log verbosity in production and wait one week",
            "prefer horizontal scale for resilience and deployment safety",
            "Throttle all user traffic permanently to 60% of normal",
            "Ignore scaling and focus only on dashboard cosmetics"
          ],
          "correct": 1,
          "explanation": "The action must directly address the constrained resource while keeping reliability in view. Prefer horizontal scale for resilience and deployment safety."
        }
      ]
    },
    {
      "id": "sc-hv-061",
      "type": "multi-select",
      "question": "You are deciding whether to scale up or out for a stateful compute tier. Which factors support vertical scaling first?",
      "options": [
        "Working set must remain in one large memory space to avoid cross-node chatter",
        "You need immediate relief with minimal architecture changes",
        "You want lower blast radius by distributing requests over many nodes",
        "You are already at hardware limits on largest instance type"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-062",
      "type": "multi-select",
      "question": "A service has sudden 5x traffic spikes and frequent deploys. Which factors support horizontal scaling?",
      "options": [
        "Add nodes quickly during spikes with autoscaling",
        "Reduce single-node failure impact by spreading load",
        "Depend on one huge server to simplify failover",
        "Avoid partitioning work entirely even with skew"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-063",
      "type": "multi-select",
      "question": "Before choosing vertical scaling, what risks should be explicitly called out?",
      "options": [
        "Hard ceiling at max instance size",
        "Larger failure domain when one node dies",
        "Need for stronger partitioning strategy across many nodes",
        "Potentially longer replacement times for very large nodes"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-064",
      "type": "multi-select",
      "question": "You suspect horizontal scaling is underperforming. Which signals indicate coordination overhead is the culprit?",
      "options": [
        "Cross-node lock wait time rises with node count",
        "Cluster-wide metadata updates dominate p99",
        "Single-node CPU jumps when traffic drops",
        "Queue depth shrinks while request latency increases"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-065",
      "type": "multi-select",
      "question": "A team wants to compare scaling strategies financially. Which inputs are required for a meaningful cost model?",
      "options": [
        "Per-node fixed and variable compute cost",
        "Coordination and ops overhead as node count grows",
        "Only average CPU utilization over one hour",
        "Failure cost and recovery time assumptions"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-066",
      "type": "multi-select",
      "question": "Which changes often improve horizontal scaling efficiency before adding more nodes?",
      "options": [
        "Reduce shared-state hot spots and lock contention",
        "Improve partition-key quality to reduce skew",
        "Disable observability to save CPU",
        "Increase request fan-out per call path"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-067",
      "type": "multi-select",
      "question": "You are deciding whether to scale up or out for a stateful compute tier. Which factors support vertical scaling first?",
      "options": [
        "Working set must remain in one large memory space to avoid cross-node chatter",
        "You need immediate relief with minimal architecture changes",
        "You want lower blast radius by distributing requests over many nodes",
        "You are already at hardware limits on largest instance type"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-068",
      "type": "multi-select",
      "question": "A service has sudden 5x traffic spikes and frequent deploys. Which factors support horizontal scaling?",
      "options": [
        "Add nodes quickly during spikes with autoscaling",
        "Reduce single-node failure impact by spreading load",
        "Depend on one huge server to simplify failover",
        "Avoid partitioning work entirely even with skew"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-069",
      "type": "multi-select",
      "question": "Before choosing vertical scaling, what risks should be explicitly called out?",
      "options": [
        "Hard ceiling at max instance size",
        "Larger failure domain when one node dies",
        "Need for stronger partitioning strategy across many nodes",
        "Potentially longer replacement times for very large nodes"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-070",
      "type": "multi-select",
      "question": "You suspect horizontal scaling is underperforming. Which signals indicate coordination overhead is the culprit?",
      "options": [
        "Cross-node lock wait time rises with node count",
        "Cluster-wide metadata updates dominate p99",
        "Single-node CPU jumps when traffic drops",
        "Queue depth shrinks while request latency increases"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-071",
      "type": "multi-select",
      "question": "A team wants to compare scaling strategies financially. Which inputs are required for a meaningful cost model?",
      "options": [
        "Per-node fixed and variable compute cost",
        "Coordination and ops overhead as node count grows",
        "Only average CPU utilization over one hour",
        "Failure cost and recovery time assumptions"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-072",
      "type": "multi-select",
      "question": "Which changes often improve horizontal scaling efficiency before adding more nodes?",
      "options": [
        "Reduce shared-state hot spots and lock contention",
        "Improve partition-key quality to reduce skew",
        "Disable observability to save CPU",
        "Increase request fan-out per call path"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-073",
      "type": "multi-select",
      "question": "You are deciding whether to scale up or out for a stateful compute tier. Which factors support vertical scaling first?",
      "options": [
        "Working set must remain in one large memory space to avoid cross-node chatter",
        "You need immediate relief with minimal architecture changes",
        "You want lower blast radius by distributing requests over many nodes",
        "You are already at hardware limits on largest instance type"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-074",
      "type": "multi-select",
      "question": "A service has sudden 5x traffic spikes and frequent deploys. Which factors support horizontal scaling?",
      "options": [
        "Add nodes quickly during spikes with autoscaling",
        "Reduce single-node failure impact by spreading load",
        "Depend on one huge server to simplify failover",
        "Avoid partitioning work entirely even with skew"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-075",
      "type": "multi-select",
      "question": "Before choosing vertical scaling, what risks should be explicitly called out?",
      "options": [
        "Hard ceiling at max instance size",
        "Larger failure domain when one node dies",
        "Need for stronger partitioning strategy across many nodes",
        "Potentially longer replacement times for very large nodes"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-076",
      "type": "multi-select",
      "question": "You suspect horizontal scaling is underperforming. Which signals indicate coordination overhead is the culprit?",
      "options": [
        "Cross-node lock wait time rises with node count",
        "Cluster-wide metadata updates dominate p99",
        "Single-node CPU jumps when traffic drops",
        "Queue depth shrinks while request latency increases"
      ],
      "correctIndices": [
        0,
        1
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-077",
      "type": "multi-select",
      "question": "A team wants to compare scaling strategies financially. Which inputs are required for a meaningful cost model?",
      "options": [
        "Per-node fixed and variable compute cost",
        "Coordination and ops overhead as node count grows",
        "Only average CPU utilization over one hour",
        "Failure cost and recovery time assumptions"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "The correct choices capture the primary scaling trade-offs for capacity, reliability, and operational complexity. The excluded options are incomplete or counterproductive in this context."
    },
    {
      "id": "sc-hv-078",
      "type": "numeric-input",
      "question": "Each node can sustain 1800 QPS at 70% utilization. For a target of 12000 QPS peak, how many nodes are required?",
      "answer": 10,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Effective capacity per node at target utilization is 1260 QPS. 12000 / 1260 is 9.523809523809524, so round up to 10 nodes."
    },
    {
      "id": "sc-hv-079",
      "type": "numeric-input",
      "question": "You currently run 12 nodes at 2400 QPS each and expect 50% demand growth. If you target 75% utilization, how many nodes should the new fleet have?",
      "answer": 24,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Current peak is 28800 QPS. Future peak is 43200 QPS. At 75% utilization each node contributes 1800 QPS, so you need 24 nodes."
    },
    {
      "id": "sc-hv-080",
      "type": "numeric-input",
      "question": "Option A uses 14 small instances at $0.4/hour each. Option B uses 6 large instances at $1.1/hour each. What is the percent cost increase of B vs A?",
      "answer": 17.86,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "A costs $5.60/hour. B costs $6.60/hour. Increase is 1.00 on a base of 5.60, which is 17.9%."
    },
    {
      "id": "sc-hv-081",
      "type": "numeric-input",
      "question": "A horizontally scaled tier has 18 equal nodes behind a load balancer. If one node fails suddenly and traffic redistributes perfectly, approximately what percent of raw capacity is lost?",
      "answer": 5.56,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "One of 18 identical nodes is lost, so raw capacity reduction is 1/18 = 5.56%."
    },
    {
      "id": "sc-hv-082",
      "type": "numeric-input",
      "question": "Each node can sustain 1800 QPS at 70% utilization. For a target of 12000 QPS peak, how many nodes are required?",
      "answer": 10,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Effective capacity per node at target utilization is 1260 QPS. 12000 / 1260 is 9.523809523809524, so round up to 10 nodes."
    },
    {
      "id": "sc-hv-083",
      "type": "numeric-input",
      "question": "You currently run 12 nodes at 2400 QPS each and expect 50% demand growth. If you target 75% utilization, how many nodes should the new fleet have?",
      "answer": 24,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Current peak is 28800 QPS. Future peak is 43200 QPS. At 75% utilization each node contributes 1800 QPS, so you need 24 nodes."
    },
    {
      "id": "sc-hv-084",
      "type": "numeric-input",
      "question": "Option A uses 14 small instances at $0.4/hour each. Option B uses 6 large instances at $1.1/hour each. What is the percent cost increase of B vs A?",
      "answer": 17.86,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "A costs $5.60/hour. B costs $6.60/hour. Increase is 1.00 on a base of 5.60, which is 17.9%."
    },
    {
      "id": "sc-hv-085",
      "type": "numeric-input",
      "question": "A horizontally scaled tier has 18 equal nodes behind a load balancer. If one node fails suddenly and traffic redistributes perfectly, approximately what percent of raw capacity is lost?",
      "answer": 5.56,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "One of 18 identical nodes is lost, so raw capacity reduction is 1/18 = 5.56%."
    },
    {
      "id": "sc-hv-086",
      "type": "numeric-input",
      "question": "Each node can sustain 1800 QPS at 70% utilization. For a target of 12000 QPS peak, how many nodes are required?",
      "answer": 10,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Effective capacity per node at target utilization is 1260 QPS. 12000 / 1260 is 9.523809523809524, so round up to 10 nodes."
    },
    {
      "id": "sc-hv-087",
      "type": "numeric-input",
      "question": "You currently run 12 nodes at 2400 QPS each and expect 50% demand growth. If you target 75% utilization, how many nodes should the new fleet have?",
      "answer": 24,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Current peak is 28800 QPS. Future peak is 43200 QPS. At 75% utilization each node contributes 1800 QPS, so you need 24 nodes."
    },
    {
      "id": "sc-hv-088",
      "type": "numeric-input",
      "question": "Option A uses 14 small instances at $0.4/hour each. Option B uses 6 large instances at $1.1/hour each. What is the percent cost increase of B vs A?",
      "answer": 17.86,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "A costs $5.60/hour. B costs $6.60/hour. Increase is 1.00 on a base of 5.60, which is 17.9%."
    },
    {
      "id": "sc-hv-089",
      "type": "numeric-input",
      "question": "A horizontally scaled tier has 18 equal nodes behind a load balancer. If one node fails suddenly and traffic redistributes perfectly, approximately what percent of raw capacity is lost?",
      "answer": 5.56,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "One of 18 identical nodes is lost, so raw capacity reduction is 1/18 = 5.56%."
    },
    {
      "id": "sc-hv-090",
      "type": "ordering",
      "question": "Rank this scaling decision flow from first to last for a production service.",
      "items": [
        "Identify the dominant bottleneck from metrics (CPU, memory, network, coordination)",
        "Choose vertical or horizontal strategy that targets that bottleneck",
        "Apply rollout guardrails (canary, limits, rollback criteria)",
        "Re-measure latency, error rate, and utilization after change"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-091",
      "type": "ordering",
      "question": "Rank approaches from LOWEST to HIGHEST coordination overhead at similar throughput targets.",
      "items": [
        "Scale one stateless service horizontally with independent workers",
        "Scale partitioned workers with occasional cross-shard operations",
        "Scale tightly coupled workers requiring shared distributed locks",
        "Scale globally synchronized workers with frequent consensus writes"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-092",
      "type": "ordering",
      "question": "Rank options from FASTEST short-term capacity relief to SLOWEST.",
      "items": [
        "Increase instance size within the same family if headroom exists",
        "Add more existing nodes behind current load balancer policy",
        "Refactor service to remove shared-state contention",
        "Redesign architecture to split domain into separate bounded services"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-093",
      "type": "ordering",
      "question": "Rank failure blast radius from SMALLEST to LARGEST for equal total capacity.",
      "items": [
        "20 small nodes each carrying ~5% traffic",
        "10 medium nodes each carrying ~10% traffic",
        "4 large nodes each carrying ~25% traffic",
        "1 very large node carrying 100% traffic"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-094",
      "type": "ordering",
      "question": "Rank this scaling decision flow from first to last for a production service.",
      "items": [
        "Identify the dominant bottleneck from metrics (CPU, memory, network, coordination)",
        "Choose vertical or horizontal strategy that targets that bottleneck",
        "Apply rollout guardrails (canary, limits, rollback criteria)",
        "Re-measure latency, error rate, and utilization after change"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-095",
      "type": "ordering",
      "question": "Rank approaches from LOWEST to HIGHEST coordination overhead at similar throughput targets.",
      "items": [
        "Scale one stateless service horizontally with independent workers",
        "Scale partitioned workers with occasional cross-shard operations",
        "Scale tightly coupled workers requiring shared distributed locks",
        "Scale globally synchronized workers with frequent consensus writes"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-096",
      "type": "ordering",
      "question": "Rank options from FASTEST short-term capacity relief to SLOWEST.",
      "items": [
        "Increase instance size within the same family if headroom exists",
        "Add more existing nodes behind current load balancer policy",
        "Refactor service to remove shared-state contention",
        "Redesign architecture to split domain into separate bounded services"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-097",
      "type": "ordering",
      "question": "Rank failure blast radius from SMALLEST to LARGEST for equal total capacity.",
      "items": [
        "20 small nodes each carrying ~5% traffic",
        "10 medium nodes each carrying ~10% traffic",
        "4 large nodes each carrying ~25% traffic",
        "1 very large node carrying 100% traffic"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-098",
      "type": "ordering",
      "question": "Rank this scaling decision flow from first to last for a production service.",
      "items": [
        "Identify the dominant bottleneck from metrics (CPU, memory, network, coordination)",
        "Choose vertical or horizontal strategy that targets that bottleneck",
        "Apply rollout guardrails (canary, limits, rollback criteria)",
        "Re-measure latency, error rate, and utilization after change"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-099",
      "type": "ordering",
      "question": "Rank approaches from LOWEST to HIGHEST coordination overhead at similar throughput targets.",
      "items": [
        "Scale one stateless service horizontally with independent workers",
        "Scale partitioned workers with occasional cross-shard operations",
        "Scale tightly coupled workers requiring shared distributed locks",
        "Scale globally synchronized workers with frequent consensus writes"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    },
    {
      "id": "sc-hv-100",
      "type": "ordering",
      "question": "Rank options from FASTEST short-term capacity relief to SLOWEST.",
      "items": [
        "Increase instance size within the same family if headroom exists",
        "Add more existing nodes behind current load balancer policy",
        "Refactor service to remove shared-state contention",
        "Redesign architecture to split domain into separate bounded services"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ranking follows standard scaling operations practice: diagnose first, then choose and safely roll out interventions while considering coordination cost and blast radius."
    }
  ]
}
