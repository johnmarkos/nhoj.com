{
  "unit": 7,
  "unitTitle": "Scaling Compute",
  "chapter": 3,
  "chapterTitle": "Horizontal vs Vertical Scaling Decisions",
  "chapterDescription": "Capacity planning trade-offs between larger nodes and more nodes across bottlenecks, reliability goals, and cost constraints.",
  "problems": [
    {
      "id": "sc-hv-001",
      "type": "multiple-choice",
      "question": "A ad ranking service reports: CPU 95% during feature extraction while memory is 48%. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because requests are independent and CPU-bound.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-002",
      "type": "multiple-choice",
      "question": "A timeline fanout worker reports: heap usage hits OOM before CPU exceeds 40%. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because the hot path needs a larger in-memory working set immediately."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-003",
      "type": "multiple-choice",
      "question": "A edge image resizer reports: network egress is maxed at 25 Gbps and CPU is 42%. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because aggregate NIC bandwidth scales best by adding nodes.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-004",
      "type": "multiple-choice",
      "question": "A fraud scoring API reports: cross-node locks dominate p99 after adding more workers. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because more nodes increased coordination overhead without reducing contention.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "sc-hv-005",
      "type": "multiple-choice",
      "question": "A checkout API reports: single node replacements cause visible brownouts during deploy. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because smaller nodes reduce replacement blast radius.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-006",
      "type": "multiple-choice",
      "question": "A search aggregator reports: single-thread latency regressed after model complexity increased. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because stronger per-core performance is the immediate bottleneck."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-007",
      "type": "multiple-choice",
      "question": "A notification sender reports: CPU and network both moderate but one JVM pauses for 4s GC. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because more nodes absorb pause impact and smooth tail latency.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-008",
      "type": "multiple-choice",
      "question": "A pricing engine reports: memory fragmentation causes frequent allocator stalls. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because larger memory headroom is the fastest stabilizing step.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-009",
      "type": "multiple-choice",
      "question": "A video transcoding queue reports: queue depth rises with high CPU on all workers. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because parallel jobs scale linearly with worker count.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-010",
      "type": "multiple-choice",
      "question": "A profile read API reports: cache working set no longer fits and miss penalties spike. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because larger nodes restore cache residency without repartitioning."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        }
      ]
    },
    {
      "id": "sc-hv-011",
      "type": "multiple-choice",
      "question": "A shipment planner reports: AZ-level loss removes 33% of capacity with current fleet. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because more nodes per AZ lowers failure impact per node.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-012",
      "type": "multiple-choice",
      "question": "A metrics ingest gateway reports: packet drops appear at per-host NIC limit. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale horizontally first because capacity is constrained by host network limits.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-013",
      "type": "multiple-choice",
      "question": "A document rendering service reports: runtime is mostly single-threaded due to legacy library. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale vertically first because bigger/faster cores help before rewrite is complete.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-014",
      "type": "multiple-choice",
      "question": "A session enrichment API reports: latency rises as cluster metadata writes scale with node count. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because reducing node count can cut coordination tax for now."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "sc-hv-015",
      "type": "multiple-choice",
      "question": "A coupon validation service reports: node memory is exhausted from large rule tables. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale vertically first because state footprint dominates and needs larger memory boxes.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-016",
      "type": "multiple-choice",
      "question": "A webhook delivery worker reports: traffic is bursty 6x at top of hour. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale horizontally first because elastic node count handles bursts better.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-017",
      "type": "multiple-choice",
      "question": "A order audit pipeline reports: storage bandwidth on local NVMe is saturated per host. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because more hosts increase aggregate local I/O channels.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-018",
      "type": "multiple-choice",
      "question": "A chat presence service reports: one huge node is stable but failover takes 8 minutes. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because faster recovery comes from many smaller failure domains."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-019",
      "type": "multiple-choice",
      "question": "A personalization API reports: per-request CPU cost doubled after model rollout. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because stateless compute can be parallelized safely.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-020",
      "type": "multiple-choice",
      "question": "A inventory diff worker reports: RSS grows with batch size and jobs fail from OOM. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because memory ceiling is the hard limit right now.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-021",
      "type": "multiple-choice",
      "question": "A report generation service reports: autoscaling adds nodes but lock wait keeps rising. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale vertically first because contention suggests scale-up before redesign.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-022",
      "type": "multiple-choice",
      "question": "A catalog search indexer reports: nodes are under 50% CPU but one server hit max packets/s. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because adding hosts increases packet processing capacity."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-023",
      "type": "multiple-choice",
      "question": "A stream metadata API reports: request rate is steady but long-tail spikes on GC events. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because extra nodes reduce impact of individual GC stalls.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-024",
      "type": "multiple-choice",
      "question": "A tax calculation engine reports: same-host cache locality is crucial for 40MB hot state. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because scale-up preserves locality with minimal refactor.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "sc-hv-025",
      "type": "multiple-choice",
      "question": "A IoT command gateway reports: device spikes require 2-minute elasticity windows. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because rapid node count expansion matches burst profile.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-026",
      "type": "multiple-choice",
      "question": "A recommendation retrieval API reports: memory use is flat but run queue length is high. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because CPU scheduling pressure favors more workers."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "sc-hv-027",
      "type": "multiple-choice",
      "question": "A promotion rules evaluator reports: largest instance type still has 25% memory headroom. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because scaling out improves resilience while headroom exists.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-028",
      "type": "multiple-choice",
      "question": "A ledger replay worker reports: coordination service reaches write limits at 80 nodes. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because fewer stronger workers reduce coordination load.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Start by identifying the limiting factor, then rule out options that violate scale or semantics. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-029",
      "type": "multiple-choice",
      "question": "A email template compiler reports: build tasks are embarrassingly parallel. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because parallel execution maps directly to more nodes.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Lead with the key assumption, then remove options that break units, scale, or architecture constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-030",
      "type": "multiple-choice",
      "question": "A ML feature store API reports: memory bandwidth saturation appears before CPU maxes. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because larger machines improve memory-channel throughput."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Solve this by pinning the governing ratio first and using it to discard impossible answers. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "sc-hv-031",
      "type": "multiple-choice",
      "question": "A billing statement exporter reports: nightly batch misses deadline with fixed worker pool. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because more workers reduce wall-clock completion time.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "Frame the problem around the main tradeoff first, then test each option for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-032",
      "type": "multiple-choice",
      "question": "A OCR processing pipeline reports: one host crash drops 20% throughput today. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale horizontally first because spreading load decreases per-node criticality.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "The fastest path is to anchor on the core constraint and eliminate implausible options early. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-033",
      "type": "multiple-choice",
      "question": "A geo lookup API reports: dataset just exceeded RAM on current instance family. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale vertically first because fit-in-memory requirement drives immediate scale-up.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "A reliable method is to name the primary boundary condition, then evaluate options against it. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "sc-hv-034",
      "type": "multiple-choice",
      "question": "A ad click ingestion reports: CPU is fine but TLS handshake rate saturates hosts. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because additional frontends increase handshake capacity."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation.",
      "detailedExplanation": "A practical approach here is to lock down the dominant constraint before comparing answer choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "sc-hv-035",
      "type": "multiple-choice",
      "question": "A compliance scan service reports: cross-shard barriers dominate compute time. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale vertically first because adding nodes worsens barrier synchronization overhead.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change.",
      "detailedExplanation": "Treat this as a constraint-filtering problem: find the bottleneck first, then narrow the choices. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for feed ranking API: CPU saturation with independent requests. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "CPU-bound parallel workload",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "add nodes behind load balancer and watch tail latency",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Anchor on the base formula, preserve unit integrity, and then run a reasonableness check. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for rules engine: heap OOM before CPU pressure. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "memory-bound working set"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "move to larger-memory instances as a short-term fix",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Follow the canonical calculation path and check both units and magnitude before finalizing. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for render farm: network throughput per host capped. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "network bottleneck",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "increase host count to raise aggregate egress",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Use a formula-first approach with explicit units to avoid hidden conversion mistakes. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for stateful matcher: distributed lock wait rises with node count. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "coordination overhead",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "reduce cross-node coordination then scale carefully"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for checkout workers: deploys cause significant capacity dips. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "large-node blast radius",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "split into more smaller workers",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for geo processor: single-thread hot path limits latency. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "per-core performance ceiling"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "use larger/faster cores while planning parallelization",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Use a formula-first approach with explicit units to avoid hidden conversion mistakes. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for notification fanout: bursty arrival every 5 minutes. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "elasticity requirement",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "enable fast horizontal autoscaling",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Start from the governing formula, keep units visible, and validate the final magnitude. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for anti-fraud service: metadata quorum writes dominate p99. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "control-plane bottleneck",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "decrease node churn and batch control updates"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Apply the main relationship stepwise and verify unit consistency at each step. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for preview generator: jobs are independent and queue-backed. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "embarrassingly parallel workload",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Treat this as a continuation step: preserve earlier constraints and recheck feasibility. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "increase worker replicas",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Advance from the first-stage output, then verify that this decision still respects the same limits. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Work through the core math with unit labels attached, then verify scale plausibility. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for document parser: RSS climbs with document complexity. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "memory pressure"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Advance from the first-stage output, then verify that this decision still respects the same limits. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "scale up RAM and cap concurrent docs",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Treat this as a continuation step: preserve earlier constraints and recheck feasibility. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Use the core equation with explicit unit tracking before committing to an answer. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for metrics rollup: packet-per-second cap reached. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "host networking limit",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "add ingest nodes and rebalance producers",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Follow the canonical calculation path and check both units and magnitude before finalizing. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for promotion evaluator: cross-shard fanout grew 4x. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "high coordination fanout",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "co-locate related keys before adding nodes"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Anchor on the base formula, preserve unit integrity, and then run a reasonableness check. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for invoice calculator: tail spikes tied to stop-the-world pauses. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "single-node pause sensitivity",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "add more nodes to dilute pause impact",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for chat delivery: single node failure removes 18% capacity. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "failure-domain problem"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "increase node count to cut per-node share",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Use a formula-first approach with explicit units to avoid hidden conversion mistakes. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for search suggest: cache no longer fits on current hosts. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "insufficient memory footprint",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Caching answers should define invalidation behavior and staleness boundaries; hit rate alone is not a correctness guarantee."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "upgrade node memory class",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Apply the main relationship stepwise and verify unit consistency at each step. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for stream enrich: queue age rises while CPU on all nodes > 90%. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "compute saturation",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Message design should specify delivery guarantees, ordering scope, and backpressure behavior under failure, not just happy-path throughput."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "add workers and enforce backpressure"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Start from the governing formula, keep units visible, and validate the final magnitude. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for catalog merge: barrier synchronization dominates runtime. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "synchronization overhead",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "reduce barrier frequency before scaling out",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Use a formula-first approach with explicit units to avoid hidden conversion mistakes. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for sensor gateway: connection table maxes out per instance. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "per-host state limit"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Use the earlier stage as the boundary condition and solve this step under that constraint. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "increase node count and shard connections",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Use the result from the previous step as a hard constraint, then evaluate this stage against it. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Compute from the primary formula first, then sanity-check the scale of the result. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for billing export: batch misses SLA by 30%. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "insufficient parallel capacity",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "add temporary worker pool for batch window",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Anchor on the base formula, preserve unit integrity, and then run a reasonableness check. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for report precompute: larger instance type available with 2x memory. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "quick vertical relief option",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "scale up now and revisit partitioning"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Follow the canonical calculation path and check both units and magnitude before finalizing. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for live scoreboard: frequent deployment with tight SLOs. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "operational resilience pressure",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Advance from the first-stage output, then verify that this decision still respects the same limits. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "prefer more small nodes for safer rollouts",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Treat this as a continuation step: preserve earlier constraints and recheck feasibility. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Use the core equation with explicit unit tracking before committing to an answer. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for OCR API: CPU fine but memory bandwidth saturated. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "memory-channel bottleneck"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Treat this as a continuation step: preserve earlier constraints and recheck feasibility. The key API design signal is tradeoff clarity: client ergonomics, backward compatibility, and evolvability should be justified explicitly."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "move to instances with higher memory bandwidth",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Advance from the first-stage output, then verify that this decision still respects the same limits. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Work through the core math with unit labels attached, then verify scale plausibility. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for vector search: coordinator CPU pegs while workers idle. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "central coordination bottleneck",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Translate the prior stage outcome into an operational check before selecting the next move. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "split coordinator role then scale",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "Carry the prior stage assumptions forward and revalidate units before making the next decision. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Apply the main relationship stepwise and verify unit consistency at each step. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for ad delivery: TLS termination maxes per host. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "frontend host bottleneck",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "scale out edge terminators"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Start from the governing formula, keep units visible, and validate the final magnitude. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for compliance scanner: state transfer during failover is too large. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "heavy per-node state size",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics.",
          "detailedExplanation": "Keep the previous conclusion fixed, then test this stage for consistency and scale. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "first reduce state size, then re-evaluate strategy",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability.",
          "detailedExplanation": "This stage is best solved by propagating the earlier result and validating edge conditions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers."
        }
      ],
      "detailedExplanation": "Start from the governing formula, keep units visible, and validate the final magnitude. Translate workload into per-node limits and peak demand so scaling thresholds and headroom decisions are explicit.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-061",
      "type": "multi-select",
      "question": "Which signals justify choosing horizontal scaling first?",
      "options": [
        "Independent request processing and high CPU across nodes",
        "Need lower blast radius per failure",
        "Working set only fits on one very large machine",
        "Bursty demand needing elastic capacity"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Treat each candidate as a separate true/false check against the same governing requirement. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-062",
      "type": "multi-select",
      "question": "Which conditions make vertical scaling a reasonable first move?",
      "options": [
        "Memory ceiling is the immediate blocker",
        "Minimal time for architectural change",
        "Hard requirement to reduce single-node risk",
        "Strong single-thread performance is required"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Run a one-by-one validity check and discard options that depend on unstated conditions. A good sanity check compares against anchor numbers and names which assumption must change if the result looks implausible.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-063",
      "type": "multi-select",
      "question": "Which are common costs of horizontal scaling?",
      "options": [
        "Higher coordination/metadata overhead",
        "More complex partitioning and balancing",
        "Guaranteed lower cloud bill at any scale",
        "Increased operational surface area"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Avoid grouped guessing: test every option directly against the system boundary condition. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-064",
      "type": "multi-select",
      "question": "Which are key risks of vertical-only strategy over time?",
      "options": [
        "Hitting max instance-size limits",
        "Larger per-node blast radius",
        "Automatic elimination of coordination bugs",
        "Potentially slower recovery/replacement"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Use independent validation per option to prevent partial truths from slipping into the final set. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-065",
      "type": "multi-select",
      "question": "Which metrics are most useful before deciding between scale up vs out?",
      "options": [
        "Per-resource utilization (CPU/memory/network)",
        "Queue depth and queue age trends",
        "Only daily average request count",
        "Tail latency with concurrency context"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Assess each option separately and keep answers that hold across the full problem context. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-066",
      "type": "multi-select",
      "question": "For cost modeling of scaling paths, which inputs matter?",
      "options": [
        "Per-node cost by instance class",
        "Coordination overhead as node count rises",
        "Failure and recovery cost assumptions",
        "Only peak QPS without utilization targets"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Check every option on its own merits and reject statements that are only true under hidden assumptions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-067",
      "type": "multi-select",
      "question": "Which engineering steps improve horizontal efficiency before adding nodes?",
      "options": [
        "Reduce lock contention hot spots",
        "Improve partition-key distribution",
        "Increase cross-service synchronous fanout",
        "Minimize shared mutable state"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Evaluate each option independently against the constraint instead of looking for a pattern across choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-068",
      "type": "multi-select",
      "question": "Which statements about blast radius are accurate?",
      "options": [
        "More smaller nodes usually reduce per-node impact",
        "One huge node can make failures more severe",
        "Blast radius is unrelated to node size mix",
        "Deployment safety often improves with smaller increments"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-069",
      "type": "multi-select",
      "question": "Which workloads typically benefit from horizontal scaling?",
      "options": [
        "Queue-backed independent jobs",
        "Stateless APIs with uniform requests",
        "Monolithic single-threaded code with shared mutable state",
        "Batch pipelines that can shard by key"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Treat each candidate as a separate true/false check against the same governing requirement. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-070",
      "type": "multi-select",
      "question": "Which workloads often require some vertical scaling component?",
      "options": [
        "Large in-memory models requiring high RAM per process",
        "Latency-sensitive single-thread hot loops",
        "Simple stateless request routers only",
        "Workloads constrained by per-process memory bandwidth"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Evaluate each option independently against the constraint instead of looking for a pattern across choices. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-071",
      "type": "multi-select",
      "question": "Which anti-patterns often hide true scaling bottlenecks?",
      "options": [
        "Scaling blindly on CPU average only",
        "Ignoring queue age and tail latency",
        "Correlating metrics with deployment events",
        "Skipping bottleneck decomposition by resource"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Check every option on its own merits and reject statements that are only true under hidden assumptions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-072",
      "type": "multi-select",
      "question": "When scale-out appears ineffective, which checks are high-value?",
      "options": [
        "Measure cross-node coordination cost",
        "Inspect partition skew and hot keys",
        "Assume DNS is root cause by default",
        "Review shared datastore contention"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Assess each option separately and keep answers that hold across the full problem context. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-073",
      "type": "multi-select",
      "question": "Which are practical short-term actions during memory-bound incidents?",
      "options": [
        "Move to larger-memory nodes temporarily",
        "Reduce per-request memory footprint",
        "Increase retries to smooth memory spikes",
        "Cap concurrency until headroom returns"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Use independent validation per option to prevent partial truths from slipping into the final set. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-074",
      "type": "multi-select",
      "question": "Which statements about coordination overhead are true?",
      "options": [
        "It can rise nonlinearly with node count",
        "Global locks can erase scale-out gains",
        "It always decreases when adding nodes",
        "Partition-local work usually scales better"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Avoid grouped guessing: test every option directly against the system boundary condition. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-075",
      "type": "multi-select",
      "question": "Which are valid reasons to mix vertical and horizontal strategies?",
      "options": [
        "Scale up for immediate relief, then scale out for resilience",
        "Use larger nodes for coordinators and more small workers",
        "Pick one strategy forever regardless of workload changes",
        "Adapt strategy by bottleneck phase and growth stage"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Run a one-by-one validity check and discard options that depend on unstated conditions. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-076",
      "type": "multi-select",
      "question": "Which signals suggest network-bound scaling limits?",
      "options": [
        "Per-host egress plateaus at NIC limit",
        "CPU remains moderate during saturation",
        "OOM kills dominate incidents",
        "Adding hosts raises aggregate throughput"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Treat each candidate as a separate true/false check against the same governing requirement. Bandwidth planning should normalize units first, then include protocol overhead and peak multipliers to avoid underestimating production load.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-077",
      "type": "multi-select",
      "question": "Which guardrails reduce risk while applying scaling changes?",
      "options": [
        "Canary rollout with rollback thresholds",
        "Predefined max node/size limits",
        "Disable alerts during rollout to reduce noise",
        "Post-change metric comparison against baseline"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading.",
      "detailedExplanation": "Score each option independently and keep only those that remain valid under the stated constraints. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-078",
      "type": "numeric-input",
      "question": "Each node handles 1600 QPS at 80% target utilization. Peak target is 14000 QPS. Nodes needed?",
      "answer": 11,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Effective per-node capacity is 1280 QPS. 14000/1280 = 10.94, so 11 nodes.",
      "detailedExplanation": "Do the conversion step first and maintain unit labels to prevent silent math errors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-079",
      "type": "numeric-input",
      "question": "Current fleet: 10 nodes at 2200 QPS each. Forecast +40% traffic. Keep 70% utilization. New node count?",
      "answer": 20,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Future peak is 30799.999999999996 QPS. At target utilization each node provides 1540 QPS, so need 20 nodes.",
      "detailedExplanation": "Use base-unit arithmetic plus a magnitude check to keep the estimate robust under time pressure. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "sc-hv-080",
      "type": "numeric-input",
      "question": "Option A: 12 small nodes at $0.45/hr. Option B: 5 large nodes at $1.25/hr. Percent increase B vs A?",
      "answer": 15.74,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "A costs 5.40/hr and B costs 6.25/hr. Increase is 15.74%.",
      "detailedExplanation": "Use base-unit arithmetic plus a magnitude check to keep the estimate robust under time pressure. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-081",
      "type": "numeric-input",
      "question": "Tier has 24 equal nodes. One node fails and traffic redistributes perfectly. Percent capacity loss?",
      "answer": 4.17,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Losing 1 of 24 equal nodes reduces raw capacity by 1/24 = 4.17%.",
      "detailedExplanation": "Do the conversion step first and maintain unit labels to prevent silent math errors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-082",
      "type": "numeric-input",
      "question": "A vertical move doubles per-node memory from 64GB to 128GB. Fleet shrinks from 14 to 8 nodes. Total memory change (%)?",
      "answer": 14.29,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Old total memory 896GB, new 1024GB. Change is 14.29%.",
      "detailedExplanation": "Normalize units before calculating, and keep order-of-magnitude checks explicit throughout. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-083",
      "type": "numeric-input",
      "question": "Autoscaling target is 65% CPU. Each node sustains 3000 QPS at 100% CPU linear assumption. For 39000 QPS peak, nodes needed?",
      "answer": 20,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Per-node safe throughput 1950 QPS. 39000/1950 = 20.00 so 20 nodes.",
      "detailedExplanation": "Anchor the math in base units and check each transformation to avoid compounding conversion errors. Storage estimates should separate raw data, replication, and retention horizon so capacity and cost risk are visible early.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-084",
      "type": "numeric-input",
      "question": "A workload needs 9 TB/day egress. Each node safely delivers 350 MB/s average. Minimum nodes required?",
      "answer": 1,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Each node handles about 30.24 TB/day. Need 1 nodes for 9 TB/day.",
      "detailedExplanation": "Start with unit normalization, then verify that the final magnitude passes a quick sanity check. Bandwidth planning should normalize units first, then include protocol overhead and peak multipliers to avoid underestimating production load.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-085",
      "type": "numeric-input",
      "question": "Scale-out plan adds 6 nodes to current 18. By what percent does raw node count increase?",
      "answer": 33.33,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Adding 6 to 18 is a 6/18 = 33.33% increase.",
      "detailedExplanation": "Reduce the problem to base units, compute, and sanity-check the output scale before finalizing. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-086",
      "type": "numeric-input",
      "question": "Single large node costs $2.40/hr. Equivalent capacity uses 7 small nodes at $0.38/hr. Percent cheaper option?",
      "answer": 9.77,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Small-node option costs 2.66/hr. Large node costs 2.40/hr, which is 9.77% cheaper.",
      "detailedExplanation": "Make the units explicit at every step, then validate the resulting magnitude against known anchors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-087",
      "type": "numeric-input",
      "question": "At 30 nodes, coordination overhead consumes 18% CPU. At 45 nodes, 27% CPU. Relative overhead increase (%)?",
      "answer": 50,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Coordination overhead rose from 18% to 27%, a relative increase of 50.00%.",
      "detailedExplanation": "Convert to base units first, then track powers of ten so arithmetic mistakes are easier to catch. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "sc-hv-088",
      "type": "numeric-input",
      "question": "Batch job takes 90 min on 12 workers. Assume ideal scaling. Time on 18 workers (minutes)?",
      "answer": 60,
      "unit": "minutes",
      "tolerance": 0.1,
      "explanation": "Under ideal scaling, time is inversely proportional to workers: 90*12/18 = 60 minutes.",
      "detailedExplanation": "Use base-unit arithmetic plus a magnitude check to keep the estimate robust under time pressure. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Kubernetes Horizontal Pod Autoscaling",
          "url": "https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/"
        }
      ]
    },
    {
      "id": "sc-hv-089",
      "type": "numeric-input",
      "question": "A service currently has 16 nodes with 25% spare headroom. Traffic grows 20%. Additional nodes needed (same size)?",
      "answer": 4,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "With 25% headroom, effective capacity equals 20 node-equivalents. After 20% growth you need 19.2 node-equivalents, so 16 nodes remain sufficient and additional nodes needed is 4.",
      "detailedExplanation": "Do the conversion step first and maintain unit labels to prevent silent math errors. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "sc-hv-090",
      "type": "ordering",
      "question": "Rank the scaling workflow from first to last.",
      "items": [
        "Identify bottleneck by resource and contention",
        "Choose scale up/out hypothesis and expected impact",
        "Roll out gradually with guardrails",
        "Re-measure SLO and saturation after rollout"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Use relative magnitude to draft the order and confirm it with local adjacency checks. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-091",
      "type": "ordering",
      "question": "Rank from lowest to highest coordination overhead.",
      "items": [
        "Independent stateless workers",
        "Partitioned workers with rare cross-shard calls",
        "Workers using frequent distributed locks",
        "Workers requiring global consensus updates"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Establish the extremes first and fill the middle with pairwise comparisons. Consistency choices should be tied to concrete invariants and failure modes, then balanced against latency and availability cost.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ]
    },
    {
      "id": "sc-hv-092",
      "type": "ordering",
      "question": "Rank from smallest to largest per-node failure blast radius.",
      "items": [
        "24 small nodes",
        "12 medium nodes",
        "6 large nodes",
        "1 very large node"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Prioritize ratio-based comparisons and validate each neighboring step to avoid inversion mistakes. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-093",
      "type": "ordering",
      "question": "Rank from fastest short-term relief to slowest.",
      "items": [
        "Resize to larger instances in same family",
        "Add more replicas with existing topology",
        "Refactor to reduce shared-state contention",
        "Redesign architecture boundaries"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Start with the clear smallest/largest anchors, then place intermediate items by pairwise checks. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-094",
      "type": "ordering",
      "question": "Rank autoscaling signals from least to most direct for compute saturation.",
      "items": [
        "Daily average traffic",
        "Five-minute average CPU",
        "Queue age and tail latency",
        "Per-resource saturation plus queue age under load"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Rank by dominant bottleneck or magnitude, then validate adjacent transitions for consistency. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-095",
      "type": "ordering",
      "question": "Rank interventions from most to least useful when memory is the hard bottleneck.",
      "items": [
        "Increase per-node memory",
        "Reduce per-request memory footprint",
        "Improve partitioning to lower duplication",
        "Only increase retries"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Build the ordering from major scale differences first, then refine with adjacent comparisons. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-096",
      "type": "ordering",
      "question": "Rank decision quality from weakest to strongest.",
      "items": [
        "Choose strategy from team preference only",
        "Choose from average CPU alone",
        "Choose from multi-metric bottleneck analysis",
        "Choose from bottleneck analysis plus canary validation"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Order by relative impact rather than exact values, then verify the sequence one boundary at a time. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-097",
      "type": "ordering",
      "question": "Rank from least to most resilient deployment pattern.",
      "items": [
        "Single large node replacement",
        "Few large nodes with long drains",
        "Moderate node pool with canary",
        "Many small nodes with progressive rollout"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Compare relative scale first, then confirm neighboring items pairwise to lock in the order. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-098",
      "type": "ordering",
      "question": "Rank from least to most scalable for burst handling.",
      "items": [
        "Fixed-size vertical-only fleet",
        "Vertical scale plus manual adds",
        "Horizontal autoscaling by CPU only",
        "Horizontal autoscaling by CPU and queue age"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Use relative magnitude to draft the order and confirm it with local adjacency checks. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-099",
      "type": "ordering",
      "question": "Rank from lowest to highest operational complexity.",
      "items": [
        "Single pool of homogeneous nodes",
        "Two pools split by workload class",
        "Multi-pool with custom schedulers",
        "Global multi-region compute with per-region policies"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Establish the extremes first and fill the middle with pairwise comparisons. Compute sizing should distinguish average vs peak demand and map both to per-node limits and scaling triggers.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "sc-hv-100",
      "type": "ordering",
      "question": "Rank from worst to best incident response sequence.",
      "items": [
        "Scale randomly and hope",
        "Scale first then inspect metrics",
        "Diagnose bottleneck then scale",
        "Diagnose, scale with guardrails, verify outcome"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice.",
      "detailedExplanation": "Prioritize ratio-based comparisons and validate each neighboring step to avoid inversion mistakes. Translate target percentages into concrete time or request budgets, then test whether incident frequency and recovery speed can actually satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    }
  ]
}
