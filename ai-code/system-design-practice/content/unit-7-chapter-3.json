{
  "unit": 7,
  "unitTitle": "Scaling Compute",
  "chapter": 3,
  "chapterTitle": "Horizontal vs Vertical Scaling Decisions",
  "chapterDescription": "Capacity planning trade-offs between larger nodes and more nodes across bottlenecks, reliability goals, and cost constraints.",
  "problems": [
    {
      "id": "sc-hv-001",
      "type": "multiple-choice",
      "question": "A ad ranking service reports: CPU 95% during feature extraction while memory is 48%. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because requests are independent and CPU-bound.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-002",
      "type": "multiple-choice",
      "question": "A timeline fanout worker reports: heap usage hits OOM before CPU exceeds 40%. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because the hot path needs a larger in-memory working set immediately."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-003",
      "type": "multiple-choice",
      "question": "A edge image resizer reports: network egress is maxed at 25 Gbps and CPU is 42%. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because aggregate NIC bandwidth scales best by adding nodes.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-004",
      "type": "multiple-choice",
      "question": "A fraud scoring API reports: cross-node locks dominate p99 after adding more workers. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because more nodes increased coordination overhead without reducing contention.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-005",
      "type": "multiple-choice",
      "question": "A checkout API reports: single node replacements cause visible brownouts during deploy. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because smaller nodes reduce replacement blast radius.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-006",
      "type": "multiple-choice",
      "question": "A search aggregator reports: single-thread latency regressed after model complexity increased. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because stronger per-core performance is the immediate bottleneck."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-007",
      "type": "multiple-choice",
      "question": "A notification sender reports: CPU and network both moderate but one JVM pauses for 4s GC. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because more nodes absorb pause impact and smooth tail latency.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-008",
      "type": "multiple-choice",
      "question": "A pricing engine reports: memory fragmentation causes frequent allocator stalls. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because larger memory headroom is the fastest stabilizing step.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-009",
      "type": "multiple-choice",
      "question": "A video transcoding queue reports: queue depth rises with high CPU on all workers. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because parallel jobs scale linearly with worker count.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-010",
      "type": "multiple-choice",
      "question": "A profile read API reports: cache working set no longer fits and miss penalties spike. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because larger nodes restore cache residency without repartitioning."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-011",
      "type": "multiple-choice",
      "question": "A shipment planner reports: AZ-level loss removes 33% of capacity with current fleet. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because more nodes per AZ lowers failure impact per node.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-012",
      "type": "multiple-choice",
      "question": "A metrics ingest gateway reports: packet drops appear at per-host NIC limit. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale horizontally first because capacity is constrained by host network limits.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-013",
      "type": "multiple-choice",
      "question": "A document rendering service reports: runtime is mostly single-threaded due to legacy library. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale vertically first because bigger/faster cores help before rewrite is complete.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-014",
      "type": "multiple-choice",
      "question": "A session enrichment API reports: latency rises as cluster metadata writes scale with node count. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because reducing node count can cut coordination tax for now."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-015",
      "type": "multiple-choice",
      "question": "A coupon validation service reports: node memory is exhausted from large rule tables. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale vertically first because state footprint dominates and needs larger memory boxes.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-016",
      "type": "multiple-choice",
      "question": "A webhook delivery worker reports: traffic is bursty 6x at top of hour. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale horizontally first because elastic node count handles bursts better.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-017",
      "type": "multiple-choice",
      "question": "A order audit pipeline reports: storage bandwidth on local NVMe is saturated per host. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because more hosts increase aggregate local I/O channels.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-018",
      "type": "multiple-choice",
      "question": "A chat presence service reports: one huge node is stable but failover takes 8 minutes. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because faster recovery comes from many smaller failure domains."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-019",
      "type": "multiple-choice",
      "question": "A personalization API reports: per-request CPU cost doubled after model rollout. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because stateless compute can be parallelized safely.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-020",
      "type": "multiple-choice",
      "question": "A inventory diff worker reports: RSS grows with batch size and jobs fail from OOM. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because memory ceiling is the hard limit right now.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-021",
      "type": "multiple-choice",
      "question": "A report generation service reports: autoscaling adds nodes but lock wait keeps rising. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale vertically first because contention suggests scale-up before redesign.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-022",
      "type": "multiple-choice",
      "question": "A catalog search indexer reports: nodes are under 50% CPU but one server hit max packets/s. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because adding hosts increases packet processing capacity."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-023",
      "type": "multiple-choice",
      "question": "A stream metadata API reports: request rate is steady but long-tail spikes on GC events. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because extra nodes reduce impact of individual GC stalls.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-024",
      "type": "multiple-choice",
      "question": "A tax calculation engine reports: same-host cache locality is crucial for 40MB hot state. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because scale-up preserves locality with minimal refactor.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-025",
      "type": "multiple-choice",
      "question": "A IoT command gateway reports: device spikes require 2-minute elasticity windows. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because rapid node count expansion matches burst profile.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-026",
      "type": "multiple-choice",
      "question": "A recommendation retrieval API reports: memory use is flat but run queue length is high. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because CPU scheduling pressure favors more workers."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-027",
      "type": "multiple-choice",
      "question": "A promotion rules evaluator reports: largest instance type still has 25% memory headroom. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because scaling out improves resilience while headroom exists.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-028",
      "type": "multiple-choice",
      "question": "A ledger replay worker reports: coordination service reaches write limits at 80 nodes. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale vertically first because fewer stronger workers reduce coordination load.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-029",
      "type": "multiple-choice",
      "question": "A email template compiler reports: build tasks are embarrassingly parallel. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale horizontally first because parallel execution maps directly to more nodes.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-030",
      "type": "multiple-choice",
      "question": "A ML feature store API reports: memory bandwidth saturation appears before CPU maxes. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale vertically first because larger machines improve memory-channel throughput."
      ],
      "correct": 3,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-031",
      "type": "multiple-choice",
      "question": "A billing statement exporter reports: nightly batch misses deadline with fixed worker pool. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale horizontally first because more workers reduce wall-clock completion time.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-032",
      "type": "multiple-choice",
      "question": "A OCR processing pipeline reports: one host crash drops 20% throughput today. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Scale horizontally first because spreading load decreases per-node criticality.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 1,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-033",
      "type": "multiple-choice",
      "question": "A geo lookup API reports: dataset just exceeded RAM on current instance family. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Scale vertically first because fit-in-memory requirement drives immediate scale-up.",
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 0,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-034",
      "type": "multiple-choice",
      "question": "A ad click ingestion reports: CPU is fine but TLS handshake rate saturates hosts. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Change DNS TTL and assume that resolves capacity bottlenecks.",
        "Scale horizontally first because additional frontends increase handshake capacity."
      ],
      "correct": 3,
      "explanation": "Horizontal scaling is preferred when workload parallelizes well, bandwidth is host-limited, or resilience/blast-radius dominates. It raises aggregate capacity while improving failure isolation."
    },
    {
      "id": "sc-hv-035",
      "type": "multiple-choice",
      "question": "A compliance scan service reports: cross-shard barriers dominate compute time. For the next quarter, what is the strongest first scaling move?",
      "options": [
        "Do nothing on compute and only increase client retry count.",
        "Disable observability agents so dashboards look healthier.",
        "Scale vertically first because adding nodes worsens barrier synchronization overhead.",
        "Change DNS TTL and assume that resolves capacity bottlenecks."
      ],
      "correct": 2,
      "explanation": "Vertical scaling is preferred when per-node memory/per-core constraints or coordination costs dominate. It buys immediate headroom with minimal architecture change."
    },
    {
      "id": "sc-hv-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for feed ranking API: CPU saturation with independent requests. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "CPU-bound parallel workload",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "add nodes behind load balancer and watch tail latency",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for rules engine: heap OOM before CPU pressure. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "memory-bound working set"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "move to larger-memory instances as a short-term fix",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for render farm: network throughput per host capped. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "network bottleneck",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "increase host count to raise aggregate egress",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for stateful matcher: distributed lock wait rises with node count. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "coordination overhead",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "reduce cross-node coordination then scale carefully"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for checkout workers: deploys cause significant capacity dips. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "large-node blast radius",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "split into more smaller workers",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for geo processor: single-thread hot path limits latency. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "per-core performance ceiling"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "use larger/faster cores while planning parallelization",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for notification fanout: bursty arrival every 5 minutes. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "elasticity requirement",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "enable fast horizontal autoscaling",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for anti-fraud service: metadata quorum writes dominate p99. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "control-plane bottleneck",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "decrease node churn and batch control updates"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for preview generator: jobs are independent and queue-backed. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "embarrassingly parallel workload",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "increase worker replicas",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for document parser: RSS climbs with document complexity. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "memory pressure"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "scale up RAM and cap concurrent docs",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for metrics rollup: packet-per-second cap reached. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "host networking limit",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "add ingest nodes and rebalance producers",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for promotion evaluator: cross-shard fanout grew 4x. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "high coordination fanout",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "co-locate related keys before adding nodes"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for invoice calculator: tail spikes tied to stop-the-world pauses. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "single-node pause sensitivity",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "add more nodes to dilute pause impact",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for chat delivery: single node failure removes 18% capacity. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "failure-domain problem"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "increase node count to cut per-node share",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for search suggest: cache no longer fits on current hosts. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "insufficient memory footprint",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "upgrade node memory class",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for stream enrich: queue age rises while CPU on all nodes > 90%. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "compute saturation",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "add workers and enforce backpressure"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for catalog merge: barrier synchronization dominates runtime. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "synchronization overhead",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "reduce barrier frequency before scaling out",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for sensor gateway: connection table maxes out per instance. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "per-host state limit"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "increase node count and shard connections",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for billing export: batch misses SLA by 30%. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "insufficient parallel capacity",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "add temporary worker pool for batch window",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for report precompute: larger instance type available with 2x memory. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "quick vertical relief option",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "scale up now and revisit partitioning"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for live scoreboard: frequent deployment with tight SLOs. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "operational resilience pressure",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that diagnosis, what is the strongest immediate action?",
          "options": [
            "prefer more small nodes for safer rollouts",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for OCR API: CPU fine but memory bandwidth saturated. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter",
            "memory-channel bottleneck"
          ],
          "correct": 3,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given that bottleneck, which scaling action should you take first?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "move to instances with higher memory bandwidth",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 1,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for vector search: coordinator CPU pegs while workers idle. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "central coordination bottleneck",
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 0,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Based on that root cause, what is the best next move now?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "split coordinator role then scale",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 2,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for ad delivery: TLS termination maxes per host. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "frontend host bottleneck",
            "UI thread rendering bottleneck",
            "Certificate renewal jitter"
          ],
          "correct": 1,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "With that diagnosis confirmed, what is the most effective immediate response?",
          "options": [
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work",
            "scale out edge terminators"
          ],
          "correct": 3,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call for compliance scanner: state transfer during failover is too large. What is the best diagnosis to anchor scaling decisions?",
          "options": [
            "DNS cache warmup issue",
            "UI thread rendering bottleneck",
            "heavy per-node state size",
            "Certificate renewal jitter"
          ],
          "correct": 2,
          "explanation": "Scaling decisions should start from the actual limiting resource or coordination pattern, not generic tactics."
        },
        {
          "question": "Given this constraint, which action best restores capacity quickly?",
          "options": [
            "first reduce state size, then re-evaluate strategy",
            "Disable retries globally and accept higher failure rate",
            "Freeze deploys for one month without changing capacity",
            "Only tune log sampling and postpone scaling work"
          ],
          "correct": 0,
          "explanation": "The next action should directly reduce the identified bottleneck while preserving service reliability."
        }
      ]
    },
    {
      "id": "sc-hv-061",
      "type": "multi-select",
      "question": "Which signals justify choosing horizontal scaling first?",
      "options": [
        "Independent request processing and high CPU across nodes",
        "Need lower blast radius per failure",
        "Working set only fits on one very large machine",
        "Bursty demand needing elastic capacity"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-062",
      "type": "multi-select",
      "question": "Which conditions make vertical scaling a reasonable first move?",
      "options": [
        "Memory ceiling is the immediate blocker",
        "Minimal time for architectural change",
        "Hard requirement to reduce single-node risk",
        "Strong single-thread performance is required"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-063",
      "type": "multi-select",
      "question": "Which are common costs of horizontal scaling?",
      "options": [
        "Higher coordination/metadata overhead",
        "More complex partitioning and balancing",
        "Guaranteed lower cloud bill at any scale",
        "Increased operational surface area"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-064",
      "type": "multi-select",
      "question": "Which are key risks of vertical-only strategy over time?",
      "options": [
        "Hitting max instance-size limits",
        "Larger per-node blast radius",
        "Automatic elimination of coordination bugs",
        "Potentially slower recovery/replacement"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-065",
      "type": "multi-select",
      "question": "Which metrics are most useful before deciding between scale up vs out?",
      "options": [
        "Per-resource utilization (CPU/memory/network)",
        "Queue depth and queue age trends",
        "Only daily average request count",
        "Tail latency with concurrency context"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-066",
      "type": "multi-select",
      "question": "For cost modeling of scaling paths, which inputs matter?",
      "options": [
        "Per-node cost by instance class",
        "Coordination overhead as node count rises",
        "Failure and recovery cost assumptions",
        "Only peak QPS without utilization targets"
      ],
      "correctIndices": [
        0,
        1,
        2
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-067",
      "type": "multi-select",
      "question": "Which engineering steps improve horizontal efficiency before adding nodes?",
      "options": [
        "Reduce lock contention hot spots",
        "Improve partition-key distribution",
        "Increase cross-service synchronous fanout",
        "Minimize shared mutable state"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-068",
      "type": "multi-select",
      "question": "Which statements about blast radius are accurate?",
      "options": [
        "More smaller nodes usually reduce per-node impact",
        "One huge node can make failures more severe",
        "Blast radius is unrelated to node size mix",
        "Deployment safety often improves with smaller increments"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-069",
      "type": "multi-select",
      "question": "Which workloads typically benefit from horizontal scaling?",
      "options": [
        "Queue-backed independent jobs",
        "Stateless APIs with uniform requests",
        "Monolithic single-threaded code with shared mutable state",
        "Batch pipelines that can shard by key"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-070",
      "type": "multi-select",
      "question": "Which workloads often require some vertical scaling component?",
      "options": [
        "Large in-memory models requiring high RAM per process",
        "Latency-sensitive single-thread hot loops",
        "Simple stateless request routers only",
        "Workloads constrained by per-process memory bandwidth"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-071",
      "type": "multi-select",
      "question": "Which anti-patterns often hide true scaling bottlenecks?",
      "options": [
        "Scaling blindly on CPU average only",
        "Ignoring queue age and tail latency",
        "Correlating metrics with deployment events",
        "Skipping bottleneck decomposition by resource"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-072",
      "type": "multi-select",
      "question": "When scale-out appears ineffective, which checks are high-value?",
      "options": [
        "Measure cross-node coordination cost",
        "Inspect partition skew and hot keys",
        "Assume DNS is root cause by default",
        "Review shared datastore contention"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-073",
      "type": "multi-select",
      "question": "Which are practical short-term actions during memory-bound incidents?",
      "options": [
        "Move to larger-memory nodes temporarily",
        "Reduce per-request memory footprint",
        "Increase retries to smooth memory spikes",
        "Cap concurrency until headroom returns"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-074",
      "type": "multi-select",
      "question": "Which statements about coordination overhead are true?",
      "options": [
        "It can rise nonlinearly with node count",
        "Global locks can erase scale-out gains",
        "It always decreases when adding nodes",
        "Partition-local work usually scales better"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-075",
      "type": "multi-select",
      "question": "Which are valid reasons to mix vertical and horizontal strategies?",
      "options": [
        "Scale up for immediate relief, then scale out for resilience",
        "Use larger nodes for coordinators and more small workers",
        "Pick one strategy forever regardless of workload changes",
        "Adapt strategy by bottleneck phase and growth stage"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-076",
      "type": "multi-select",
      "question": "Which signals suggest network-bound scaling limits?",
      "options": [
        "Per-host egress plateaus at NIC limit",
        "CPU remains moderate during saturation",
        "OOM kills dominate incidents",
        "Adding hosts raises aggregate throughput"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-077",
      "type": "multi-select",
      "question": "Which guardrails reduce risk while applying scaling changes?",
      "options": [
        "Canary rollout with rollback thresholds",
        "Predefined max node/size limits",
        "Disable alerts during rollout to reduce noise",
        "Post-change metric comparison against baseline"
      ],
      "correctIndices": [
        0,
        1,
        3
      ],
      "explanation": "Correct choices align with bottleneck-driven scaling and operational trade-offs; excluded options are incomplete or misleading."
    },
    {
      "id": "sc-hv-078",
      "type": "numeric-input",
      "question": "Each node handles 1600 QPS at 80% target utilization. Peak target is 14000 QPS. Nodes needed?",
      "answer": 11,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Effective per-node capacity is 1280 QPS. 14000/1280 = 10.94, so 11 nodes."
    },
    {
      "id": "sc-hv-079",
      "type": "numeric-input",
      "question": "Current fleet: 10 nodes at 2200 QPS each. Forecast +40% traffic. Keep 70% utilization. New node count?",
      "answer": 20,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Future peak is 30799.999999999996 QPS. At target utilization each node provides 1540 QPS, so need 20 nodes."
    },
    {
      "id": "sc-hv-080",
      "type": "numeric-input",
      "question": "Option A: 12 small nodes at $0.45/hr. Option B: 5 large nodes at $1.25/hr. Percent increase B vs A?",
      "answer": 15.74,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "A costs 5.40/hr and B costs 6.25/hr. Increase is 15.74%."
    },
    {
      "id": "sc-hv-081",
      "type": "numeric-input",
      "question": "Tier has 24 equal nodes. One node fails and traffic redistributes perfectly. Percent capacity loss?",
      "answer": 4.17,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Losing 1 of 24 equal nodes reduces raw capacity by 1/24 = 4.17%."
    },
    {
      "id": "sc-hv-082",
      "type": "numeric-input",
      "question": "A vertical move doubles per-node memory from 64GB to 128GB. Fleet shrinks from 14 to 8 nodes. Total memory change (%)?",
      "answer": 14.29,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Old total memory 896GB, new 1024GB. Change is 14.29%."
    },
    {
      "id": "sc-hv-083",
      "type": "numeric-input",
      "question": "Autoscaling target is 65% CPU. Each node sustains 3000 QPS at 100% CPU linear assumption. For 39000 QPS peak, nodes needed?",
      "answer": 20,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Per-node safe throughput 1950 QPS. 39000/1950 = 20.00 so 20 nodes."
    },
    {
      "id": "sc-hv-084",
      "type": "numeric-input",
      "question": "A workload needs 9 TB/day egress. Each node safely delivers 350 MB/s average. Minimum nodes required?",
      "answer": 1,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "Each node handles about 30.24 TB/day. Need 1 nodes for 9 TB/day."
    },
    {
      "id": "sc-hv-085",
      "type": "numeric-input",
      "question": "Scale-out plan adds 6 nodes to current 18. By what percent does raw node count increase?",
      "answer": 33.33,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Adding 6 to 18 is a 6/18 = 33.33% increase."
    },
    {
      "id": "sc-hv-086",
      "type": "numeric-input",
      "question": "Single large node costs $2.40/hr. Equivalent capacity uses 7 small nodes at $0.38/hr. Percent cheaper option?",
      "answer": 9.77,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Small-node option costs 2.66/hr. Large node costs 2.40/hr, which is 9.77% cheaper."
    },
    {
      "id": "sc-hv-087",
      "type": "numeric-input",
      "question": "At 30 nodes, coordination overhead consumes 18% CPU. At 45 nodes, 27% CPU. Relative overhead increase (%)?",
      "answer": 50,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "Coordination overhead rose from 18% to 27%, a relative increase of 50.00%."
    },
    {
      "id": "sc-hv-088",
      "type": "numeric-input",
      "question": "Batch job takes 90 min on 12 workers. Assume ideal scaling. Time on 18 workers (minutes)?",
      "answer": 60,
      "unit": "minutes",
      "tolerance": 0.1,
      "explanation": "Under ideal scaling, time is inversely proportional to workers: 90*12/18 = 60 minutes."
    },
    {
      "id": "sc-hv-089",
      "type": "numeric-input",
      "question": "A service currently has 16 nodes with 25% spare headroom. Traffic grows 20%. Additional nodes needed (same size)?",
      "answer": 4,
      "unit": "nodes",
      "tolerance": 0.1,
      "explanation": "With 25% headroom, effective capacity equals 20 node-equivalents. After 20% growth you need 19.2 node-equivalents, so 16 nodes remain sufficient and additional nodes needed is 4."
    },
    {
      "id": "sc-hv-090",
      "type": "ordering",
      "question": "Rank the scaling workflow from first to last.",
      "items": [
        "Identify bottleneck by resource and contention",
        "Choose scale up/out hypothesis and expected impact",
        "Roll out gradually with guardrails",
        "Re-measure SLO and saturation after rollout"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-091",
      "type": "ordering",
      "question": "Rank from lowest to highest coordination overhead.",
      "items": [
        "Independent stateless workers",
        "Partitioned workers with rare cross-shard calls",
        "Workers using frequent distributed locks",
        "Workers requiring global consensus updates"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-092",
      "type": "ordering",
      "question": "Rank from smallest to largest per-node failure blast radius.",
      "items": [
        "24 small nodes",
        "12 medium nodes",
        "6 large nodes",
        "1 very large node"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-093",
      "type": "ordering",
      "question": "Rank from fastest short-term relief to slowest.",
      "items": [
        "Resize to larger instances in same family",
        "Add more replicas with existing topology",
        "Refactor to reduce shared-state contention",
        "Redesign architecture boundaries"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-094",
      "type": "ordering",
      "question": "Rank autoscaling signals from least to most direct for compute saturation.",
      "items": [
        "Daily average traffic",
        "Five-minute average CPU",
        "Queue age and tail latency",
        "Per-resource saturation plus queue age under load"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-095",
      "type": "ordering",
      "question": "Rank interventions from most to least useful when memory is the hard bottleneck.",
      "items": [
        "Increase per-node memory",
        "Reduce per-request memory footprint",
        "Improve partitioning to lower duplication",
        "Only increase retries"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-096",
      "type": "ordering",
      "question": "Rank decision quality from weakest to strongest.",
      "items": [
        "Choose strategy from team preference only",
        "Choose from average CPU alone",
        "Choose from multi-metric bottleneck analysis",
        "Choose from bottleneck analysis plus canary validation"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-097",
      "type": "ordering",
      "question": "Rank from least to most resilient deployment pattern.",
      "items": [
        "Single large node replacement",
        "Few large nodes with long drains",
        "Moderate node pool with canary",
        "Many small nodes with progressive rollout"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-098",
      "type": "ordering",
      "question": "Rank from least to most scalable for burst handling.",
      "items": [
        "Fixed-size vertical-only fleet",
        "Vertical scale plus manual adds",
        "Horizontal autoscaling by CPU only",
        "Horizontal autoscaling by CPU and queue age"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-099",
      "type": "ordering",
      "question": "Rank from lowest to highest operational complexity.",
      "items": [
        "Single pool of homogeneous nodes",
        "Two pools split by workload class",
        "Multi-pool with custom schedulers",
        "Global multi-region compute with per-region policies"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    },
    {
      "id": "sc-hv-100",
      "type": "ordering",
      "question": "Rank from worst to best incident response sequence.",
      "items": [
        "Scale randomly and hope",
        "Scale first then inspect metrics",
        "Diagnose bottleneck then scale",
        "Diagnose, scale with guardrails, verify outcome"
      ],
      "correctOrder": [
        0,
        1,
        2,
        3
      ],
      "explanation": "The ordering reflects a bottleneck-first approach and reliability-aware scaling practice."
    }
  ]
}
