{
  "unit": 1,
  "unitTitle": "Estimation",
  "chapter": 3,
  "chapterTitle": "Storage Math",
  "chapterDescription": "User data to bytes, bytes to disks, retention policies, replication",
  "problems": [
    {
      "id": "storage-001",
      "type": "multiple-choice",
      "question": "You store 1KB per user action. Users average 20 actions/day. You have 1 million DAU. How much new storage per day?",
      "options": ["~200 MB", "~2 GB", "~20 GB", "~200 GB"],
      "correct": 2,
      "explanation": "1KB × 20 actions × 1M users = 20 billion bytes = 20 GB per day.",
      "detailedExplanation": "The key clue in this question is \"you store 1KB per user action\". Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 1KB and 20 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-002",
      "type": "multiple-choice",
      "question": "A user profile has: username (50 bytes), email (100 bytes), bio (500 bytes), timestamps (16 bytes). Size for 10 million users?",
      "options": ["~670 MB", "~6.7 GB", "~67 GB", "~670 GB"],
      "correct": 1,
      "explanation": "50 + 100 + 500 + 16 = 666 bytes per user. 666 × 10M = 6.66 GB.",
      "detailedExplanation": "Read this as a scenario about \"user profile has: username (50 bytes), email (100 bytes), bio (500 bytes), timestamps\". Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 50 and 100 in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-003",
      "type": "multiple-choice",
      "question": "You keep 90 days of logs. Daily log volume is 50 GB. Total storage needed?",
      "options": ["~450 GB", "~4.5 TB", "~45 TB", "~450 TB"],
      "correct": 1,
      "explanation": "90 days × 50 GB = 4,500 GB = 4.5 TB.",
      "detailedExplanation": "The decision turns on \"you keep 90 days of logs\". Eliminate options that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. If values like 90 days and 50 GB appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-004",
      "type": "multiple-choice",
      "question": "Your database uses 3× replication. Primary data is 500 GB. Total storage with replicas?",
      "options": ["~500 GB", "~1 TB", "~1.5 TB", "~2 TB"],
      "correct": 2,
      "explanation": "3× replication means 3 copies total. 500 GB × 3 = 1.5 TB.",
      "detailedExplanation": "This prompt is really about \"your database uses 3× replication\". Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 3 and 500 GB appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-005",
      "type": "multiple-choice",
      "question": "A tweet is ~300 bytes. Twitter has 500 million tweets/day. Daily tweet storage?",
      "options": ["~15 GB", "~150 GB", "~1.5 TB", "~15 TB"],
      "correct": 1,
      "explanation": "300 bytes × 500M = 150 billion bytes = 150 GB per day.",
      "detailedExplanation": "Use \"tweet is ~300 bytes\" as your starting point, then verify tradeoffs carefully. Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 300 and 500 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-006",
      "type": "multiple-choice",
      "question": "You compress logs at 10:1 ratio. Uncompressed daily logs are 100 GB. Compressed storage for 30 days?",
      "options": ["~30 GB", "~300 GB", "~3 TB", "~30 TB"],
      "correct": 1,
      "explanation": "100 GB ÷ 10 = 10 GB compressed per day. 10 GB × 30 = 300 GB.",
      "detailedExplanation": "The core signal here is \"you compress logs at 10:1 ratio\". Prefer the choice that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. If values like 10 and 1 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-007",
      "type": "multiple-choice",
      "question": "An image thumbnail is 10 KB. You have 100 million images. Thumbnail storage?",
      "options": ["~100 GB", "~1 TB", "~10 TB", "~100 TB"],
      "correct": 1,
      "explanation": "10 KB × 100M = 1,000 GB = 1 TB.",
      "detailedExplanation": "If you keep \"image thumbnail is 10 KB\" in view, the correct answer separates faster. Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 10 KB and 100 in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-008",
      "type": "multiple-choice",
      "question": "Your index is 20% the size of your data. Data is 500 GB. Total storage (data + index)?",
      "options": ["~520 GB", "~600 GB", "~700 GB", "~1 TB"],
      "correct": 1,
      "explanation": "Index = 500 × 0.2 = 100 GB. Total = 500 + 100 = 600 GB.",
      "detailedExplanation": "Start from \"your index is 20% the size of your data\", then pressure-test the result against the options. Reject options that conflict with the primary access pattern or index strategy. Schema and index choices should follow access patterns and write/read amplification constraints. Keep quantities like 20 and 500 GB in aligned units before selecting an answer. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-009",
      "type": "multiple-choice",
      "question": "A video is 1 GB per hour at 1080p. Users upload 10,000 hours of video daily. Daily upload storage?",
      "options": ["~1 TB", "~10 TB", "~100 TB", "~1 PB"],
      "correct": 1,
      "explanation": "1 GB × 10,000 hours = 10,000 GB = 10 TB per day.",
      "detailedExplanation": "The key clue in this question is \"video is 1 GB per hour at 1080p\". Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 1 GB and 10,000 hours in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-010",
      "type": "multiple-choice",
      "question": "You shard by user_id across 16 shards. Total data is 1.6 TB. Average per shard (assuming even distribution)?",
      "options": ["~10 GB", "~100 GB", "~160 GB", "~1 TB"],
      "correct": 1,
      "explanation": "1.6 TB ÷ 16 shards = 100 GB per shard.",
      "detailedExplanation": "The decision turns on \"you shard by user_id across 16 shards\". Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 16 and 1.6 TB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-011",
      "type": "multiple-choice",
      "question": "A chat message averages 200 bytes. Users send 50 messages/day. 10 million DAU. Daily message storage?",
      "options": ["~10 GB", "~100 GB", "~1 TB", "~10 TB"],
      "correct": 1,
      "explanation": "200 bytes × 50 msgs × 10M users = 100 billion bytes = 100 GB.",
      "detailedExplanation": "Read this as a scenario about \"chat message averages 200 bytes\". Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 200 and 50 in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-012",
      "type": "multiple-choice",
      "question": "Your SSD gives 500 MB/s sequential read. Time to read 1 TB?",
      "options": ["~3 minutes", "~33 minutes", "~3.3 hours", "~33 hours"],
      "correct": 1,
      "explanation": "1 TB = 1,000,000 MB. 1,000,000 ÷ 500 = 2,000 seconds = 33.3 minutes.",
      "detailedExplanation": "The key clue in this question is \"your SSD gives 500 MB/s sequential read\". Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 500 MB and 1 TB in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-013",
      "type": "multiple-choice",
      "question": "A database row has 5 columns averaging 50 bytes each, plus 50 bytes overhead. 100 million rows. Table size?",
      "options": ["~3 GB", "~30 GB", "~300 GB", "~3 TB"],
      "correct": 1,
      "explanation": "(5 × 50) + 50 = 300 bytes per row. 300 × 100M = 30 GB.",
      "detailedExplanation": "Start from \"database row has 5 columns averaging 50 bytes each, plus 50 bytes overhead\", then pressure-test the result against the options. Discard modeling choices that look clean but perform poorly for the target queries. Schema and index choices should follow access patterns and write/read amplification constraints. Numbers such as 5 and 50 should be normalized first so downstream reasoning stays consistent. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-014",
      "type": "multiple-choice",
      "question": "You retain data for 2 years. Growth is 100 GB/month. Steady-state storage after retention kicks in?",
      "options": ["~240 GB", "~1.2 TB", "~2.4 TB", "~12 TB"],
      "correct": 2,
      "explanation": "2 years = 24 months. 100 GB × 24 = 2.4 TB at steady state.",
      "detailedExplanation": "If you keep \"you retain data for 2 years\" in view, the correct answer separates faster. Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 2 and 100 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "storage-015",
      "type": "multiple-choice",
      "question": "An emoji reaction is 20 bytes (user_id + post_id + emoji_id + timestamp). 1 billion reactions/day. Daily storage?",
      "options": ["~2 GB", "~20 GB", "~200 GB", "~2 TB"],
      "correct": 1,
      "explanation": "20 bytes × 1B = 20 billion bytes = 20 GB.",
      "detailedExplanation": "The core signal here is \"emoji reaction is 20 bytes (user_id + post_id + emoji_id + timestamp)\". Prefer the choice that fits durability and cost requirements for the workload shape. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 20 and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-016",
      "type": "multiple-choice",
      "question": "Your CDN caches the top 10% of content. Total content is 50 TB. CDN cache size needed?",
      "options": ["~500 GB", "~5 TB", "~50 TB", "~500 TB"],
      "correct": 1,
      "explanation": "10% of 50 TB = 5 TB.",
      "detailedExplanation": "Use \"your CDN caches the top 10% of content\" as your starting point, then verify tradeoffs carefully. Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. Keep quantities like 10 and 50 TB in aligned units before selecting an answer. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-017",
      "type": "multiple-choice",
      "question": "A JSON API response averages 5 KB. You cache 1 million responses. Cache memory needed?",
      "options": ["~500 MB", "~5 GB", "~50 GB", "~500 GB"],
      "correct": 1,
      "explanation": "5 KB × 1M = 5 GB.",
      "detailedExplanation": "This prompt is really about \"jSON API response averages 5 KB\". Prefer the choice that keeps client behavior explicit while preserving evolvability. Prioritize explicit semantics and upgrade safety, not just short-term convenience. If values like 5 KB and 1 appear, convert them into one unit basis before comparison. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-018",
      "type": "multiple-choice",
      "question": "You store UUIDs (16 bytes) as primary keys instead of auto-increment integers (8 bytes). 1 billion rows. Extra storage?",
      "options": ["~800 MB", "~8 GB", "~80 GB", "~800 GB"],
      "correct": 1,
      "explanation": "Extra = 16 - 8 = 8 bytes per row. 8 × 1B = 8 GB extra.",
      "detailedExplanation": "The decision turns on \"you store UUIDs (16 bytes) as primary keys instead of auto-increment integers (8 bytes)\". Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 16 and 8 in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-019",
      "type": "multiple-choice",
      "question": "A user uploads a 5 MB photo. You store original + 3 resized versions (500 KB, 100 KB, 10 KB). Total per photo?",
      "options": ["~5.1 MB", "~5.6 MB", "~6.1 MB", "~20 MB"],
      "correct": 1,
      "explanation": "5 MB + 0.5 + 0.1 + 0.01 = 5.61 MB per photo.",
      "detailedExplanation": "Read this as a scenario about \"user uploads a 5 MB photo\". Prefer the choice that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. If values like 5 MB and 3 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-020",
      "type": "multiple-choice",
      "question": "Your database has 400 GB of data and is 80% full. You want to stay under 70% utilization. How much total capacity should you provision?",
      "options": ["~500 GB", "~570 GB", "~715 GB", "~800 GB"],
      "correct": 1,
      "explanation": "You have 400 GB of data. For 70% utilization: 400 ÷ 0.7 = 571 GB capacity needed.",
      "detailedExplanation": "Read this as a scenario about \"your database has 400 GB of data and is 80% full\". Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 400 GB and 80 in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-021",
      "type": "multiple-choice",
      "question": "A Kafka topic has 3 partitions, replication factor 3, retention 7 days. Daily ingest is 10 GB. Total storage?",
      "options": ["~70 GB", "~210 GB", "~630 GB", "~1.9 TB"],
      "correct": 1,
      "explanation": "7 days × 10 GB = 70 GB retained. RF 3 = 70 × 3 = 210 GB. Partitions don't multiply storage (they divide the data).",
      "detailedExplanation": "The decision turns on \"kafka topic has 3 partitions, replication factor 3, retention 7 days\". Reject designs that improve throughput while weakening reliability guarantees. A good message-system answer defines guarantees clearly for both producer and consumer paths. Numbers such as 3 and 7 days should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-022",
      "type": "multiple-choice",
      "question": "You store time-series metrics: 8-byte timestamp + 8-byte value. 1 million metrics, sampled every 10 seconds. Daily storage?",
      "options": ["~14 GB", "~140 GB", "~1.4 TB", "~14 TB"],
      "correct": 1,
      "explanation": "Samples per day = 86,400 ÷ 10 = 8,640. Per metric = 8,640 × 16 bytes = 138 KB. Total = 138 KB × 1M = 138 GB ≈ 140 GB.",
      "detailedExplanation": "Start from \"you store time-series metrics: 8-byte timestamp + 8-byte value\", then pressure-test the result against the options. Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 8 and 1 in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-023",
      "type": "multiple-choice",
      "question": "An analytics event is 500 bytes. 100 million events/day. 90-day retention. Total storage?",
      "options": ["~450 GB", "~4.5 TB", "~45 TB", "~450 TB"],
      "correct": 1,
      "explanation": "Daily = 500 × 100M = 50 GB. 90 days = 50 × 90 = 4,500 GB = 4.5 TB.",
      "detailedExplanation": "The key clue in this question is \"analytics event is 500 bytes\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Numbers such as 500 and 100 should be normalized first so downstream reasoning stays consistent. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-024",
      "type": "multiple-choice",
      "question": "Your blob storage costs $0.02/GB/month. You store 100 TB. Monthly cost?",
      "options": ["~$200", "~$2,000", "~$20,000", "~$200,000"],
      "correct": 1,
      "explanation": "100 TB = 100,000 GB. $0.02 × 100,000 = $2,000/month.",
      "detailedExplanation": "The core signal here is \"your blob storage costs $0\". Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 0.02 and 100 TB in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-025",
      "type": "multiple-choice",
      "question": "PostgreSQL TOAST threshold is 2 KB. You have a 10 KB JSON column. How much is stored out-of-line?",
      "options": ["~2 KB", "~8 KB", "~10 KB", "Depends on compression"],
      "correct": 3,
      "explanation": "TOAST compresses first, then stores out-of-line if still > 2KB. Actual out-of-line size depends on how compressible the JSON is.",
      "detailedExplanation": "If you keep \"postgreSQL TOAST threshold is 2 KB\" in view, the correct answer separates faster. Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 2 KB and 10 KB in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-026",
      "type": "multiple-choice",
      "question": "A B-tree index on a 8-byte column with 100 million rows. Approximate index size? (Assume ~15 bytes per entry with overhead)",
      "options": ["~150 MB", "~1.5 GB", "~15 GB", "~150 GB"],
      "correct": 1,
      "explanation": "15 bytes × 100M = 1.5 GB for the index.",
      "detailedExplanation": "This prompt is really about \"b-tree index on a 8-byte column with 100 million rows\". Reject options that conflict with the primary access pattern or index strategy. Schema and index choices should follow access patterns and write/read amplification constraints. Keep quantities like 8 and 100 in aligned units before selecting an answer. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-027",
      "type": "multiple-choice",
      "question": "You move from VARCHAR(255) to VARCHAR(50) on a column that actually stores 20-char strings. Space saved per row?",
      "options": ["0 bytes", "~30 bytes", "~205 bytes", "~235 bytes"],
      "correct": 0,
      "explanation": "VARCHAR stores actual length, not declared max. If strings are 20 chars, storage is the same regardless of VARCHAR limit.",
      "detailedExplanation": "Use \"you move from VARCHAR(255) to VARCHAR(50) on a column that actually stores 20-char\" as your starting point, then verify tradeoffs carefully. Prefer the choice that fits durability and cost requirements for the workload shape. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 255 and 50 in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-028",
      "type": "multiple-choice",
      "question": "Audio at 128 kbps. How much storage for 1 million 3-minute songs?",
      "options": ["~2.9 TB", "~29 TB", "~290 TB", "~2.9 PB"],
      "correct": 0,
      "explanation": "128 kbps × 180 sec = 23,040 Kb = 2.88 MB per song. 2.88 MB × 1M = 2.88 TB.",
      "detailedExplanation": "Read this as a scenario about \"audio at 128 kbps\". Prefer the choice that fits durability and cost requirements for the workload shape. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 128 and 1 in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-029",
      "type": "multiple-choice",
      "question": "Your write-ahead log (WAL) retains 1 hour of writes. Write rate is 10 MB/s. WAL storage needed?",
      "options": ["~3.6 GB", "~36 GB", "~360 GB", "~3.6 TB"],
      "correct": 1,
      "explanation": "10 MB/s × 3,600 sec = 36,000 MB = 36 GB.",
      "detailedExplanation": "The decision turns on \"your write-ahead log (WAL) retains 1 hour of writes\". Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 1 hour and 10 MB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-030",
      "type": "multiple-choice",
      "question": "You denormalize and store user_name (50 bytes) in each of 1 billion order rows instead of joining. Extra storage?",
      "options": ["~5 GB", "~50 GB", "~500 GB", "~5 TB"],
      "correct": 1,
      "explanation": "50 bytes × 1B = 50 GB extra storage for the denormalized field.",
      "detailedExplanation": "Use \"you denormalize and store user_name (50 bytes) in each of 1 billion order rows instead\" as your starting point, then verify tradeoffs carefully. Prefer the choice that fits durability and cost requirements for the workload shape. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 50 and 1 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-031",
      "type": "multiple-choice",
      "question": "An HDD has 10 TB capacity, 100 MB/s throughput. An SSD has 1 TB capacity, 500 MB/s throughput. For 5 TB data with random reads, which needs fewer drives?",
      "options": [
        "HDD (1 drive)",
        "SSD (5 drives)",
        "Same number",
        "Depends on read pattern"
      ],
      "correct": 1,
      "explanation": "HDD: 1 drive fits 5 TB. SSD: need 5 drives for capacity. But for random reads, SSDs are ~100x faster. The question says 'random reads' so SSD wins on performance, but needs more drives for capacity.",
      "detailedExplanation": "This prompt is really about \"hDD has 10 TB capacity, 100 MB/s throughput\". Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 10 TB and 100 MB in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-032",
      "type": "multiple-choice",
      "question": "You add a secondary index on a 500 GB table. Index is estimated at 50 GB. During creation, temporary space needed?",
      "options": ["~50 GB", "~100 GB", "~500 GB", "Varies by database"],
      "correct": 3,
      "explanation": "Different databases handle index creation differently. Some need 2× index size, some need table size, some do it incrementally. Always check your specific database.",
      "detailedExplanation": "If you keep \"you add a secondary index on a 500 GB table\" in view, the correct answer separates faster. Prefer the schema/index decision that minimizes query and write amplification for this workload. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Keep quantities like 500 GB and 50 GB in aligned units before selecting an answer. Common pitfall: indexing that over-amplifies writes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-033",
      "type": "multiple-choice",
      "question": "RAID 10 with 4 × 1 TB drives. Usable capacity?",
      "options": ["~1 TB", "~2 TB", "~3 TB", "~4 TB"],
      "correct": 1,
      "explanation": "RAID 10 mirrors then stripes. 4 drives give 50% usable capacity. 4 TB × 0.5 = 2 TB.",
      "detailedExplanation": "The core signal here is \"rAID 10 with 4 × 1 TB drives\". Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 10 and 4 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-034",
      "type": "multiple-choice",
      "question": "RAID 5 with 4 × 1 TB drives. Usable capacity?",
      "options": ["~1 TB", "~2 TB", "~3 TB", "~4 TB"],
      "correct": 2,
      "explanation": "RAID 5 loses 1 drive to parity. 4 - 1 = 3 TB usable.",
      "detailedExplanation": "The key clue in this question is \"rAID 5 with 4 × 1 TB drives\". Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 5 and 4 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-035",
      "type": "multiple-choice",
      "question": "S3 charges $0.005/1000 GET requests. You serve 100 million image requests/day. Monthly GET cost?",
      "options": ["~$150", "~$1,500", "~$15,000", "~$150,000"],
      "correct": 2,
      "explanation": "100M/day × 30 = 3B requests/month. 3B ÷ 1000 × $0.005 = $15,000.",
      "detailedExplanation": "Start from \"s3 charges $0\", then pressure-test the result against the options. Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 0.005 and 1000 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-036",
      "type": "multiple-choice",
      "question": "You store embeddings: 1536 floats (4 bytes each) per vector. 10 million vectors. Storage needed?",
      "options": ["~6.1 GB", "~61 GB", "~610 GB", "~6.1 TB"],
      "correct": 1,
      "explanation": "1536 × 4 = 6,144 bytes per vector. 6,144 × 10M = 61.4 GB.",
      "detailedExplanation": "The decision turns on \"you store embeddings: 1536 floats (4 bytes each) per vector\". Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 1536 and 4 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-037",
      "type": "multiple-choice",
      "question": "Your hot data (last 30 days) is 500 GB. Cold data (older) is 10 TB. You move cold to cheaper storage at $0.004/GB/mo vs $0.02/GB/mo. Monthly savings?",
      "options": ["~$16", "~$160", "~$1,600", "~$16,000"],
      "correct": 1,
      "explanation": "Savings per GB = $0.02 - $0.004 = $0.016. 10,000 GB × $0.016 = $160/month.",
      "detailedExplanation": "Read this as a scenario about \"your hot data (last 30 days) is 500 GB\". Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. If values like 30 days and 500 GB appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-038",
      "type": "multiple-choice",
      "question": "A microservice checkpoint is 100 MB. You keep last 10 checkpoints per instance. 50 instances. Checkpoint storage?",
      "options": ["~5 GB", "~50 GB", "~500 GB", "~5 TB"],
      "correct": 1,
      "explanation": "100 MB × 10 × 50 = 50,000 MB = 50 GB.",
      "detailedExplanation": "Use \"microservice checkpoint is 100 MB\" as your starting point, then verify tradeoffs carefully. Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 100 MB and 10 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-039",
      "type": "multiple-choice",
      "question": "You store geolocation: lat (8 bytes) + lng (8 bytes) + timestamp (8 bytes) + user_id (8 bytes). 1 location/minute per user, 100K active users, 30-day retention. Storage?",
      "options": ["~14 GB", "~140 GB", "~1.4 TB", "~14 TB"],
      "correct": 1,
      "explanation": "32 bytes × 1440 min/day × 30 days × 100K = 32 × 43.2M × 100K = 138 GB ≈ 140 GB.",
      "detailedExplanation": "This prompt is really about \"you store geolocation: lat (8 bytes) + lng (8 bytes) + timestamp (8 bytes) + user_id (8\". Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 8 and 1 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-040",
      "type": "multiple-choice",
      "question": "Your full backup is 1 TB. Daily incrementals are 50 GB. Weekly fulls + daily incrementals, 4-week retention. Total backup storage?",
      "options": ["~4 TB", "~5.2 TB", "~6.4 TB", "~11.4 TB"],
      "correct": 1,
      "explanation": "4 weekly fulls = 4 TB. Each week has 6 daily incrementals (one full + 6 incrementals = 7 days). 4 weeks × 6 × 50 GB = 1.2 TB of incrementals. Total = 4 + 1.2 = 5.2 TB.",
      "detailedExplanation": "This prompt is really about \"your full backup is 1 TB\". Discard storage decisions that optimize one dimension while violating another core requirement. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 1 TB and 50 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-041",
      "type": "multiple-choice",
      "question": "A document search index is typically 30-50% of source data size. Your documents are 100 GB. Elasticsearch storage needed?",
      "options": ["~30-50 GB", "~100 GB", "~130-150 GB", "~200-300 GB"],
      "correct": 2,
      "explanation": "You store both source (100 GB) and index (30-50 GB). Total = 130-150 GB.",
      "detailedExplanation": "Use \"document search index is typically 30-50% of source data size\" as your starting point, then verify tradeoffs carefully. Discard modeling choices that look clean but perform poorly for the target queries. Schema and index choices should follow access patterns and write/read amplification constraints. Keep quantities like 30 and 50 in aligned units before selecting an answer. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-042",
      "type": "multiple-choice",
      "question": "You enable soft deletes (add deleted_at column, 8 bytes). Table has 500 million rows, 10% are deleted but retained. Storage overhead?",
      "options": ["~400 MB", "~4 GB", "~40 GB", "~400 GB"],
      "correct": 1,
      "explanation": "Overhead = 8 bytes × 500M rows = 4 GB. (All rows get the column, not just deleted ones.)",
      "detailedExplanation": "The core signal here is \"you enable soft deletes (add deleted_at column, 8 bytes)\". Prefer the schema/index decision that minimizes query and write amplification for this workload. Schema and index choices should follow access patterns and write/read amplification constraints. Numbers such as 8 and 500 should be normalized first so downstream reasoning stays consistent. Common pitfall: indexing that over-amplifies writes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-043",
      "type": "multiple-choice",
      "question": "A graph database stores: node (100 bytes) + 10 edges per node (50 bytes each). 10 million nodes. Storage?",
      "options": ["~600 MB", "~6 GB", "~60 GB", "~600 GB"],
      "correct": 1,
      "explanation": "Per node: 100 + (10 × 50) = 600 bytes. 600 × 10M = 6 GB.",
      "detailedExplanation": "If you keep \"graph database stores: node (100 bytes) + 10 edges per node (50 bytes each)\" in view, the correct answer separates faster. Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 100 and 10 should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-044",
      "type": "multiple-choice",
      "question": "You switch from storing timestamps as strings (20 bytes) to epoch integers (8 bytes). Table has 1 billion rows with 3 timestamp columns. Space saved?",
      "options": ["~3.6 GB", "~36 GB", "~360 GB", "~3.6 TB"],
      "correct": 1,
      "explanation": "Savings per timestamp = 20 - 8 = 12 bytes. 12 × 3 × 1B = 36 GB.",
      "detailedExplanation": "Start from \"you switch from storing timestamps as strings (20 bytes) to epoch integers (8 bytes)\", then pressure-test the result against the options. Reject options that conflict with the primary access pattern or index strategy. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Keep quantities like 20 and 8 in aligned units before selecting an answer. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-045",
      "type": "multiple-choice",
      "question": "Your Redis cache uses 32 GB RAM. Keys average 50 bytes, values 200 bytes. Approximate number of entries?",
      "options": ["~12 million", "~64 million", "~128 million", "~256 million"],
      "correct": 2,
      "explanation": "With Redis overhead (~50-100 bytes per entry), estimate ~300 bytes total per entry. 32 GB ÷ 300 bytes ≈ 107M. Closest is ~128M (actual depends on data types).",
      "detailedExplanation": "The key clue in this question is \"your Redis cache uses 32 GB RAM\". Discard cache tactics that hide consistency bugs under high load. Cache design quality is mostly about correctness boundaries, not only hit rate. Numbers such as 32 GB and 50 should be normalized first so downstream reasoning stays consistent. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-046",
      "type": "multiple-choice",
      "question": "You partition by month. Each partition is 100 GB. You keep 24 months. Adding a new month, dropping oldest. Steady-state storage?",
      "options": ["~100 GB", "~1.2 TB", "~2.4 TB", "~4.8 TB"],
      "correct": 2,
      "explanation": "24 months × 100 GB = 2.4 TB steady state.",
      "detailedExplanation": "Read this as a scenario about \"you partition by month\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. Throughput is only one part; replay behavior and consumer lag handling matter equally. If values like 100 GB and 24 appear, convert them into one unit basis before comparison. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-047",
      "type": "multiple-choice",
      "question": "A page view event: session_id (36 bytes), url (200 bytes avg), timestamp (8 bytes), user_agent (150 bytes avg). 50 million page views/day. Daily storage?",
      "options": ["~2 GB", "~20 GB", "~200 GB", "~2 TB"],
      "correct": 1,
      "explanation": "36 + 200 + 8 + 150 = 394 bytes. 394 × 50M = 19.7 GB ≈ 20 GB.",
      "detailedExplanation": "The decision turns on \"page view event: session_id (36 bytes), url (200 bytes avg), timestamp (8 bytes),\". Reject designs that improve throughput while weakening reliability guarantees. Throughput is only one part; replay behavior and consumer lag handling matter equally. Numbers such as 36 and 200 should be normalized first so downstream reasoning stays consistent. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-048",
      "type": "multiple-choice",
      "question": "You add table compression with 2:1 ratio. Table is 800 GB. After compression?",
      "options": ["~200 GB", "~400 GB", "~600 GB", "~800 GB"],
      "correct": 1,
      "explanation": "2:1 compression = half the size. 800 ÷ 2 = 400 GB.",
      "detailedExplanation": "This prompt is really about \"you add table compression with 2:1 ratio\". Reject options that conflict with the primary access pattern or index strategy. Choose data shape based on workload paths, not on normalization dogma alone. If values like 2 and 1 appear, convert them into one unit basis before comparison. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-049",
      "type": "multiple-choice",
      "question": "Your blob store has 1 million objects averaging 1 MB. Each object has 1 KB of metadata. Metadata storage overhead?",
      "options": ["~100 MB", "~1 GB", "~10 GB", "~100 GB"],
      "correct": 1,
      "explanation": "1 KB × 1M = 1 GB of metadata.",
      "detailedExplanation": "Use \"your blob store has 1 million objects averaging 1 MB\" as your starting point, then verify tradeoffs carefully. Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 1 and 1 MB in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-050",
      "type": "multiple-choice",
      "question": "An audit log row: timestamp (8), user_id (8), action (50), resource_id (8), old_value (500), new_value (500). 1 million changes/day, 7 year retention. Total storage?",
      "options": ["~275 GB", "~2.75 TB", "~27.5 TB", "~275 TB"],
      "correct": 1,
      "explanation": "Row = 8+8+50+8+500+500 = 1,074 bytes ≈ 1 KB. 1 KB × 1M × 365 × 7 = 2.55 TB ≈ 2.75 TB.",
      "detailedExplanation": "If you keep \"audit log row: timestamp (8), user_id (8), action (50), resource_id (8), old_value\" in view, the correct answer separates faster. Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. If values like 8 and 50 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-051",
      "type": "multiple-choice",
      "question": "You store 4K video at 20 Mbps. How much storage per hour of video?",
      "options": ["~2.5 GB", "~9 GB", "~25 GB", "~90 GB"],
      "correct": 1,
      "explanation": "20 Mbps × 3,600 sec = 72,000 Mb = 9,000 MB = 9 GB per hour.",
      "detailedExplanation": "The core signal here is \"you store 4K video at 20 Mbps\". Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 4K and 20 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-052",
      "type": "multiple-choice",
      "question": "Your database VACUUM reclaims 20% dead tuples on a 1 TB table. Approximate space reclaimed?",
      "options": ["~20 GB", "~200 GB", "~2 GB", "Depends on fill factor"],
      "correct": 1,
      "explanation": "20% of 1 TB = 200 GB potentially reclaimable (actual reclaim depends on implementation).",
      "detailedExplanation": "Use \"your database VACUUM reclaims 20% dead tuples on a 1 TB table\" as your starting point, then verify tradeoffs carefully. Reject options that conflict with the primary access pattern or index strategy. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Numbers such as 20 and 1 TB should be normalized first so downstream reasoning stays consistent. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-053",
      "type": "multiple-choice",
      "question": "You store feature flags: flag_name (50 bytes), enabled (1 byte), updated_at (8 bytes), rules JSON (1 KB avg). 10,000 flags. Total storage?",
      "options": ["~1 MB", "~10 MB", "~100 MB", "~1 GB"],
      "correct": 1,
      "explanation": "Per flag: 50 + 1 + 8 + 1024 ≈ 1,083 bytes ≈ 1 KB. 1 KB × 10K = 10 MB.",
      "detailedExplanation": "This prompt is really about \"you store feature flags: flag_name (50 bytes), enabled (1 byte), updated_at (8 bytes),\". Prefer the choice that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. If values like 50 and 1 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-054",
      "type": "multiple-choice",
      "question": "An ML model checkpoint is 500 MB. You keep the last 100 training runs. Storage for model checkpoints?",
      "options": ["~5 GB", "~50 GB", "~500 GB", "~5 TB"],
      "correct": 1,
      "explanation": "500 MB × 100 = 50 GB.",
      "detailedExplanation": "The decision turns on \"mL model checkpoint is 500 MB\". Prefer the choice that fits durability and cost requirements for the workload shape. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 500 MB and 100 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-055",
      "type": "multiple-choice",
      "question": "You change primary key from INT (4 bytes) to BIGINT (8 bytes). Foreign keys in 5 other tables reference it, totaling 2 billion foreign key entries. Extra storage?",
      "options": ["~800 MB", "~8 GB", "~80 GB", "~800 GB"],
      "correct": 1,
      "explanation": "Extra per FK = 4 bytes. 4 × 2B = 8 GB extra. (Plus the PK table itself, but that's smaller.)",
      "detailedExplanation": "Read this as a scenario about \"you change primary key from INT (4 bytes) to BIGINT (8 bytes)\". Prefer the schema/index decision that minimizes query and write amplification for this workload. Schema and index choices should follow access patterns and write/read amplification constraints. If values like 4 and 8 appear, convert them into one unit basis before comparison. Common pitfall: indexing that over-amplifies writes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-056",
      "type": "multiple-choice",
      "question": "Your CDC (change data capture) stream captures all table changes. Table has 10,000 writes/sec, avg change size 500 bytes. Hourly CDC storage?",
      "options": ["~1.8 GB", "~18 GB", "~180 GB", "~1.8 TB"],
      "correct": 1,
      "explanation": "10,000 × 500 × 3,600 = 18 billion bytes = 18 GB per hour.",
      "detailedExplanation": "The key clue in this question is \"your CDC (change data capture) stream captures all table changes\". Eliminate options that ignore delivery semantics or backpressure behavior. Throughput is only one part; replay behavior and consumer lag handling matter equally. Keep quantities like 10,000 and 500 in aligned units before selecting an answer. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-057",
      "type": "multiple-choice",
      "question": "A user's friend list stores user_id pairs (8 bytes each = 16 bytes per friendship). Average 200 friends per user, 100 million users. Storage?",
      "options": ["~16 GB", "~160 GB", "~1.6 TB", "~16 TB"],
      "correct": 1,
      "explanation": "Friendships = 100M × 200 ÷ 2 (bidirectional counted once) = 10B. 16 bytes × 10B = 160 GB.",
      "detailedExplanation": "Start from \"user's friend list stores user_id pairs (8 bytes each = 16 bytes per friendship)\", then pressure-test the result against the options. Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 8 and 16 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-058",
      "type": "multiple-choice",
      "question": "You enable point-in-time recovery with 24-hour retention. Write rate creates 50 GB of WAL/day. PITR storage overhead?",
      "options": ["~25 GB", "~50 GB", "~100 GB", "~150 GB"],
      "correct": 1,
      "explanation": "24-hour retention of WAL = 50 GB (you retain one day of changes).",
      "detailedExplanation": "If you keep \"you enable point-in-time recovery with 24-hour retention\" in view, the correct answer separates faster. Prioritize the option that best protects the reliability objective under the stated failure conditions. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. If values like 24 and 50 GB appear, convert them into one unit basis before comparison. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-059",
      "type": "multiple-choice",
      "question": "Your columnar database compresses an integer column (1 billion values, mostly sequential) from 8 bytes to 0.5 bytes via delta encoding. Space saved?",
      "options": ["~750 MB", "~7.5 GB", "~75 GB", "~750 GB"],
      "correct": 1,
      "explanation": "Original = 8 × 1B = 8 GB. Compressed = 0.5 × 1B = 0.5 GB. Saved = 7.5 GB.",
      "detailedExplanation": "The core signal here is \"your columnar database compresses an integer column (1 billion values, mostly\". Eliminate options that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 1 and 8 in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-060",
      "type": "multiple-choice",
      "question": "You store sessions: session_id (16 bytes), user_id (8), data (2 KB avg), expires_at (8). 1 million concurrent sessions. Storage?",
      "options": ["~200 MB", "~2 GB", "~20 GB", "~200 GB"],
      "correct": 1,
      "explanation": "Per session: 16 + 8 + 2048 + 8 = 2,080 bytes ≈ 2 KB. 2 KB × 1M = 2 GB.",
      "detailedExplanation": "The core signal here is \"you store sessions: session_id (16 bytes), user_id (8), data (2 KB avg), expires_at (8)\". Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 16 and 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-061",
      "type": "multiple-choice",
      "question": "Your S3 bucket has 100 million objects with versioning enabled. Average 3 versions per object, 1 MB average size. Total storage?",
      "options": ["~100 TB", "~300 TB", "~1 PB", "~3 PB"],
      "correct": 1,
      "explanation": "100M objects × 3 versions × 1 MB = 300 TB.",
      "detailedExplanation": "If you keep \"your S3 bucket has 100 million objects with versioning enabled\" in view, the correct answer separates faster. Prefer the choice that fits durability and cost requirements for the workload shape. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 100 and 3 should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-062",
      "type": "multiple-choice",
      "question": "A search query log: query (100 bytes avg), user_id (8), timestamp (8), results_count (4), latency_ms (4). 10 million queries/day, 90-day retention. Storage?",
      "options": ["~11 GB", "~110 GB", "~1.1 TB", "~11 TB"],
      "correct": 1,
      "explanation": "Per query: 100 + 8 + 8 + 4 + 4 = 124 bytes. 124 × 10M × 90 = 111.6 GB ≈ 110 GB.",
      "detailedExplanation": "This prompt is really about \"search query log: query (100 bytes avg), user_id (8), timestamp (8), results_count (4),\". Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 100 and 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-063",
      "type": "multiple-choice",
      "question": "You implement multi-tenancy with tenant_id (8 bytes) added to every table. Total rows across all tables: 5 billion. Overhead?",
      "options": ["~4 GB", "~40 GB", "~400 GB", "~4 TB"],
      "correct": 1,
      "explanation": "8 bytes × 5B = 40 GB.",
      "detailedExplanation": "Use \"you implement multi-tenancy with tenant_id (8 bytes) added to every table\" as your starting point, then verify tradeoffs carefully. Prefer the schema/index decision that minimizes query and write amplification for this workload. Choose data shape based on workload paths, not on normalization dogma alone. If values like 8 and 5 appear, convert them into one unit basis before comparison. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-064",
      "type": "multiple-choice",
      "question": "Your data lake ingests 1 TB/day in Parquet format. Parquet compresses JSON source data 5:1. Original JSON size?",
      "options": ["~200 GB", "~1 TB", "~5 TB", "~25 TB"],
      "correct": 2,
      "explanation": "If Parquet is 1 TB with 5:1 compression, original JSON was 5 TB.",
      "detailedExplanation": "Read this as a scenario about \"your data lake ingests 1 TB/day in Parquet format\". Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 1 TB and 5 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-065",
      "type": "multiple-choice",
      "question": "A bloom filter with 1% false positive rate needs ~10 bits per element. For 100 million elements, bloom filter size?",
      "options": ["~12.5 MB", "~125 MB", "~1.25 GB", "~12.5 GB"],
      "correct": 1,
      "explanation": "10 bits × 100M = 1 billion bits = 125 MB.",
      "detailedExplanation": "The decision turns on \"bloom filter with 1% false positive rate needs ~10 bits per element\". Eliminate options that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 1 and 10 in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-066",
      "type": "multiple-choice",
      "question": "You implement row-level security adding a policy_id (4 bytes) to 10 billion rows. Storage overhead?",
      "options": ["~4 GB", "~40 GB", "~400 GB", "~4 TB"],
      "correct": 1,
      "explanation": "4 bytes × 10B = 40 GB.",
      "detailedExplanation": "Start from \"you implement row-level security adding a policy_id (4 bytes) to 10 billion rows\", then pressure-test the result against the options. Eliminate options that ignore durability, retention, or access-pattern constraints. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 4 and 10 should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-067",
      "type": "multiple-choice",
      "question": "HyperLogLog for cardinality estimation uses 12 KB per counter. You track unique visitors for 1 million pages. Storage?",
      "options": ["~1.2 GB", "~12 GB", "~120 GB", "~1.2 TB"],
      "correct": 1,
      "explanation": "12 KB × 1M = 12 GB.",
      "detailedExplanation": "The key clue in this question is \"hyperLogLog for cardinality estimation uses 12 KB per counter\". Discard modeling choices that look clean but perform poorly for the target queries. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Numbers such as 12 KB and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-068",
      "type": "multiple-choice",
      "question": "Your distributed cache has 10 nodes, each with 64 GB RAM, 80% utilization, 2× replication. Effective cache capacity?",
      "options": ["~256 GB", "~512 GB", "~640 GB", "~1.28 TB"],
      "correct": 0,
      "explanation": "Total RAM = 10 × 64 = 640 GB. At 80% = 512 GB usable. With 2× replication, effective = 512 ÷ 2 = 256 GB.",
      "detailedExplanation": "The core signal here is \"your distributed cache has 10 nodes, each with 64 GB RAM, 80% utilization, 2×\". Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. Numbers such as 10 and 64 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-069",
      "type": "multiple-choice",
      "question": "A columnar store with 1 billion rows. Column A has 1,000 distinct values (dictionary encoded, 2 bytes per row). Column B has 100 million distinct values (no encoding, 8 bytes). Per-column storage?",
      "options": [
        "A: ~2 GB, B: ~8 GB",
        "A: ~2 GB, B: ~80 GB",
        "A: ~2 MB, B: ~8 GB",
        "A: ~2 KB, B: ~800 MB"
      ],
      "correct": 0,
      "explanation": "Column A: 2 bytes × 1B = 2 GB (plus small dictionary). Column B: 8 bytes × 1B = 8 GB.",
      "detailedExplanation": "If you keep \"columnar store with 1 billion rows\" in view, the correct answer separates faster. Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 1 and 1,000 in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-070",
      "type": "multiple-choice",
      "question": "Your Git repo has 100,000 commits. Average diff size is 10 KB (compressed). Approximate .git directory size?",
      "options": ["~100 MB", "~1 GB", "~10 GB", "~100 GB"],
      "correct": 1,
      "explanation": "10 KB × 100K = 1 GB (rough estimate; Git also stores trees and refs).",
      "detailedExplanation": "The key clue in this question is \"your Git repo has 100,000 commits\". Prefer the choice that fits durability and cost requirements for the workload shape. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 100,000 and 10 KB appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-071",
      "type": "multiple-choice",
      "question": "You store IP addresses as VARCHAR(45) for IPv6 compatibility (worst case) vs BINARY(16). 1 billion rows. Maximum storage difference?",
      "options": ["~3 GB", "~29 GB", "~290 GB", "~2.9 TB"],
      "correct": 1,
      "explanation": "VARCHAR(45) worst case ≈ 45 bytes, BINARY(16) = 16 bytes. Diff = 29 bytes × 1B = 29 GB max.",
      "detailedExplanation": "Start from \"you store IP addresses as VARCHAR(45) for IPv6 compatibility (worst case) vs BINARY(16)\", then pressure-test the result against the options. Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 45 and 16 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-072",
      "type": "multiple-choice",
      "question": "An engineer says \"our 100 GB database will need 1 TB in a year\" with 20% monthly growth. Is this reasonable?",
      "options": [
        "Yes, about right",
        "Too high—should be ~500 GB",
        "Too low—should be ~2 TB",
        "Too low—should be ~9 TB"
      ],
      "correct": 0,
      "explanation": "20% monthly growth for 12 months: 1.2^12 = 8.9. So 100 GB × 8.9 = 890 GB. The estimate of 1 TB is about right (within 15%).",
      "detailedExplanation": "The decision turns on \"engineer says our 100 GB database will need 1 TB in a year with 20% monthly growth\". Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 100 GB and 1 TB appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "storage-073",
      "type": "multiple-choice",
      "question": "You enable query logging (500 bytes avg per query) at 1,000 QPS. Daily log storage?",
      "options": ["~4.3 GB", "~43 GB", "~430 GB", "~4.3 TB"],
      "correct": 1,
      "explanation": "500 bytes × 1,000 × 86,400 = 43.2 GB per day.",
      "detailedExplanation": "Read this as a scenario about \"you enable query logging (500 bytes avg per query) at 1,000 QPS\". Eliminate options that ignore durability, retention, or access-pattern constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 500 and 1,000 QPS appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "storage-074",
      "type": "multiple-choice",
      "question": "Your time-series database uses 16 bytes per point (8 timestamp + 8 value). You downsample from 1-second to 1-minute resolution after 7 days. Storage ratio vs keeping all 1-second data for 30 days?",
      "options": ["~4× less", "~10× less", "~30× less", "~60× less"],
      "correct": 0,
      "explanation": "30 days at 1s = 30 × 86,400 = 2.59M points. With downsampling: 7 days at 1s (604,800) + 23 days at 1m (33,120) = 637,920 points. Ratio = 2.59M ÷ 638K ≈ 4× less storage.",
      "detailedExplanation": "Use \"your time-series database uses 16 bytes per point (8 timestamp + 8 value)\" as your starting point, then verify tradeoffs carefully. Prefer the choice that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 16 and 8 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-075",
      "type": "multiple-choice",
      "question": "A product catalog: name (100), description (1 KB), price (8), images (5 URLs × 100), categories (5 × 50). 1 million products. Storage?",
      "options": ["~180 MB", "~1.8 GB", "~18 GB", "~180 GB"],
      "correct": 1,
      "explanation": "Per product: 100 + 1000 + 8 + 500 + 250 = 1,858 bytes ≈ 1.8 KB. 1.8 KB × 1M = 1.8 GB.",
      "detailedExplanation": "This prompt is really about \"product catalog: name (100), description (1 KB), price (8), images (5 URLs × 100),\". Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. If values like 100 and 1 KB appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-076",
      "type": "multiple-choice",
      "question": "Your clickstream data: session_id (16), timestamp (8), page_url (200), referrer (200), viewport JSON (500). 500 million events/day, 30-day retention. Storage?",
      "options": ["~1.4 TB", "~14 TB", "~140 TB", "~1.4 PB"],
      "correct": 1,
      "explanation": "Per event: 16 + 8 + 200 + 200 + 500 = 924 bytes ≈ 1 KB. 1 KB × 500M × 30 = 15 TB ≈ 14 TB.",
      "detailedExplanation": "If you keep \"your clickstream data: session_id (16), timestamp (8), page_url (200), referrer (200),\" in view, the correct answer separates faster. Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. A good message-system answer defines guarantees clearly for both producer and consumer paths. If values like 16 and 8 appear, convert them into one unit basis before comparison. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-077",
      "type": "multiple-choice",
      "question": "You store 1080p video thumbnails (one per second of video). Thumbnail = 50 KB. For 1 million hours of video content, thumbnail storage?",
      "options": ["~18 TB", "~180 TB", "~1.8 PB", "~18 PB"],
      "correct": 1,
      "explanation": "1M hours × 3,600 sec × 50 KB = 180 TB.",
      "detailedExplanation": "The core signal here is \"you store 1080p video thumbnails (one per second of video)\". Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 50 KB and 1 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-078",
      "type": "multiple-choice",
      "question": "An A/B test stores: user_id (8), experiment_id (4), variant (1), timestamp (8). 100 experiments, 10 million users each. Storage?",
      "options": ["~2.1 GB", "~21 GB", "~210 GB", "~2.1 TB"],
      "correct": 1,
      "explanation": "Per assignment: 8 + 4 + 1 + 8 = 21 bytes. 21 × 100 × 10M = 21 GB.",
      "detailedExplanation": "The key clue in this question is \"a/B test stores: user_id (8), experiment_id (4), variant (1), timestamp (8)\". Discard storage decisions that optimize one dimension while violating another core requirement. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 8 and 4 in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-079",
      "type": "multiple-choice",
      "question": "You normalize an address into street (100), city (50), state (2), zip (10), country (2) vs storing as single text (200). 100 million addresses. Space impact?",
      "options": [
        "Normalized saves ~4 GB",
        "Same storage",
        "Denormalized saves ~4 GB",
        "Depends on indexing"
      ],
      "correct": 2,
      "explanation": "Normalized: 100 + 50 + 2 + 10 + 2 = 164 bytes. Denormalized: 200 bytes. Diff = 36 bytes × 100M = 3.6 GB less for normalized. So normalized saves ~4 GB.",
      "detailedExplanation": "Start from \"you normalize an address into street (100), city (50), state (2), zip (10), country (2)\", then pressure-test the result against the options. Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. If values like 100 and 50 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-080",
      "type": "multiple-choice",
      "question": "Your Prometheus stores 1 million time series, 15-second scrape interval, 15-day retention. Approximate storage?",
      "options": ["~86 GB", "~172 GB", "~864 GB", "~1.7 TB"],
      "correct": 1,
      "explanation": "Points per series = 15 days × 86,400 sec/day ÷ 15 sec = 86,400 points. At ~2 bytes/point (Prometheus compression): 1M series × 86.4K points × 2 bytes = 173 GB.",
      "detailedExplanation": "Start from \"your Prometheus stores 1 million time series, 15-second scrape interval, 15-day\", then pressure-test the result against the options. Prefer the choice that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 1 and 15 in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-081",
      "type": "multiple-choice",
      "question": "You add full-text search to a 50 GB text corpus. Inverted index is typically 20-30% of source. Total storage with index?",
      "options": ["~55-60 GB", "~60-65 GB", "~65-75 GB", "~100-150 GB"],
      "correct": 1,
      "explanation": "Index = 50 × 0.2-0.3 = 10-15 GB. Total = 50 + 10-15 = 60-65 GB.",
      "detailedExplanation": "The key clue in this question is \"you add full-text search to a 50 GB text corpus\". Prefer the schema/index decision that minimizes query and write amplification for this workload. Modeling quality is measured by query fit, cardinality behavior, and operational cost. If values like 50 GB and 20 appear, convert them into one unit basis before comparison. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-082",
      "type": "multiple-choice",
      "question": "Your event sourcing system stores events at 1 KB avg, 10,000 events/sec. 1-year retention. Total storage?",
      "options": ["~31 TB", "~315 TB", "~3.15 PB", "~31.5 PB"],
      "correct": 1,
      "explanation": "1 KB × 10,000 × 86,400 × 365 = 315 TB.",
      "detailedExplanation": "Read this as a scenario about \"your event sourcing system stores events at 1 KB avg, 10,000 events/sec\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Numbers such as 1 KB and 10,000 should be normalized first so downstream reasoning stays consistent. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-083",
      "type": "multiple-choice",
      "question": "A notification: user_id (8), type (20), message (200), created_at (8), read (1). 1 million users, 50 notifications each. Storage?",
      "options": ["~1.2 GB", "~12 GB", "~120 GB", "~1.2 TB"],
      "correct": 1,
      "explanation": "Per notification: 8 + 20 + 200 + 8 + 1 = 237 bytes. 237 × 50 × 1M = 11.85 GB ≈ 12 GB.",
      "detailedExplanation": "The decision turns on \"notification: user_id (8), type (20), message (200), created_at (8), read (1)\". Discard storage decisions that optimize one dimension while violating another core requirement. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 8 and 20 in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-084",
      "type": "multiple-choice",
      "question": "You shard by hash(user_id) % 64. One shard grows to 2× the average due to a power user. Even shards are 50 GB. Hot shard size?",
      "options": ["~75 GB", "~100 GB", "~150 GB", "~200 GB"],
      "correct": 1,
      "explanation": "Hot shard is 2× average. Average is 50 GB. Hot = 100 GB.",
      "detailedExplanation": "This prompt is really about \"you shard by hash(user_id) % 64\". Prefer the choice that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 64 and 2 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-085",
      "type": "multiple-choice",
      "question": "Your object store charges $0.01/GB for storage, $0.09/GB for egress. You store 10 TB, serve 50 TB/month. Monthly cost?",
      "options": [
        "~$100 storage + $4,500 egress",
        "~$100 storage + $450 egress",
        "~$1,000 storage + $4,500 egress",
        "~$1,000 storage + $45,000 egress"
      ],
      "correct": 0,
      "explanation": "Storage: 10,000 GB × $0.01 = $100. Egress: 50,000 GB × $0.09 = $4,500. Total = $4,600.",
      "detailedExplanation": "Use \"your object store charges $0\" as your starting point, then verify tradeoffs carefully. Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 0.01 and 0.09 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-086",
      "type": "multiple-choice",
      "question": "A hash table with 100 million entries, 50% load factor, 8-byte keys, 8-byte values. Memory needed?",
      "options": ["~1.6 GB", "~3.2 GB", "~6.4 GB", "~12.8 GB"],
      "correct": 1,
      "explanation": "Data size: 100M entries × 16 bytes = 1.6 GB. At 50% load factor, hash table needs 2× slots for data = 3.2 GB total allocation.",
      "detailedExplanation": "The core signal here is \"hash table with 100 million entries, 50% load factor, 8-byte keys, 8-byte values\". Prefer the schema/index decision that minimizes query and write amplification for this workload. Choose data shape based on workload paths, not on normalization dogma alone. Numbers such as 100 and 50 should be normalized first so downstream reasoning stays consistent. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-087",
      "type": "multiple-choice",
      "question": "Your database replication lag is measured by WAL position. Primary is at position 10 GB ahead of replica. Replica processes 100 MB/s. Lag in time?",
      "options": [
        "~10 seconds",
        "~100 seconds",
        "~1,000 seconds",
        "~10,000 seconds"
      ],
      "correct": 1,
      "explanation": "10 GB ÷ 100 MB/s = 10,000 MB ÷ 100 = 100 seconds.",
      "detailedExplanation": "If you keep \"your database replication lag is measured by WAL position\" in view, the correct answer separates faster. Eliminate approaches that hand-wave conflict resolution or quorum behavior. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Numbers such as 10 GB and 100 MB should be normalized first so downstream reasoning stays consistent. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "storage-088",
      "type": "multiple-choice",
      "question": "You use base64 encoding for binary data in JSON. A 750 KB image becomes how large?",
      "options": ["~750 KB", "~850 KB", "~1 MB", "~1.5 MB"],
      "correct": 2,
      "explanation": "Base64 expands data by 4/3 (33% overhead). 750 × 1.33 = 1,000 KB = 1 MB.",
      "detailedExplanation": "Start from \"you use base64 encoding for binary data in JSON\", then pressure-test the result against the options. Discard storage decisions that optimize one dimension while violating another core requirement. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 750 KB and 4 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-089",
      "type": "multiple-choice",
      "question": "A sparse matrix is 99% zeros. Dense storage would be 100 GB. Using coordinate format (row, col, value = 12 bytes per non-zero), sparse storage?",
      "options": [
        "~1.2 GB",
        "~12 GB",
        "~120 GB",
        "Depends on matrix dimensions"
      ],
      "correct": 0,
      "explanation": "1% non-zero of 100 GB = 1 GB of actual values. In coordinate format: need ~12 bytes per value vs original ~8 bytes. Sparse = 1 GB × (12/8) = 1.5 GB. Closest is ~1.2 GB.",
      "detailedExplanation": "The key clue in this question is \"sparse matrix is 99% zeros\". Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 99 and 100 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-090",
      "type": "multiple-choice",
      "question": "Your incremental backup captures changes since last backup. Daily changes are 5% of 2 TB database. Weekly incremental backup chain (6 incrementals)?",
      "options": ["~60 GB", "~120 GB", "~600 GB", "~1.2 TB"],
      "correct": 2,
      "explanation": "5% of 2 TB = 100 GB per day. 6 days × 100 GB = 600 GB.",
      "detailedExplanation": "The decision turns on \"your incremental backup captures changes since last backup\". Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 5 and 2 TB should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-091",
      "type": "multiple-choice",
      "question": "A trie for 1 million English words (avg 8 characters). Approximate memory using standard implementation?",
      "options": ["~8 MB", "~80 MB", "~800 MB", "~8 GB"],
      "correct": 1,
      "explanation": "Tries have high overhead due to pointers. Rough estimate: 1M words × 8 chars × ~10 bytes/node = 80 MB (actual varies widely by implementation).",
      "detailedExplanation": "Read this as a scenario about \"trie for 1 million English words (avg 8 characters)\". Prefer the choice that fits durability and cost requirements for the workload shape. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 1 and 8 in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-092",
      "type": "multiple-choice",
      "question": "You change from storing NULL as a marker byte (1 byte per nullable column) to a bitmap (1 bit). Table has 10 nullable columns, 1 billion rows. Space saved?",
      "options": ["~900 MB", "~9 GB", "~90 GB", "~900 GB"],
      "correct": 1,
      "explanation": "Old: 10 bytes per row. New: ~2 bytes (bitmap). Saved ≈ 8 bytes × 1B = 8 GB ≈ 9 GB.",
      "detailedExplanation": "The key clue in this question is \"you change from storing NULL as a marker byte (1 byte per nullable column) to a bitmap\". Discard modeling choices that look clean but perform poorly for the target queries. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Keep quantities like 1 and 10 in aligned units before selecting an answer. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-093",
      "type": "multiple-choice",
      "question": "Your data warehouse uses columnar format. A 1 TB row-oriented table with 100 columns, only 10 regularly queried. Effective scan reduction?",
      "options": ["~10%", "~50%", "~90%", "~99%"],
      "correct": 2,
      "explanation": "Columnar only reads needed columns. 10/100 = 10% of data read. Reduction = 90%.",
      "detailedExplanation": "Start from \"your data warehouse uses columnar format\", then pressure-test the result against the options. Discard modeling choices that look clean but perform poorly for the target queries. Choose data shape based on workload paths, not on normalization dogma alone. Numbers such as 1 TB and 100 should be normalized first so downstream reasoning stays consistent. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-094",
      "type": "multiple-choice",
      "question": "An LSM tree has 10 MB memtable, 10:1 size ratio between levels, 5 levels. Maximum storage?",
      "options": ["~1.1 GB", "~11 GB", "~111 GB", "~1.1 TB"],
      "correct": 2,
      "explanation": "Level sizes: 10 MB, 100 MB, 1 GB, 10 GB, 100 GB. Total = 10 + 100 + 1000 + 10000 + 100000 MB = 111,110 MB ≈ 111 GB.",
      "detailedExplanation": "If you keep \"lSM tree has 10 MB memtable, 10:1 size ratio between levels, 5 levels\" in view, the correct answer separates faster. Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. If values like 10 MB and 10 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-095",
      "type": "multiple-choice",
      "question": "You store user preferences as JSON (2 KB avg) vs normalized relational (15 rows × 50 bytes = 750 bytes). 50 million users. Storage difference?",
      "options": [
        "JSON uses ~62 GB more",
        "JSON uses ~6 GB more",
        "Same",
        "Relational uses more due to row overhead"
      ],
      "correct": 0,
      "explanation": "JSON: 2 KB × 50M = 100 GB. Relational: 750 bytes × 50M = 37.5 GB. Diff = 62.5 GB.",
      "detailedExplanation": "The core signal here is \"you store user preferences as JSON (2 KB avg) vs normalized relational (15 rows × 50\". Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 2 KB and 15 should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-096",
      "type": "multiple-choice",
      "question": "Your CDC system captures before/after images for each update. Table has 1 KB rows, 10,000 updates/sec, 24-hour retention. CDC storage?",
      "options": ["~1.7 TB", "~17 TB", "~170 TB", "~1.7 PB"],
      "correct": 0,
      "explanation": "Before + after = 2 KB per update. 2 KB × 10,000 × 86,400 = 1.73 TB.",
      "detailedExplanation": "Use \"your CDC system captures before/after images for each update\" as your starting point, then verify tradeoffs carefully. Discard modeling choices that look clean but perform poorly for the target queries. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Keep quantities like 1 KB and 10,000 in aligned units before selecting an answer. Common pitfall: unbounded cardinality in joins or fan-out.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-097",
      "type": "multiple-choice",
      "question": "A GIN (generalized inverted) index on a JSONB column with 10 keys per document, 50 million documents. Index size estimate?",
      "options": ["~5 GB", "~50 GB", "~500 GB", "Highly variable"],
      "correct": 3,
      "explanation": "GIN index size depends heavily on key cardinality, value distribution, and PostgreSQL version. Could range from 5 GB to 500 GB. No reliable estimate without more info.",
      "detailedExplanation": "This prompt is really about \"gIN (generalized inverted) index on a JSONB column with 10 keys per document, 50\". Eliminate designs that create ambiguous API semantics or brittle versioning paths. Interface decisions should be justified by contract stability and client impact over time. If values like 10 and 50 appear, convert them into one unit basis before comparison. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-098",
      "type": "multiple-choice",
      "question": "You're planning storage for year 3. Year 1 data: 100 GB, 50% annual growth, 3× replication, plus backup storage equal to primary. Year 3 total storage?",
      "options": ["~675 GB", "~1.35 TB", "~2.7 TB", "~8.1 TB"],
      "correct": 1,
      "explanation": "Year 3 raw data: 100 × 1.5² = 225 GB. With 3× replication: 675 GB. Backup equals primary: another 675 GB. Total = 1,350 GB ≈ 1.35 TB.",
      "detailedExplanation": "The decision turns on \"you're planning storage for year 3\". Eliminate options that ignore durability, retention, or access-pattern constraints. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 3 and 1 in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "storage-099",
      "type": "multiple-choice",
      "question": "An engineer proposes 10 GB for a year of metrics: 1,000 time series, 10-second intervals, 8-byte values. Is this estimate correct?",
      "options": [
        "About right",
        "Too low by ~3×",
        "Too low by ~25×",
        "Too high by ~10×"
      ],
      "correct": 2,
      "explanation": "Points per year = 365 × 86,400 ÷ 10 = 3.15M per series. 1,000 series × 3.15M × 8 bytes = 25.2 TB. Proposal is 10 GB. Off by 2,500×. Too low by ~25× is the closest.",
      "detailedExplanation": "Read this as a scenario about \"engineer proposes 10 GB for a year of metrics: 1,000 time series, 10-second intervals,\". Discard storage decisions that optimize one dimension while violating another core requirement. Storage decisions should align durability expectations with access and cost behavior. If values like 10 GB and 1,000 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "storage-100",
      "type": "multiple-choice",
      "question": "You run VACUUM FULL on a 500 GB PostgreSQL table with 40% bloat. Temporary space needed during operation?",
      "options": ["~200 GB", "~300 GB", "~500 GB", "~700 GB"],
      "correct": 2,
      "explanation": "VACUUM FULL creates a new copy of the table. It needs space for the new table (~300 GB without bloat) plus keeps the old until done. Total needed ≈ 500 GB free space.",
      "detailedExplanation": "The key clue in this question is \"you run VACUUM FULL on a 500 GB PostgreSQL table with 40% bloat\". Prefer the schema/index decision that minimizes query and write amplification for this workload. Modeling quality is measured by query fit, cardinality behavior, and operational cost. Numbers such as 500 GB and 40 should be normalized first so downstream reasoning stays consistent. Common pitfall: schema optimized for entities instead of queries.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n001",
      "type": "numeric-input",
      "question": "A user uploads 10 photos/day at 2MB each. Monthly storage per user?",
      "answer": 600,
      "unit": "MB",
      "tolerance": 0.1,
      "explanation": "10 × 2MB × 30 days = 600 MB per user per month.",
      "detailedExplanation": "Start from \"user uploads 10 photos/day at 2MB each\", then pressure-test the result against the options. Normalize units before computing so conversion mistakes do not propagate. Storage decisions should align durability expectations with access and cost behavior. If values like 10 and 2MB appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n002",
      "type": "numeric-input",
      "question": "1 million users each store 500KB of profile data. Total storage in GB?",
      "answer": 500,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "1M × 500KB = 500,000 MB = 500 GB.",
      "detailedExplanation": "The decision turns on \"1 million users each store 500KB of profile data\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 1 and 500KB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n003",
      "type": "numeric-input",
      "question": "A log line is 200 bytes. At 1,000 logs/second, how many GB per day?",
      "answer": 17.28,
      "unit": "GB",
      "tolerance": 0.15,
      "explanation": "200 × 1,000 × 86,400 = 17.28 billion bytes = 17.28 GB.",
      "detailedExplanation": "Read this as a scenario about \"log line is 200 bytes\". Normalize units before computing so conversion mistakes do not propagate. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 200 and 1,000 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n004",
      "type": "numeric-input",
      "question": "A database row is 1KB. How many million rows fit in 100GB?",
      "answer": 100,
      "unit": "million",
      "tolerance": 0.1,
      "explanation": "100GB = 100,000 MB = 100,000,000 KB = 100 million rows.",
      "detailedExplanation": "Use \"database row is 1KB\" as your starting point, then verify tradeoffs carefully. Keep every transformation in one unit system and check order of magnitude at the end. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 1KB and 100GB in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n005",
      "type": "numeric-input",
      "question": "Video streams at 5 Mbps. How many GB for 2 hours of video?",
      "answer": 4.5,
      "unit": "GB",
      "tolerance": 0.15,
      "explanation": "5 Mbps × 7,200 sec = 36,000 Mb = 4,500 MB = 4.5 GB.",
      "detailedExplanation": "This prompt is really about \"video streams at 5 Mbps\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 5 and 2 hours should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "stor-n006",
      "type": "numeric-input",
      "question": "A message is 500 bytes. 10 million messages/day. Daily storage in GB?",
      "answer": 5,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "500 × 10M = 5 billion bytes = 5 GB.",
      "detailedExplanation": "If you keep \"message is 500 bytes\" in view, the correct answer separates faster. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 500 and 10 should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n007",
      "type": "numeric-input",
      "question": "1 PB of storage. At 1 TB/day growth, how many days until full?",
      "answer": 1000,
      "unit": "days",
      "tolerance": 0.1,
      "explanation": "1 PB = 1,000 TB. 1,000 TB ÷ 1 TB/day = 1,000 days.",
      "detailedExplanation": "The core signal here is \"1 PB of storage\". Normalize units before computing so conversion mistakes do not propagate. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 1 and 1 TB appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "stor-n008",
      "type": "numeric-input",
      "question": "An image thumbnail is 25KB. 50 million thumbnails need how much storage in TB?",
      "answer": 1.25,
      "unit": "TB",
      "tolerance": 0.15,
      "explanation": "25KB × 50M = 1,250,000 MB = 1,250 GB = 1.25 TB.",
      "detailedExplanation": "The key clue in this question is \"image thumbnail is 25KB\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 25KB and 50 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n009",
      "type": "numeric-input",
      "question": "JSON API response averages 5KB. 100 million cached responses need how many TB?",
      "answer": 0.5,
      "unit": "TB",
      "tolerance": 0.15,
      "explanation": "5KB × 100M = 500,000 MB = 500 GB = 0.5 TB.",
      "detailedExplanation": "Start from \"jSON API response averages 5KB\", then pressure-test the result against the options. Normalize units before computing so conversion mistakes do not propagate. Prioritize explicit semantics and upgrade safety, not just short-term convenience. If values like 5KB and 100 appear, convert them into one unit basis before comparison. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n010",
      "type": "numeric-input",
      "question": "A UUID is 16 bytes. 1 billion UUIDs need how many GB?",
      "answer": 16,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "16 bytes × 1 billion = 16 GB.",
      "detailedExplanation": "The core signal here is \"uUID is 16 bytes\". Normalize units before computing so conversion mistakes do not propagate. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 16 and 1 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n011",
      "type": "numeric-input",
      "question": "User activity log: 1KB per event, 50 events/user/day, 1M users. Daily storage in TB?",
      "answer": 0.05,
      "unit": "TB",
      "tolerance": 0.2,
      "explanation": "1KB × 50 × 1M = 50 GB = 0.05 TB per day.",
      "detailedExplanation": "If you keep \"user activity log: 1KB per event, 50 events/user/day, 1M users\" in view, the correct answer separates faster. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. A good message-system answer defines guarantees clearly for both producer and consumer paths. Numbers such as 1KB and 50 should be normalized first so downstream reasoning stays consistent. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n012",
      "type": "numeric-input",
      "question": "A 4K video is 50 Mbps. Storage for 1 hour in GB?",
      "answer": 22.5,
      "unit": "GB",
      "tolerance": 0.15,
      "explanation": "50 Mbps × 3,600 sec = 180,000 Mb = 22,500 MB = 22.5 GB.",
      "detailedExplanation": "This prompt is really about \"4K video is 50 Mbps\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 4K and 50 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "stor-n013",
      "type": "numeric-input",
      "question": "Tweet-like posts average 300 bytes. 500 million posts need how many GB?",
      "answer": 150,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "300 × 500M = 150 billion bytes = 150 GB.",
      "detailedExplanation": "Use \"tweet-like posts average 300 bytes\" as your starting point, then verify tradeoffs carefully. Normalize units before computing so conversion mistakes do not propagate. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 300 and 500 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n014",
      "type": "numeric-input",
      "question": "Email averages 75KB with attachments. 1 billion emails stored need how many PB?",
      "answer": 0.075,
      "unit": "PB",
      "tolerance": 0.2,
      "explanation": "75KB × 1B = 75 TB = 0.075 PB.",
      "detailedExplanation": "Read this as a scenario about \"email averages 75KB with attachments\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 75KB and 1 should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n015",
      "type": "numeric-input",
      "question": "A session record is 2KB. 10 million concurrent sessions need how much GB for session storage?",
      "answer": 20,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "2KB × 10M = 20,000 MB = 20 GB.",
      "detailedExplanation": "The decision turns on \"session record is 2KB\". Normalize units before computing so conversion mistakes do not propagate. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 2KB and 10 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n016",
      "type": "numeric-input",
      "question": "Metrics: 8 bytes per data point, 1000 metrics, sampled every 10 seconds. Daily storage in GB?",
      "answer": 0.069,
      "unit": "GB",
      "tolerance": 0.15,
      "explanation": "8 bytes × 1000 metrics × 8640 samples/day = 69.12 million bytes = 69 MB ≈ 0.069 GB per day.",
      "detailedExplanation": "Start from \"metrics: 8 bytes per data point, 1000 metrics, sampled every 10 seconds\", then pressure-test the result against the options. Normalize units before computing so conversion mistakes do not propagate. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 8 and 1000 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n017",
      "type": "numeric-input",
      "question": "An index entry is 50 bytes. Indexing 100 million documents needs how much GB?",
      "answer": 5,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "50 × 100M = 5 billion bytes = 5 GB.",
      "detailedExplanation": "The key clue in this question is \"index entry is 50 bytes\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Choose data shape based on workload paths, not on normalization dogma alone. Numbers such as 50 and 100 should be normalized first so downstream reasoning stays consistent. Common pitfall: indexing that over-amplifies writes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-n018",
      "type": "numeric-input",
      "question": "A compressed backup is 20% of original 500GB database. Backup size in GB?",
      "answer": 100,
      "unit": "GB",
      "tolerance": 0.1,
      "explanation": "500GB × 0.20 = 100 GB compressed.",
      "detailedExplanation": "The core signal here is \"compressed backup is 20% of original 500GB database\". Normalize units before computing so conversion mistakes do not propagate. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 20 and 500GB appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-o001",
      "type": "ordering",
      "question": "Rank these by storage size (smallest to largest).",
      "items": [
        "1 million UUIDs",
        "1 million tweets",
        "1 million photos",
        "1 million video thumbnails"
      ],
      "correctOrder": [0, 1, 3, 2],
      "explanation": "UUIDs (16MB) < Tweets (300MB) < Thumbnails (25GB) < Photos (2TB).",
      "detailedExplanation": "If you keep \"rank these by storage size (smallest to largest)\" in view, the correct answer separates faster. Build the rank from biggest differences first, then refine with adjacent checks. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 16MB and 300MB in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-o002",
      "type": "ordering",
      "question": "Rank by bytes (smallest to largest).",
      "items": ["1 KB", "1 MB", "2^20 bytes", "1000 KB"],
      "correctOrder": [0, 3, 1, 2],
      "explanation": "1KB < 1000KB = 1MB = 2^20 bytes (all three equal ~1M bytes).",
      "detailedExplanation": "This prompt is really about \"rank by bytes (smallest to largest)\". Place obvious extremes first, then sort the middle by pairwise comparison. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 1KB and 1000KB should be normalized first so downstream reasoning stays consistent. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-o005",
      "type": "ordering",
      "question": "Rank by daily storage growth (lowest to highest).",
      "items": [
        "10 QPS × 1KB",
        "100 QPS × 500B",
        "50 QPS × 5KB",
        "1000 QPS × 200B"
      ],
      "correctOrder": [0, 1, 3, 2],
      "explanation": "10×1KB=0.86GB < 100×500B=4.3GB < 1000×200B=17.3GB < 50×5KB=21.6GB daily.",
      "detailedExplanation": "The decision turns on \"rank by daily storage growth (lowest to highest)\". Order by relative scale and bottleneck effect, then validate neighboring items. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 10 and 1KB in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "stor-o004",
      "type": "ordering",
      "question": "Rank by storage efficiency (most to least efficient).",
      "items": ["Gzip text", "Raw JSON", "Binary protobuf", "Base64 encoded"],
      "correctOrder": [2, 0, 1, 3],
      "explanation": "Protobuf (binary) < Gzip < Raw JSON < Base64 (33% overhead).",
      "detailedExplanation": "Read this as a scenario about \"rank by storage efficiency (most to least efficient)\". Place obvious extremes first, then sort the middle by pairwise comparison. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 33 appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-o009",
      "type": "ordering",
      "question": "Rank by daily storage growth (lowest to highest).",
      "items": [
        "10 QPS × 1KB",
        "100 QPS × 500B",
        "50 QPS × 5KB",
        "1000 QPS × 200B"
      ],
      "correctOrder": [0, 1, 3, 2],
      "explanation": "10×1KB=0.86GB < 100×500B=4.3GB < 1000×200B=17.3GB < 50×5KB=21.6GB daily.",
      "detailedExplanation": "If you keep \"rank by daily storage growth (lowest to highest)\" in view, the correct answer separates faster. Order by relative scale and bottleneck effect, then validate neighboring items. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 10 and 1KB in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "stor-o006",
      "type": "ordering",
      "question": "Rank these video qualities by storage per hour (smallest to largest).",
      "items": [
        "4K (50 Mbps)",
        "1080p (8 Mbps)",
        "720p (5 Mbps)",
        "480p (2.5 Mbps)"
      ],
      "correctOrder": [3, 2, 1, 0],
      "explanation": "480p (1.1GB) < 720p (2.25GB) < 1080p (3.6GB) < 4K (22.5GB).",
      "detailedExplanation": "Start from \"rank these video qualities by storage per hour (smallest to largest)\", then pressure-test the result against the options. Build the rank from biggest differences first, then refine with adjacent checks. Storage decisions should align durability expectations with access and cost behavior. Keep quantities like 1.1GB and 2.25GB in aligned units before selecting an answer. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "stor-o007",
      "type": "ordering",
      "question": "Rank these database row sizes (smallest to largest).",
      "items": [
        "User profile (2KB)",
        "Order with items (10KB)",
        "Product listing (500B)",
        "Transaction log (100B)"
      ],
      "correctOrder": [3, 2, 0, 1],
      "explanation": "Log (100B) < Product (500B) < Profile (2KB) < Order (10KB).",
      "detailedExplanation": "The key clue in this question is \"rank these database row sizes (smallest to largest)\". Place obvious extremes first, then sort the middle by pairwise comparison. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 100B and 500B appear, convert them into one unit basis before comparison. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-o008",
      "type": "ordering",
      "question": "Rank by compression ratio (best to worst compression).",
      "items": [
        "Repeated text",
        "Random binary",
        "Structured JSON",
        "Already compressed image"
      ],
      "correctOrder": [0, 2, 3, 1],
      "explanation": "Repeated text compresses best, JSON well, compressed images minimally, random binary worst.",
      "detailedExplanation": "The core signal here is \"rank by compression ratio (best to worst compression)\". Place obvious extremes first, then sort the middle by pairwise comparison. Storage decisions should align durability expectations with access and cost behavior. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-m001",
      "type": "multi-select",
      "question": "Which are approximately 1 GB?",
      "options": ["1 billion bytes", "1 million KB", "1000 MB", "2^30 bytes"],
      "correctIndices": [0, 1, 2, 3],
      "explanation": "All are approximately 1 GB: 1 billion bytes = 1GB, 1 million KB = 1GB, 1000 MB = 1GB, 2^30 ≈ 1.07GB.",
      "detailedExplanation": "Use \"approximately 1 GB\" as your starting point, then verify tradeoffs carefully. Validate each option independently; do not select statements that are only partially true. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 1 GB and 1 appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-m002",
      "type": "multi-select",
      "question": "Which fit in 1 TB of storage?",
      "options": [
        "100 million 10KB records",
        "1 million 1MB photos",
        "10,000 100GB videos",
        "1 billion 500B messages"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "100M×10KB=1TB ✓, 1M×1MB=1TB ✓, 10K×100GB=1PB ✗, 1B×500B=500GB ✓.",
      "detailedExplanation": "The core signal here is \"fit in 1 TB of storage\". Validate each option independently; do not select statements that are only partially true. Storage decisions should align durability expectations with access and cost behavior. If values like 1 TB and 100M appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-m003",
      "type": "multi-select",
      "question": "Which correctly describe binary storage prefixes?",
      "options": [
        "1 KiB = 1024 bytes",
        "1 MB = exactly 1 million bytes",
        "1 GiB > 1 GB",
        "2^20 = 1 MiB"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "KiB uses 1024. MB is 10^6 in SI, but often means 2^20. GiB (2^30) > GB (10^9). 2^20 = 1 MiB.",
      "detailedExplanation": "If you keep \"correctly describe binary storage prefixes\" in view, the correct answer separates faster. Avoid pattern guessing and evaluate each candidate directly against the scenario. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 1024 and 10 in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-m004",
      "type": "multi-select",
      "question": "A system stores 1KB per user. Which user counts need more than 1GB?",
      "options": [
        "500,000 users",
        "1 million users",
        "2 million users",
        "500 million users"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "1GB = 1M KB. 1M, 2M, and 500M users all need ≥1GB. 500K needs only 500MB.",
      "detailedExplanation": "Start from \"system stores 1KB per user\", then pressure-test the result against the options. Validate each option independently; do not select statements that are only partially true. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 1KB and 1GB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-m005",
      "type": "multi-select",
      "question": "Which are valid ways to estimate 1 year of 100 QPS log storage at 500 bytes/log?",
      "options": [
        "~1.5 TB",
        "~157 GB",
        "500 × 100 × 86400 × 365 bytes",
        "About 1.6 trillion bytes"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "100×500×86400×365 = 1.58 trillion bytes = 1.58 TB ≈ 1.5 TB.",
      "detailedExplanation": "The key clue in this question is \"valid ways to estimate 1 year of 100 QPS log storage at 500 bytes/log\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 1 and 100 QPS in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "stor-m006",
      "type": "multi-select",
      "question": "Which storage estimates are reasonable for a social media photo service (100M users)?",
      "options": [
        "10 PB for all user photos",
        "1 TB for thumbnails",
        "100 GB for user metadata",
        "1 PB for original photos"
      ],
      "correctIndices": [0, 3],
      "explanation": "100M users × 1000 photos × 2MB = 200 PB for originals (10 PB reasonable subset). Thumbnails ~2.5 PB, metadata 100GB reasonable.",
      "detailedExplanation": "Read this as a scenario about \"storage estimates are reasonable for a social media photo service (100M users)\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Capacity answers are more defensible when growth and replication are modeled explicitly. If values like 100M and 1000 appear, convert them into one unit basis before comparison. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-m007",
      "type": "multi-select",
      "question": "Which reduce storage requirements?",
      "options": [
        "Compression",
        "Deduplication",
        "Adding indexes",
        "Shorter retention periods"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Compression and deduplication reduce size. Shorter retention deletes old data. Indexes ADD storage.",
      "detailedExplanation": "The decision turns on \"reduce storage requirements\". Treat every option as a separate true/false test under the same constraints. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-m008",
      "type": "multi-select",
      "question": "A video platform stores 100 hours of new video daily at 1080p (3 GB/hour). Which are true?",
      "options": [
        "300 GB daily growth",
        "~110 TB yearly growth",
        "Need ~10 TB for 1 month",
        "30-day retention needs ~9 TB"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "100×3=300GB/day, 300×365=109.5TB/year, 300×30=9TB for 30 days.",
      "detailedExplanation": "This prompt is really about \"video platform stores 100 hours of new video daily at 1080p (3 GB/hour)\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. If values like 100 hours and 3 GB appear, convert them into one unit basis before comparison. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "Cloudflare CDN and cache concepts",
          "url": "https://developers.cloudflare.com/cache/"
        }
      ]
    },
    {
      "id": "stor-t001",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your service logs 500 bytes per request at 1,000 QPS. Daily log volume?",
          "options": ["~4 GB", "~43 GB", "~430 GB", "~4.3 TB"],
          "correct": 1,
          "explanation": "500 × 1000 × 86400 = 43.2 billion bytes = 43.2 GB.",
          "detailedExplanation": "The core signal here is \"your service logs 500 bytes per request at 1,000 QPS\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity answers are more defensible when growth and replication are modeled explicitly. Numbers such as 500 and 1,000 QPS should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead."
        },
        {
          "question": "With 90-day retention, how much log storage do you need?",
          "options": ["~400 GB", "~4 TB", "~40 TB", "~400 TB"],
          "correct": 1,
          "explanation": "43 GB × 90 days = 3.87 TB ≈ 4 TB.",
          "detailedExplanation": "Use \"with 90-day retention, how much log storage do you need\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 90 and 43 GB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements."
        }
      ],
      "explanation": "Log storage planning requires calculating daily volume and multiplying by retention period.",
      "detailedExplanation": "The core signal here is \"log storage planning requires calculating daily volume and multiplying by retention\". Do not reset assumptions between stages; carry forward prior constraints directly. Storage decisions should align durability expectations with access and cost behavior. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-t002",
      "type": "two-stage",
      "stages": [
        {
          "question": "Users upload 5 photos/day (2MB each). With 1M daily active users, daily upload volume?",
          "options": ["~1 TB", "~10 TB", "~100 TB", "~1 PB"],
          "correct": 1,
          "explanation": "5 × 2MB × 1M = 10 TB per day.",
          "detailedExplanation": "The decision turns on \"users upload 5 photos/day (2MB each)\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Numbers such as 5 and 2MB should be normalized first so downstream reasoning stays consistent. Common pitfall: underestimating replication and retention overhead."
        },
        {
          "question": "If you keep 3 copies for redundancy and photos are stored forever, annual storage growth?",
          "options": ["~1 PB", "~10 PB", "~100 PB", "~1 EB"],
          "correct": 1,
          "explanation": "10 TB × 365 × 3 = 10.95 PB ≈ 10 PB yearly.",
          "detailedExplanation": "Start from \"if you keep 3 copies for redundancy and photos are stored forever, annual storage growth\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Keep quantities like 3 and 10 TB in aligned units before selecting an answer. Common pitfall: ignoring durability/recovery requirements."
        }
      ],
      "explanation": "Photo storage at scale requires accounting for redundancy and indefinite retention.",
      "detailedExplanation": "Use \"photo storage at scale requires accounting for redundancy and indefinite retention\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity answers are more defensible when growth and replication are modeled explicitly. Common pitfall: underestimating replication and retention overhead.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-t003",
      "type": "two-stage",
      "stages": [
        {
          "question": "A cache stores 1 million entries at 5KB each. Cache memory needed?",
          "options": ["~500 MB", "~5 GB", "~50 GB", "~500 GB"],
          "correct": 1,
          "explanation": "1M × 5KB = 5,000 MB = 5 GB.",
          "detailedExplanation": "Start from \"cache stores 1 million entries at 5KB each\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat freshness policy and invalidation paths as first-class constraints. Numbers such as 1 and 5KB should be normalized first so downstream reasoning stays consistent. Common pitfall: hot-key skew causing uneven load."
        },
        {
          "question": "If you add a second cache layer with 10x entries but 100 bytes each, additional memory?",
          "options": ["~100 MB", "~1 GB", "~10 GB", "~100 GB"],
          "correct": 1,
          "explanation": "10M × 100B = 1,000 MB = 1 GB.",
          "detailedExplanation": "The decision turns on \"if you add a second cache layer with 10x entries but 100 bytes each, additional memory\". Solve this as chained reasoning where stage two must respect stage one assumptions. Cache design quality is mostly about correctness boundaries, not only hit rate. Numbers such as 10x and 100 should be normalized first so downstream reasoning stays consistent. Common pitfall: invalidation races under concurrent writes."
        }
      ],
      "explanation": "Multi-tier caching: L1 stores full objects, L2 stores keys/pointers.",
      "detailedExplanation": "This prompt is really about \"multi-tier caching: L1 stores full objects, L2 stores keys/pointers\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Common pitfall: ignoring durability/recovery requirements.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "stor-t004",
      "type": "two-stage",
      "stages": [
        {
          "question": "An e-commerce site has 10 million products with 1KB metadata each. Metadata storage?",
          "options": ["~1 GB", "~10 GB", "~100 GB", "~1 TB"],
          "correct": 1,
          "explanation": "10M × 1KB = 10 GB.",
          "detailedExplanation": "Use \"e-commerce site has 10 million products with 1KB metadata each\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Capacity answers are more defensible when growth and replication are modeled explicitly. Keep quantities like 10 and 1KB in aligned units before selecting an answer. Common pitfall: choosing tier by cost only and missing access constraints."
        },
        {
          "question": "Each product has 10 images at 100KB each. Image storage for the catalog?",
          "options": ["~1 TB", "~10 TB", "~100 TB", "~1 PB"],
          "correct": 1,
          "explanation": "10M × 10 × 100KB = 10 TB.",
          "detailedExplanation": "The core signal here is \"each product has 10 images at 100KB each\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Storage decisions should align durability expectations with access and cost behavior. Numbers such as 10 and 100KB should be normalized first so downstream reasoning stays consistent. Common pitfall: ignoring durability/recovery requirements."
        }
      ],
      "explanation": "Product catalogs: metadata is small, images dominate storage.",
      "detailedExplanation": "The decision turns on \"product catalogs: metadata is small, images dominate storage\". Solve this as chained reasoning where stage two must respect stage one assumptions. Separate raw data, redundancy overhead, and retention horizon when reasoning about storage choices. Common pitfall: choosing tier by cost only and missing access constraints.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    }
  ]
}
