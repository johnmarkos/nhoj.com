{
  "unit": 4,
  "unitTitle": "Storage Selection",
  "chapter": 5,
  "chapterTitle": "Graph & Search Engines",
  "chapterDescription": "Graph databases for relationship traversal and search engines for full-text search.",
  "problems": [
    {
      "id": "gs-001",
      "type": "multiple-choice",
      "question": "What is a graph database?",
      "options": [
        "A database that creates charts and graphs",
        "A database optimized for storing and traversing relationships between entities",
        "A visual database",
        "A database for graphics files"
      ],
      "correct": 1,
      "explanation": "Graph databases store data as nodes (entities) and edges (relationships). They're optimized for traversing connections: 'friends of friends', 'shortest path', 'all connections within 3 hops'. Much faster than JOINs for deep relationship queries."
    },
    {
      "id": "gs-002",
      "type": "multi-select",
      "question": "Which are graph databases?",
      "options": ["Neo4j", "MongoDB", "Amazon Neptune", "JanusGraph"],
      "correctIndices": [0, 2, 3],
      "explanation": "Neo4j is the most popular graph database. Amazon Neptune is AWS's managed graph service. JanusGraph is open-source, distributed. MongoDB is a document database — it can store references but isn't optimized for graph traversals."
    },
    {
      "id": "gs-003",
      "type": "multiple-choice",
      "question": "What are nodes and edges in a graph database?",
      "options": [
        "Tables and rows",
        "Nodes are entities (people, products); edges are relationships between them (follows, purchased)",
        "Nodes are servers; edges are network connections",
        "Nodes are data points; edges are axes"
      ],
      "correct": 1,
      "explanation": "Graph model: nodes represent entities (User, Product, City), edges represent relationships (FOLLOWS, PURCHASED, LIVES_IN). Both can have properties. The structure makes relationship queries natural and fast."
    },
    {
      "id": "gs-004",
      "type": "multiple-choice",
      "question": "When is a graph database better than a relational database?",
      "options": [
        "For simple CRUD applications",
        "When queries involve traversing many relationships (multi-hop paths, recommendations, networks)",
        "For storing time-series data",
        "When data has no relationships"
      ],
      "correct": 1,
      "explanation": "Graph databases excel when relationship traversal is central: social networks (friends of friends), recommendation engines, fraud detection (connected entities), network analysis. Relational JOINs become expensive for multi-hop queries."
    },
    {
      "id": "gs-005",
      "type": "two-stage",
      "stages": [
        {
          "question": "You need to find 'friends of friends of friends' in a social network. In SQL, how would you express this?",
          "options": [
            "SELECT * FROM friends",
            "Three JOINs: friends → friends → friends",
            "A single JOIN",
            "SQL can't express this"
          ],
          "correct": 1,
          "explanation": "In SQL: SELECT DISTINCT f3.friend_id FROM friends f1 JOIN friends f2 ON f1.friend_id = f2.user_id JOIN friends f3 ON f2.friend_id = f3.user_id WHERE f1.user_id = ?. Each hop = another JOIN. Performance degrades with hop count."
        },
        {
          "question": "In Neo4j (Cypher), the same query looks like:",
          "options": [
            "SELECT friends^3",
            "MATCH (u:User)-[:FRIEND*3]-(fof) WHERE u.id = ? RETURN fof",
            "Three separate queries",
            "Graph databases can't do this"
          ],
          "correct": 1,
          "explanation": "Cypher: MATCH (u:User)-[:FRIEND*3]-(fof) traverses exactly 3 FRIEND hops. The *3 means 'repeat 3 times.' More readable and typically faster than SQL JOINs for deep traversals. Graph DBs are built for this."
        }
      ]
    },
    {
      "id": "gs-006",
      "type": "multiple-choice",
      "question": "What is Cypher?",
      "options": [
        "An encryption algorithm",
        "Neo4j's graph query language, using ASCII-art pattern matching",
        "A graph visualization tool",
        "A graph serialization format"
      ],
      "correct": 1,
      "explanation": "Cypher is Neo4j's query language. It uses ASCII-art patterns: (a)-[:KNOWS]->(b) represents nodes and relationships visually. MATCH, CREATE, WHERE, RETURN are key clauses. Cypher is now an open standard (GQL) adopted by other databases."
    },
    {
      "id": "gs-007",
      "type": "multi-select",
      "question": "What are common use cases for graph databases?",
      "options": [
        "Social networks (friends, followers, connections)",
        "Fraud detection (finding suspicious patterns)",
        "Recommendation engines (users who liked X also liked Y)",
        "Simple key-value caching"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Graph use cases: social networks (relationship traversal), fraud detection (spotting connected suspicious entities), recommendations (collaborative filtering, content-based). Key-value caching doesn't need relationship modeling — use Redis."
    },
    {
      "id": "gs-008",
      "type": "multiple-choice",
      "question": "What is a property graph?",
      "options": [
        "A graph that owns property",
        "A graph model where both nodes and edges can have key-value properties",
        "A real estate database",
        "A graph with privacy properties"
      ],
      "correct": 1,
      "explanation": "Property graphs are the most common graph model. Nodes have labels (Person, Movie) and properties (name, age). Edges have types (ACTED_IN, DIRECTED) and properties (role, since). Neo4j, Neptune, and most graph DBs use this model."
    },
    {
      "id": "gs-009",
      "type": "multiple-choice",
      "question": "What is RDF (Resource Description Framework)?",
      "options": [
        "A graph query language",
        "A graph model using subject-predicate-object triples, common in semantic web",
        "A file format for graphs",
        "A graph visualization standard"
      ],
      "correct": 1,
      "explanation": "RDF represents data as triples: (subject, predicate, object) like (Alice, knows, Bob). Used in semantic web, knowledge graphs, linked data. SPARQL is the query language. More standardized but often less intuitive than property graphs."
    },
    {
      "id": "gs-010",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're building a knowledge graph connecting entities (people, places, concepts). What's a suitable model?",
          "options": [
            "Key-value pairs",
            "RDF triples — standard for knowledge representation",
            "Document store",
            "Time-series"
          ],
          "correct": 1,
          "explanation": "RDF is designed for knowledge graphs: represent facts as triples, link to external ontologies, support reasoning. Many knowledge graphs (Wikidata, Google Knowledge Graph) use RDF or similar models."
        },
        {
          "question": "You're building a social network with user profiles and flexible relationship types. Which model?",
          "options": [
            "RDF — it's always better",
            "Property graph — more intuitive for application data",
            "Relational with JOINs",
            "Document store with references"
          ],
          "correct": 1,
          "explanation": "Property graphs are more intuitive for application developers: nodes are objects with properties, edges are typed relationships. Less formal than RDF but easier to model and query for typical applications. Neo4j uses property graphs."
        }
      ]
    },
    {
      "id": "gs-011",
      "type": "multiple-choice",
      "question": "What is SPARQL?",
      "options": [
        "A graph database",
        "The query language for RDF data",
        "A graph visualization library",
        "A graph partitioning algorithm"
      ],
      "correct": 1,
      "explanation": "SPARQL is to RDF what SQL is to relational databases. It queries triple stores using pattern matching: SELECT ?person WHERE { ?person knows ?other }. Standard for semantic web and linked data queries."
    },
    {
      "id": "gs-012",
      "type": "multiple-choice",
      "question": "What is Amazon Neptune?",
      "options": [
        "An ocean monitoring service",
        "AWS's managed graph database supporting both property graphs and RDF",
        "A network monitoring tool",
        "A data visualization service"
      ],
      "correct": 1,
      "explanation": "Amazon Neptune is AWS's managed graph database. It supports property graphs (Gremlin queries) and RDF (SPARQL queries). Fully managed: no servers to manage, automatic replication, backups. Good for AWS-centric architectures."
    },
    {
      "id": "gs-013",
      "type": "multi-select",
      "question": "What query languages does Amazon Neptune support?",
      "options": ["Gremlin (property graph traversal)", "SPARQL (RDF queries)", "Cypher", "SQL"],
      "correctIndices": [0, 1],
      "explanation": "Neptune supports Gremlin (Apache TinkerPop's graph traversal language) for property graphs and SPARQL for RDF. It doesn't support Cypher (Neo4j's language) or SQL. Choose based on your graph model."
    },
    {
      "id": "gs-014",
      "type": "multiple-choice",
      "question": "What is Gremlin?",
      "options": [
        "A fuzzy creature",
        "A graph traversal language from Apache TinkerPop, used by many graph databases",
        "A graph database",
        "A graph visualization tool"
      ],
      "correct": 1,
      "explanation": "Gremlin is a graph traversal language from Apache TinkerPop. It's vendor-neutral, supported by Neptune, JanusGraph, Azure Cosmos DB, and others. Queries are step-based: g.V().has('name','Alice').out('knows').values('name')."
    },
    {
      "id": "gs-015",
      "type": "two-stage",
      "stages": [
        {
          "question": "You need shortest path between two users in a social network. Which database type handles this best?",
          "options": [
            "Relational with recursive CTEs",
            "Graph database with built-in shortest path algorithms",
            "Key-value store",
            "Document database"
          ],
          "correct": 1,
          "explanation": "Graph databases have native shortest path algorithms: Neo4j's shortestPath(), Gremlin's repeat().until(). They're optimized for traversal. SQL can do it with recursive CTEs but it's slower and more complex for large graphs."
        },
        {
          "question": "The social network has 100 million users. What becomes challenging with graph databases?",
          "options": [
            "Storing the data",
            "Distributed traversals — following edges across nodes on different servers",
            "Creating relationships",
            "Graph databases scale infinitely"
          ],
          "correct": 1,
          "explanation": "At massive scale, the graph is distributed across servers. Traversing an edge might require a network hop to another server. This 'super-node' problem and cross-partition traversals are challenging. Some graph DBs handle this better than others."
        }
      ]
    },
    {
      "id": "gs-016",
      "type": "multiple-choice",
      "question": "What is a super-node in graph databases?",
      "options": [
        "A very powerful server",
        "A node with an extremely high number of connections (e.g., a celebrity with millions of followers)",
        "The primary node in a cluster",
        "A node with no connections"
      ],
      "correct": 1,
      "explanation": "Super-nodes have millions of edges (celebrity accounts, popular products). Traversing through them is slow — reading all their edges is expensive. Solutions: edge pagination, materialized views, or special handling in queries."
    },
    {
      "id": "gs-017",
      "type": "multi-select",
      "question": "How do you handle super-nodes in graph databases?",
      "options": [
        "Limit traversal depth",
        "Paginate edge retrieval",
        "Pre-compute common queries for super-nodes",
        "Delete super-nodes"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Super-node strategies: limit depth (MATCH path LIMIT 1000), paginate edges (fetch 100 at a time), pre-compute popular queries (cache 'top friends of celebrity'). Deleting isn't practical — celebrities exist. Design around them."
    },
    {
      "id": "gs-018",
      "type": "multiple-choice",
      "question": "What is JanusGraph?",
      "options": [
        "A Roman god database",
        "An open-source, distributed graph database that uses pluggable backends",
        "A graph visualization tool",
        "A proprietary Neo4j feature"
      ],
      "correct": 1,
      "explanation": "JanusGraph is open-source, distributed, and backend-agnostic. It can use Cassandra, HBase, or Bigtable for storage, and Elasticsearch or Solr for indexing. Good for: large-scale graphs needing horizontal scaling. Uses Gremlin."
    },
    {
      "id": "gs-019",
      "type": "multiple-choice",
      "question": "When would you choose Neo4j over JanusGraph?",
      "options": [
        "When you need horizontal scaling across many nodes",
        "When you want a mature, integrated solution with Cypher and great tooling",
        "When you need Cassandra as a backend",
        "When you need maximum flexibility"
      ],
      "correct": 1,
      "explanation": "Neo4j is more mature, has better tooling (browser, visualization), Cypher is more intuitive than Gremlin for many. Neo4j Enterprise has clustering. JanusGraph is better for: massive scale with commodity backends, Gremlin preference, avoiding vendor lock-in."
    },
    {
      "id": "gs-020",
      "type": "ordering",
      "question": "Rank these from most to least suitable for a graph database:",
      "items": ["Social network friend recommendations", "E-commerce product catalog", "Fraud detection ring analysis", "Time-series metrics storage"],
      "correctOrder": [0, 2, 1, 3],
      "explanation": "Friend recommendations and fraud rings are classic graph problems (deep traversals). Product catalog can use graphs for recommendations but is often fine in relational. Time-series has no relationship traversal — use a time-series DB."
    },
    {
      "id": "gs-021",
      "type": "multiple-choice",
      "question": "What is Elasticsearch?",
      "options": [
        "A graph database",
        "A distributed search and analytics engine built on Apache Lucene",
        "A caching system",
        "A message queue"
      ],
      "correct": 1,
      "explanation": "Elasticsearch is a distributed search engine. It provides full-text search, structured search, analytics, and aggregations. Built on Lucene. Part of the ELK stack (Elasticsearch, Logstash, Kibana). Used for: log analysis, site search, metrics."
    },
    {
      "id": "gs-022",
      "type": "multi-select",
      "question": "What is Elasticsearch commonly used for?",
      "options": [
        "Full-text search (site search, product search)",
        "Log aggregation and analysis",
        "Real-time analytics and dashboards",
        "ACID transactions"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Elasticsearch use cases: search (text search with relevance ranking), logs (centralize and query logs), analytics (aggregate and visualize data). It's not designed for ACID transactions — it's eventually consistent and optimized for read-heavy search."
    },
    {
      "id": "gs-023",
      "type": "multiple-choice",
      "question": "What is an inverted index?",
      "options": [
        "An upside-down database",
        "A data structure mapping terms to the documents containing them, enabling fast text search",
        "A reversed B-tree",
        "An index on descending order"
      ],
      "correct": 1,
      "explanation": "Inverted indexes map terms → documents. For 'the quick brown fox', index entries: 'quick' → [doc1], 'brown' → [doc1], 'fox' → [doc1]. To find documents with 'fox', look up 'fox' directly. This is how search engines achieve fast text search."
    },
    {
      "id": "gs-024",
      "type": "two-stage",
      "stages": [
        {
          "question": "You search for 'running shoes' in an e-commerce site. The search engine finds products with 'run', 'runner', 'running'. What feature enables this?",
          "options": [
            "Exact matching",
            "Stemming or lemmatization — reducing words to their root form",
            "Spell checking",
            "Random matching"
          ],
          "correct": 1,
          "explanation": "Stemming reduces words to roots: 'running' → 'run'. The index stores 'run', matching queries for 'run', 'running', 'runs', 'runner'. This broadens recall. Elasticsearch uses analyzers that include stemmers."
        },
        {
          "question": "The search also handles typos: 'runnign shoes' still finds results. What feature?",
          "options": [
            "Stemming",
            "Fuzzy matching — allowing edit distance between query and indexed terms",
            "Auto-correct by the browser",
            "Exact matching with wildcards"
          ],
          "correct": 1,
          "explanation": "Fuzzy matching allows small edit distances (insertions, deletions, substitutions). 'runnign' is 1 edit from 'running'. Elasticsearch supports fuzzy queries. Fuzziness improves recall for typos but can reduce precision."
        }
      ]
    },
    {
      "id": "gs-025",
      "type": "multiple-choice",
      "question": "What is tokenization in text search?",
      "options": [
        "Converting text to cryptocurrency",
        "Breaking text into individual terms (tokens) for indexing",
        "Encrypting text",
        "Validating text format"
      ],
      "correct": 1,
      "explanation": "Tokenization splits text into searchable terms: 'The Quick Brown Fox' → ['the', 'quick', 'brown', 'fox']. Tokenizers handle: word boundaries, punctuation, case. Different languages need different tokenizers. Part of Elasticsearch's analyzer pipeline."
    },
    {
      "id": "gs-026",
      "type": "multi-select",
      "question": "What is an analyzer in Elasticsearch?",
      "options": [
        "A person who analyzes data",
        "A pipeline of: character filters → tokenizer → token filters",
        "The component that processes text for indexing and search",
        "A visualization tool"
      ],
      "correctIndices": [1, 2],
      "explanation": "An analyzer processes text in stages: character filters (strip HTML), tokenizer (split into tokens), token filters (lowercase, stem, remove stopwords). Elasticsearch has built-in analyzers (standard, english) or you can build custom ones."
    },
    {
      "id": "gs-027",
      "type": "multiple-choice",
      "question": "What are stopwords in text search?",
      "options": [
        "Words that stop the search",
        "Common words (the, is, and) often filtered out because they don't add search value",
        "Offensive words to filter",
        "Words at the end of sentences"
      ],
      "correct": 1,
      "explanation": "Stopwords are very common words that rarely help distinguish documents: 'the', 'is', 'and', 'of'. Removing them reduces index size and improves relevance. But be careful: 'The Who' (band) loses meaning without 'the'."
    },
    {
      "id": "gs-028",
      "type": "two-stage",
      "stages": [
        {
          "question": "You index documents in Elasticsearch. Each document has title, body, and tags. How does Elasticsearch store this?",
          "options": [
            "As a single blob",
            "Each field has its own inverted index",
            "In a relational table",
            "As a graph"
          ],
          "correct": 1,
          "explanation": "Each field is indexed separately. The 'title' field has its own inverted index, as does 'body' and 'tags'. Queries can search specific fields (title:shoes) or all fields. Different fields can use different analyzers."
        },
        {
          "question": "You want 'title' matches to score higher than 'body' matches. How?",
          "options": [
            "Delete the body field",
            "Boost the title field in the query",
            "Store title twice",
            "It's not possible"
          ],
          "correct": 1,
          "explanation": "Field boosting: in your query, boost title: {multi_match: {query: 'shoes', fields: ['title^3', 'body']}}. The ^3 means title matches count 3x. Tuning boosts is key to relevance — what fields matter most for your use case?"
        }
      ]
    },
    {
      "id": "gs-029",
      "type": "multiple-choice",
      "question": "What is relevance scoring in search engines?",
      "options": [
        "Counting document views",
        "Calculating how well each document matches the query, typically using TF-IDF or BM25",
        "Sorting by date",
        "Random ordering"
      ],
      "correct": 1,
      "explanation": "Relevance scoring ranks documents by match quality. Classic algorithm: TF-IDF (term frequency × inverse document frequency). Modern: BM25 (Elasticsearch default). Factors: how often the term appears, how rare it is globally, field length."
    },
    {
      "id": "gs-030",
      "type": "multiple-choice",
      "question": "What does TF-IDF measure?",
      "options": [
        "Document size",
        "Term importance: frequent in this document (TF) but rare across all documents (IDF)",
        "Query speed",
        "Index size"
      ],
      "correct": 1,
      "explanation": "TF-IDF: Term Frequency (how often in this doc) × Inverse Document Frequency (how rare across all docs). 'the' has high TF but low IDF (common everywhere). 'elasticsearch' has lower TF but higher IDF (rarer). TF-IDF balances both."
    },
    {
      "id": "gs-031",
      "type": "multi-select",
      "question": "What factors typically affect search relevance scoring?",
      "options": [
        "Term frequency in the document",
        "How rare the term is across all documents",
        "Document length normalization",
        "Document creation date"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "BM25/TF-IDF factors: term frequency (more mentions = more relevant), inverse document frequency (rare terms are more significant), length normalization (don't favor longer documents just for having more words). Date isn't default but can be added as a boost."
    },
    {
      "id": "gs-032",
      "type": "multiple-choice",
      "question": "What is an Elasticsearch index?",
      "options": [
        "A database table",
        "A collection of documents with similar structure, like a database in relational terms",
        "A single document",
        "A query optimization hint"
      ],
      "correct": 1,
      "explanation": "An Elasticsearch index is like a database — it holds documents. Documents in an index typically share a structure (product index, user index). Indexes are split into shards for distribution. Queries can span multiple indexes."
    },
    {
      "id": "gs-033",
      "type": "multiple-choice",
      "question": "What is a shard in Elasticsearch?",
      "options": [
        "A broken piece of glass",
        "A partition of an index, distributed across nodes for scalability",
        "A type of query",
        "A backup copy"
      ],
      "correct": 1,
      "explanation": "An index is divided into shards. Each shard is a self-contained Lucene index. Shards can be on different nodes — this enables horizontal scaling. Primary shards hold data; replica shards are copies for HA and read scaling."
    },
    {
      "id": "gs-034",
      "type": "two-stage",
      "stages": [
        {
          "question": "You create an index with 5 primary shards. Can you change this later?",
          "options": [
            "Yes, just update settings",
            "No — primary shard count is fixed at index creation",
            "Yes, but only by adding shards",
            "Yes, with zero downtime"
          ],
          "correct": 1,
          "explanation": "Primary shard count is fixed at creation. The document-to-shard routing depends on shard count. To change, you must reindex into a new index with different shard count. This is a critical upfront decision."
        },
        {
          "question": "You can change replica count later. Why is that different?",
          "options": [
            "Replicas don't store data",
            "Replicas are copies — adding/removing doesn't change data routing",
            "Replicas are in a different region",
            "It's not different — both are fixed"
          ],
          "correct": 1,
          "explanation": "Replicas are copies of primary shards. Adding replicas just copies data to more nodes (more read capacity, higher availability). Removing replicas deletes copies. Data routing still uses primary shards, so replica count can change anytime."
        }
      ]
    },
    {
      "id": "gs-035",
      "type": "multiple-choice",
      "question": "What is the ELK stack?",
      "options": [
        "A type of animal tracking",
        "Elasticsearch, Logstash, Kibana — for log aggregation, search, and visualization",
        "A programming framework",
        "An encryption standard"
      ],
      "correct": 1,
      "explanation": "ELK: Elasticsearch (search/store), Logstash (collect/transform logs), Kibana (visualize/dashboard). Now often called Elastic Stack, including Beats (lightweight data shippers). Standard for centralized logging and observability."
    },
    {
      "id": "gs-036",
      "type": "multi-select",
      "question": "What does Logstash do in the ELK stack?",
      "options": [
        "Collect logs from various sources",
        "Parse and transform log data",
        "Send data to Elasticsearch",
        "Provide search queries"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Logstash: collects (input plugins for files, syslog, beats, etc.), parses/transforms (filter plugins for grok, mutate, date), outputs (to Elasticsearch, other destinations). It's a data pipeline. For simple forwarding, Filebeat is lighter."
    },
    {
      "id": "gs-037",
      "type": "multiple-choice",
      "question": "What is Kibana?",
      "options": [
        "An Elasticsearch query language",
        "A visualization and dashboard tool for Elasticsearch data",
        "A log collector",
        "A graph database"
      ],
      "correct": 1,
      "explanation": "Kibana provides visualization: dashboards, charts, maps, and the Discover interface for exploring data. It's the 'K' in ELK. Also includes dev tools for Elasticsearch queries and management. The primary UI for Elastic Stack."
    },
    {
      "id": "gs-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're implementing product search for an e-commerce site. Users search for 'comfortable running shoes'. What capabilities do you need?",
          "options": [
            "Exact string matching only",
            "Full-text search with relevance ranking, typo tolerance, and synonym support",
            "SQL queries",
            "Graph traversal"
          ],
          "correct": 1,
          "explanation": "E-commerce search needs: full-text (match across title, description), relevance (best matches first), typo tolerance ('runnning'), synonyms ('sneakers' = 'running shoes'). This is what Elasticsearch/Algolia/Solr provide."
        },
        {
          "question": "Users also want to filter by size, price, and brand, and sort by price. What Elasticsearch features help?",
          "options": [
            "Full-text search only",
            "Aggregations for facets, filters for structured fields, sorting",
            "Graph queries",
            "Time-series functions"
          ],
          "correct": 1,
          "explanation": "Combine: full-text query (match) + filters (term/range for size, price, brand) + aggregations (count products per brand for faceted navigation) + sort (by price). Elasticsearch handles all of this in one query."
        }
      ]
    },
    {
      "id": "gs-039",
      "type": "multiple-choice",
      "question": "What are aggregations in Elasticsearch?",
      "options": [
        "Combining multiple indexes",
        "Computing metrics like counts, averages, histograms across documents",
        "Aggregating servers",
        "Combining queries"
      ],
      "correct": 1,
      "explanation": "Aggregations compute analytics: terms agg (count by category), avg agg (average price), date histogram (orders per day). Used for: faceted search (show counts per filter), dashboards, analytics. Elasticsearch is strong at real-time aggregations."
    },
    {
      "id": "gs-040",
      "type": "multi-select",
      "question": "What types of Elasticsearch aggregations are there?",
      "options": [
        "Bucket aggregations (group documents)",
        "Metric aggregations (calculate values like sum, avg)",
        "Pipeline aggregations (aggregate on aggregation results)",
        "Graph aggregations (traverse relationships)"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Bucket aggs group docs (terms, histogram, date_histogram). Metric aggs calculate values (sum, avg, min, max, cardinality). Pipeline aggs operate on other aggs (derivative, moving_avg). No 'graph aggregations' — Elasticsearch isn't a graph DB."
    },
    {
      "id": "gs-041",
      "type": "multiple-choice",
      "question": "What is Apache Solr?",
      "options": [
        "A solar energy database",
        "An open-source search platform built on Lucene, similar to Elasticsearch",
        "A database for astronomy",
        "A caching layer"
      ],
      "correct": 1,
      "explanation": "Solr is another search platform built on Lucene, like Elasticsearch. It's been around longer, has different operational characteristics. Both are capable; Elasticsearch has gained popularity for its ease of use and ecosystem (ELK)."
    },
    {
      "id": "gs-042",
      "type": "ordering",
      "question": "Rank these from most to least suitable for Elasticsearch:",
      "items": ["Full-text product search", "Real-time log analytics", "OLTP transactional workload", "Site-wide search with autocomplete"],
      "correctOrder": [0, 3, 1, 2],
      "explanation": "Product search and site search are core Elasticsearch strengths. Log analytics works well (ELK stack). OLTP is not suitable — Elasticsearch is eventually consistent, not designed for transactional integrity."
    },
    {
      "id": "gs-043",
      "type": "multiple-choice",
      "question": "What is OpenSearch?",
      "options": [
        "A search engine by Google",
        "AWS's open-source fork of Elasticsearch after licensing changes",
        "A browser search feature",
        "An Elasticsearch plugin"
      ],
      "correct": 1,
      "explanation": "OpenSearch is AWS's fork of Elasticsearch (and Kibana → OpenSearch Dashboards). Created when Elastic changed licenses. AWS continues OpenSearch as open-source. Feature parity is high; ecosystem compatibility varies. AWS uses OpenSearch for their managed service."
    },
    {
      "id": "gs-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your e-commerce site has 10 million products. You need type-ahead autocomplete as users type. What approach?",
          "options": [
            "Full-text search on each keystroke",
            "Completion suggester with prefix matching",
            "Load all products to client and filter",
            "Use a relational database LIKE query"
          ],
          "correct": 1,
          "explanation": "Completion suggester is optimized for prefix matching (as-you-type). It uses a different data structure (FST) for fast prefix lookups. Full-text search on every keystroke is slower. Client-side filtering doesn't scale to 10M products."
        },
        {
          "question": "You also want 'Did you mean?' for typos. What feature?",
          "options": [
            "Completion suggester",
            "Term suggester or phrase suggester",
            "Spell checking plugin required",
            "Not possible in Elasticsearch"
          ],
          "correct": 1,
          "explanation": "Term suggester finds similar terms for potential typos. Phrase suggester does multi-word corrections. Combined with your search, you can show 'Did you mean: running shoes?' when someone searches 'runnin shoez'. Built into Elasticsearch."
        }
      ]
    },
    {
      "id": "gs-045",
      "type": "multiple-choice",
      "question": "What is Algolia?",
      "options": [
        "An algorithm library",
        "A hosted search-as-a-service with focus on speed and developer experience",
        "An Elasticsearch plugin",
        "A database"
      ],
      "correct": 1,
      "explanation": "Algolia is a managed search service. Key differentiators: speed (millisecond responses), great developer experience, built-in features (typo tolerance, synonyms, ranking). Trade-off: more expensive than self-managed, less flexible for complex use cases."
    },
    {
      "id": "gs-046",
      "type": "multi-select",
      "question": "When might you choose Algolia over Elasticsearch?",
      "options": [
        "You want fast setup without managing infrastructure",
        "Developer experience and documentation matter",
        "You need complex log analytics",
        "Budget is limited and you have Elasticsearch expertise"
      ],
      "correctIndices": [0, 1],
      "explanation": "Algolia wins on: hosted (no ops), developer experience (great docs, SDKs, UI components), speed. Elasticsearch wins on: log analytics, complex aggregations, self-managed cost at scale, flexibility. Choose based on your needs and resources."
    },
    {
      "id": "gs-047",
      "type": "multiple-choice",
      "question": "What is Meilisearch?",
      "options": [
        "A search engine by Facebook",
        "An open-source, fast, typo-tolerant search engine designed for ease of use",
        "An Elasticsearch fork",
        "A graph database"
      ],
      "correct": 1,
      "explanation": "Meilisearch is open-source, focused on simplicity and speed. Designed for: site search, product search. Features: instant search, typo tolerance, facets. Simpler than Elasticsearch but less powerful for complex analytics. Good for straightforward search needs."
    },
    {
      "id": "gs-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're choosing between Elasticsearch and a graph database for a fraud detection system. What's the key question?",
          "options": [
            "Which is faster?",
            "Are queries about text search/aggregations or relationship traversal?",
            "Which is cheaper?",
            "Which is more popular?"
          ],
          "correct": 1,
          "explanation": "The key: what are your queries? If fraud detection means: find suspicious text patterns, aggregate transactions → Elasticsearch. If it means: find connected networks of accounts, traverse relationship chains → graph database."
        },
        {
          "question": "Fraud detection needs both: text search on transactions AND traversing account relationships. What approach?",
          "options": [
            "Use only Elasticsearch",
            "Use only a graph database",
            "Use both: Elasticsearch for search, graph DB for relationship analysis",
            "Use a relational database for both"
          ],
          "correct": 2,
          "explanation": "Polyglot persistence: use the right tool for each job. Elasticsearch searches and aggregates transactions. Graph DB finds connected fraud rings. Many fraud systems use both, querying each for its strengths."
        }
      ]
    },
    {
      "id": "gs-049",
      "type": "multiple-choice",
      "question": "What is a mapping in Elasticsearch?",
      "options": [
        "A geographic map visualization",
        "The schema definition for an index — field names, types, and analyzers",
        "A transformation function",
        "A routing table"
      ],
      "correct": 1,
      "explanation": "Mapping defines the index structure: field names, types (text, keyword, date, integer), how to analyze text fields. Like a schema but more flexible — new fields can be auto-detected. Important: once set, changing field types requires reindexing."
    },
    {
      "id": "gs-050",
      "type": "multi-select",
      "question": "What's the difference between 'text' and 'keyword' field types in Elasticsearch?",
      "options": [
        "text is analyzed (tokenized, searchable) for full-text search",
        "keyword is not analyzed — for exact matching, sorting, aggregations",
        "text is for short strings; keyword is for long text",
        "keyword supports fuzzy matching; text doesn't"
      ],
      "correctIndices": [0, 1],
      "explanation": "'text' fields are analyzed: 'The Quick Fox' → ['the', 'quick', 'fox']. 'keyword' is stored exactly: used for exact match, sort, aggregate. Often you want both: multi-field mapping with 'title' (text) and 'title.keyword' (keyword)."
    },
    {
      "id": "gs-051",
      "type": "multiple-choice",
      "question": "Why is Elasticsearch described as 'near real-time'?",
      "options": [
        "It's almost as good as real-time",
        "There's a small delay (1 second by default) before new documents are searchable",
        "It uses near-field communication",
        "Real-time is marketing speak"
      ],
      "correct": 1,
      "explanation": "After indexing, documents aren't immediately searchable. Elasticsearch refreshes indexes periodically (default: 1 second) to make new documents visible. You can force refresh, but it's expensive. This trade-off enables high write throughput."
    },
    {
      "id": "gs-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "You index a document to Elasticsearch and immediately search for it. It's not found. Why?",
          "options": [
            "The document was rejected",
            "The index hasn't refreshed yet — the document isn't searchable until refresh",
            "Wrong query syntax",
            "Network latency"
          ],
          "correct": 1,
          "explanation": "Near real-time: documents are searchable after the next refresh (default 1 second). For immediate reads after write, use refresh: true in the index request (but sparingly — refreshing is expensive)."
        },
        {
          "question": "Setting refresh_interval to -1 disables automatic refresh. When might you do this?",
          "options": [
            "For production search",
            "During bulk indexing — refresh once after the batch completes",
            "To improve search speed",
            "Never — always use default"
          ],
          "correct": 1,
          "explanation": "During bulk/batch indexing, disable refresh (refresh_interval: -1), index all documents, then manually refresh once. This is much faster than refreshing after each document. Restore normal refresh for ongoing writes."
        }
      ]
    },
    {
      "id": "gs-053",
      "type": "multiple-choice",
      "question": "What is a document in Elasticsearch?",
      "options": [
        "A file on disk",
        "A JSON object stored in an index — the basic unit of data",
        "A search query",
        "A shard"
      ],
      "correct": 1,
      "explanation": "Documents are JSON objects: {\"title\": \"...\", \"author\": \"...\", \"content\": \"...\"}. Each has an _id (auto-generated or specified). Documents are stored in indexes. Similar to rows in SQL but schema is flexible (though mappings define types)."
    },
    {
      "id": "gs-054",
      "type": "multi-select",
      "question": "What query types does Elasticsearch support?",
      "options": [
        "match (full-text analyzed search)",
        "term (exact keyword matching)",
        "bool (combine queries with must/should/must_not)",
        "JOIN (like SQL joins)"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Elasticsearch query types: match (full-text), term (exact), bool (combine), range (numeric/date ranges), and many more. No JOINs — it's not relational. For relationships, denormalize or use nested/parent-child documents."
    },
    {
      "id": "gs-055",
      "type": "multiple-choice",
      "question": "What is a bool query in Elasticsearch?",
      "options": [
        "A query that returns true/false",
        "A query that combines multiple queries with AND/OR/NOT logic (must/should/must_not)",
        "A query on boolean fields",
        "A binary search query"
      ],
      "correct": 1,
      "explanation": "Bool query combines clauses: 'must' (AND — all must match), 'should' (OR — any can match, improves score), 'must_not' (NOT — must not match), 'filter' (like must but no scoring). Most real queries use bool to combine conditions."
    },
    {
      "id": "gs-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "You want products matching 'running shoes' that are in stock (status: available) and under $100. How to structure this?",
          "options": [
            "Multiple separate queries",
            "Bool query: must match 'running shoes', filter status=available and price<100",
            "Use SQL",
            "It's not possible"
          ],
          "correct": 1,
          "explanation": "Bool query: {must: [{match: {title: 'running shoes'}}], filter: [{term: {status: 'available'}}, {range: {price: {lt: 100}}}]}. 'must' affects relevance score; 'filter' doesn't (faster, cacheable). Use filter for yes/no criteria."
        },
        {
          "question": "Why put status and price in 'filter' instead of 'must'?",
          "options": [
            "No difference",
            "Filters don't calculate relevance scores — faster and cacheable",
            "Filters are required; must is optional",
            "Filters support more operators"
          ],
          "correct": 1,
          "explanation": "Filter clauses: don't score (faster), are cached (reusable). For exact match criteria (status = available, price < 100), filters are more efficient. Use 'must' for full-text queries where relevance matters."
        }
      ]
    },
    {
      "id": "gs-057",
      "type": "multiple-choice",
      "question": "What are nested documents in Elasticsearch?",
      "options": [
        "Documents stored inside folders",
        "A way to index arrays of objects where each object is independently searchable",
        "Compressed documents",
        "Linked documents"
      ],
      "correct": 1,
      "explanation": "Nested type handles arrays of objects. Without nested: {tags: [{name: 'a', count: 1}, {name: 'b', count: 2}]} is flattened, losing association. With nested, you can query 'tag name=a AND count>0' per object. More storage, specialized queries."
    },
    {
      "id": "gs-058",
      "type": "multi-select",
      "question": "What limitations does Elasticsearch have compared to relational databases?",
      "options": [
        "No ACID transactions — eventually consistent",
        "No JOINs across indexes",
        "Not designed for frequent updates",
        "No support for structured data"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Elasticsearch limitations: eventually consistent (not ACID), no JOINs (denormalize instead), updates are expensive (reindexing segments). It does support structured data (integers, dates, etc.) — it's just optimized for search, not transactions."
    },
    {
      "id": "gs-059",
      "type": "multiple-choice",
      "question": "What is the typical data flow for using Elasticsearch alongside a primary database?",
      "options": [
        "Replace the primary database with Elasticsearch",
        "Write to primary DB, sync changes to Elasticsearch for search",
        "Use Elasticsearch as the only data store",
        "Query primary DB through Elasticsearch"
      ],
      "correct": 1,
      "explanation": "Common pattern: primary database (PostgreSQL, MongoDB) is source of truth. Changes sync to Elasticsearch (via application, CDC, Logstash). Search queries go to Elasticsearch; other queries hit the primary. Polyglot persistence."
    },
    {
      "id": "gs-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "You use PostgreSQL as primary and Elasticsearch for search. How do you keep them in sync?",
          "options": [
            "They auto-sync",
            "Application writes to both, or use CDC tools like Debezium to stream changes",
            "Elasticsearch reads from PostgreSQL on each query",
            "Sync isn't needed"
          ],
          "correct": 1,
          "explanation": "Options: (1) Application writes to both (simple but coupling). (2) CDC: Debezium captures PostgreSQL changes, streams to Kafka, then to Elasticsearch (decoupled, robust). (3) Periodic batch reindex (simpler but laggy)."
        },
        {
          "question": "What if Elasticsearch is briefly out of sync with PostgreSQL?",
          "options": [
            "Critical failure",
            "Often acceptable — search results lag slightly but primary DB is authoritative",
            "Roll back PostgreSQL",
            "Elasticsearch must always be in sync"
          ],
          "correct": 1,
          "explanation": "For search, brief lag is usually acceptable: new products appear a few seconds late in search. The primary DB is authoritative. For important operations (checkout), always use primary DB. Search can be eventually consistent."
        }
      ]
    },
    {
      "id": "gs-061",
      "type": "multiple-choice",
      "question": "What is Apache Lucene?",
      "options": [
        "A graph database",
        "The underlying search library used by Elasticsearch and Solr",
        "A log collector",
        "A database driver"
      ],
      "correct": 1,
      "explanation": "Lucene is the Java search library: inverted indexes, text analysis, relevance scoring. Elasticsearch and Solr are built on Lucene, adding: distribution, REST API, clustering, management. Lucene is the search engine; ES/Solr are platforms."
    },
    {
      "id": "gs-062",
      "type": "multi-select",
      "question": "What challenges exist with graph database scaling?",
      "options": [
        "Traversals may cross partition boundaries",
        "Super-nodes create performance bottlenecks",
        "Sharding is more complex than key-value partitioning",
        "Graph databases are always slower than relational"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Graph scaling challenges: cross-partition traversals (network hops), super-nodes (millions of edges to read), complex sharding (where to split a graph?). Graphs aren't always slower — they're faster for relationship-heavy queries."
    },
    {
      "id": "gs-063",
      "type": "multiple-choice",
      "question": "What is a knowledge graph?",
      "options": [
        "A graph of student grades",
        "A graph representing entities and their relationships to encode knowledge (like Wikidata)",
        "A graph database product",
        "A visualization of education"
      ],
      "correct": 1,
      "explanation": "Knowledge graphs represent entities (people, places, concepts) and relationships (born_in, capital_of) to encode knowledge. Examples: Google Knowledge Graph, Wikidata, enterprise knowledge bases. Often use RDF/SPARQL or property graphs."
    },
    {
      "id": "gs-064",
      "type": "two-stage",
      "stages": [
        {
          "question": "Google shows a panel with structured info when you search 'Albert Einstein'. Where does this come from?",
          "options": [
            "Wikipedia scraping",
            "Google Knowledge Graph — structured entities and relationships",
            "User-submitted data",
            "Random generation"
          ],
          "correct": 1,
          "explanation": "Google Knowledge Graph stores structured data about entities: 'Albert Einstein' — born (1879), nationality (German), known for (relativity). This powers info panels, related searches, and understanding query intent."
        },
        {
          "question": "Building a similar knowledge graph for your domain. What storage would you consider?",
          "options": [
            "Key-value store",
            "Graph database or RDF triple store",
            "Time-series database",
            "File storage"
          ],
          "correct": 1,
          "explanation": "Knowledge graphs naturally fit graph databases (entities as nodes, relationships as edges) or RDF triple stores (entity-predicate-object triples). Neo4j for property graph approach, or Amazon Neptune/Stardog for RDF."
        }
      ]
    },
    {
      "id": "gs-065",
      "type": "multiple-choice",
      "question": "What is vector search?",
      "options": [
        "Searching for arrows",
        "Searching by similarity in high-dimensional vector space (used for semantic search, images, embeddings)",
        "A type of graph traversal",
        "Binary search"
      ],
      "correct": 1,
      "explanation": "Vector search finds similar items in embedding space. Documents/images are converted to vectors (using ML models), stored in vector DBs, queried by similarity (cosine, euclidean). Powers semantic search ('meaning' not just keywords), image similarity, recommendations."
    },
    {
      "id": "gs-066",
      "type": "multi-select",
      "question": "Which databases support vector search?",
      "options": [
        "Elasticsearch (with dense_vector)",
        "Pinecone (purpose-built vector DB)",
        "PostgreSQL (with pgvector)",
        "Neo4j (core feature)"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Elasticsearch has dense_vector type with kNN search. Pinecone is built for vectors. PostgreSQL has pgvector extension. Neo4j is a graph DB, not primarily for vectors (though some integration exists). Vector search is growing in importance."
    },
    {
      "id": "gs-067",
      "type": "multiple-choice",
      "question": "How does semantic search differ from keyword search?",
      "options": [
        "Semantic search uses a thesaurus",
        "Semantic search understands meaning — 'running shoes' matches 'jogging sneakers' even without keyword overlap",
        "Keyword search is more accurate",
        "They're the same"
      ],
      "correct": 1,
      "explanation": "Keyword search matches terms. Semantic search embeds query and documents into vector space where similar meanings are close together. 'running shoes' and 'jogging sneakers' have similar embeddings even with different words. Powered by ML models."
    },
    {
      "id": "gs-068",
      "type": "two-stage",
      "stages": [
        {
          "question": "You want to add semantic search to your product catalog. What's needed?",
          "options": [
            "Better keywords",
            "Embedding model to vectorize products and queries, plus vector storage/search",
            "More synonyms",
            "Faster hardware"
          ],
          "correct": 1,
          "explanation": "Semantic search pipeline: (1) Embedding model (like BERT, OpenAI) converts text to vectors. (2) Index product vectors in vector DB/search. (3) At query time, embed the query, find nearest product vectors. (4) Optionally combine with keyword search."
        },
        {
          "question": "You have Elasticsearch already. Can you add semantic search?",
          "options": [
            "No — need a separate vector DB",
            "Yes — Elasticsearch supports dense_vector fields and kNN search",
            "Only with plugins",
            "Semantic search isn't real"
          ],
          "correct": 1,
          "explanation": "Elasticsearch 8.0+ has native kNN search on dense_vector fields. Store embeddings, query with knn search. You can combine it with traditional BM25 search (hybrid search). No separate vector DB needed, though specialized ones may perform better at scale."
        }
      ]
    },
    {
      "id": "gs-069",
      "type": "ordering",
      "question": "Rank these from best to worst fit for a graph database:",
      "items": ["Recommendation system (users who liked X)", "Simple product catalog", "Social network connections", "Log storage and search"],
      "correctOrder": [2, 0, 1, 3],
      "explanation": "Social networks (traverse connections) are the classic graph case. Recommendations often use graphs (collaborative filtering). Product catalogs might use graphs for relationships but often don't need deep traversal. Log storage needs a search/time-series DB."
    },
    {
      "id": "gs-070",
      "type": "multiple-choice",
      "question": "What is graph neural network (GNN)?",
      "options": [
        "A type of graph database",
        "Machine learning on graph-structured data for tasks like node classification and link prediction",
        "A network of graph databases",
        "A visualization technique"
      ],
      "correct": 1,
      "explanation": "GNNs apply deep learning to graphs. Uses: predict missing links (will users connect?), classify nodes (is this account fake?), predict properties. Not a database — an ML technique that uses graph data. Can be powered by graph DB data."
    },
    {
      "id": "gs-071",
      "type": "multiple-choice",
      "question": "What is Elasticsearch ILM (Index Lifecycle Management)?",
      "options": [
        "Index load management",
        "Automated policies for managing index phases: hot → warm → cold → delete",
        "Index logging management",
        "A backup tool"
      ],
      "correct": 1,
      "explanation": "ILM automates index lifecycle: hot phase (recent, actively indexed), warm (still queried but not written), cold (rarely queried, cheaper storage), delete (after retention period). Essential for log management where data ages out."
    },
    {
      "id": "gs-072",
      "type": "two-stage",
      "stages": [
        {
          "question": "You store application logs in Elasticsearch. After 30 days, you want to delete them. How?",
          "options": [
            "Manual deletion scripts",
            "Use ILM policy with delete phase after 30 days",
            "Truncate the index",
            "Delete isn't supported"
          ],
          "correct": 1,
          "explanation": "Create an ILM policy: after 30 days, transition to delete phase. Attach policy to your log index template. Elasticsearch automatically deletes indexes that age out. No manual cleanup needed."
        },
        {
          "question": "For cost optimization, you want 30-day old logs on cheaper storage before deletion at 90 days. How?",
          "options": [
            "Copy to S3 manually",
            "ILM: hot (7d) → warm (move to cheaper nodes, 30d) → cold (90d) → delete",
            "Use a separate index",
            "Can't tier storage in Elasticsearch"
          ],
          "correct": 1,
          "explanation": "ILM phases with different node attributes: hot nodes (fast SSDs), warm nodes (cheaper HDDs), cold nodes (minimal). ILM migrates data based on age. Also supports: force merge, shrink, searchable snapshots for archived data."
        }
      ]
    },
    {
      "id": "gs-073",
      "type": "multiple-choice",
      "question": "What is ArangoDB?",
      "options": [
        "A fruit database",
        "A multi-model database supporting documents, graphs, and key-value in one engine",
        "A NoSQL-only database",
        "An Oracle product"
      ],
      "correct": 1,
      "explanation": "ArangoDB is multi-model: store documents (like MongoDB), query graphs (like Neo4j), and use key-value patterns — all in one database with one query language (AQL). Simplifies architecture when you need multiple data models."
    },
    {
      "id": "gs-074",
      "type": "multi-select",
      "question": "When might a multi-model database like ArangoDB be beneficial?",
      "options": [
        "Application needs both document storage and graph traversal",
        "Want to avoid managing multiple databases",
        "Need the absolute best performance for one specific model",
        "Simplifying operational complexity"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Multi-model benefits: single DB for multiple needs, simpler ops, unified query language. Trade-off: specialized databases (Neo4j for graphs, Elasticsearch for search) may outperform multi-model at their specialty. Evaluate your specific needs."
    },
    {
      "id": "gs-075",
      "type": "multiple-choice",
      "question": "What is the difference between OLTP and OLAP graph workloads?",
      "options": [
        "No difference for graphs",
        "OLTP: small, fast traversals (real-time); OLAP: large-scale analytics over the entire graph",
        "OLTP is for relational only",
        "OLAP uses more memory"
      ],
      "correct": 1,
      "explanation": "OLTP graphs: 'find friends of user X' — small, fast traversals in real-time. OLAP graphs: 'compute PageRank for all nodes' — full-graph analytics. Different tools: Neo4j for OLTP, graph processing frameworks (GraphX, Neptune Analytics) for OLAP."
    },
    {
      "id": "gs-076",
      "type": "multiple-choice",
      "question": "What is Apache TinkerPop?",
      "options": [
        "A graph visualization tool",
        "A graph computing framework providing the Gremlin query language and standard APIs",
        "A graph database",
        "A game"
      ],
      "correct": 1,
      "explanation": "TinkerPop is a graph computing framework. It defines: Gremlin (traversal language), APIs for graph databases. Many DBs implement TinkerPop (Neptune, JanusGraph, Azure Cosmos DB). Write Gremlin once, run on any TinkerPop-compatible DB."
    },
    {
      "id": "gs-077",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're choosing between Neo4j and Amazon Neptune. What's a key consideration?",
          "options": [
            "They're identical",
            "Neo4j: Cypher, strong ecosystem, can self-host. Neptune: managed, Gremlin/SPARQL, AWS integration",
            "Neo4j is only for small graphs",
            "Neptune is open source"
          ],
          "correct": 1,
          "explanation": "Neo4j: mature, Cypher (intuitive), great tooling, can self-host or use Aura (managed). Neptune: AWS managed, uses Gremlin/SPARQL (not Cypher), integrates with AWS services. Choose based on cloud strategy, query language preference, ops capacity."
        },
        {
          "question": "Your team knows SQL well but not graph query languages. What might help adoption?",
          "options": [
            "Avoid graph databases",
            "Neo4j — Cypher is most SQL-like; good learning resources",
            "Use raw Gremlin — it's simple",
            "Write custom adapters"
          ],
          "correct": 1,
          "explanation": "Cypher is the most approachable for SQL developers: MATCH (a)-[:KNOWS]->(b) RETURN a, b is readable. Neo4j has great documentation and community. Gremlin is more imperative/programmatic. Consider team ramp-up time."
        }
      ]
    },
    {
      "id": "gs-078",
      "type": "multiple-choice",
      "question": "What is the Elasticsearch query DSL?",
      "options": [
        "A programming language",
        "A JSON-based domain-specific language for expressing search queries",
        "A command-line tool",
        "A visualization dashboard"
      ],
      "correct": 1,
      "explanation": "Query DSL is how you write Elasticsearch queries: JSON describing match queries, filters, aggregations, sorting. It's expressive but verbose. Libraries and helpers (elasticsearch-py, NEST) wrap it in friendlier APIs."
    },
    {
      "id": "gs-079",
      "type": "multi-select",
      "question": "What operational tasks are important for Elasticsearch clusters?",
      "options": [
        "Monitoring cluster health and node status",
        "Managing shard allocation and rebalancing",
        "Index lifecycle management for data retention",
        "Defragmenting hard drives"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "ES ops: monitor health (yellow/green/red), manage shards (allocation, rebalancing, hot spots), ILM (aging data through phases), capacity planning (disk, memory, CPU). Disk defragmentation is OS-level, not ES-specific."
    },
    {
      "id": "gs-080",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your Elasticsearch cluster shows yellow health. What does this mean?",
          "options": [
            "Critical failure",
            "All primary shards allocated, but some replica shards are not",
            "Data is being indexed",
            "Everything is fine"
          ],
          "correct": 1,
          "explanation": "Yellow: all primary shards OK (data is safe), but some replicas aren't allocated (reduced redundancy). Common after adding a new index or losing a node. Green: all primaries and replicas OK. Red: some primaries missing (data unavailable)."
        },
        {
          "question": "The cluster stays yellow for hours. Common causes?",
          "options": [
            "Too much data",
            "Not enough nodes to allocate all replicas, or shard allocation disabled",
            "Slow queries",
            "Indexing too fast"
          ],
          "correct": 1,
          "explanation": "Persistent yellow often means: (1) Not enough nodes for replicas (e.g., 1 node cluster with replicas=1 — replica can't be on same node as primary). (2) Allocation settings blocking placement. Check _cluster/allocation/explain."
        }
      ]
    },
    {
      "id": "gs-081",
      "type": "multiple-choice",
      "question": "What is Azure Cosmos DB's graph API?",
      "options": [
        "A standalone graph database",
        "Cosmos DB's graph model accessed via Gremlin queries",
        "A Microsoft Graph feature",
        "An API for diagrams"
      ],
      "correct": 1,
      "explanation": "Cosmos DB is multi-model. Its graph API stores property graphs, queried via Gremlin. Same global distribution, SLAs, and scaling as Cosmos DB. Useful if you're already in Azure ecosystem and need managed graph capabilities."
    },
    {
      "id": "gs-082",
      "type": "ordering",
      "question": "Rank these Elasticsearch use cases from most common to least common:",
      "items": ["Application search (site, product)", "Log aggregation (ELK)", "Metrics storage", "Primary transactional database"],
      "correctOrder": [1, 0, 2, 3],
      "explanation": "Log aggregation (ELK stack) is perhaps the most common ES use case. Application search is core functionality. Metrics are possible but time-series DBs are often better. Primary transactional DB is not recommended — ES isn't designed for transactions."
    },
    {
      "id": "gs-083",
      "type": "multiple-choice",
      "question": "What is typesense?",
      "options": [
        "A typeface library",
        "An open-source, fast search engine focused on developer experience and typo tolerance",
        "An Elasticsearch plugin",
        "A keyboard utility"
      ],
      "correct": 1,
      "explanation": "Typesense is an open-source search engine. Focus: speed (in-memory), simplicity, typo tolerance, out-of-box features. Positioned as a simpler alternative to Elasticsearch for search use cases. Not for log analytics."
    },
    {
      "id": "gs-084",
      "type": "multi-select",
      "question": "When might you choose a simpler search engine (Typesense, Meilisearch) over Elasticsearch?",
      "options": [
        "Need fast setup with sensible defaults",
        "Primary use case is search, not analytics",
        "Need complex aggregations and log analytics",
        "Want minimal operational overhead"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Simpler engines win on: quick setup, search-focused features, low ops. Elasticsearch wins on: complex aggregations, log analytics, ecosystem (ELK), flexibility. Match the tool to your needs."
    },
    {
      "id": "gs-085",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're building a recommendation system: 'users who bought X also bought Y'. Is this a graph problem?",
          "options": [
            "No — recommendations are statistical",
            "Yes — it's about relationships between users and products",
            "Only if using Neo4j",
            "Recommendations can't use graphs"
          ],
          "correct": 1,
          "explanation": "Recommendation can be modeled as graphs: users and products are nodes, purchases are edges. 'Users who bought X also bought Y' traverses from product X to users to their other products. Collaborative filtering on a bipartite graph."
        },
        {
          "question": "Would you use a graph database or other approach?",
          "options": [
            "Must use a graph database",
            "Depends — graph DB for real-time, batch processing for pre-computed recommendations",
            "Only use SQL",
            "Recommendations don't need databases"
          ],
          "correct": 1,
          "explanation": "Options: (1) Real-time graph traversal (Neo4j) for dynamic recommendations. (2) Batch compute (Spark) and store in cache/DB for fast serving. (3) ML-based (embeddings, matrix factorization). Many systems combine approaches."
        }
      ]
    },
    {
      "id": "gs-086",
      "type": "multiple-choice",
      "question": "What is Tigergraph?",
      "options": [
        "A tiger conservation database",
        "A distributed graph database focused on deep link analytics at scale",
        "An open-source Neo4j alternative",
        "A time-series database"
      ],
      "correct": 1,
      "explanation": "TigerGraph is an enterprise graph database emphasizing: deep link analytics (10+ hops), parallel graph processing, high scale. Has its own query language (GSQL). Used in fraud detection, recommendation at large enterprises."
    },
    {
      "id": "gs-087",
      "type": "multiple-choice",
      "question": "What is MemGraph?",
      "options": [
        "An in-memory graph database designed for real-time performance",
        "A memory profiling tool",
        "A graph visualization library",
        "A caching layer for Neo4j"
      ],
      "correct": 0,
      "explanation": "MemGraph is an in-memory graph database with Cypher compatibility. Designed for: real-time, low-latency graph queries. In-memory means faster than disk-based but limited by RAM. Good for real-time fraud, recommendation where speed is critical."
    },
    {
      "id": "gs-088",
      "type": "multi-select",
      "question": "What factors matter when choosing a graph database?",
      "options": [
        "Query language (Cypher, Gremlin, SPARQL)",
        "Scale requirements (single server vs. distributed)",
        "Managed vs. self-hosted options",
        "SQL compatibility"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Consider: query language (team skills, expressiveness), scale (Neo4j single-server vs. distributed options), managed options (Neptune, Aura), ecosystem. SQL compatibility isn't typical — graph DBs have specialized query languages for traversals."
    },
    {
      "id": "gs-089",
      "type": "two-stage",
      "stages": [
        {
          "question": "Your application needs: full-text search on descriptions AND social graph traversal for friend recommendations. How would you architect this?",
          "options": [
            "Use Elasticsearch for everything",
            "Use Neo4j for everything",
            "Elasticsearch for search, Neo4j (or graph) for recommendations",
            "Use a relational database"
          ],
          "correct": 2,
          "explanation": "Polyglot persistence: Elasticsearch excels at search, graph DBs excel at traversals. Use each for its strength. Primary DB (PostgreSQL?) might be source of truth, with sync to ES and graph DB. More complex but better performance."
        },
        {
          "question": "How do you keep Elasticsearch and Neo4j in sync with the primary database?",
          "options": [
            "They auto-sync",
            "Application writes to all three, or use CDC to stream changes",
            "Manual periodic exports",
            "They don't need to be in sync"
          ],
          "correct": 1,
          "explanation": "Sync strategies: (1) Application writes to all (coupling, consistency challenges). (2) CDC (Debezium) captures primary DB changes, streams to both ES and Neo4j. (3) Periodic batch sync (simpler but laggy). CDC is most robust."
        }
      ]
    },
    {
      "id": "gs-090",
      "type": "multiple-choice",
      "question": "What is the biggest mistake when adding search to an application?",
      "options": [
        "Using Elasticsearch",
        "Treating search as just another database query instead of investing in relevance tuning",
        "Having too many indexes",
        "Using cloud services"
      ],
      "correct": 1,
      "explanation": "Search is not just 'query matching'. Good search needs: relevance tuning (field boosts, synonyms), understanding user intent, handling typos, showing useful results. Simply indexing data and querying often yields poor user experience."
    },
    {
      "id": "gs-091",
      "type": "multi-select",
      "question": "What improves search relevance?",
      "options": [
        "Boosting important fields (title > body)",
        "Adding synonyms (sneakers = running shoes)",
        "Tuning the BM25/scoring parameters",
        "Using more shards"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Relevance tuning: field boosts (prioritize matches in title), synonyms (expand coverage), scoring parameters (tune k1, b in BM25), custom scoring (boost recent, popular). Shards affect scale, not relevance."
    },
    {
      "id": "gs-092",
      "type": "multiple-choice",
      "question": "What is query expansion in search?",
      "options": [
        "Making queries longer",
        "Automatically adding related terms to broaden the search (synonyms, stemming)",
        "Expanding to more indexes",
        "Increasing query timeout"
      ],
      "correct": 1,
      "explanation": "Query expansion broadens search: 'TV' expands to 'TV OR television OR LCD OR LED'. Via synonyms, stemming, or ML (word embeddings). Increases recall (more results) but may reduce precision (less targeted). Balance based on use case."
    },
    {
      "id": "gs-093",
      "type": "two-stage",
      "stages": [
        {
          "question": "Users complain search results aren't relevant. First diagnostic step?",
          "options": [
            "Add more hardware",
            "Analyze what users search for and what they click — understand the gap",
            "Delete the index",
            "Switch databases"
          ],
          "correct": 1,
          "explanation": "Understand the problem: what are users searching for? What are they clicking (or not)? What's appearing in results? Log searches and clicks, analyze patterns. This reveals: missing synonyms, wrong field boosts, indexing issues."
        },
        {
          "question": "Users search 'laptop computer' but results show keyboards. What might be wrong?",
          "options": [
            "Database corruption",
            "Products are in a 'computer accessories' category with shared terms, need better field boosts",
            "Too many shards",
            "Elasticsearch doesn't support this"
          ],
          "correct": 1,
          "explanation": "Likely: 'computer' appears in many products (keyboards are 'computer keyboards'). Solutions: boost exact matches, boost title field, use categories in filtering/boosting, analyze why keyboards score higher (maybe more 'computer' mentions in description)."
        }
      ]
    },
    {
      "id": "gs-094",
      "type": "ordering",
      "question": "Rank these from most to least important for production search:",
      "items": ["Relevance tuning", "Ultra-low latency (<5ms)", "Basic functionality working", "Synonym support"],
      "correctOrder": [2, 0, 3, 1],
      "explanation": "First: basic functionality (results appear). Then: relevance (right results). Synonyms improve coverage. Ultra-low latency is nice but 50-100ms is usually fine for search. Prioritize getting good results before micro-optimizing speed."
    },
    {
      "id": "gs-095",
      "type": "multiple-choice",
      "question": "What is the main advantage of managed search services (Elastic Cloud, Amazon OpenSearch Service)?",
      "options": [
        "They're always faster",
        "Reduced operational burden — automatic upgrades, scaling, backups",
        "They're free",
        "Better search algorithms"
      ],
      "correct": 1,
      "explanation": "Managed services handle: cluster provisioning, upgrades, scaling, backups, monitoring. You focus on indexing and queries. Trade-offs: cost (typically higher than self-managed), less control, potential vendor lock-in."
    },
    {
      "id": "gs-096",
      "type": "multi-select",
      "question": "What are trade-offs of self-managed vs. managed Elasticsearch?",
      "options": [
        "Self-managed: more control, lower cost at scale, more ops work",
        "Managed: less ops, higher cost, some limitations",
        "Self-managed is always better",
        "Managed: faster time to production"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Self-managed: control, potentially cheaper at large scale, but significant ops (upgrades, security, monitoring). Managed: quick start, less ops, but costs and some feature limitations. Choice depends on team capacity and scale."
    },
    {
      "id": "gs-097",
      "type": "two-stage",
      "stages": [
        {
          "question": "You're indexing 1TB of product data in Elasticsearch. How many primary shards would you start with?",
          "options": [
            "1 shard",
            "1000 shards",
            "Approximately 20-50 shards (rule of thumb: 20-50GB per shard)",
            "It doesn't matter"
          ],
          "correct": 2,
          "explanation": "Rule of thumb: 20-50GB per shard. 1TB ÷ 50GB = 20 shards. Too few = large shards (slow). Too many = overhead (many small shards). Shard count is fixed after creation, so estimate future growth. Start reasonable, plan to reindex if needed."
        },
        {
          "question": "You expect data to grow to 10TB over 2 years. Strategy?",
          "options": [
            "Create 200 shards now",
            "Use time-based indexes (daily/weekly) with ILM, each with appropriate shards",
            "One giant index forever",
            "Delete old data"
          ],
          "correct": 1,
          "explanation": "Time-based indexes (products-2024.01, products-2024.02 or rolling) allow: appropriate shards per time period, ILM for lifecycle, easy deletion of old data. Aliases provide a unified view. Better than one ever-growing index."
        }
      ]
    },
    {
      "id": "gs-098",
      "type": "multiple-choice",
      "question": "What is an Elasticsearch alias?",
      "options": [
        "An alternative server name",
        "A pointer to one or more indexes, enabling index abstraction and zero-downtime reindexing",
        "A field alias",
        "A user alias"
      ],
      "correct": 1,
      "explanation": "Aliases are logical names pointing to indexes. Query 'products' alias instead of 'products-v1' index. To reindex: create products-v2, reindex data, atomically switch alias. Zero downtime. Also used for filtering (alias with a filter)."
    },
    {
      "id": "gs-099",
      "type": "multi-select",
      "question": "When would you combine graph database with search engine?",
      "options": [
        "Need both relationship traversal and full-text search",
        "Building an e-commerce platform with social features",
        "Simple CRUD application",
        "Knowledge graph with entity search"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Combine when: need traversal (graph) AND search (text matching, relevance). E-commerce with social (product search + friend recommendations). Knowledge graphs (entity relationships + entity search). Simple CRUD likely needs neither."
    },
    {
      "id": "gs-100",
      "type": "multiple-choice",
      "question": "What's the key takeaway about graph databases and search engines?",
      "options": [
        "They replace relational databases entirely",
        "They're specialized tools — use for relationship traversal (graph) or full-text search (search), often alongside other databases",
        "Everyone needs both",
        "They're interchangeable"
      ],
      "correct": 1,
      "explanation": "Graph DBs and search engines are specialized. Graphs excel at relationship traversal; search engines at text matching and relevance. Use them for their strengths, often in polyglot architectures. Don't force-fit — use relational/document DBs for other needs."
    }
  ]
}
