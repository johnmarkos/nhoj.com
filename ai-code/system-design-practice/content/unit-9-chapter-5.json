{
  "unit": 9,
  "unitTitle": "Reliability",
  "chapter": 5,
  "chapterTitle": "Graceful Degradation & Dependency Isolation",
  "chapterDescription": "Preserve core user journeys during dependency degradation with fallback modes and strict boundaries.",
  "problems": [
    {
      "id": "rel-gd-001",
      "type": "multiple-choice",
      "question": "Case Alpha: checkout page render path. Primary reliability risk is non-critical dependency blocking checkout. Which next move is strongest? A rollback window is still available for the next 15 minutes.",
      "options": [
        "Isolate critical path from optional dependencies with strict bulkhead pools.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-002",
      "type": "multiple-choice",
      "question": "Case Beta: profile feed API. Primary reliability risk is fallback mode with stale unsafe data. Which next move is strongest? Leadership asked for an action that lowers recurrence, not just symptoms.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Define fallback data-quality tiers and expose degraded semantics explicitly.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-003",
      "type": "multiple-choice",
      "question": "Case Gamma: recommendation widget service. Primary reliability risk is kill switch missing for expensive feature. Which next move is strongest? Two downstream teams depend on this path during peak traffic.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Use kill switches to disable expensive non-core features within seconds.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-004",
      "type": "multiple-choice",
      "question": "Case Delta: search autosuggest path. Primary reliability risk is bulkhead boundaries crossed by shared pools. Which next move is strongest? Recent game-day results showed hidden cross-zone coupling.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Return minimal safe responses rather than waiting on slow optional calls."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-005",
      "type": "multiple-choice",
      "question": "Case Epsilon: invoice generation flow. Primary reliability risk is degraded mode hidden from clients. Which next move is strongest? Customer impact is concentrated on invariant-critical transactions.",
      "options": [
        "Precompute essential fallback artifacts for high-traffic journeys.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-006",
      "type": "multiple-choice",
      "question": "Case Zeta: notification preference API. Primary reliability risk is partial outage causing full-page failure. Which next move is strongest? The previous mitigation improved averages but not tail behavior.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply per-dependency timeouts and fallback chaining with bounded depth.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-007",
      "type": "multiple-choice",
      "question": "Case Eta: chat attachment pipeline. Primary reliability risk is critical path coupled to optional enrichment. Which next move is strongest? Telemetry indicates one fault domain is driving most failures.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Protect critical write flows from read-path degradation side effects.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-008",
      "type": "multiple-choice",
      "question": "Case Theta: dashboard analytics backend. Primary reliability risk is cache fallback TTL too long for safety. Which next move is strongest? Operations wants a reversible step before broader architecture changes.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Test degradation scenarios in game days to validate user-journey continuity."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        }
      ]
    },
    {
      "id": "rel-gd-009",
      "type": "multiple-choice",
      "question": "Case Iota: catalog browse service. Primary reliability risk is default fallback overloading primary path. Which next move is strongest? SLO burn rate accelerated after a config rollout this morning.",
      "options": [
        "Separate auth/invariant checks from optional personalization dependencies.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-010",
      "type": "multiple-choice",
      "question": "Case Kappa: device sync endpoint. Primary reliability risk is degradation policy undocumented per endpoint. Which next move is strongest? A shared dependency has uncertain health signals right now.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Track degraded-mode activation and recovery as SLO-governed behavior.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-011",
      "type": "multiple-choice",
      "question": "Case Lambda: checkout page render path. Primary reliability risk is non-critical dependency blocking checkout. Which next move is strongest? The incident review highlighted missing boundary ownership.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Isolate critical path from optional dependencies with strict bulkhead pools.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-012",
      "type": "multiple-choice",
      "question": "Case Mu: profile feed API. Primary reliability risk is fallback mode with stale unsafe data. Which next move is strongest? Current runbooks assume fail-stop behavior, but reality is partial failure.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Define fallback data-quality tiers and expose degraded semantics explicitly."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-013",
      "type": "multiple-choice",
      "question": "Case Nu: recommendation widget service. Primary reliability risk is kill switch missing for expensive feature. Which next move is strongest? A canary can be deployed immediately if the strategy is clear.",
      "options": [
        "Use kill switches to disable expensive non-core features within seconds.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-014",
      "type": "multiple-choice",
      "question": "Case Xi: search autosuggest path. Primary reliability risk is bulkhead boundaries crossed by shared pools. Which next move is strongest? Capacity remains available only in one neighboring zone.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Return minimal safe responses rather than waiting on slow optional calls.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "rel-gd-015",
      "type": "multiple-choice",
      "question": "Case Omicron: invoice generation flow. Primary reliability risk is degraded mode hidden from clients. Which next move is strongest? Client retries are already elevated and could amplify mistakes.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Precompute essential fallback artifacts for high-traffic journeys.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-016",
      "type": "multiple-choice",
      "question": "Case Pi: notification preference API. Primary reliability risk is partial outage causing full-page failure. Which next move is strongest? The team must preserve core write correctness under mitigation.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Apply per-dependency timeouts and fallback chaining with bounded depth."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-017",
      "type": "multiple-choice",
      "question": "Case Rho: chat attachment pipeline. Primary reliability risk is critical path coupled to optional enrichment. Which next move is strongest? Recent staffing changes require simpler operational controls.",
      "options": [
        "Protect critical write flows from read-path degradation side effects.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-018",
      "type": "multiple-choice",
      "question": "Case Sigma: dashboard analytics backend. Primary reliability risk is cache fallback TTL too long for safety. Which next move is strongest? Cross-region latency variance increased during the event.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Test degradation scenarios in game days to validate user-journey continuity.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        }
      ]
    },
    {
      "id": "rel-gd-019",
      "type": "multiple-choice",
      "question": "Case Tau: catalog browse service. Primary reliability risk is default fallback overloading primary path. Which next move is strongest? This path mixes latency-sensitive and correctness-sensitive requests.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Separate auth/invariant checks from optional personalization dependencies.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-020",
      "type": "multiple-choice",
      "question": "Case Upsilon: device sync endpoint. Primary reliability risk is degradation policy undocumented per endpoint. Which next move is strongest? The service has one hidden shared component with no backup path.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Track degraded-mode activation and recovery as SLO-governed behavior."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-021",
      "type": "multiple-choice",
      "question": "Case Phi: checkout page render path. Primary reliability risk is non-critical dependency blocking checkout. Which next move is strongest? The product team accepts degraded reads but not incorrect writes.",
      "options": [
        "Isolate critical path from optional dependencies with strict bulkhead pools.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-022",
      "type": "multiple-choice",
      "question": "Case Chi: profile feed API. Primary reliability risk is fallback mode with stale unsafe data. Which next move is strongest? Change approval favors narrowly scoped policies over global flips.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Define fallback data-quality tiers and expose degraded semantics explicitly.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-023",
      "type": "multiple-choice",
      "question": "Case Psi: recommendation widget service. Primary reliability risk is kill switch missing for expensive feature. Which next move is strongest? A previous outage showed stale metadata can outlive infrastructure recovery.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Use kill switches to disable expensive non-core features within seconds.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-024",
      "type": "multiple-choice",
      "question": "Case Omega: search autosuggest path. Primary reliability risk is bulkhead boundaries crossed by shared pools. Which next move is strongest? On-call needs mitigation that is observable by explicit metrics.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Return minimal safe responses rather than waiting on slow optional calls."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-025",
      "type": "multiple-choice",
      "question": "Case Atlas: invoice generation flow. Primary reliability risk is degraded mode hidden from clients. Which next move is strongest? A recent dependency upgrade introduced unknown failure semantics.",
      "options": [
        "Precompute essential fallback artifacts for high-traffic journeys.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-026",
      "type": "multiple-choice",
      "question": "Case Nova: notification preference API. Primary reliability risk is partial outage causing full-page failure. Which next move is strongest? Business impact is highest in the top 5% of critical flows.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply per-dependency timeouts and fallback chaining with bounded depth.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-027",
      "type": "multiple-choice",
      "question": "Case Orion: chat attachment pipeline. Primary reliability risk is critical path coupled to optional enrichment. Which next move is strongest? Regional failover is possible but expensive if used prematurely.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Protect critical write flows from read-path degradation side effects.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-028",
      "type": "multiple-choice",
      "question": "Case Vega: dashboard analytics backend. Primary reliability risk is cache fallback TTL too long for safety. Which next move is strongest? A hot tenant currently consumes disproportionate worker capacity.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Test degradation scenarios in game days to validate user-journey continuity."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        }
      ]
    },
    {
      "id": "rel-gd-029",
      "type": "multiple-choice",
      "question": "Case Helios: catalog browse service. Primary reliability risk is default fallback overloading primary path. Which next move is strongest? The immediate goal is to shrink blast radius while maintaining service.",
      "options": [
        "Separate auth/invariant checks from optional personalization dependencies.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-030",
      "type": "multiple-choice",
      "question": "Case Aurora: device sync endpoint. Primary reliability risk is degradation policy undocumented per endpoint. Which next move is strongest? Queue age is rising even though average CPU appears normal.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Track degraded-mode activation and recovery as SLO-governed behavior.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-031",
      "type": "multiple-choice",
      "question": "Case Nimbus: checkout page render path. Primary reliability risk is non-critical dependency blocking checkout. Which next move is strongest? A control-plane API is healthy but data-plane errors are increasing.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Isolate critical path from optional dependencies with strict bulkhead pools.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-032",
      "type": "multiple-choice",
      "question": "Case Pulse: profile feed API. Primary reliability risk is fallback mode with stale unsafe data. Which next move is strongest? Different teams currently use conflicting reliability vocabulary.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents.",
        "Define fallback data-quality tiers and expose degraded semantics explicitly."
      ],
      "correct": 3,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-033",
      "type": "multiple-choice",
      "question": "Case Forge: recommendation widget service. Primary reliability risk is kill switch missing for expensive feature. Which next move is strongest? Legal/compliance constraints require explicit behavior in degraded mode.",
      "options": [
        "Use kill switches to disable expensive non-core features within seconds.",
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 0,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-034",
      "type": "multiple-choice",
      "question": "Case Harbor: search autosuggest path. Primary reliability risk is bulkhead boundaries crossed by shared pools. Which next move is strongest? Past incidents show this failure mode recurs every quarter.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Return minimal safe responses rather than waiting on slow optional calls.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 1,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-035",
      "type": "multiple-choice",
      "question": "Case Vector: invoice generation flow. Primary reliability risk is degraded mode hidden from clients. Which next move is strongest? User trust impact is tied to visible inconsistency, not only downtime.",
      "options": [
        "Ignore the domain boundary and optimize only global average latency.",
        "Apply one uniform policy everywhere regardless workload criticality.",
        "Precompute essential fallback artifacts for high-traffic journeys.",
        "Rely on manual intervention as the primary control during recurring incidents."
      ],
      "correct": 2,
      "explanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius.",
      "detailedExplanation": "The strongest response addresses the dominant failure mode directly while preserving reliability boundaries and controlled blast radius. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for checkout page render path: signal points to bulkhead boundaries crossed by shared pools. The on-call report includes repeated occurrences across multiple weeks. What is the primary diagnosis?",
          "options": [
            "The design for checkout page render path is mismatched to bulkhead boundaries crossed by shared pools, creating repeat reliability incidents.",
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 0,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Apply per-dependency timeouts and fallback chaining with bounded depth.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 1,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for profile feed API: signal points to degraded mode hidden from clients. The same alert pattern appeared during the last failover drill. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The design for profile feed API is mismatched to degraded mode hidden from clients, creating repeat reliability incidents.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 1,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Protect critical write flows from read-path degradation side effects.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 2,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for recommendation widget service: signal points to partial outage causing full-page failure. A recent release changed timeout and queue settings simultaneously. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "The design for recommendation widget service is mismatched to partial outage causing full-page failure, creating repeat reliability incidents.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 2,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior.",
            "Test degradation scenarios in game days to validate user-journey continuity."
          ],
          "correct": 3,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for search autosuggest path: signal points to critical path coupled to optional enrichment. Regional traffic shifted unexpectedly due to external dependency issues. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications.",
            "The design for search autosuggest path is mismatched to critical path coupled to optional enrichment, creating repeat reliability incidents."
          ],
          "correct": 3,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Separate auth/invariant checks from optional personalization dependencies.",
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 0,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for invoice generation flow: signal points to cache fallback TTL too long for safety. Customer-support tickets show concentrated failures for premium tenants. What is the primary diagnosis?",
          "options": [
            "The design for invoice generation flow is mismatched to cache fallback TTL too long for safety, creating repeat reliability incidents.",
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 0,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Track degraded-mode activation and recovery as SLO-governed behavior.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 1,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for notification preference API: signal points to default fallback overloading primary path. The service map reveals one overloaded shared subdependency. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The design for notification preference API is mismatched to default fallback overloading primary path, creating repeat reliability incidents.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 1,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Isolate critical path from optional dependencies with strict bulkhead pools.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 2,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for chat attachment pipeline: signal points to degradation policy undocumented per endpoint. Recent postmortems flagged unclear ownership boundaries. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "The design for chat attachment pipeline is mismatched to degradation policy undocumented per endpoint, creating repeat reliability incidents.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 2,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior.",
            "Define fallback data-quality tiers and expose degraded semantics explicitly."
          ],
          "correct": 3,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for dashboard analytics backend: signal points to non-critical dependency blocking checkout. Saturation appears before autoscaling can react effectively. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications.",
            "The design for dashboard analytics backend is mismatched to non-critical dependency blocking checkout, creating repeat reliability incidents."
          ],
          "correct": 3,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Use kill switches to disable expensive non-core features within seconds.",
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 0,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for catalog browse service: signal points to fallback mode with stale unsafe data. The team needs a mitigation that is safe to canary first. What is the primary diagnosis?",
          "options": [
            "The design for catalog browse service is mismatched to fallback mode with stale unsafe data, creating repeat reliability incidents.",
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 0,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Return minimal safe responses rather than waiting on slow optional calls.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 1,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for device sync endpoint: signal points to kill switch missing for expensive feature. A stale state window has already produced duplicate operations. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The design for device sync endpoint is mismatched to kill switch missing for expensive feature, creating repeat reliability incidents.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 1,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Precompute essential fallback artifacts for high-traffic journeys.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 2,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for checkout page render path: signal points to bulkhead boundaries crossed by shared pools. A planned migration starts next week, raising risk tolerance questions. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "The design for checkout page render path is mismatched to bulkhead boundaries crossed by shared pools, creating repeat reliability incidents.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 2,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior.",
            "Apply per-dependency timeouts and fallback chaining with bounded depth."
          ],
          "correct": 3,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for profile feed API: signal points to degraded mode hidden from clients. Current dashboards lack one key domain-segmented signal. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications.",
            "The design for profile feed API is mismatched to degraded mode hidden from clients, creating repeat reliability incidents."
          ],
          "correct": 3,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Protect critical write flows from read-path degradation side effects.",
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 0,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for recommendation widget service: signal points to partial outage causing full-page failure. Two related services apply inconsistent retry or failover policies. What is the primary diagnosis?",
          "options": [
            "The design for recommendation widget service is mismatched to partial outage causing full-page failure, creating repeat reliability incidents.",
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 0,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Test degradation scenarios in game days to validate user-journey continuity.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 1,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for search autosuggest path: signal points to critical path coupled to optional enrichment. Error budget burn is now in the red for this service. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The design for search autosuggest path is mismatched to critical path coupled to optional enrichment, creating repeat reliability incidents.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 1,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Separate auth/invariant checks from optional personalization dependencies.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 2,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for invoice generation flow: signal points to cache fallback TTL too long for safety. An executive incident review requests explicit long-term hardening. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "The design for invoice generation flow is mismatched to cache fallback TTL too long for safety, creating repeat reliability incidents.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 2,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior.",
            "Track degraded-mode activation and recovery as SLO-governed behavior."
          ],
          "correct": 3,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for notification preference API: signal points to default fallback overloading primary path. This path is business-critical during a recurring daily peak. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications.",
            "The design for notification preference API is mismatched to default fallback overloading primary path, creating repeat reliability incidents."
          ],
          "correct": 3,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Isolate critical path from optional dependencies with strict bulkhead pools.",
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 0,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for chat attachment pipeline: signal points to degradation policy undocumented per endpoint. Previous fixes optimized throughput but missed correctness controls. What is the primary diagnosis?",
          "options": [
            "The design for chat attachment pipeline is mismatched to degradation policy undocumented per endpoint, creating repeat reliability incidents.",
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 0,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Define fallback data-quality tiers and expose degraded semantics explicitly.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 1,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for dashboard analytics backend: signal points to non-critical dependency blocking checkout. The incident is now affecting one zone and spreading slowly. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The design for dashboard analytics backend is mismatched to non-critical dependency blocking checkout, creating repeat reliability incidents.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 1,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Use kill switches to disable expensive non-core features within seconds.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 2,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for catalog browse service: signal points to fallback mode with stale unsafe data. Traffic mix changed after a mobile-app release. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "The design for catalog browse service is mismatched to fallback mode with stale unsafe data, creating repeat reliability incidents.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 2,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior.",
            "Return minimal safe responses rather than waiting on slow optional calls."
          ],
          "correct": 3,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for device sync endpoint: signal points to kill switch missing for expensive feature. A backup path exists but has not been validated this month. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications.",
            "The design for device sync endpoint is mismatched to kill switch missing for expensive feature, creating repeat reliability incidents."
          ],
          "correct": 3,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Precompute essential fallback artifacts for high-traffic journeys.",
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 0,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for checkout page render path: signal points to bulkhead boundaries crossed by shared pools. The team can deploy one targeted policy update in under an hour. What is the primary diagnosis?",
          "options": [
            "The design for checkout page render path is mismatched to bulkhead boundaries crossed by shared pools, creating repeat reliability incidents.",
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 0,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Apply per-dependency timeouts and fallback chaining with bounded depth.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 1,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for profile feed API: signal points to degraded mode hidden from clients. A synthetic probe confirms inconsistent behavior across fault domains. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The design for profile feed API is mismatched to degraded mode hidden from clients, creating repeat reliability incidents.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 1,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Protect critical write flows from read-path degradation side effects.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 2,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for recommendation widget service: signal points to partial outage causing full-page failure. The top failure class now accounts for more than half of incidents. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "The design for recommendation widget service is mismatched to partial outage causing full-page failure, creating repeat reliability incidents.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 2,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior.",
            "Test degradation scenarios in game days to validate user-journey continuity."
          ],
          "correct": 3,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for search autosuggest path: signal points to critical path coupled to optional enrichment. There is pressure to avoid broad architecture rewrites during business hours. What is the primary diagnosis?",
          "options": [
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications.",
            "The design for search autosuggest path is mismatched to critical path coupled to optional enrichment, creating repeat reliability incidents."
          ],
          "correct": 3,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Separate auth/invariant checks from optional personalization dependencies.",
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 0,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "Incident diagnosis for invoice generation flow: signal points to cache fallback TTL too long for safety. Audit stakeholders require clear traceability for mitigation decisions. What is the primary diagnosis?",
          "options": [
            "The design for invoice generation flow is mismatched to cache fallback TTL too long for safety, creating repeat reliability incidents.",
            "No diagnosis is needed because short-term retries will resolve the issue naturally.",
            "The event is random variance and does not indicate a reliability control gap.",
            "This is purely a monitoring issue with no architecture or policy implications."
          ],
          "correct": 0,
          "explanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior.",
          "detailedExplanation": "The first step is identifying the control mismatch between required reliability behavior and actual system behavior. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        },
        {
          "question": "After diagnosis, what is the strongest next change?",
          "options": [
            "Disable safeguards temporarily so the system can process backlog faster.",
            "Track degraded-mode activation and recovery as SLO-governed behavior.",
            "Delay architecture changes and continue current runbook without policy updates.",
            "Expand traffic immediately to prove confidence in current behavior."
          ],
          "correct": 1,
          "explanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence.",
          "detailedExplanation": "Pick the smallest high-leverage change that closes the identified reliability gap and reduces recurrence. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them."
        }
      ],
      "detailedExplanation": "Apply the relevant estimation formula and verify units. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-061",
      "type": "multi-select",
      "question": "Which indicators most directly reveal cross-domain blast radius? (Select all that apply)",
      "options": [
        "Error/latency spikes correlated by fault domain",
        "Dependency saturation by priority class",
        "Blast-radius mapping for shared services",
        "Single global average latency without segmentation"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-062",
      "type": "multi-select",
      "question": "Which controls reduce hidden single points of failure? (Select all that apply)",
      "options": [
        "Guardrails for degraded modes",
        "Dependency budgets for critical paths",
        "Unbounded retries as a universal fix",
        "Explicit runbooks with abort criteria"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-063",
      "type": "multi-select",
      "question": "During partial failures, which practices improve diagnosis quality? (Select all that apply)",
      "options": [
        "Per-domain isolation of shared dependencies",
        "Bulk traffic expansion before root-cause triage",
        "Priority-aware admission controls",
        "Clear fail-open/fail-closed boundaries"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-064",
      "type": "multi-select",
      "question": "What belongs in a useful dependency failure taxonomy? (Select all that apply)",
      "options": [
        "Relying on tribal knowledge without documentation",
        "Postmortem actions tracked to closure",
        "Validation drills for mitigation changes",
        "Updated contracts for degraded behavior"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-065",
      "type": "multi-select",
      "question": "Which patterns limit correlated failures across zones? (Select all that apply)",
      "options": [
        "Canary failover tests by zone",
        "Independent control-plane dependencies",
        "Per-tenant isolation limits",
        "Assuming all failures are fail-stop"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-066",
      "type": "multi-select",
      "question": "Which runbook elements increase incident execution reliability? (Select all that apply)",
      "options": [
        "Write fencing during failback",
        "Rollback checkpoints in runbooks",
        "Promote any available replica immediately",
        "Freshness checks before promotion"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-067",
      "type": "multi-select",
      "question": "Which signals should trigger graceful isolation first? (Select all that apply)",
      "options": [
        "Blast-radius mapping for shared services",
        "Single global average latency without segmentation",
        "Error/latency spikes correlated by fault domain",
        "Dependency saturation by priority class"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-068",
      "type": "multi-select",
      "question": "Which architectural choices help contain tenant-induced overload? (Select all that apply)",
      "options": [
        "Unbounded retries as a universal fix",
        "Explicit runbooks with abort criteria",
        "Guardrails for degraded modes",
        "Dependency budgets for critical paths"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-069",
      "type": "multi-select",
      "question": "For reliability policies, which items should be explicit per endpoint? (Select all that apply)",
      "options": [
        "Priority-aware admission controls",
        "Clear fail-open/fail-closed boundaries",
        "Per-domain isolation of shared dependencies",
        "Bulk traffic expansion before root-cause triage"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "rel-gd-070",
      "type": "multi-select",
      "question": "Which anti-patterns commonly enlarge outage blast radius? (Select all that apply)",
      "options": [
        "Validation drills for mitigation changes",
        "Updated contracts for degraded behavior",
        "Relying on tribal knowledge without documentation",
        "Postmortem actions tracked to closure"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-071",
      "type": "multi-select",
      "question": "What improves confidence in failover assumptions? (Select all that apply)",
      "options": [
        "Per-tenant isolation limits",
        "Assuming all failures are fail-stop",
        "Canary failover tests by zone",
        "Independent control-plane dependencies"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-072",
      "type": "multi-select",
      "question": "Which data is essential when classifying partial vs fail-stop incidents? (Select all that apply)",
      "options": [
        "Promote any available replica immediately",
        "Freshness checks before promotion",
        "Write fencing during failback",
        "Rollback checkpoints in runbooks"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-073",
      "type": "multi-select",
      "question": "Which controls improve safety when control-plane health is uncertain? (Select all that apply)",
      "options": [
        "Error/latency spikes correlated by fault domain",
        "Dependency saturation by priority class",
        "Blast-radius mapping for shared services",
        "Single global average latency without segmentation"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-074",
      "type": "multi-select",
      "question": "For critical writes, which guardrails reduce corruption risk under faults? (Select all that apply)",
      "options": [
        "Guardrails for degraded modes",
        "Dependency budgets for critical paths",
        "Unbounded retries as a universal fix",
        "Explicit runbooks with abort criteria"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-075",
      "type": "multi-select",
      "question": "Which recurring reviews keep reliability boundaries accurate over time? (Select all that apply)",
      "options": [
        "Per-domain isolation of shared dependencies",
        "Bulk traffic expansion before root-cause triage",
        "Priority-aware admission controls",
        "Clear fail-open/fail-closed boundaries"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-076",
      "type": "multi-select",
      "question": "Which decisions help teams align on reliability trade-offs during incidents? (Select all that apply)",
      "options": [
        "Relying on tribal knowledge without documentation",
        "Postmortem actions tracked to closure",
        "Validation drills for mitigation changes",
        "Updated contracts for degraded behavior"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-077",
      "type": "multi-select",
      "question": "What evidence best shows a mitigation reduced recurrence risk? (Select all that apply)",
      "options": [
        "Canary failover tests by zone",
        "Independent control-plane dependencies",
        "Per-tenant isolation limits",
        "Assuming all failures are fail-stop"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery.",
      "detailedExplanation": "The strongest selections are concrete controls that improve containment, clarity, and controlled recovery. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-078",
      "type": "numeric-input",
      "question": "A service processes 4,200,000 requests/day and 0.22% violate reliability SLO. How many violations/day?",
      "answer": 9240,
      "unit": "requests",
      "tolerance": 0.03,
      "explanation": "0.0022 * 4,200,000 = 9,240.",
      "detailedExplanation": "0.0022 * 4,200,000 = 9,240. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-079",
      "type": "numeric-input",
      "question": "Incident queue receives 1,800 items/min and drains 2,050 items/min. Net drain rate?",
      "answer": 250,
      "unit": "items/min",
      "tolerance": 0,
      "explanation": "2,050 - 1,800 = 250.",
      "detailedExplanation": "2,050 - 1,800 = 250. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "rel-gd-080",
      "type": "numeric-input",
      "question": "Retry policy adds 0.35 extra attempts per request at 60,000 req/sec. Effective attempts/sec?",
      "answer": 81000,
      "unit": "attempts/sec",
      "tolerance": 0.02,
      "explanation": "60,000 * 1.35 = 81,000.",
      "detailedExplanation": "60,000 * 1.35 = 81,000. Message systems should be evaluated on delivery semantics, ordering scope, replay behavior, and backpressure handling under failure.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-081",
      "type": "numeric-input",
      "question": "Failover takes 18 seconds and happens 21 times/day. Total failover seconds/day?",
      "answer": 378,
      "unit": "seconds",
      "tolerance": 0,
      "explanation": "18 * 21 = 378.",
      "detailedExplanation": "18 * 21 = 378. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-082",
      "type": "numeric-input",
      "question": "Target p99 latency is 700ms; observed p99 is 980ms. Percent over target?",
      "answer": 40,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "(980 - 700) / 700 = 40%.",
      "detailedExplanation": "(980 - 700) / 700 = 40%. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-083",
      "type": "numeric-input",
      "question": "If 31% of 120,000 requests/min are critical-path, how many critical requests/min?",
      "answer": 37200,
      "unit": "requests/min",
      "tolerance": 0.02,
      "explanation": "0.31 * 120,000 = 37,200.",
      "detailedExplanation": "0.31 * 120,000 = 37,200. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-084",
      "type": "numeric-input",
      "question": "Error rate drops from 1.2% to 0.3%. Percent reduction?",
      "answer": 75,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "(1.2 - 0.3) / 1.2 = 75%.",
      "detailedExplanation": "(1.2 - 0.3) / 1.2 = 75%. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-085",
      "type": "numeric-input",
      "question": "A 7-node quorum system requires majority writes. Minimum acknowledgements required?",
      "answer": 4,
      "unit": "acks",
      "tolerance": 0,
      "explanation": "Majority of 7 is 4.",
      "detailedExplanation": "Majority of 7 is 4. Consistency decisions should be anchored to required invariants and failure modes, then balanced against latency and availability costs.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-086",
      "type": "numeric-input",
      "question": "Backlog is 48,000 tasks and net drain is 320 tasks/min. Minutes to clear backlog?",
      "answer": 150,
      "unit": "minutes",
      "tolerance": 0,
      "explanation": "48,000 / 320 = 150.",
      "detailedExplanation": "48,000 / 320 = 150. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-087",
      "type": "numeric-input",
      "question": "A system with 14 zones has 2 unavailable. What percent remain available?",
      "answer": 85.71,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "12 / 14 = 85.71%.",
      "detailedExplanation": "12 / 14 = 85.71%. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-088",
      "type": "numeric-input",
      "question": "MTTR improved from 45 min to 30 min. Percent reduction?",
      "answer": 33.33,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "(45 - 30) / 45 = 33.33%.",
      "detailedExplanation": "(45 - 30) / 45 = 33.33%. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-089",
      "type": "numeric-input",
      "question": "If 9% of 2,500,000 daily operations need manual recovery checks, checks/day?",
      "answer": 225000,
      "unit": "operations",
      "tolerance": 0.02,
      "explanation": "0.09 * 2,500,000 = 225,000.",
      "detailedExplanation": "0.09 * 2,500,000 = 225,000. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-090",
      "type": "ordering",
      "question": "Order a reliability response lifecycle.",
      "items": [
        "Detect and scope affected fault domains",
        "Contain blast radius with safe controls",
        "Apply targeted root-cause mitigation",
        "Validate recovery and harden recurrence defenses"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Scope, contain, fix, then harden.",
      "detailedExplanation": "Scope, contain, fix, then harden. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-091",
      "type": "ordering",
      "question": "Order from lowest to highest reliability risk.",
      "items": [
        "Isolated dependency with fallback and budget",
        "Shared dependency with guardrails",
        "Shared dependency without domain limits",
        "Implicit dependency with no failure policy"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Risk grows as boundaries and controls are removed.",
      "detailedExplanation": "Risk grows as boundaries and controls are removed. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-092",
      "type": "ordering",
      "question": "Order failover safety steps.",
      "items": [
        "Verify candidate health and freshness",
        "Fence stale writers and freeze unsafe paths",
        "Shift critical traffic gradually",
        "Run failback readiness checks before restoration"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Safety comes from validation, fencing, gradual shift, and planned restoration.",
      "detailedExplanation": "Safety comes from validation, fencing, gradual shift, and planned restoration. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-093",
      "type": "ordering",
      "question": "Order by increasing overload-protection strength.",
      "items": [
        "No admission limits",
        "Global static request cap",
        "Priority-aware shedding",
        "Priority-aware shedding plus per-domain concurrency bounds"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Protection strengthens with class-aware and domain-aware controls.",
      "detailedExplanation": "Protection strengthens with class-aware and domain-aware controls. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-094",
      "type": "ordering",
      "question": "Order data recovery execution.",
      "items": [
        "Select recovery point by RPO target",
        "Restore into validation environment",
        "Verify integrity and reconcile diffs",
        "Promote and re-enable writes with monitoring"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Reliable recovery is staged and verified before write promotion.",
      "detailedExplanation": "Reliable recovery is staged and verified before write promotion. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-095",
      "type": "ordering",
      "question": "Order reliability operations loop.",
      "items": [
        "Define SLIs tied to user impact",
        "Set SLO and error-budget policy",
        "Operate alerts/runbooks against policy",
        "Review incidents and close corrective actions"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "The operations loop ties objective targets to execution and learning.",
      "detailedExplanation": "The operations loop ties objective targets to execution and learning. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-096",
      "type": "ordering",
      "question": "Order by increasing blast radius.",
      "items": [
        "Single process failure",
        "Single node failure",
        "Single zone failure",
        "Cross-region control-plane failure"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Blast radius expands from local process to regional control failure.",
      "detailedExplanation": "Blast radius expands from local process to regional control failure. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-097",
      "type": "ordering",
      "question": "Order retry-policy maturity.",
      "items": [
        "Fixed immediate retries",
        "Capped exponential backoff",
        "Capped backoff with jitter",
        "Jittered backoff with retry budgets and telemetry"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Maturity grows with safeguards and measurable control.",
      "detailedExplanation": "Maturity grows with safeguards and measurable control. Message systems should be evaluated on delivery semantics, ordering scope, replay behavior, and backpressure handling under failure.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-098",
      "type": "ordering",
      "question": "Order degradation sophistication.",
      "items": [
        "Undocumented ad hoc fallback",
        "Manual kill switch only",
        "Documented fallback tiers per endpoint",
        "Automated policy-driven degradation with user semantics"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Sophistication increases with explicit, automated, user-visible policy.",
      "detailedExplanation": "Sophistication increases with explicit, automated, user-visible policy. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "rel-gd-099",
      "type": "ordering",
      "question": "Order incident command rigor.",
      "items": [
        "Ad hoc responders with no roles",
        "Named incident commander only",
        "Commander plus role-defined operations",
        "Role-defined operations plus decision log and action tracking"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Rigor improves with role clarity, timeline, and accountability.",
      "detailedExplanation": "Rigor improves with role clarity, timeline, and accountability. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "rel-gd-100",
      "type": "ordering",
      "question": "Order reliability validation confidence.",
      "items": [
        "Single success in staging",
        "Limited production canary success",
        "Sustained SLO recovery in production",
        "Sustained recovery plus recurrence drill pass"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Confidence rises with sustained production behavior and recurrence testing.",
      "detailedExplanation": "Confidence rises with sustained production behavior and recurrence testing. Convert targets into concrete counts and time budgets first, then reason about whether incident frequency and recovery time can satisfy them.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    }
  ]
}
