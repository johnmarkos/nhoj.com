{
  "unit": 8,
  "unitTitle": "Consistency & Coordination",
  "chapter": 5,
  "chapterTitle": "Coordination Patterns & Distributed Locking",
  "chapterDescription": "Designing safe coordination using leases, leader election, fencing tokens, and lock policies that balance safety and liveness under failures.",
  "problems": [
    {
      "id": "cc-cl-001",
      "type": "multiple-choice",
      "question": "A payment worker lease scheduler is facing split-brain leadership after network partition. Which coordination/locking decision is strongest? A recent partition event exposed ownership ambiguity.",
      "options": [
        "Use fencing tokens and enforce token checks at the resource boundary.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Given the observed bottleneck and guardrails, coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A payment worker lease scheduler is facing split-brain leadership after network partition, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The key clue in this question is \"payment worker lease scheduler is facing split-brain leadership after network partition\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-002",
      "type": "multiple-choice",
      "question": "A inventory reservation lock service is facing lock expiry and stale owner writes. Which coordination/locking decision is strongest? Correctness requires exactly-once side effects at boundaries.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use lease-based ownership with renewals and conservative expiry margins."
      ],
      "correct": 3,
      "explanation": "From an incident-first perspective, coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A inventory reservation lock service is facing lock expiry and stale owner writes, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Read this as a scenario about \"inventory reservation lock service is facing lock expiry and stale owner writes\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-003",
      "type": "multiple-choice",
      "question": "A leader-elected config updater is facing lost lease renewal under GC pause. Which coordination/locking decision is strongest? Coordination latency budget is tight but secondary to correctness.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use randomized backoff/jitter for lock retries to avoid herd effects.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Under the stated reliability and cost constraints, coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A leader-elected config updater is facing lost lease renewal under GC pause, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The decision turns on \"leader-elected config updater is facing lost lease renewal under GC pause\". Discard cache tactics that hide consistency bugs under high load. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-004",
      "type": "multiple-choice",
      "question": "A distributed cron executor is facing thundering herd on lock acquisition. Which coordination/locking decision is strongest? Current implementation lacks explicit fencing semantics.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Separate leader election from work ownership and verify epoch on writes.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Prioritizing blast-radius reduction first, coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A distributed cron executor is facing thundering herd on lock acquisition, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "This prompt is really about \"distributed cron executor is facing thundering herd on lock acquisition\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-005",
      "type": "multiple-choice",
      "question": "A queue consumer coordination service is facing lock service partial outage. Which coordination/locking decision is strongest? The service saw duplicate singleton execution last week.",
      "options": [
        "Implement deterministic lock handoff/draining for graceful ownership transfer.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "With latency and correctness objectives explicit, coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A queue consumer coordination service is facing lock service partial outage, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "Use \"queue consumer coordination service is facing lock service partial outage\" as your starting point, then verify tradeoffs carefully. Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-006",
      "type": "multiple-choice",
      "question": "A session cleanup lease manager is facing clock-skew affecting lease validity. Which coordination/locking decision is strongest? Operators need deterministic failover runbooks.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use quorum-backed coordination store with monotonic session/term semantics."
      ],
      "correct": 3,
      "explanation": "Looking at rollback safety and operational load, coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A session cleanup lease manager is facing clock-skew affecting lease validity, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "The core signal here is \"session cleanup lease manager is facing clock-skew affecting lease validity\". Eliminate answers that do not directly address the failure mode, recovery path, or blast radius. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-007",
      "type": "multiple-choice",
      "question": "A order pipeline coordinator is facing double execution of singleton job. Which coordination/locking decision is strongest? Backoff behavior is currently synchronized across workers.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Apply idempotent job execution with dedupe key even for singleton tasks.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A order pipeline coordinator is facing double execution of singleton job, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "If you keep \"order pipeline coordinator is facing double execution of singleton job\" in view, the correct answer separates faster. Eliminate answers that do not directly address the failure mode, recovery path, or blast radius. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-008",
      "type": "multiple-choice",
      "question": "A fraud rule publisher lock path is facing fencing token not enforced downstream. Which coordination/locking decision is strongest? System clocks are not trusted for strict lease authority.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Detect and revoke stale ownership via heartbeat + session invalidation.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A fraud rule publisher lock path is facing fencing token not enforced downstream, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Start from \"fraud rule publisher lock path is facing fencing token not enforced downstream\", then pressure-test the result against the options. Reject options that improve speed but weaken freshness or invalidation correctness. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-009",
      "type": "multiple-choice",
      "question": "A document edit lock manager is facing lock starvation under high contention. Which coordination/locking decision is strongest? Incident analysis found stale owners writing after failover.",
      "options": [
        "Instrument lock delay/renew failure metrics and trigger safe degraded mode.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A document edit lock manager is facing lock starvation under high contention, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The key clue in this question is \"document edit lock manager is facing lock starvation under high contention\". Eliminate answers that do not directly address the failure mode, recovery path, or blast radius. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-010",
      "type": "multiple-choice",
      "question": "A quota reset coordinator is facing orphaned lock after worker crash. Which coordination/locking decision is strongest? The team needs safe degraded behavior under lock-store outage.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Scope lock granularity to reduce contention hot spots and starvation risk."
      ],
      "correct": 3,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A quota reset coordinator is facing orphaned lock after worker crash, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "The decision turns on \"quota reset coordinator is facing orphaned lock after worker crash\". Prefer the choice that keeps client behavior explicit while preserving evolvability. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-011",
      "type": "multiple-choice",
      "question": "A tenant migration orchestrator is facing split-brain leadership after network partition. Which coordination/locking decision is strongest? GC pauses are common in one runtime tier.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use fencing tokens and enforce token checks at the resource boundary.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A tenant migration orchestrator is facing split-brain leadership after network partition, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "Read this as a scenario about \"tenant migration orchestrator is facing split-brain leadership after network partition\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-012",
      "type": "multiple-choice",
      "question": "A cache rebuild coordinator is facing lock expiry and stale owner writes. Which coordination/locking decision is strongest? Cross-region links occasionally flap under load.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Use lease-based ownership with renewals and conservative expiry margins.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A cache rebuild coordinator is facing lock expiry and stale owner writes, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "The key clue in this question is \"cache rebuild coordinator is facing lock expiry and stale owner writes\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-013",
      "type": "multiple-choice",
      "question": "A notification batch ownership service is facing lost lease renewal under GC pause. Which coordination/locking decision is strongest? Downstream services currently trust caller identity only.",
      "options": [
        "Use randomized backoff/jitter for lock retries to avoid herd effects.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A notification batch ownership service is facing lost lease renewal under GC pause, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "Start from \"notification batch ownership service is facing lost lease renewal under GC pause\", then pressure-test the result against the options. Reject options that improve speed but weaken freshness or invalidation correctness. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-014",
      "type": "multiple-choice",
      "question": "A data export leader election service is facing thundering herd on lock acquisition. Which coordination/locking decision is strongest? Leader transitions happen frequently during deploys.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Separate leader election from work ownership and verify epoch on writes."
      ],
      "correct": 3,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A data export leader election service is facing thundering herd on lock acquisition, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "If you keep \"data export leader election service is facing thundering herd on lock acquisition\" in view, the correct answer separates faster. Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-015",
      "type": "multiple-choice",
      "question": "A index rebuild lock service is facing lock service partial outage. Which coordination/locking decision is strongest? Lock contention spikes at minute boundaries.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Implement deterministic lock handoff/draining for graceful ownership transfer.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A index rebuild lock service is facing lock service partial outage, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The core signal here is \"index rebuild lock service is facing lock service partial outage\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-016",
      "type": "multiple-choice",
      "question": "A feature rollout coordinator is facing clock-skew affecting lease validity. Which coordination/locking decision is strongest? Retry storms correlate with ownership churn.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Use quorum-backed coordination store with monotonic session/term semantics.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A feature rollout coordinator is facing clock-skew affecting lease validity, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Use \"feature rollout coordinator is facing clock-skew affecting lease validity\" as your starting point, then verify tradeoffs carefully. Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-017",
      "type": "multiple-choice",
      "question": "A billing close-job lock manager is facing double execution of singleton job. Which coordination/locking decision is strongest? Some jobs can tolerate delay but not duplication.",
      "options": [
        "Apply idempotent job execution with dedupe key even for singleton tasks.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A billing close-job lock manager is facing double execution of singleton job, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "This prompt is really about \"billing close-job lock manager is facing double execution of singleton job\". Reject options that improve speed but weaken freshness or invalidation correctness. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-018",
      "type": "multiple-choice",
      "question": "A shipment allocator lease service is facing fencing token not enforced downstream. Which coordination/locking decision is strongest? A prior fix increased throughput but reduced safety.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Detect and revoke stale ownership via heartbeat + session invalidation."
      ],
      "correct": 3,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A shipment allocator lease service is facing fencing token not enforced downstream, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "The decision turns on \"shipment allocator lease service is facing fencing token not enforced downstream\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-019",
      "type": "multiple-choice",
      "question": "A reconciliation task coordinator is facing lock starvation under high contention. Which coordination/locking decision is strongest? Tenant fairness is required during lock acquisition.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Instrument lock delay/renew failure metrics and trigger safe degraded mode.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A reconciliation task coordinator is facing lock starvation under high contention, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "Read this as a scenario about \"reconciliation task coordinator is facing lock starvation under high contention\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-020",
      "type": "multiple-choice",
      "question": "A moderation queue ownership service is facing orphaned lock after worker crash. Which coordination/locking decision is strongest? Ownership telemetry is incomplete during incidents.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Scope lock granularity to reduce contention hot spots and starvation risk.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A moderation queue ownership service is facing orphaned lock after worker crash, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Read this as a scenario about \"moderation queue ownership service is facing orphaned lock after worker crash\". Reject options that improve speed but weaken freshness or invalidation correctness. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-021",
      "type": "multiple-choice",
      "question": "A payment worker lease scheduler is facing split-brain leadership after network partition. Which coordination/locking decision is strongest? Multiple workers may race after restart storms.",
      "options": [
        "Use fencing tokens and enforce token checks at the resource boundary.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A payment worker lease scheduler is facing split-brain leadership after network partition, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The decision turns on \"payment worker lease scheduler is facing split-brain leadership after network partition\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-022",
      "type": "multiple-choice",
      "question": "A inventory reservation lock service is facing lock expiry and stale owner writes. Which coordination/locking decision is strongest? Rollback safety is required for any coordinator changes.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use lease-based ownership with renewals and conservative expiry margins."
      ],
      "correct": 3,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A inventory reservation lock service is facing lock expiry and stale owner writes, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Start from \"inventory reservation lock service is facing lock expiry and stale owner writes\", then pressure-test the result against the options. Reject options that improve speed but weaken freshness or invalidation correctness. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-023",
      "type": "multiple-choice",
      "question": "A leader-elected config updater is facing lost lease renewal under GC pause. Which coordination/locking decision is strongest? Critical resource updates must reject stale owners.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use randomized backoff/jitter for lock retries to avoid herd effects.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A leader-elected config updater is facing lost lease renewal under GC pause, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The key clue in this question is \"leader-elected config updater is facing lost lease renewal under GC pause\". Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-024",
      "type": "multiple-choice",
      "question": "A distributed cron executor is facing thundering herd on lock acquisition. Which coordination/locking decision is strongest? Capacity limits prevent blanket strictness on all paths.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Separate leader election from work ownership and verify epoch on writes.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A distributed cron executor is facing thundering herd on lock acquisition, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "The core signal here is \"distributed cron executor is facing thundering herd on lock acquisition\". Discard cache tactics that hide consistency bugs under high load. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-025",
      "type": "multiple-choice",
      "question": "A queue consumer coordination service is facing lock service partial outage. Which coordination/locking decision is strongest? Ownership semantics need explicit API contracts.",
      "options": [
        "Implement deterministic lock handoff/draining for graceful ownership transfer.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A queue consumer coordination service is facing lock service partial outage, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "If you keep \"queue consumer coordination service is facing lock service partial outage\" in view, the correct answer separates faster. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-026",
      "type": "multiple-choice",
      "question": "A session cleanup lease manager is facing clock-skew affecting lease validity. Which coordination/locking decision is strongest? Queue backlog grows when lock retries synchronize.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use quorum-backed coordination store with monotonic session/term semantics."
      ],
      "correct": 3,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A session cleanup lease manager is facing clock-skew affecting lease validity, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "This prompt is really about \"session cleanup lease manager is facing clock-skew affecting lease validity\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-027",
      "type": "multiple-choice",
      "question": "A order pipeline coordinator is facing double execution of singleton job. Which coordination/locking decision is strongest? Failure detector false positives occur under packet loss.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Apply idempotent job execution with dedupe key even for singleton tasks.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A order pipeline coordinator is facing double execution of singleton job, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "Use \"order pipeline coordinator is facing double execution of singleton job\" as your starting point, then verify tradeoffs carefully. Discard cache tactics that hide consistency bugs under high load. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-028",
      "type": "multiple-choice",
      "question": "A fraud rule publisher lock path is facing fencing token not enforced downstream. Which coordination/locking decision is strongest? Coordination store maintenance windows are unavoidable.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Detect and revoke stale ownership via heartbeat + session invalidation.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A fraud rule publisher lock path is facing fencing token not enforced downstream, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Read this as a scenario about \"fraud rule publisher lock path is facing fencing token not enforced downstream\". Discard cache tactics that hide consistency bugs under high load. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-029",
      "type": "multiple-choice",
      "question": "A document edit lock manager is facing lock starvation under high contention. Which coordination/locking decision is strongest? Failover drills showed ambiguous leader epochs.",
      "options": [
        "Instrument lock delay/renew failure metrics and trigger safe degraded mode.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A document edit lock manager is facing lock starvation under high contention, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The decision turns on \"document edit lock manager is facing lock starvation under high contention\". Prioritize the option that best protects the reliability objective under the stated failure conditions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-030",
      "type": "multiple-choice",
      "question": "A quota reset coordinator is facing orphaned lock after worker crash. Which coordination/locking decision is strongest? Current docs do not define lock liveness guarantees.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Scope lock granularity to reduce contention hot spots and starvation risk."
      ],
      "correct": 3,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A quota reset coordinator is facing orphaned lock after worker crash, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "Use \"quota reset coordinator is facing orphaned lock after worker crash\" as your starting point, then verify tradeoffs carefully. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-031",
      "type": "multiple-choice",
      "question": "A tenant migration orchestrator is facing split-brain leadership after network partition. Which coordination/locking decision is strongest? Compensating actions exist but are rarely tested.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Use fencing tokens and enforce token checks at the resource boundary.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A tenant migration orchestrator is facing split-brain leadership after network partition, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "This prompt is really about \"tenant migration orchestrator is facing split-brain leadership after network partition\". Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-032",
      "type": "multiple-choice",
      "question": "A cache rebuild coordinator is facing lock expiry and stale owner writes. Which coordination/locking decision is strongest? Data writes should be safe even during leadership churn.",
      "options": [
        "Assume lock holder identity is always current without epoch checks.",
        "Use lease-based ownership with renewals and conservative expiry margins.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps."
      ],
      "correct": 1,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A cache rebuild coordinator is facing lock expiry and stale owner writes, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "If you keep \"cache rebuild coordinator is facing lock expiry and stale owner writes\" in view, the correct answer separates faster. Prefer the choice that balances hit rate with clear staleness and invalidation behavior. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-033",
      "type": "multiple-choice",
      "question": "A notification batch ownership service is facing lost lease renewal under GC pause. Which coordination/locking decision is strongest? Critical windows cannot pause all coordinators simultaneously.",
      "options": [
        "Use randomized backoff/jitter for lock retries to avoid herd effects.",
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks."
      ],
      "correct": 0,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A notification batch ownership service is facing lost lease renewal under GC pause, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "The core signal here is \"notification batch ownership service is facing lost lease renewal under GC pause\". Prefer the choice that balances hit rate with clear staleness and invalidation behavior. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-034",
      "type": "multiple-choice",
      "question": "A data export leader election service is facing thundering herd on lock acquisition. Which coordination/locking decision is strongest? This path is high-impact despite low request volume.",
      "options": [
        "Use wall-clock timestamps alone to validate lease ownership.",
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Separate leader election from work ownership and verify epoch on writes."
      ],
      "correct": 3,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A data export leader election service is facing thundering herd on lock acquisition, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
      "detailedExplanation": "The key clue in this question is \"data export leader election service is facing thundering herd on lock acquisition\". Discard cache tactics that hide consistency bugs under high load. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-035",
      "type": "multiple-choice",
      "question": "A index rebuild lock service is facing lock service partial outage. Which coordination/locking decision is strongest? Post-incident prevention must be measurable.",
      "options": [
        "Disable lock expiration to avoid ownership flaps.",
        "Assume lock holder identity is always current without epoch checks.",
        "Implement deterministic lock handoff/draining for graceful ownership transfer.",
        "Use wall-clock timestamps alone to validate lease ownership."
      ],
      "correct": 2,
      "explanation": "Coordination correctness requires explicit ownership validity, stale-owner rejection, and failure-aware lease semantics. For A index rebuild lock service is facing lock service partial outage, this is the strongest fit in Coordination Patterns & Distributed Locking.",
      "detailedExplanation": "Start from \"index rebuild lock service is facing lock service partial outage\", then pressure-test the result against the options. Eliminate answers that do not directly address the failure mode, recovery path, or blast radius. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: leader-elected config updater reports failures around thundering herd on lock acquisition. What is the primary diagnosis?",
          "options": [
            "The current coordination model for leader-elected config updater mismatches thundering herd on lock acquisition, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation."
          ],
          "correct": 0,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For leader-elected config updater reports failures around thundering herd on lock acquisition, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Use \"scenario: leader-elected config updater reports failures around thundering herd on lock\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change while preventing stale-owner writes?",
          "options": [
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Implement deterministic lock handoff/draining for graceful ownership transfer."
          ],
          "correct": 3,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change while preventing stale-owner writes, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The core signal here is \"after confirming diagnosis, what is the strongest next change while preventing\". Solve this as chained reasoning where stage two must respect stage one assumptions. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates."
        }
      ],
      "detailedExplanation": "The decision turns on \"coordination Patterns & Distributed Locking\". Solve this as chained reasoning where stage two must respect stage one assumptions. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: distributed cron executor reports failures around lock service partial outage. What is the primary diagnosis?",
          "options": [
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for distributed cron executor mismatches lock service partial outage, creating safety/liveness risk."
          ],
          "correct": 3,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For distributed cron executor reports failures around lock service partial outage, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Read this as a scenario about \"scenario: distributed cron executor reports failures around lock service partial outage\". Solve this as chained reasoning where stage two must respect stage one assumptions. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change during partition recovery?",
          "options": [
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Use quorum-backed coordination store with monotonic session/term semantics.",
            "Force a single global lock for all workflows to simplify ownership."
          ],
          "correct": 2,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change during partition recovery, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The key clue in this question is \"after confirming diagnosis, what is the strongest next change during partition recovery\". Solve this as chained reasoning where stage two must respect stage one assumptions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"coordination Patterns & Distributed Locking\". Do not reset assumptions between stages; carry forward prior constraints directly. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: queue consumer coordination service reports failures around clock-skew affecting lease validity. What is the primary diagnosis?",
          "options": [
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for queue consumer coordination service mismatches clock-skew affecting lease validity, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains."
          ],
          "correct": 2,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For queue consumer coordination service reports failures around clock-skew affecting lease validity, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The decision turns on \"scenario: queue consumer coordination service reports failures around clock-skew\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: consumer lag growth under burst traffic."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change under lock-store latency spikes?",
          "options": [
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Apply idempotent job execution with dedupe key even for singleton tasks.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable."
          ],
          "correct": 1,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change under lock-store latency spikes, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Start from \"after confirming diagnosis, what is the strongest next change under lock-store latency\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes."
        }
      ],
      "detailedExplanation": "Use \"coordination Patterns & Distributed Locking\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: session cleanup lease manager reports failures around double execution of singleton job. What is the primary diagnosis?",
          "options": [
            "Leader changes never require downstream write validation.",
            "The current coordination model for session cleanup lease manager mismatches double execution of singleton job, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks."
          ],
          "correct": 1,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For session cleanup lease manager reports failures around double execution of singleton job, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Start from \"scenario: session cleanup lease manager reports failures around double execution of\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change without split-brain risk?",
          "options": [
            "Detect and revoke stale ownership via heartbeat + session invalidation.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only."
          ],
          "correct": 0,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change without split-brain risk, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The decision turns on \"after confirming diagnosis, what is the strongest next change without split-brain risk\". Solve this as chained reasoning where stage two must respect stage one assumptions. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "This prompt is really about \"coordination Patterns & Distributed Locking\". Solve this as chained reasoning where stage two must respect stage one assumptions. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: order pipeline coordinator reports failures around fencing token not enforced downstream. What is the primary diagnosis?",
          "options": [
            "The current coordination model for order pipeline coordinator mismatches fencing token not enforced downstream, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation."
          ],
          "correct": 0,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For order pipeline coordinator reports failures around fencing token not enforced downstream, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Start from \"scenario: order pipeline coordinator reports failures around fencing token not enforced\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change with strict side-effect correctness?",
          "options": [
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Instrument lock delay/renew failure metrics and trigger safe degraded mode."
          ],
          "correct": 3,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change with strict side-effect correctness, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The decision turns on \"after confirming diagnosis, what is the strongest next change with strict side-effect\". Solve this as chained reasoning where stage two must respect stage one assumptions. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "This prompt is really about \"coordination Patterns & Distributed Locking\". Solve this as chained reasoning where stage two must respect stage one assumptions. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: fraud rule publisher lock path reports failures around lock starvation under high contention. What is the primary diagnosis?",
          "options": [
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for fraud rule publisher lock path mismatches lock starvation under high contention, creating safety/liveness risk."
          ],
          "correct": 3,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For fraud rule publisher lock path reports failures around lock starvation under high contention, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The decision turns on \"scenario: fraud rule publisher lock path reports failures around lock starvation under\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change while keeping retry storms bounded?",
          "options": [
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Scope lock granularity to reduce contention hot spots and starvation risk.",
            "Force a single global lock for all workflows to simplify ownership."
          ],
          "correct": 2,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change while keeping retry storms bounded, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Start from \"after confirming diagnosis, what is the strongest next change while keeping retry\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "Use \"coordination Patterns & Distributed Locking\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: document edit lock manager reports failures around orphaned lock after worker crash. What is the primary diagnosis?",
          "options": [
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for document edit lock manager mismatches orphaned lock after worker crash, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains."
          ],
          "correct": 2,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For document edit lock manager reports failures around orphaned lock after worker crash, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The core signal here is \"scenario: document edit lock manager reports failures around orphaned lock after worker\". Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change under GC pause variability?",
          "options": [
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Use fencing tokens and enforce token checks at the resource boundary.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable."
          ],
          "correct": 1,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change under GC pause variability, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Use \"after confirming diagnosis, what is the strongest next change under GC pause variability\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates."
        }
      ],
      "detailedExplanation": "The core signal here is \"coordination Patterns & Distributed Locking\". Solve this as chained reasoning where stage two must respect stage one assumptions. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: quota reset coordinator reports failures around split-brain leadership after network partition. What is the primary diagnosis?",
          "options": [
            "Leader changes never require downstream write validation.",
            "The current coordination model for quota reset coordinator mismatches split-brain leadership after network partition, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks."
          ],
          "correct": 1,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For quota reset coordinator reports failures around split-brain leadership after network partition, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The key clue in this question is \"scenario: quota reset coordinator reports failures around split-brain leadership after\". Do not reset assumptions between stages; carry forward prior constraints directly. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: ambiguous contracts that hide behavior changes."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change during leader handoff?",
          "options": [
            "Use lease-based ownership with renewals and conservative expiry margins.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only."
          ],
          "correct": 0,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change during leader handoff, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Read this as a scenario about \"after confirming diagnosis, what is the strongest next change during leader handoff\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes."
        }
      ],
      "detailedExplanation": "If you keep \"coordination Patterns & Distributed Locking\" in view, the correct answer separates faster. Do not reset assumptions between stages; carry forward prior constraints directly. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: tenant migration orchestrator reports failures around lock expiry and stale owner writes. What is the primary diagnosis?",
          "options": [
            "The current coordination model for tenant migration orchestrator mismatches lock expiry and stale owner writes, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation."
          ],
          "correct": 0,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For tenant migration orchestrator reports failures around lock expiry and stale owner writes, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "This prompt is really about \"scenario: tenant migration orchestrator reports failures around lock expiry and stale\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: stale data despite high hit rates."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change with limited ops intervention?",
          "options": [
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Use randomized backoff/jitter for lock retries to avoid herd effects."
          ],
          "correct": 3,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change with limited ops intervention, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "If you keep \"after confirming diagnosis, what is the strongest next change with limited ops\" in view, the correct answer separates faster. Do not reset assumptions between stages; carry forward prior constraints directly. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "Start from \"coordination Patterns & Distributed Locking\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: cache rebuild coordinator reports failures around lost lease renewal under GC pause. What is the primary diagnosis?",
          "options": [
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for cache rebuild coordinator mismatches lost lease renewal under GC pause, creating safety/liveness risk."
          ],
          "correct": 3,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For cache rebuild coordinator reports failures around lost lease renewal under GC pause, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "If you keep \"scenario: cache rebuild coordinator reports failures around lost lease renewal under GC\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change before broad rollout?",
          "options": [
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Separate leader election from work ownership and verify epoch on writes.",
            "Force a single global lock for all workflows to simplify ownership."
          ],
          "correct": 2,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change before broad rollout, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "This prompt is really about \"after confirming diagnosis, what is the strongest next change before broad rollout\". Do not reset assumptions between stages; carry forward prior constraints directly. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes."
        }
      ],
      "detailedExplanation": "The key clue in this question is \"coordination Patterns & Distributed Locking\". Do not reset assumptions between stages; carry forward prior constraints directly. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: notification batch ownership service reports failures around thundering herd on lock acquisition. What is the primary diagnosis?",
          "options": [
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for notification batch ownership service mismatches thundering herd on lock acquisition, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains."
          ],
          "correct": 2,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For notification batch ownership service reports failures around thundering herd on lock acquisition, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Read this as a scenario about \"scenario: notification batch ownership service reports failures around thundering herd\". Solve this as chained reasoning where stage two must respect stage one assumptions. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change under quorum degradation?",
          "options": [
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Implement deterministic lock handoff/draining for graceful ownership transfer.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable."
          ],
          "correct": 1,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change under quorum degradation, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The key clue in this question is \"after confirming diagnosis, what is the strongest next change under quorum degradation\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"coordination Patterns & Distributed Locking\". Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: data export leader election service reports failures around lock service partial outage. What is the primary diagnosis?",
          "options": [
            "Leader changes never require downstream write validation.",
            "The current coordination model for data export leader election service mismatches lock service partial outage, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks."
          ],
          "correct": 1,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For data export leader election service reports failures around lock service partial outage, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Use \"scenario: data export leader election service reports failures around lock service\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change while preserving tenant fairness?",
          "options": [
            "Use quorum-backed coordination store with monotonic session/term semantics.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only."
          ],
          "correct": 0,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change while preserving tenant fairness, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The core signal here is \"after confirming diagnosis, what is the strongest next change while preserving tenant\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates."
        }
      ],
      "detailedExplanation": "The decision turns on \"coordination Patterns & Distributed Locking\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: index rebuild lock service reports failures around clock-skew affecting lease validity. What is the primary diagnosis?",
          "options": [
            "The current coordination model for index rebuild lock service mismatches clock-skew affecting lease validity, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation."
          ],
          "correct": 0,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For index rebuild lock service reports failures around clock-skew affecting lease validity, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Start from \"scenario: index rebuild lock service reports failures around clock-skew affecting lease\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: using weak consistency for strict invariants."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change during deploy churn?",
          "options": [
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Apply idempotent job execution with dedupe key even for singleton tasks."
          ],
          "correct": 3,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change during deploy churn, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The decision turns on \"after confirming diagnosis, what is the strongest next change during deploy churn\". Do not reset assumptions between stages; carry forward prior constraints directly. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: stale data despite high hit rates."
        }
      ],
      "detailedExplanation": "This prompt is really about \"coordination Patterns & Distributed Locking\". Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: feature rollout coordinator reports failures around double execution of singleton job. What is the primary diagnosis?",
          "options": [
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for feature rollout coordinator mismatches double execution of singleton job, creating safety/liveness risk."
          ],
          "correct": 3,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For feature rollout coordinator reports failures around double execution of singleton job, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The decision turns on \"scenario: feature rollout coordinator reports failures around double execution of\". Solve this as chained reasoning where stage two must respect stage one assumptions. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: misreading quorum behavior during failures."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change with deterministic failover semantics?",
          "options": [
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Detect and revoke stale ownership via heartbeat + session invalidation.",
            "Force a single global lock for all workflows to simplify ownership."
          ],
          "correct": 2,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change with deterministic failover semantics, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Start from \"after confirming diagnosis, what is the strongest next change with deterministic\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "Use \"coordination Patterns & Distributed Locking\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: billing close-job lock manager reports failures around fencing token not enforced downstream. What is the primary diagnosis?",
          "options": [
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for billing close-job lock manager mismatches fencing token not enforced downstream, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains."
          ],
          "correct": 2,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For billing close-job lock manager reports failures around fencing token not enforced downstream, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The key clue in this question is \"scenario: billing close-job lock manager reports failures around fencing token not\". Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change under clock uncertainty?",
          "options": [
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Instrument lock delay/renew failure metrics and trigger safe degraded mode.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable."
          ],
          "correct": 1,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change under clock uncertainty, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Read this as a scenario about \"after confirming diagnosis, what is the strongest next change under clock uncertainty\". Do not reset assumptions between stages; carry forward prior constraints directly. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: stale data despite high hit rates."
        }
      ],
      "detailedExplanation": "If you keep \"coordination Patterns & Distributed Locking\" in view, the correct answer separates faster. Solve this as chained reasoning where stage two must respect stage one assumptions. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: shipment allocator lease service reports failures around lock starvation under high contention. What is the primary diagnosis?",
          "options": [
            "Leader changes never require downstream write validation.",
            "The current coordination model for shipment allocator lease service mismatches lock starvation under high contention, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks."
          ],
          "correct": 1,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For shipment allocator lease service reports failures around lock starvation under high contention, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The core signal here is \"scenario: shipment allocator lease service reports failures around lock starvation\". Do not reset assumptions between stages; carry forward prior constraints directly. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change during singleton job pressure?",
          "options": [
            "Scope lock granularity to reduce contention hot spots and starvation risk.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only."
          ],
          "correct": 0,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change during singleton job pressure, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Use \"after confirming diagnosis, what is the strongest next change during singleton job\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "The core signal here is \"coordination Patterns & Distributed Locking\". Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: reconciliation task coordinator reports failures around orphaned lock after worker crash. What is the primary diagnosis?",
          "options": [
            "The current coordination model for reconciliation task coordinator mismatches orphaned lock after worker crash, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation."
          ],
          "correct": 0,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For reconciliation task coordinator reports failures around orphaned lock after worker crash, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The decision turns on \"scenario: reconciliation task coordinator reports failures around orphaned lock after\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: using weak consistency for strict invariants."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change with downstream token enforcement?",
          "options": [
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Use fencing tokens and enforce token checks at the resource boundary."
          ],
          "correct": 3,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change with downstream token enforcement, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Start from \"after confirming diagnosis, what is the strongest next change with downstream token\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "Use \"coordination Patterns & Distributed Locking\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: moderation queue ownership service reports failures around split-brain leadership after network partition. What is the primary diagnosis?",
          "options": [
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for moderation queue ownership service mismatches split-brain leadership after network partition, creating safety/liveness risk."
          ],
          "correct": 3,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For moderation queue ownership service reports failures around split-brain leadership after network partition, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Start from \"scenario: moderation queue ownership service reports failures around split-brain\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change while reducing lock contention?",
          "options": [
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Use lease-based ownership with renewals and conservative expiry margins.",
            "Force a single global lock for all workflows to simplify ownership."
          ],
          "correct": 2,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change while reducing lock contention, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The decision turns on \"after confirming diagnosis, what is the strongest next change while reducing lock\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "This prompt is really about \"coordination Patterns & Distributed Locking\". Do not reset assumptions between stages; carry forward prior constraints directly. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: payment worker lease scheduler reports failures around lock expiry and stale owner writes. What is the primary diagnosis?",
          "options": [
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for payment worker lease scheduler mismatches lock expiry and stale owner writes, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains."
          ],
          "correct": 2,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For payment worker lease scheduler reports failures around lock expiry and stale owner writes, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Use \"scenario: payment worker lease scheduler reports failures around lock expiry and stale\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change under transient packet loss?",
          "options": [
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Use randomized backoff/jitter for lock retries to avoid herd effects.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable."
          ],
          "correct": 1,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change under transient packet loss, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The core signal here is \"after confirming diagnosis, what is the strongest next change under transient packet\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "The decision turns on \"coordination Patterns & Distributed Locking\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: inventory reservation lock service reports failures around lost lease renewal under GC pause. What is the primary diagnosis?",
          "options": [
            "Leader changes never require downstream write validation.",
            "The current coordination model for inventory reservation lock service mismatches lost lease renewal under GC pause, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks."
          ],
          "correct": 1,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For inventory reservation lock service reports failures around lost lease renewal under GC pause, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Read this as a scenario about \"scenario: inventory reservation lock service reports failures around lost lease renewal\". Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change with explicit degraded mode?",
          "options": [
            "Separate leader election from work ownership and verify epoch on writes.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only."
          ],
          "correct": 0,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change with explicit degraded mode, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The key clue in this question is \"after confirming diagnosis, what is the strongest next change with explicit degraded\". Do not reset assumptions between stages; carry forward prior constraints directly. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"coordination Patterns & Distributed Locking\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: leader-elected config updater reports failures around thundering herd on lock acquisition. What is the primary diagnosis?",
          "options": [
            "The current coordination model for leader-elected config updater mismatches thundering herd on lock acquisition, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation."
          ],
          "correct": 0,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For leader-elected config updater reports failures around thundering herd on lock acquisition, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "If you keep \"scenario: leader-elected config updater reports failures around thundering herd on lock\" in view, the correct answer separates faster. Solve this as chained reasoning where stage two must respect stage one assumptions. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change during incident containment?",
          "options": [
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Implement deterministic lock handoff/draining for graceful ownership transfer."
          ],
          "correct": 3,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change during incident containment, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "This prompt is really about \"after confirming diagnosis, what is the strongest next change during incident\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "The key clue in this question is \"coordination Patterns & Distributed Locking\". Do not reset assumptions between stages; carry forward prior constraints directly. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: distributed cron executor reports failures around lock service partial outage. What is the primary diagnosis?",
          "options": [
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for distributed cron executor mismatches lock service partial outage, creating safety/liveness risk."
          ],
          "correct": 3,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For distributed cron executor reports failures around lock service partial outage, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "This prompt is really about \"scenario: distributed cron executor reports failures around lock service partial outage\". Solve this as chained reasoning where stage two must respect stage one assumptions. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: using weak consistency for strict invariants."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change with replay-safe job semantics?",
          "options": [
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Use quorum-backed coordination store with monotonic session/term semantics.",
            "Force a single global lock for all workflows to simplify ownership."
          ],
          "correct": 2,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change with replay-safe job semantics, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "If you keep \"after confirming diagnosis, what is the strongest next change with replay-safe job\" in view, the correct answer separates faster. Solve this as chained reasoning where stage two must respect stage one assumptions. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "Start from \"coordination Patterns & Distributed Locking\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: queue consumer coordination service reports failures around clock-skew affecting lease validity. What is the primary diagnosis?",
          "options": [
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation.",
            "The current coordination model for queue consumer coordination service mismatches clock-skew affecting lease validity, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains."
          ],
          "correct": 2,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For queue consumer coordination service reports failures around clock-skew affecting lease validity, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The key clue in this question is \"scenario: queue consumer coordination service reports failures around clock-skew\". Solve this as chained reasoning where stage two must respect stage one assumptions. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change while preserving throughput?",
          "options": [
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Apply idempotent job execution with dedupe key even for singleton tasks.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable."
          ],
          "correct": 1,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change while preserving throughput, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Read this as a scenario about \"after confirming diagnosis, what is the strongest next change while preserving\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: invalidation races under concurrent writes."
        }
      ],
      "detailedExplanation": "If you keep \"coordination Patterns & Distributed Locking\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: session cleanup lease manager reports failures around double execution of singleton job. What is the primary diagnosis?",
          "options": [
            "Leader changes never require downstream write validation.",
            "The current coordination model for session cleanup lease manager mismatches double execution of singleton job, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks."
          ],
          "correct": 1,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For session cleanup lease manager reports failures around double execution of singleton job, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "The core signal here is \"scenario: session cleanup lease manager reports failures around double execution of\". Solve this as chained reasoning where stage two must respect stage one assumptions. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change under high acquisition fanout?",
          "options": [
            "Detect and revoke stale ownership via heartbeat + session invalidation.",
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only."
          ],
          "correct": 0,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change under high acquisition fanout, this is the strongest fit in Coordination Patterns & Distributed Locking. Keep mitigation tied to the stated constraints.",
          "detailedExplanation": "Use \"after confirming diagnosis, what is the strongest next change under high acquisition\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: stale data despite high hit rates."
        }
      ],
      "detailedExplanation": "The core signal here is \"coordination Patterns & Distributed Locking\". Solve this as chained reasoning where stage two must respect stage one assumptions. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "Scenario: order pipeline coordinator reports failures around fencing token not enforced downstream. What is the primary diagnosis?",
          "options": [
            "The current coordination model for order pipeline coordinator mismatches fencing token not enforced downstream, creating safety/liveness risk.",
            "Coordination anomalies are harmless if eventually one owner remains.",
            "Lease validity can be inferred solely from local clocks.",
            "Leader changes never require downstream write validation."
          ],
          "correct": 0,
          "explanation": "This reflects coordination safety gaps between ownership claims and resource-write validation. For order pipeline coordinator reports failures around fencing token not enforced downstream, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "The core signal here is \"scenario: order pipeline coordinator reports failures around fencing token not enforced\". Solve this as chained reasoning where stage two must respect stage one assumptions. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior."
        },
        {
          "question": "After confirming diagnosis, what is the strongest next change with measurable coordination SLOs?",
          "options": [
            "Force a single global lock for all workflows to simplify ownership.",
            "Allow stale owners to finish writes if lock service is unstable.",
            "Pause all workers on uncertainty and rely on manual cleanup only.",
            "Instrument lock delay/renew failure metrics and trigger safe degraded mode."
          ],
          "correct": 3,
          "explanation": "Apply ownership model fixes that block stale writers and stabilize leader/lease transitions. For After confirming diagnosis, what is the strongest next change with measurable coordination SLOs, this is the strongest fit in Coordination Patterns & Distributed Locking.",
          "detailedExplanation": "Use \"after confirming diagnosis, what is the strongest next change with measurable\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: hot-key skew causing uneven load."
        }
      ],
      "detailedExplanation": "The core signal here is \"coordination Patterns & Distributed Locking\". Solve this as chained reasoning where stage two must respect stage one assumptions. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-061",
      "type": "multi-select",
      "question": "Fencing tokens protect against which failures? (Select all that apply)",
      "options": [
        "Stale owner writes after lease expiry",
        "Split-brain leader overlap",
        "Guaranteed zero retries",
        "Delayed messages from old leader terms"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Fencing ensures only newest valid owner can mutate protected resources.",
      "detailedExplanation": "If you keep \"fencing tokens protect against which failures? (Select all that apply)\" in view, the correct answer separates faster. Validate each option independently; do not select statements that are only partially true. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-062",
      "type": "multi-select",
      "question": "Good lease design usually includes which? (Select all that apply)",
      "options": [
        "Renewal heartbeat",
        "Conservative expiry margin",
        "Infinite lease duration",
        "Clear ownership revocation semantics"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Leases need renewal and bounded validity with explicit revocation behavior.",
      "detailedExplanation": "This prompt is really about \"good lease design usually includes which? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-063",
      "type": "multi-select",
      "question": "Leader election safety practices include which? (Select all that apply)",
      "options": [
        "Monotonic term/epoch numbers",
        "Quorum-based election store",
        "Blind local clock winner choice",
        "Write-path term validation"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Election safety requires term monotonicity and quorum/validation controls.",
      "detailedExplanation": "Use \"leader election safety practices include which? (Select all that apply)\" as your starting point, then verify tradeoffs carefully. Treat every option as a separate true/false test under the same constraints. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-064",
      "type": "multi-select",
      "question": "Common lock anti-patterns include which? (Select all that apply)",
      "options": [
        "No jitter on retries",
        "No stale-owner write rejection",
        "Per-resource lock granularity tuning",
        "Undocumented lock expiry assumptions"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Missing jitter, stale-owner checks, and explicit assumptions cause failures.",
      "detailedExplanation": "Read this as a scenario about \"common lock anti-patterns include which? (Select all that apply)\". Treat every option as a separate true/false test under the same constraints. Treat freshness policy and invalidation paths as first-class constraints. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-065",
      "type": "multi-select",
      "question": "How to improve liveness under lock contention? (Select all that apply)",
      "options": [
        "Randomized backoff",
        "Smaller lock scope",
        "Global synchronized retry bursts",
        "Queue-based acquisition fairness"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Backoff, scope reduction, and fairness improve liveness under load.",
      "detailedExplanation": "The decision turns on \"to improve liveness under lock contention? (Select all that apply)\". Treat every option as a separate true/false test under the same constraints. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-066",
      "type": "multi-select",
      "question": "When lock service is degraded, safe behavior can include which? (Select all that apply)",
      "options": [
        "Read-only fallback for some paths",
        "Fail closed on invariant-critical writes",
        "Continue unsafe writes without ownership validation",
        "Operator-visible degraded mode"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Degraded modes should preserve correctness and make risk explicit.",
      "detailedExplanation": "Start from \"lock service is degraded, safe behavior can include which? (Select all that apply)\", then pressure-test the result against the options. Treat every option as a separate true/false test under the same constraints. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-067",
      "type": "multi-select",
      "question": "Singleton job safety often needs which? (Select all that apply)",
      "options": [
        "Lease/leader ownership check",
        "Idempotent execution key",
        "Assume scheduler never duplicates execution",
        "Fencing at side-effect sink"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Singleton safety requires ownership and dedupe protections.",
      "detailedExplanation": "The key clue in this question is \"singleton job safety often needs which? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-068",
      "type": "multi-select",
      "question": "Clock skew affects lease systems how? (Select all that apply)",
      "options": [
        "Can produce false lease-expiry assumptions",
        "Can allow stale owner overlap risk",
        "Makes logical/term checks unnecessary",
        "Requires conservative lease timing"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Skew undermines naive timing; term-based validation and timing margins help.",
      "detailedExplanation": "The core signal here is \"clock skew affects lease systems how? (Select all that apply)\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-069",
      "type": "multi-select",
      "question": "Useful coordination observability includes which? (Select all that apply)",
      "options": [
        "Lock acquisition latency",
        "Lease renewal failure rate",
        "Only average CPU",
        "Term/epoch conflict events"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Coordination health needs direct lock/lease/election telemetry.",
      "detailedExplanation": "If you keep \"useful coordination observability includes which? (Select all that apply)\" in view, the correct answer separates faster. Validate each option independently; do not select statements that are only partially true. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-070",
      "type": "multi-select",
      "question": "Which reduce split-brain write risk? (Select all that apply)",
      "options": [
        "Resource-side fencing checks",
        "Term-aware write validation",
        "Trusting cached leader identity indefinitely",
        "Quorum-backed leadership state"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Split-brain safety needs both election correctness and resource-side enforcement.",
      "detailedExplanation": "The key clue in this question is \"reduce split-brain write risk? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-071",
      "type": "multi-select",
      "question": "For lock starvation prevention, which are useful? (Select all that apply)",
      "options": [
        "Fair queueing or priority policy",
        "Bounded retry backoff windows",
        "Unbounded high-priority preemption forever",
        "Per-tenant acquisition limits"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Fairness mechanisms limit starvation in shared lock domains.",
      "detailedExplanation": "Start from \"for lock starvation prevention, which are useful? (Select all that apply)\", then pressure-test the result against the options. Avoid pattern guessing and evaluate each candidate directly against the scenario. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-072",
      "type": "multi-select",
      "question": "Coordination boundaries should usually separate which concerns? (Select all that apply)",
      "options": [
        "Ownership election vs work execution",
        "Safety checks vs business side effects",
        "All operations into one global lock",
        "Critical vs non-critical resource paths"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Clear boundaries keep coordination safer and less coupled.",
      "detailedExplanation": "The decision turns on \"coordination boundaries should usually separate which concerns? (Select all that apply)\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-073",
      "type": "multi-select",
      "question": "Failover drill quality improves with which? (Select all that apply)",
      "options": [
        "Measured promotion time",
        "Stale-owner write simulation",
        "Skipping downstream validation checks",
        "Rollback criteria"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "High-quality drills test stale-owner rejection and recovery criteria.",
      "detailedExplanation": "Read this as a scenario about \"failover drill quality improves with which? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-074",
      "type": "multi-select",
      "question": "When using distributed locks, what should be idempotent? (Select all that apply)",
      "options": [
        "Lock holder side effects",
        "Compensation actions",
        "Ownership checks only",
        "Retry-driven command processing"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Idempotency protects correctness when coordination retries/replays happen.",
      "detailedExplanation": "Use \"using distributed locks, what should be idempotent? (Select all that apply)\" as your starting point, then verify tradeoffs carefully. Treat every option as a separate true/false test under the same constraints. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-075",
      "type": "multi-select",
      "question": "Which are signs coordination scope is too broad? (Select all that apply)",
      "options": [
        "High lock contention across unrelated workflows",
        "Slow leader handoff affecting many services",
        "Independent paths unaffected by lock scope",
        "Frequent global lock bottlenecks"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Over-broad coordination increases contention and blast radius.",
      "detailedExplanation": "This prompt is really about \"signs coordination scope is too broad? (Select all that apply)\". Validate each option independently; do not select statements that are only partially true. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-076",
      "type": "multi-select",
      "question": "What helps safe lease renewal? (Select all that apply)",
      "options": [
        "Renew before expiry threshold",
        "Treat missed renewals as ownership loss",
        "Ignore renewal failures under load",
        "Persist renewal attempts for audit/debug"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Renewal logic should be conservative, explicit, and observable.",
      "detailedExplanation": "If you keep \"helps safe lease renewal? (Select all that apply)\" in view, the correct answer separates faster. Treat every option as a separate true/false test under the same constraints. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-077",
      "type": "multi-select",
      "question": "For downstream stale-write defense, useful controls include which? (Select all that apply)",
      "options": [
        "Reject writes with older fencing token",
        "Compare term/epoch monotonicity",
        "Accept any authenticated write regardless epoch",
        "Log token mismatch incidents"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Downstream resource validation is essential to stale-owner defense.",
      "detailedExplanation": "The core signal here is \"for downstream stale-write defense, useful controls include which? (Select all that\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Cache design quality is mostly about correctness boundaries, not only hit rate. Common pitfall: hot-key skew causing uneven load.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-078",
      "type": "numeric-input",
      "question": "Lock acquisition attempts are 120,000/min with 3.5% contention failures. Failures/min (Coordination Patterns & Distributed Locking context)?",
      "answer": 4200,
      "unit": "attempts",
      "tolerance": 0.02,
      "explanation": "0.035 * 120,000 = 4,200.",
      "detailedExplanation": "The key clue in this question is \"lock acquisition attempts are 120,000/min with 3\". Normalize units before computing so conversion mistakes do not propagate. Consistency decisions should be explicit about which conflicts are acceptable and why. If values like 120,000 and 3.5 appear, convert them into one unit basis before comparison. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-079",
      "type": "numeric-input",
      "question": "Lease TTL is 12s and renewals occur every 4s. How many renewal opportunities before expiry?",
      "answer": 3,
      "unit": "renewals",
      "tolerance": 0,
      "explanation": "12/4 = 3 renewal intervals.",
      "detailedExplanation": "Start from \"lease TTL is 12s and renewals occur every 4s\", then pressure-test the result against the options. Normalize units before computing so conversion mistakes do not propagate. Treat freshness policy and invalidation paths as first-class constraints. If values like 12s and 4s appear, convert them into one unit basis before comparison. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "Redis Documentation",
          "url": "https://redis.io/docs/latest/"
        },
        {
          "title": "Cache-Aside pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/cache-aside"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-080",
      "type": "numeric-input",
      "question": "Leader failover takes 18s and occurs 14 times/day. Total failover downtime minutes/day (Coordination Patterns & Distributed Locking context)?",
      "answer": 4.2,
      "unit": "minutes",
      "tolerance": 0.05,
      "explanation": "18*14=252s = 4.2 minutes.",
      "detailedExplanation": "Start from \"leader failover takes 18s and occurs 14 times/day\", then pressure-test the result against the options. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Tie the decision to concrete operational outcomes, not abstract reliability language. Numbers such as 18s and 14 should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-081",
      "type": "numeric-input",
      "question": "A singleton job runs 6,000 times/day. Duplicate execution rate is 0.4%. Duplicates/day?",
      "answer": 24,
      "unit": "runs",
      "tolerance": 0.02,
      "explanation": "0.004*6,000=24.",
      "detailedExplanation": "The key clue in this question is \"singleton job runs 6,000 times/day\". Normalize units before computing so conversion mistakes do not propagate. Strong answers connect quorum/coordination settings to concrete correctness goals. If values like 6,000 and 0.4 appear, convert them into one unit basis before comparison. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-082",
      "type": "numeric-input",
      "question": "Fencing token mismatches are 540/day out of 1,800,000 protected writes/day. Mismatch rate (%)?",
      "answer": 0.03,
      "unit": "%",
      "tolerance": 0.01,
      "explanation": "540/1,800,000=0.0003 = 0.03%.",
      "detailedExplanation": "Read this as a scenario about \"fencing token mismatches are 540/day out of 1,800,000 protected writes/day\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Numbers such as 540 and 1,800 should be normalized first so downstream reasoning stays consistent. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "RFC 7519: JSON Web Token (JWT)",
          "url": "https://www.rfc-editor.org/rfc/rfc7519"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-083",
      "type": "numeric-input",
      "question": "Lock delay p99 is 320ms; target is 200ms. Percent over target?",
      "answer": 60,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "(320-200)/200=60%.",
      "detailedExplanation": "The decision turns on \"lock delay p99 is 320ms\". Normalize units before computing so conversion mistakes do not propagate. Tie the decision to concrete operational outcomes, not abstract reliability language. If values like 320ms and 200ms appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "Percentile",
          "url": "https://en.wikipedia.org/wiki/Percentile"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-084",
      "type": "numeric-input",
      "question": "Coordinator handles 75,000 ownership checks/sec. 8% are critical-path checks requiring strict fencing. Critical checks/sec?",
      "answer": 6000,
      "unit": "checks/sec",
      "tolerance": 0.02,
      "explanation": "0.08*75,000=6,000.",
      "detailedExplanation": "This prompt is really about \"coordinator handles 75,000 ownership checks/sec\". Keep every transformation in one unit system and check order of magnitude at the end. Strong answers connect quorum/coordination settings to concrete correctness goals. Keep quantities like 75,000 and 8 in aligned units before selecting an answer. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-085",
      "type": "numeric-input",
      "question": "Backoff jitter spreads retries uniformly over 500ms window for 2,000 contenders. Average contenders per 10ms slice?",
      "answer": 40,
      "unit": "contenders",
      "tolerance": 0.2,
      "explanation": "500ms/10ms=50 slices; 2,000/50=40.",
      "detailedExplanation": "Use \"backoff jitter spreads retries uniformly over 500ms window for 2,000 contenders\" as your starting point, then verify tradeoffs carefully. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Numbers such as 500ms and 2,000 should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-086",
      "type": "numeric-input",
      "question": "Lease-renew success is 99.2% across 900,000 renewals/day. Failed renewals/day?",
      "answer": 7200,
      "unit": "renewals",
      "tolerance": 0.03,
      "explanation": "0.8% of 900,000 = 7,200.",
      "detailedExplanation": "The core signal here is \"lease-renew success is 99\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Consistency decisions should be explicit about which conflicts are acceptable and why. Numbers such as 99.2 and 900,000 should be normalized first so downstream reasoning stays consistent. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-087",
      "type": "numeric-input",
      "question": "A stale-owner incident drops from 150/week to 18/week after fencing enforcement. Percent reduction?",
      "answer": 88,
      "unit": "%",
      "tolerance": 0.3,
      "explanation": "(150-18)/150=88%.",
      "detailedExplanation": "If you keep \"stale-owner incident drops from 150/week to 18/week after fencing enforcement\" in view, the correct answer separates faster. Normalize units before computing so conversion mistakes do not propagate. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. If values like 150 and 18 appear, convert them into one unit basis before comparison. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-088",
      "type": "numeric-input",
      "question": "Term conflicts are 96/day; each triggers 12s safe pause window. Total pause minutes/day?",
      "answer": 19.2,
      "unit": "minutes",
      "tolerance": 0.05,
      "explanation": "96*12=1,152s=19.2min.",
      "detailedExplanation": "Start from \"term conflicts are 96/day\", then pressure-test the result against the options. Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Numbers such as 96 and 12s should be normalized first so downstream reasoning stays consistent. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-089",
      "type": "numeric-input",
      "question": "A lock scope refactor cuts contested resources from 480 to 192. Percent reduction?",
      "answer": 60,
      "unit": "%",
      "tolerance": 0.2,
      "explanation": "(480-192)/480=60%.",
      "detailedExplanation": "The key clue in this question is \"lock scope refactor cuts contested resources from 480 to 192\". Keep every transformation in one unit system and check order of magnitude at the end. Consistency decisions should be explicit about which conflicts are acceptable and why. Keep quantities like 480 and 192 in aligned units before selecting an answer. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-090",
      "type": "ordering",
      "question": "Order a safe leader failover sequence.",
      "items": [
        "Detect leadership loss",
        "Elect new leader via quorum",
        "Start leader with new term/token",
        "Reject stale-term writes"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Failover should establish new term before accepting writes.",
      "detailedExplanation": "The decision turns on \"order a safe leader failover sequence\". Order by relative scale and bottleneck effect, then validate neighboring items. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-091",
      "type": "ordering",
      "question": "Order lock acquisition strategy maturity.",
      "items": [
        "Naive immediate retry",
        "Retry with fixed delay",
        "Retry with jitter/backoff",
        "Fair queued acquisition + metrics"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Maturity increases with stability and fairness controls.",
      "detailedExplanation": "Read this as a scenario about \"order lock acquisition strategy maturity\". Place obvious extremes first, then sort the middle by pairwise comparison. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-092",
      "type": "ordering",
      "question": "Order stale-owner defense strength.",
      "items": [
        "Owner ID check only",
        "Lease validity timestamp check",
        "Epoch/term check at write sink",
        "Fencing token monotonic enforcement"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Fencing at resource sink is strongest stale-owner protection.",
      "detailedExplanation": "The key clue in this question is \"order stale-owner defense strength\". Place obvious extremes first, then sort the middle by pairwise comparison. A strong caching answer names staleness limits, invalidation behavior, and keying strategy. Common pitfall: invalidation races under concurrent writes.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-093",
      "type": "ordering",
      "question": "Order by increasing split-brain risk.",
      "items": [
        "Quorum election + fencing",
        "Quorum election without sink validation",
        "Single-node leader cache",
        "Independent local leaders per node"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Risk rises as consensus and downstream validation weaken.",
      "detailedExplanation": "Start from \"order by increasing split-brain risk\", then pressure-test the result against the options. Build the rank from biggest differences first, then refine with adjacent checks. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-094",
      "type": "ordering",
      "question": "Order lock-scope design from broadest to narrowest.",
      "items": [
        "Global system lock",
        "Workflow-class lock",
        "Entity-group lock",
        "Per-entity lock"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Narrower scopes usually reduce contention/blast radius.",
      "detailedExplanation": "If you keep \"order lock-scope design from broadest to narrowest\" in view, the correct answer separates faster. Build the rank from biggest differences first, then refine with adjacent checks. Consistency decisions should be explicit about which conflicts are acceptable and why. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-095",
      "type": "ordering",
      "question": "Order coordination incident response flow.",
      "items": [
        "Scope affected resources",
        "Contain with safe degraded mode",
        "Apply ownership/fencing fix",
        "Add recurrence tests/alerts"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Scope, contain, fix, harden.",
      "detailedExplanation": "The core signal here is \"order coordination incident response flow\". Place obvious extremes first, then sort the middle by pairwise comparison. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-096",
      "type": "ordering",
      "question": "Order by increasing liveness under contention.",
      "items": [
        "No backoff retries",
        "Fixed retry delay",
        "Exponential backoff + jitter",
        "Fair queue + bounded retries"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Liveness improves with jitter and fairness mechanisms.",
      "detailedExplanation": "Use \"order by increasing liveness under contention\" as your starting point, then verify tradeoffs carefully. Place obvious extremes first, then sort the middle by pairwise comparison. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-097",
      "type": "ordering",
      "question": "Order rollout safety for coordination changes.",
      "items": [
        "Canary lock domain",
        "Measure stale-write and renewal metrics",
        "Expand gradually",
        "Finalize runbook/rollback guards"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Progressive rollout with metrics reduces coordination risk.",
      "detailedExplanation": "This prompt is really about \"order rollout safety for coordination changes\". Build the rank from biggest differences first, then refine with adjacent checks. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-098",
      "type": "ordering",
      "question": "Order by strongest evidence quality for coordination fix success.",
      "items": [
        "Lower average latency only",
        "Lower lock contention only",
        "Lower stale-owner and duplicate-exec incidents",
        "Sustained correctness + latency + incident reduction"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Best evidence combines correctness and performance outcomes.",
      "detailedExplanation": "The decision turns on \"order by strongest evidence quality for coordination fix success\". Place obvious extremes first, then sort the middle by pairwise comparison. Strong answers connect quorum/coordination settings to concrete correctness goals. Common pitfall: using weak consistency for strict invariants.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-099",
      "type": "ordering",
      "question": "Order by increasing operational complexity. (Coordination Patterns & Distributed Locking context B)",
      "items": [
        "Single coordinator instance",
        "Replicated lock service",
        "Replicated service + fencing enforcement",
        "Multi-region coordination with failover drills"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Complexity grows with replication, enforcement depth, and geography.",
      "detailedExplanation": "Read this as a scenario about \"order by increasing operational complexity\". Place obvious extremes first, then sort the middle by pairwise comparison. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: ignoring conflict resolution behavior.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    },
    {
      "id": "cc-cl-100",
      "type": "ordering",
      "question": "Order lease lifecycle steps.",
      "items": [
        "Acquire lease",
        "Renew lease periodically",
        "Detect renewal failure and relinquish",
        "Transfer/reacquire safely"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Safe lifecycle requires explicit relinquish and transfer behavior.",
      "detailedExplanation": "The key clue in this question is \"order lease lifecycle steps\". Build the rank from biggest differences first, then refine with adjacent checks. Pick based on invariants and acceptable anomalies, then justify latency/availability tradeoffs. Common pitfall: misreading quorum behavior during failures.",
      "references": [
        {
          "title": "CAP theorem",
          "url": "https://en.wikipedia.org/wiki/CAP_theorem"
        },
        {
          "title": "In Search of an Understandable Consensus Algorithm (Raft)",
          "url": "https://raft.github.io/raft.pdf"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ],
      "tags": [
        "consistency-coordination",
        "coordination-patterns-and-distributed-locking"
      ],
      "difficulty": "senior"
    }
  ]
}
