{
  "unit": 12,
  "unitTitle": "Interview Execution & Design Communication",
  "chapter": 5,
  "chapterTitle": "Capacity Reasoning in Live Whiteboarding",
  "chapterDescription": "Strengthen real-time capacity math, bottleneck identification, and approximation discipline during interview discussion.",
  "problems": [
    {
      "id": "int-cr-001",
      "type": "multiple-choice",
      "question": "For inventory reservation service, primary risk is unit conversion mistakes under time pressure while supporting multi-tenant isolation. Which response is strongest?",
      "options": [
        "normalize units before calculating and narrate assumptions",
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "normalize units before calculating and narrate assumptions is strongest because it directly addresses unit conversion mistakes and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In inventory reservation service, normalize units before calculating and narrate assumptions should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-002",
      "type": "multiple-choice",
      "question": "In catalog read API, highest-risk gap is sizing to average instead of peak with frequent schema evolution. Which choice best improves the design?",
      "options": [
        "ignore replication and failover capacity impact",
        "compute average and peak separately with headroom",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 1,
      "explanation": "compute average and peak separately with headroom is the right choice because it closes sizing to average instead of peak and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In catalog read API, compute average and peak separately with headroom should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-003",
      "type": "multiple-choice",
      "question": "During a design review for Profile graph service, you suspect forgetting headroom for failure scenarios under aggressive latency targets. Which action should be prioritized first?",
      "options": [
        "hide assumptions to avoid challenge",
        "optimize only one bottleneck dimension",
        "link each capacity number to a design decision",
        "mix bits and bytes inconsistently"
      ],
      "correct": 2,
      "explanation": "link each capacity number to a design decision works best because it targets forgetting headroom for failure scenarios and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Good L6 reasoning names both immediate impact and downstream tradeoffs. In Profile graph service, link each capacity number to a design decision should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-004",
      "type": "multiple-choice",
      "question": "In media transcoding pipeline, the dominant concern is throughput and latency assumptions misaligned during bot-driven traffic spikes. What is the best next move?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions",
        "use order-of-magnitude checks to catch errors"
      ],
      "correct": 3,
      "explanation": "use order-of-magnitude checks to catch errors is highest leverage because it mitigates throughput and latency assumptions misaligned and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In media transcoding pipeline, use order-of-magnitude checks to catch errors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-005",
      "type": "multiple-choice",
      "question": "For experiment assignment service, primary risk is ignoring storage growth and retention multipliers while operating across two regions. Which response is strongest?",
      "options": [
        "explicitly include replication and redundancy factors",
        "hide assumptions to avoid challenge",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time"
      ],
      "correct": 0,
      "explanation": "explicitly include replication and redundancy factors is preferred because it directly reduces ignoring storage growth and retention multipliers and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In experiment assignment service, explicitly include replication and redundancy factors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-006",
      "type": "multiple-choice",
      "question": "During incident preparation for feature flag control plane, highest-risk gap is missing read/write amplification effects under peak traffic. Which choice best improves the design?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "estimate queue growth under burst mismatch",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees"
      ],
      "correct": 1,
      "explanation": "estimate queue growth under burst mismatch is the right choice because it closes missing read/write amplification effects and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In feature flag control plane, estimate queue growth under burst mismatch should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-007",
      "type": "multiple-choice",
      "question": "During a design review for analytics ingestion pipeline, you suspect network bandwidth underestimated by bits/bytes confusion during a regional failover drill. Which action should be prioritized first?",
      "options": [
        "skip peak calculations to save time",
        "mix bits and bytes inconsistently",
        "translate latency targets into concurrency budgets",
        "optimize only one bottleneck dimension"
      ],
      "correct": 2,
      "explanation": "translate latency targets into concurrency budgets is strongest because it directly addresses network bandwidth and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Good L6 reasoning names both immediate impact and downstream tradeoffs. In analytics ingestion pipeline, translate latency targets into concurrency budgets should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-008",
      "type": "multiple-choice",
      "question": "In webhook processing service, the dominant concern is queueing effects ignored at high utilization while deployment velocity is high. What is the best next move?",
      "options": [
        "ignore replication and failover capacity impact",
        "leave math disconnected from architecture decisions",
        "treat rough estimates as exact guarantees",
        "track read/write amplification in storage math"
      ],
      "correct": 3,
      "explanation": "track read/write amplification in storage math is the right choice because it closes queueing effects ignored at high utilization and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In webhook processing service, track read/write amplification in storage math should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-009",
      "type": "multiple-choice",
      "question": "For partner integration gateway, primary risk is unclear confidence in approximated numbers when one dependency is degraded. Which response is strongest?",
      "options": [
        "state confidence and margin for each estimate",
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "state confidence and margin for each estimate is strongest because it directly addresses unclear confidence in approximated numbers and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Strong answers connect one decision to one observable outcome. In partner integration gateway, state confidence and margin for each estimate should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-010",
      "type": "multiple-choice",
      "question": "During incident preparation for admin operations console, highest-risk gap is failing to tie math back to architecture choices with strict compliance scope. Which choice best improves the design?",
      "options": [
        "ignore replication and failover capacity impact",
        "adjust architecture when math breaks constraints",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 1,
      "explanation": "adjust architecture when math breaks constraints works best because it targets failing to tie math back to architecture choices and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Good L6 reasoning names both immediate impact and downstream tradeoffs. In admin operations console, adjust architecture when math breaks constraints should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-011",
      "type": "multiple-choice",
      "question": "In model inference endpoint, the dominant concern is calculations not checked for plausibility while supporting multi-tenant isolation. What is the best next move?",
      "options": [
        "mix bits and bytes inconsistently",
        "optimize only one bottleneck dimension",
        "hide assumptions to avoid challenge",
        "keep calculations simple, legible, and auditable"
      ],
      "correct": 3,
      "explanation": "keep calculations simple, legible, and auditable is highest leverage because it mitigates calculations not checked for plausibility and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In model inference endpoint, keep calculations simple, legible, and auditable should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-012",
      "type": "multiple-choice",
      "question": "During a design review for session gateway, you suspect resource budget omitted for safety margin with frequent schema evolution. Which action should be prioritized first?",
      "options": [
        "summarize final capacity envelope and risk areas",
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 0,
      "explanation": "summarize final capacity envelope and risk areas works best because it targets resource budget omitted for safety margin and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In session gateway, summarize final capacity envelope and risk areas should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-013",
      "type": "multiple-choice",
      "question": "During incident preparation for billing reconciliation batch, highest-risk gap is unit conversion mistakes under time pressure under aggressive latency targets. Which choice best improves the design?",
      "options": [
        "hide assumptions to avoid challenge",
        "skip peak calculations to save time",
        "normalize units before calculating and narrate assumptions",
        "optimize only one bottleneck dimension"
      ],
      "correct": 2,
      "explanation": "normalize units before calculating and narrate assumptions is the right choice because it closes unit conversion mistakes and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In billing reconciliation batch, normalize units before calculating and narrate assumptions should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-014",
      "type": "multiple-choice",
      "question": "For support workflow automation, primary risk is sizing to average instead of peak during bot-driven traffic spikes. Which response is strongest?",
      "options": [
        "compute average and peak separately with headroom",
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "ignore replication and failover capacity impact"
      ],
      "correct": 0,
      "explanation": "compute average and peak separately with headroom is strongest because it directly addresses sizing to average instead of peak and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In support workflow automation, compute average and peak separately with headroom should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-015",
      "type": "multiple-choice",
      "question": "In checkout API gateway, the dominant concern is forgetting headroom for failure scenarios while operating across two regions. What is the best next move?",
      "options": [
        "optimize only one bottleneck dimension",
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "link each capacity number to a design decision"
      ],
      "correct": 3,
      "explanation": "link each capacity number to a design decision is the best first move because it directly mitigates forgetting headroom for failure scenarios and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In checkout API gateway, link each capacity number to a design decision should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-016",
      "type": "multiple-choice",
      "question": "During a design review for identity token service, you suspect throughput and latency assumptions misaligned under peak traffic. Which action should be prioritized first?",
      "options": [
        "use order-of-magnitude checks to catch errors",
        "ignore replication and failover capacity impact",
        "leave math disconnected from architecture decisions",
        "treat rough estimates as exact guarantees"
      ],
      "correct": 0,
      "explanation": "use order-of-magnitude checks to catch errors is strongest because it directly addresses throughput and latency assumptions misaligned and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In identity token service, use order-of-magnitude checks to catch errors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-017",
      "type": "multiple-choice",
      "question": "In search indexing pipeline, highest-risk gap is ignoring storage growth and retention multipliers during a regional failover drill. Which choice best improves the design?",
      "options": [
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge",
        "explicitly include replication and redundancy factors",
        "mix bits and bytes inconsistently"
      ],
      "correct": 2,
      "explanation": "explicitly include replication and redundancy factors is the best first move because it directly mitigates ignoring storage growth and retention multipliers and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Treat this as a leverage decision: small change, large risk reduction. In search indexing pipeline, explicitly include replication and redundancy factors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-018",
      "type": "multiple-choice",
      "question": "For recommendation ranking service, primary risk is missing read/write amplification effects while deployment velocity is high. Which response is strongest?",
      "options": [
        "estimate queue growth under burst mismatch",
        "ignore replication and failover capacity impact",
        "leave math disconnected from architecture decisions",
        "avoid revisiting incorrect early numbers"
      ],
      "correct": 0,
      "explanation": "estimate queue growth under burst mismatch is strongest because it directly addresses missing read/write amplification effects and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In recommendation ranking service, estimate queue growth under burst mismatch should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-019",
      "type": "multiple-choice",
      "question": "A scenario of chat delivery workers surfaced this issue: the dominant concern is network bandwidth underestimated by bits/bytes confusion when one dependency is degraded. What is the best next move?",
      "options": [
        "hide assumptions to avoid challenge",
        "optimize only one bottleneck dimension",
        "mix bits and bytes inconsistently",
        "translate latency targets into concurrency budgets"
      ],
      "correct": 3,
      "explanation": "translate latency targets into concurrency budgets is highest leverage because it mitigates network bandwidth and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In this system, translate latency targets into concurrency budgets should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-020",
      "type": "multiple-choice",
      "question": "During a design review for notification fanout dispatcher, you suspect queueing effects ignored at high utilization with strict compliance scope. Which action should be prioritized first?",
      "options": [
        "track read/write amplification in storage math",
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 0,
      "explanation": "track read/write amplification in storage math is the right choice because it closes queueing effects ignored at high utilization and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Focus on what you can deploy first without painting the team into a corner. In notification fanout dispatcher, track read/write amplification in storage math should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-021",
      "type": "multiple-choice",
      "question": "During a design review for fraud scoring engine, you suspect unclear confidence in approximated numbers while supporting multi-tenant isolation. Which action should be prioritized first?",
      "options": [
        "state confidence and margin for each estimate",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "state confidence and margin for each estimate is strongest because it directly addresses unclear confidence in approximated numbers and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In fraud scoring engine, state confidence and margin for each estimate should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-022",
      "type": "multiple-choice",
      "question": "In ad auction edge service, the dominant concern is failing to tie math back to architecture choices with frequent schema evolution. What is the best next move?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "adjust architecture when math breaks constraints"
      ],
      "correct": 3,
      "explanation": "adjust architecture when math breaks constraints is the best first move because it directly mitigates failing to tie math back to architecture choices and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In ad auction edge service, adjust architecture when math breaks constraints should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-023",
      "type": "multiple-choice",
      "question": "For document collaboration backend, primary risk is calculations not checked for plausibility under aggressive latency targets. Which response is strongest?",
      "options": [
        "skip peak calculations to save time",
        "optimize only one bottleneck dimension",
        "keep calculations simple, legible, and auditable",
        "mix bits and bytes inconsistently"
      ],
      "correct": 2,
      "explanation": "keep calculations simple, legible, and auditable is strongest because it directly addresses calculations not checked for plausibility and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In document collaboration backend, keep calculations simple, legible, and auditable should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-024",
      "type": "multiple-choice",
      "question": "During incident preparation for payments orchestration service, highest-risk gap is resource budget omitted for safety margin during bot-driven traffic spikes. Which choice best improves the design?",
      "options": [
        "leave math disconnected from architecture decisions",
        "summarize final capacity envelope and risk areas",
        "treat rough estimates as exact guarantees",
        "ignore replication and failover capacity impact"
      ],
      "correct": 1,
      "explanation": "summarize final capacity envelope and risk areas is highest leverage because it mitigates resource budget omitted for safety margin and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In payments orchestration service, summarize final capacity envelope and risk areas should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-025",
      "type": "multiple-choice",
      "question": "During a design review for inventory reservation service, you suspect unit conversion mistakes under time pressure while operating across two regions. Which action should be prioritized first?",
      "options": [
        "normalize units before calculating and narrate assumptions",
        "mix bits and bytes inconsistently",
        "hide assumptions to avoid challenge",
        "skip peak calculations to save time"
      ],
      "correct": 0,
      "explanation": "normalize units before calculating and narrate assumptions is preferred because it directly reduces unit conversion mistakes and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In inventory reservation service, normalize units before calculating and narrate assumptions should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-026",
      "type": "multiple-choice",
      "question": "In catalog read API, the dominant concern is sizing to average instead of peak under peak traffic. What is the best next move?",
      "options": [
        "ignore replication and failover capacity impact",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions",
        "compute average and peak separately with headroom"
      ],
      "correct": 3,
      "explanation": "compute average and peak separately with headroom is the right choice because it closes sizing to average instead of peak and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In catalog read API, compute average and peak separately with headroom should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-027",
      "type": "multiple-choice",
      "question": "For profile graph service, primary risk is forgetting headroom for failure scenarios during a regional failover drill. Which response is strongest?",
      "options": [
        "hide assumptions to avoid challenge",
        "mix bits and bytes inconsistently",
        "link each capacity number to a design decision",
        "optimize only one bottleneck dimension"
      ],
      "correct": 2,
      "explanation": "link each capacity number to a design decision works best because it targets forgetting headroom for failure scenarios and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In profile graph service, link each capacity number to a design decision should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-028",
      "type": "multiple-choice",
      "question": "During incident preparation for media transcoding pipeline, highest-risk gap is throughput and latency assumptions misaligned while deployment velocity is high. Which choice best improves the design?",
      "options": [
        "leave math disconnected from architecture decisions",
        "treat rough estimates as exact guarantees",
        "use order-of-magnitude checks to catch errors",
        "avoid revisiting incorrect early numbers"
      ],
      "correct": 2,
      "explanation": "use order-of-magnitude checks to catch errors is the right choice because it closes throughput and latency assumptions misaligned and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Focus on what you can deploy first without painting the team into a corner. In media transcoding pipeline, use order-of-magnitude checks to catch errors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-029",
      "type": "multiple-choice",
      "question": "During a design review for experiment assignment service, you suspect ignoring storage growth and retention multipliers when one dependency is degraded. Which action should be prioritized first?",
      "options": [
        "explicitly include replication and redundancy factors",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "explicitly include replication and redundancy factors is preferred because it directly reduces ignoring storage growth and retention multipliers and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In experiment assignment service, explicitly include replication and redundancy factors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-030",
      "type": "multiple-choice",
      "question": "In feature flag control plane, the dominant concern is missing read/write amplification effects with strict compliance scope. What is the best next move?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "estimate queue growth under burst mismatch"
      ],
      "correct": 3,
      "explanation": "estimate queue growth under burst mismatch is preferred because it directly reduces missing read/write amplification effects and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In feature flag control plane, estimate queue growth under burst mismatch should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-031",
      "type": "multiple-choice",
      "question": "During incident preparation for analytics ingestion pipeline, highest-risk gap is network bandwidth underestimated by bits/bytes confusion while supporting multi-tenant isolation. Which choice best improves the design?",
      "options": [
        "mix bits and bytes inconsistently",
        "translate latency targets into concurrency budgets",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time"
      ],
      "correct": 1,
      "explanation": "translate latency targets into concurrency budgets is the right choice because it closes network bandwidth and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In analytics ingestion pipeline, translate latency targets into concurrency budgets should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-032",
      "type": "multiple-choice",
      "question": "For webhook processing service, primary risk is queueing effects ignored at high utilization with frequent schema evolution. Which response is strongest?",
      "options": [
        "track read/write amplification in storage math",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 0,
      "explanation": "track read/write amplification in storage math works best because it targets queueing effects ignored at high utilization and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In webhook processing service, track read/write amplification in storage math should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-033",
      "type": "multiple-choice",
      "question": "While reviewing partner integration gateway, the dominant concern is unclear confidence in approximated numbers under aggressive latency targets. What is the best next move?",
      "options": [
        "skip peak calculations to save time",
        "mix bits and bytes inconsistently",
        "hide assumptions to avoid challenge",
        "state confidence and margin for each estimate"
      ],
      "correct": 3,
      "explanation": "state confidence and margin for each estimate is the right choice because it closes unclear confidence in approximated numbers and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In partner integration gateway, state confidence and margin for each estimate should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-034",
      "type": "multiple-choice",
      "question": "During a design review for admin operations console, you suspect failing to tie math back to architecture choices during bot-driven traffic spikes. Which action should be prioritized first?",
      "options": [
        "adjust architecture when math breaks constraints",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions",
        "ignore replication and failover capacity impact"
      ],
      "correct": 0,
      "explanation": "adjust architecture when math breaks constraints works best because it targets failing to tie math back to architecture choices and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Strong answers connect one decision to one observable outcome. In admin operations console, adjust architecture when math breaks constraints should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-035",
      "type": "multiple-choice",
      "question": "In model inference endpoint, highest-risk gap is calculations not checked for plausibility while operating across two regions. Which choice best improves the design?",
      "options": [
        "mix bits and bytes inconsistently",
        "keep calculations simple, legible, and auditable",
        "optimize only one bottleneck dimension",
        "hide assumptions to avoid challenge"
      ],
      "correct": 1,
      "explanation": "keep calculations simple, legible, and auditable is highest leverage because it mitigates calculations not checked for plausibility and can be rolled out with measurable impact. Alternatives are weaker because they defer mitigation, rely on brittle assumptions, or increase operational risk.",
      "detailedExplanation": "Treat this as a leverage decision: small change, large risk reduction. In model inference endpoint, keep calculations simple, legible, and auditable should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "For notification fanout dispatcher, what is the most likely core problem behind unit conversion mistakes under time pressure while supporting multi-tenant isolation?",
          "options": [
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios",
            "ignoring storage growth and retention multipliers",
            "network bandwidth underestimated by bits/bytes confusion"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is unit conversion mistakes because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In notification fanout dispatcher, unit conversion mistakes best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in notification fanout dispatcher, which adjustment gives the best risk reduction?",
          "options": [
            "skip peak calculations to save time",
            "normalize units before calculating and narrate assumptions",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, normalize units before calculating and narrate assumptions is the strongest first change because it reduces unit conversion mistakes quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In notification fanout dispatcher, normalize units before calculating and narrate assumptions is high leverage because it lowers unit conversion mistakes without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of ad auction edge service, which diagnosis is most defensible for sizing to average instead of peak during bot-driven traffic spikes?",
          "options": [
            "throughput and latency assumptions misaligned",
            "queueing effects ignored at high utilization",
            "sizing to average instead of peak",
            "missing read/write amplification effects"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is sizing to average instead of peak because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. In this system, sizing to average instead of peak best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for ad auction edge service, what is the strongest immediate response?",
          "options": [
            "compute average and peak separately with headroom",
            "leave math disconnected from architecture decisions",
            "ignore replication and failover capacity impact",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, compute average and peak separately with headroom is the strongest first change because it reduces sizing to average instead of peak quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "The right first step should be high ROI and low coordination overhead. In this system, compute average and peak separately with headroom is high leverage because it lowers sizing to average instead of peak without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. Now the signal is whether you can choose the highest-leverage next action. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "In payments orchestration service, what is the highest-priority diagnosis given forgetting headroom for failure scenarios during a regional failover drill?",
          "options": [
            "forgetting headroom for failure scenarios",
            "network bandwidth underestimated by bits/bytes confusion",
            "unclear confidence in approximated numbers",
            "ignoring storage growth and retention multipliers"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is forgetting headroom for failure scenarios because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In payments orchestration service, forgetting headroom for failure scenarios best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Given that diagnosis in payments orchestration service, which next change should be prioritized first?",
          "options": [
            "mix bits and bytes inconsistently",
            "hide assumptions to avoid challenge",
            "optimize only one bottleneck dimension",
            "link each capacity number to a design decision"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, link each capacity number to a design decision is the strongest first change because it reduces forgetting headroom for failure scenarios quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In payments orchestration service, link each capacity number to a design decision is high leverage because it lowers forgetting headroom for failure scenarios without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. This phase checks whether your mitigation plan is practical, not theoretical. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "In catalog read API, the strongest diagnosis is needed. Which primary issue best explains throughput and latency assumptions misaligned with strict compliance scope?",
          "options": [
            "missing read/write amplification effects",
            "failing to tie math back to architecture choices",
            "queueing effects ignored at high utilization",
            "throughput and latency assumptions misaligned"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is throughput and latency assumptions misaligned because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. In catalog read API, throughput and latency assumptions misaligned best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "After diagnosing catalog read API, what should change first before broad rollout?",
          "options": [
            "avoid revisiting incorrect early numbers",
            "treat rough estimates as exact guarantees",
            "use order-of-magnitude checks to catch errors",
            "leave math disconnected from architecture decisions"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, use order-of-magnitude checks to catch errors is the strongest first change because it reduces throughput and latency assumptions misaligned quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Choose the action that creates momentum for subsequent hardening work. In catalog read API, use order-of-magnitude checks to catch errors is high leverage because it lowers throughput and latency assumptions misaligned without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. The best response reduces exposure quickly without destabilizing the system. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "For media transcoding pipeline, what is the most likely core problem behind ignoring storage growth and retention multipliers under aggressive latency targets?",
          "options": [
            "unclear confidence in approximated numbers",
            "network bandwidth underestimated by bits/bytes confusion",
            "ignoring storage growth and retention multipliers",
            "calculations not checked for plausibility"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is ignoring storage growth and retention multipliers because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In media transcoding pipeline, ignoring storage growth and retention multipliers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in media transcoding pipeline, which adjustment gives the best risk reduction?",
          "options": [
            "hide assumptions to avoid challenge",
            "explicitly include replication and redundancy factors",
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, explicitly include replication and redundancy factors is the strongest first change because it reduces ignoring storage growth and retention multipliers quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In media transcoding pipeline, explicitly include replication and redundancy factors is high leverage because it lowers ignoring storage growth and retention multipliers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. The right first step should be high ROI and low coordination overhead. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of feature flag control plane, which diagnosis is most defensible for missing read/write amplification effects under peak traffic?",
          "options": [
            "queueing effects ignored at high utilization",
            "resource budget omitted for safety margin",
            "missing read/write amplification effects",
            "failing to tie math back to architecture choices"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is missing read/write amplification effects because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In this system, missing read/write amplification effects best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for feature flag control plane, what is the strongest immediate response?",
          "options": [
            "estimate queue growth under burst mismatch",
            "treat rough estimates as exact guarantees",
            "avoid revisiting incorrect early numbers",
            "ignore replication and failover capacity impact"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, estimate queue growth under burst mismatch is the strongest first change because it reduces missing read/write amplification effects quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In this system, estimate queue growth under burst mismatch is high leverage because it lowers missing read/write amplification effects without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "In webhook processing service, what is the highest-priority diagnosis given network bandwidth underestimated by bits/bytes confusion when one dependency is degraded?",
          "options": [
            "network bandwidth underestimated by bits/bytes confusion",
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "unclear confidence in approximated numbers"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is network bandwidth because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. In webhook processing service, network bandwidth best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in webhook processing service, which next change should be prioritized first?",
          "options": [
            "skip peak calculations to save time",
            "mix bits and bytes inconsistently",
            "optimize only one bottleneck dimension",
            "translate latency targets into concurrency budgets"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, translate latency targets into concurrency budgets is the strongest first change because it reduces network bandwidth quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "The best response reduces exposure quickly without destabilizing the system. In webhook processing service, translate latency targets into concurrency budgets is high leverage because it lowers network bandwidth without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. Now the signal is whether you can choose the highest-leverage next action. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "In admin operations console, the strongest diagnosis is needed. Which primary issue best explains queueing effects ignored at high utilization with frequent schema evolution?",
          "options": [
            "failing to tie math back to architecture choices",
            "sizing to average instead of peak",
            "resource budget omitted for safety margin",
            "queueing effects ignored at high utilization"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is queueing effects ignored at high utilization because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In admin operations console, queueing effects ignored at high utilization best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "After diagnosing admin operations console, what should change first before broad rollout?",
          "options": [
            "ignore replication and failover capacity impact",
            "leave math disconnected from architecture decisions",
            "track read/write amplification in storage math",
            "treat rough estimates as exact guarantees"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, track read/write amplification in storage math is the strongest first change because it reduces queueing effects ignored at high utilization quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In admin operations console, track read/write amplification in storage math is high leverage because it lowers queueing effects ignored at high utilization without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. A strong stage-2 answer balances immediate impact with operational safety. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "For session gateway, what is the most likely core problem behind unclear confidence in approximated numbers while operating across two regions?",
          "options": [
            "unclear confidence in approximated numbers",
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is unclear confidence in approximated numbers because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. In session gateway, unclear confidence in approximated numbers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in session gateway, which adjustment gives the best risk reduction?",
          "options": [
            "skip peak calculations to save time",
            "state confidence and margin for each estimate",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, state confidence and margin for each estimate is the strongest first change because it reduces unclear confidence in approximated numbers quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Now the signal is whether you can choose the highest-leverage next action. In session gateway, state confidence and margin for each estimate is high leverage because it lowers unclear confidence in approximated numbers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. The right first step should be high ROI and low coordination overhead. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of support workflow automation, which diagnosis is most defensible for failing to tie math back to architecture choices while deployment velocity is high?",
          "options": [
            "resource budget omitted for safety margin",
            "throughput and latency assumptions misaligned",
            "failing to tie math back to architecture choices",
            "sizing to average instead of peak"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is failing to tie math back to architecture choices because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. In this system, failing to tie math back to architecture choices best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for support workflow automation, what is the strongest immediate response?",
          "options": [
            "adjust architecture when math breaks constraints",
            "leave math disconnected from architecture decisions",
            "ignore replication and failover capacity impact",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, adjust architecture when math breaks constraints is the strongest first change because it reduces failing to tie math back to architecture choices quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 rewards changes that are effective, measurable, and rollout-safe. In this system, adjust architecture when math breaks constraints is high leverage because it lowers failing to tie math back to architecture choices without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of identity token service, which diagnosis is most defensible for calculations not checked for plausibility while supporting multi-tenant isolation?",
          "options": [
            "forgetting headroom for failure scenarios",
            "ignoring storage growth and retention multipliers",
            "unit conversion mistakes under time pressure",
            "calculations not checked for plausibility"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is calculations not checked for plausibility because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. In this system, calculations not checked for plausibility best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "After diagnosing identity token service, what should change first before broad rollout?",
          "options": [
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently",
            "keep calculations simple, legible, and auditable",
            "optimize only one bottleneck dimension"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, keep calculations simple, legible, and auditable is the strongest first change because it reduces calculations not checked for plausibility quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "The right first step should be high ROI and low coordination overhead. In this system, keep calculations simple, legible, and auditable is high leverage because it lowers calculations not checked for plausibility without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. Prioritize the smallest change that closes the largest risk gap. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "For recommendation ranking service, what is the most likely core problem behind resource budget omitted for safety margin during bot-driven traffic spikes?",
          "options": [
            "throughput and latency assumptions misaligned",
            "missing read/write amplification effects",
            "resource budget omitted for safety margin",
            "sizing to average instead of peak"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is resource budget omitted for safety margin because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. In recommendation ranking service, resource budget omitted for safety margin best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in recommendation ranking service, which next change should be prioritized first?",
          "options": [
            "treat rough estimates as exact guarantees",
            "summarize final capacity envelope and risk areas",
            "leave math disconnected from architecture decisions",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, summarize final capacity envelope and risk areas is the strongest first change because it reduces resource budget omitted for safety margin quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This is a prioritization question: what should ship first and why. In recommendation ranking service, summarize final capacity envelope and risk areas is high leverage because it lowers resource budget omitted for safety margin without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "In notification fanout dispatcher, the strongest diagnosis is needed. Which primary issue best explains unit conversion mistakes under time pressure during a regional failover drill?",
          "options": [
            "forgetting headroom for failure scenarios",
            "unit conversion mistakes under time pressure",
            "network bandwidth underestimated by bits/bytes confusion",
            "ignoring storage growth and retention multipliers"
          ],
          "correct": 1,
          "explanation": "The best diagnosis is unit conversion mistakes under time pressure because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In notification fanout dispatcher, unit conversion mistakes under time pressure best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for notification fanout dispatcher, what is the strongest immediate response?",
          "options": [
            "normalize units before calculating and narrate assumptions",
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension",
            "hide assumptions to avoid challenge"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, normalize units before calculating and narrate assumptions is the strongest first change because it reduces unit conversion mistakes under time pressure quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In notification fanout dispatcher, normalize units before calculating and narrate assumptions is high leverage because it lowers unit conversion mistakes under time pressure without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. Stage 2 is first-move prioritization under real delivery constraints. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "In ad auction edge service, what is the highest-priority diagnosis given sizing to average instead of peak with strict compliance scope?",
          "options": [
            "sizing to average instead of peak",
            "missing read/write amplification effects",
            "throughput and latency assumptions misaligned",
            "queueing effects ignored at high utilization"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is sizing to average instead of peak because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In ad auction edge service, sizing to average instead of peak best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in ad auction edge service, which adjustment gives the best risk reduction?",
          "options": [
            "avoid revisiting incorrect early numbers",
            "treat rough estimates as exact guarantees",
            "ignore replication and failover capacity impact",
            "compute average and peak separately with headroom"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, compute average and peak separately with headroom is the strongest first change because it reduces sizing to average instead of peak quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In ad auction edge service, compute average and peak separately with headroom is high leverage because it lowers sizing to average instead of peak without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. This is a prioritization question: what should ship first and why. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of payments orchestration service, which diagnosis is most defensible for forgetting headroom for failure scenarios under aggressive latency targets?",
          "options": [
            "network bandwidth underestimated by bits/bytes confusion",
            "unclear confidence in approximated numbers",
            "ignoring storage growth and retention multipliers",
            "forgetting headroom for failure scenarios"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is forgetting headroom for failure scenarios because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. In this system, forgetting headroom for failure scenarios best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "After diagnosing payments orchestration service, what should change first before broad rollout?",
          "options": [
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension",
            "link each capacity number to a design decision",
            "mix bits and bytes inconsistently"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, link each capacity number to a design decision is the strongest first change because it reduces forgetting headroom for failure scenarios quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This is a prioritization question: what should ship first and why. In this system, link each capacity number to a design decision is high leverage because it lowers forgetting headroom for failure scenarios without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. A good stage-2 answer includes rollout guardrails and success criteria. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "For catalog read API, what is the most likely core problem behind throughput and latency assumptions misaligned under peak traffic?",
          "options": [
            "queueing effects ignored at high utilization",
            "failing to tie math back to architecture choices",
            "throughput and latency assumptions misaligned",
            "missing read/write amplification effects"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is throughput and latency assumptions misaligned because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In catalog read API, throughput and latency assumptions misaligned best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in catalog read API, which next change should be prioritized first?",
          "options": [
            "leave math disconnected from architecture decisions",
            "use order-of-magnitude checks to catch errors",
            "treat rough estimates as exact guarantees",
            "ignore replication and failover capacity impact"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, use order-of-magnitude checks to catch errors is the strongest first change because it reduces throughput and latency assumptions misaligned quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In catalog read API, use order-of-magnitude checks to catch errors is high leverage because it lowers throughput and latency assumptions misaligned without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. Choose the action that creates momentum for subsequent hardening work. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "In media transcoding pipeline, the strongest diagnosis is needed. Which primary issue best explains ignoring storage growth and retention multipliers when one dependency is degraded?",
          "options": [
            "network bandwidth underestimated by bits/bytes confusion",
            "ignoring storage growth and retention multipliers",
            "calculations not checked for plausibility",
            "unclear confidence in approximated numbers"
          ],
          "correct": 1,
          "explanation": "The best diagnosis is ignoring storage growth and retention multipliers because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. In media transcoding pipeline, ignoring storage growth and retention multipliers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for media transcoding pipeline, what is the strongest immediate response?",
          "options": [
            "explicitly include replication and redundancy factors",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently",
            "skip peak calculations to save time"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, explicitly include replication and redundancy factors is the strongest first change because it reduces ignoring storage growth and retention multipliers quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 rewards changes that are effective, measurable, and rollout-safe. In media transcoding pipeline, explicitly include replication and redundancy factors is high leverage because it lowers ignoring storage growth and retention multipliers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "In feature flag control plane, what is the highest-priority diagnosis given missing read/write amplification effects with frequent schema evolution?",
          "options": [
            "missing read/write amplification effects",
            "failing to tie math back to architecture choices",
            "queueing effects ignored at high utilization",
            "resource budget omitted for safety margin"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is missing read/write amplification effects because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. In feature flag control plane, missing read/write amplification effects best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in feature flag control plane, which adjustment gives the best risk reduction?",
          "options": [
            "ignore replication and failover capacity impact",
            "leave math disconnected from architecture decisions",
            "avoid revisiting incorrect early numbers",
            "estimate queue growth under burst mismatch"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, estimate queue growth under burst mismatch is the strongest first change because it reduces missing read/write amplification effects quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Now the signal is whether you can choose the highest-leverage next action. In feature flag control plane, estimate queue growth under burst mismatch is high leverage because it lowers missing read/write amplification effects without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. The best response reduces exposure quickly without destabilizing the system. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of webhook processing service, which diagnosis is most defensible for network bandwidth underestimated by bits/bytes confusion while operating across two regions?",
          "options": [
            "unclear confidence in approximated numbers",
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "network bandwidth underestimated by bits/bytes confusion"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is network bandwidth because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "The goal here is precise problem framing before intervention design. In this system, network bandwidth best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "After diagnosing webhook processing service, what should change first before broad rollout?",
          "options": [
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently",
            "translate latency targets into concurrency budgets",
            "optimize only one bottleneck dimension"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, translate latency targets into concurrency budgets is the strongest first change because it reduces network bandwidth quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "With diagnosis set, this step tests execution sequencing quality. In this system, translate latency targets into concurrency budgets is high leverage because it lowers network bandwidth without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "For admin operations console, what is the most likely core problem behind queueing effects ignored at high utilization while deployment velocity is high?",
          "options": [
            "resource budget omitted for safety margin",
            "sizing to average instead of peak",
            "queueing effects ignored at high utilization",
            "failing to tie math back to architecture choices"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is queueing effects ignored at high utilization because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In admin operations console, queueing effects ignored at high utilization best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in admin operations console, which next change should be prioritized first?",
          "options": [
            "treat rough estimates as exact guarantees",
            "track read/write amplification in storage math",
            "leave math disconnected from architecture decisions",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, track read/write amplification in storage math is the strongest first change because it reduces queueing effects ignored at high utilization quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In admin operations console, track read/write amplification in storage math is high leverage because it lowers queueing effects ignored at high utilization without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. Now the signal is whether you can choose the highest-leverage next action. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "For session gateway, what is the most likely core problem behind unclear confidence in approximated numbers while supporting multi-tenant isolation?",
          "options": [
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios",
            "unclear confidence in approximated numbers",
            "calculations not checked for plausibility"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is unclear confidence in approximated numbers because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. In session gateway, unclear confidence in approximated numbers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Given that diagnosis in session gateway, which next change should be prioritized first?",
          "options": [
            "hide assumptions to avoid challenge",
            "state confidence and margin for each estimate",
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, state confidence and margin for each estimate is the strongest first change because it reduces unclear confidence in approximated numbers quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "A good stage-2 answer includes rollout guardrails and success criteria. In session gateway, state confidence and margin for each estimate is high leverage because it lowers unclear confidence in approximated numbers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of support workflow automation, which diagnosis is most defensible for failing to tie math back to architecture choices during bot-driven traffic spikes?",
          "options": [
            "sizing to average instead of peak",
            "throughput and latency assumptions misaligned",
            "resource budget omitted for safety margin",
            "failing to tie math back to architecture choices"
          ],
          "correct": 3,
          "explanation": "The best diagnosis is failing to tie math back to architecture choices because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In this system, failing to tie math back to architecture choices best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "After diagnosing support workflow automation, what should change first before broad rollout?",
          "options": [
            "adjust architecture when math breaks constraints",
            "treat rough estimates as exact guarantees",
            "avoid revisiting incorrect early numbers",
            "ignore replication and failover capacity impact"
          ],
          "correct": 0,
          "explanation": "Given that diagnosis, adjust architecture when math breaks constraints is the strongest first change because it reduces failing to tie math back to architecture choices quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In this system, adjust architecture when math breaks constraints is high leverage because it lowers failing to tie math back to architecture choices without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. Stage 2 is first-move prioritization under real delivery constraints. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "In identity token service, what is the highest-priority diagnosis given calculations not checked for plausibility during a regional failover drill?",
          "options": [
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios",
            "ignoring storage growth and retention multipliers"
          ],
          "correct": 0,
          "explanation": "The best diagnosis is calculations not checked for plausibility because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In identity token service, calculations not checked for plausibility best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in identity token service, which adjustment gives the best risk reduction?",
          "options": [
            "skip peak calculations to save time",
            "mix bits and bytes inconsistently",
            "optimize only one bottleneck dimension",
            "keep calculations simple, legible, and auditable"
          ],
          "correct": 3,
          "explanation": "Given that diagnosis, keep calculations simple, legible, and auditable is the strongest first change because it reduces calculations not checked for plausibility quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In identity token service, keep calculations simple, legible, and auditable is high leverage because it lowers calculations not checked for plausibility without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. A strong stage-2 answer balances immediate impact with operational safety. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "In recommendation ranking service, the strongest diagnosis is needed. Which primary issue best explains resource budget omitted for safety margin with strict compliance scope?",
          "options": [
            "sizing to average instead of peak",
            "missing read/write amplification effects",
            "resource budget omitted for safety margin",
            "throughput and latency assumptions misaligned"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is resource budget omitted for safety margin because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In recommendation ranking service, resource budget omitted for safety margin best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for recommendation ranking service, what is the strongest immediate response?",
          "options": [
            "ignore replication and failover capacity impact",
            "leave math disconnected from architecture decisions",
            "summarize final capacity envelope and risk areas",
            "treat rough estimates as exact guarantees"
          ],
          "correct": 2,
          "explanation": "Given that diagnosis, summarize final capacity envelope and risk areas is the strongest first change because it reduces resource budget omitted for safety margin quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In recommendation ranking service, summarize final capacity envelope and risk areas is high leverage because it lowers resource budget omitted for safety margin without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. Choose the action that creates momentum for subsequent hardening work. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "For notification fanout dispatcher, what is the most likely core problem behind unit conversion mistakes under time pressure under aggressive latency targets?",
          "options": [
            "ignoring storage growth and retention multipliers",
            "network bandwidth underestimated by bits/bytes confusion",
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios"
          ],
          "correct": 2,
          "explanation": "The best diagnosis is unit conversion mistakes because it explains the observed behavior and identifies a testable mitigation path under the stated constraints.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In notification fanout dispatcher, unit conversion mistakes best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in notification fanout dispatcher, which next change should be prioritized first?",
          "options": [
            "skip peak calculations to save time",
            "normalize units before calculating and narrate assumptions",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently"
          ],
          "correct": 1,
          "explanation": "Given that diagnosis, normalize units before calculating and narrate assumptions is the strongest first change because it reduces unit conversion mistakes quickly and can be deployed with clear guardrails.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In notification fanout dispatcher, normalize units before calculating and narrate assumptions is high leverage because it lowers unit conversion mistakes without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage problem evaluates diagnosis accuracy first and mitigation prioritization second for live capacity reasoning and unit-safe estimation. High-quality responses keep stage-2 action explicitly tied to stage-1 risk.",
      "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. Prioritize the smallest change that closes the largest risk gap. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-061",
      "type": "multi-select",
      "question": "In notification fanout dispatcher, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "explicitly include replication and redundancy factors",
        "normalize units before calculating and narrate assumptions",
        "treat rough estimates as exact guarantees",
        "track read/write amplification in storage math",
        "ignore replication and failover capacity impact"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The selected options are correct because together they reduce throughput and latency assumptions misaligned through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Multi-select problems test whether your control set works as a system. In notification fanout dispatcher, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-062",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in payments orchestration service? (Select all that apply)",
      "options": [
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "compute average and peak separately with headroom",
        "estimate queue growth under burst mismatch",
        "state confidence and margin for each estimate"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "The selected options are correct because together they reduce ignoring storage growth and retention multipliers through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Select controls that improve both correctness and day-2 operability. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-063",
      "type": "multi-select",
      "question": "For media transcoding pipeline, select the controls that most directly improve live capacity reasoning fluency. (Select all that apply)",
      "options": [
        "translate latency targets into concurrency budgets",
        "adjust architecture when math breaks constraints",
        "ignore replication and failover capacity impact",
        "link each capacity number to a design decision",
        "leave math disconnected from architecture decisions"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The selected options are correct because together they reduce missing read/write amplification effects through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "These options should form a coherent plan, not a random collection of good ideas. In media transcoding pipeline, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-064",
      "type": "multi-select",
      "question": "For webhook processing service, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "use order-of-magnitude checks to catch errors",
        "hide assumptions to avoid challenge",
        "track read/write amplification in storage math",
        "mix bits and bytes inconsistently",
        "keep calculations simple, legible, and auditable"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce network bandwidth underestimated by bits/bytes confusion through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best selections should complement each other rather than overlap. In webhook processing service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-065",
      "type": "multi-select",
      "question": "In session gateway, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "leave math disconnected from architecture decisions",
        "avoid revisiting incorrect early numbers",
        "state confidence and margin for each estimate",
        "summarize final capacity envelope and risk areas",
        "explicitly include replication and redundancy factors"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "The selected options are correct because together they reduce queueing effects ignored at high utilization through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In session gateway, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-066",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in identity token service? (Select all that apply)",
      "options": [
        "estimate queue growth under burst mismatch",
        "optimize only one bottleneck dimension",
        "normalize units before calculating and narrate assumptions",
        "adjust architecture when math breaks constraints",
        "hide assumptions to avoid challenge"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The selected options are correct because together they reduce unclear confidence in approximated numbers through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Your selected options should reduce bypass potential across different attack paths. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-067",
      "type": "multi-select",
      "question": "For notification fanout dispatcher, select the controls that most directly improve live capacity reasoning fluency. (Select all that apply)",
      "options": [
        "keep calculations simple, legible, and auditable",
        "avoid revisiting incorrect early numbers",
        "compute average and peak separately with headroom",
        "treat rough estimates as exact guarantees",
        "translate latency targets into concurrency budgets"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce failing to tie math back to architecture choices through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "These options should form a coherent plan, not a random collection of good ideas. In notification fanout dispatcher, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-068",
      "type": "multi-select",
      "question": "For payments orchestration service, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "link each capacity number to a design decision",
        "summarize final capacity envelope and risk areas",
        "track read/write amplification in storage math",
        "skip peak calculations to save time",
        "optimize only one bottleneck dimension"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "The selected options are correct because together they reduce calculations not checked for plausibility through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best selections should complement each other rather than overlap. In payments orchestration service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-069",
      "type": "multi-select",
      "question": "In media transcoding pipeline, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "ignore replication and failover capacity impact",
        "state confidence and margin for each estimate",
        "treat rough estimates as exact guarantees",
        "use order-of-magnitude checks to catch errors",
        "normalize units before calculating and narrate assumptions"
      ],
      "correctIndices": [1, 3, 4],
      "explanation": "The selected options are correct because together they reduce resource budget omitted for safety margin through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In media transcoding pipeline, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-070",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in webhook processing service? (Select all that apply)",
      "options": [
        "adjust architecture when math breaks constraints",
        "skip peak calculations to save time",
        "explicitly include replication and redundancy factors",
        "compute average and peak separately with headroom",
        "mix bits and bytes inconsistently"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The selected options are correct because together they reduce unit conversion mistakes under time pressure through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "This item rewards layered reasoning and explicit residual-risk thinking. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-071",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in session gateway? (Select all that apply)",
      "options": [
        "keep calculations simple, legible, and auditable",
        "leave math disconnected from architecture decisions",
        "estimate queue growth under burst mismatch",
        "ignore replication and failover capacity impact",
        "link each capacity number to a design decision"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce sizing to average instead of peak through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Select controls that improve both correctness and day-2 operability. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-072",
      "type": "multi-select",
      "question": "In identity token service, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "use order-of-magnitude checks to catch errors",
        "hide assumptions to avoid challenge",
        "translate latency targets into concurrency budgets",
        "summarize final capacity envelope and risk areas",
        "mix bits and bytes inconsistently"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The selected options are correct because together they reduce forgetting headroom for failure scenarios through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In identity token service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-073",
      "type": "multi-select",
      "question": "For notification fanout dispatcher, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "normalize units before calculating and narrate assumptions",
        "track read/write amplification in storage math",
        "leave math disconnected from architecture decisions",
        "avoid revisiting incorrect early numbers",
        "explicitly include replication and redundancy factors"
      ],
      "correctIndices": [0, 1, 4],
      "explanation": "The selected options are correct because together they reduce throughput and latency assumptions misaligned through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The interview signal is whether your chosen controls still hold under stress. In notification fanout dispatcher, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-074",
      "type": "multi-select",
      "question": "For payments orchestration service, select the controls that most directly improve live capacity reasoning fluency. (Select all that apply)",
      "options": [
        "optimize only one bottleneck dimension",
        "compute average and peak separately with headroom",
        "estimate queue growth under burst mismatch",
        "state confidence and margin for each estimate",
        "hide assumptions to avoid challenge"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The selected options are correct because together they reduce ignoring storage growth and retention multipliers through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "You are being tested on mitigation composition, not checkbox coverage. In payments orchestration service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-075",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in media transcoding pipeline? (Select all that apply)",
      "options": [
        "link each capacity number to a design decision",
        "treat rough estimates as exact guarantees",
        "translate latency targets into concurrency budgets",
        "avoid revisiting incorrect early numbers",
        "adjust architecture when math breaks constraints"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce missing read/write amplification effects through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "Your selected options should reduce bypass potential across different attack paths. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-076",
      "type": "multi-select",
      "question": "In webhook processing service, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "keep calculations simple, legible, and auditable",
        "optimize only one bottleneck dimension",
        "track read/write amplification in storage math",
        "skip peak calculations to save time",
        "use order-of-magnitude checks to catch errors"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The selected options are correct because together they reduce network bandwidth underestimated by bits/bytes confusion through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In webhook processing service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-077",
      "type": "multi-select",
      "question": "For session gateway, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "explicitly include replication and redundancy factors",
        "state confidence and margin for each estimate",
        "summarize final capacity envelope and risk areas"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "The selected options are correct because together they reduce queueing effects ignored at high utilization through layered mitigation and operational follow-through. The non-selected options leave meaningful gaps or add complexity without proportional risk reduction.",
      "detailedExplanation": "The interview signal is whether your chosen controls still hold under stress. In session gateway, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-078",
      "type": "numeric-input",
      "question": "In a 45-minute interview, you allocate 15% to requirements and scoping. How many minutes is that? During live capacity reasoning.",
      "answer": 6.75,
      "unit": "minutes",
      "tolerance": 0.15,
      "explanation": "45  15% = 6.75 minutes. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a 45-minute interview, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-079",
      "type": "numeric-input",
      "question": "While whiteboarding recommendation ranking service, you estimate 860 QPS and 140ms average latency. Using Little's Law, how many in-flight requests are expected? During live capacity reasoning.",
      "answer": 120.4,
      "unit": "requests",
      "tolerance": 0.15,
      "explanation": "L = W = 860  0.14 = 120.40 in-flight requests. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "Back-of-envelope math should be auditable and tied to thresholds. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-080",
      "type": "numeric-input",
      "question": "After interview feedback, design explanation time dropped from 20 to 14 minutes while preserving coverage. What is the percent reduction? During live capacity reasoning.",
      "answer": 30,
      "unit": "percent",
      "tolerance": 0.15,
      "explanation": "(20-14)/20  100 = 30.00%. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "Keep the arithmetic simple, then explain the operational implication. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-081",
      "type": "numeric-input",
      "question": "You discuss 9 serial dependencies each at 99.9% monthly reliability assumptions in an interview drill. Approximate combined downtime-hours/year if failures are independent and additive by rough estimate? During live capacity reasoning.",
      "answer": 78.84,
      "unit": "hours/year",
      "tolerance": 0.2,
      "explanation": "Back-of-envelope additive approximation: 9  8.76  78.84 hours/year. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-082",
      "type": "numeric-input",
      "question": "For a live design walkthrough, you estimate 380,000 DAU and 10 requests/user/day. What is average QPS? During live capacity reasoning.",
      "answer": 44,
      "unit": "qps",
      "tolerance": 0.15,
      "explanation": "380,000  10  86,400  44 QPS. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "A good estimate closes with an actionable design consequence. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a live design walkthrough, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-083",
      "type": "numeric-input",
      "question": "In a mock interview retro, your design suffered 8 incidents/month with 17 min MTTR each. Total monthly downtime minutes? During live capacity reasoning.",
      "answer": 136,
      "unit": "minutes/month",
      "tolerance": 0.15,
      "explanation": "8  17 = 136 minutes/month. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "The interviewer is checking both correctness and usefulness of the math. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a mock interview retro, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-084",
      "type": "numeric-input",
      "question": "A whiteboard estimate gives 12,000 QPS steady load. If you require 30% headroom, what throughput target should you state? During live capacity reasoning.",
      "answer": 15600,
      "unit": "QPS",
      "tolerance": 0.15,
      "explanation": "12,000  1.30 = 15,600 QPS. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "This is a decision-support estimate, not just arithmetic. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a 45-minute interview, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-085",
      "type": "numeric-input",
      "question": "While whiteboarding session gateway, you estimate 1220 QPS and 260ms average latency. Using Little's Law, how many in-flight requests are expected? During live capacity reasoning.",
      "answer": 317.2,
      "unit": "requests",
      "tolerance": 0.15,
      "explanation": "L = W = 1220  0.26 = 317.20 in-flight requests. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "Interview quality depends on clean assumptions and explicit units. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-086",
      "type": "numeric-input",
      "question": "After interview feedback, design explanation time dropped from 26 to 22 minutes while preserving coverage. What is the percent reduction? During live capacity reasoning.",
      "answer": 15.38,
      "unit": "percent",
      "tolerance": 0.15,
      "explanation": "(26-22)/26  100 = 15.38%. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "The value of this number is in how it changes the design choice. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-087",
      "type": "numeric-input",
      "question": "You discuss 8 serial dependencies each at 99.9% monthly reliability assumptions in an interview drill. Approximate combined downtime-hours/year if failures are independent and additive by rough estimate? During live capacity reasoning.",
      "answer": 70.08,
      "unit": "hours/year",
      "tolerance": 0.2,
      "explanation": "Back-of-envelope additive approximation: 8  8.76  70.08 hours/year. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "Numeric prompts test whether your reasoning survives unit pressure. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-088",
      "type": "numeric-input",
      "question": "For a live design walkthrough, you estimate 500,000 DAU and 6 requests/user/day. What is average QPS? During live capacity reasoning.",
      "answer": 35,
      "unit": "qps",
      "tolerance": 0.15,
      "explanation": "500,000  6  86,400  35 QPS. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "This is a decision-support estimate, not just arithmetic. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a live design walkthrough, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-089",
      "type": "numeric-input",
      "question": "In a mock interview retro, your design suffered 8 incidents/month with 15 min MTTR each. Total monthly downtime minutes? During live capacity reasoning.",
      "answer": 120,
      "unit": "minutes/month",
      "tolerance": 0.15,
      "explanation": "8  15 = 120 minutes/month. This estimate should drive a concrete live capacity reasoning and unit-safe estimation decision such as headroom, queue limits, or failover thresholds. Use this value to justify one concrete live capacity reasoning and unit-safe estimation decision.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a mock interview retro, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-090",
      "type": "ordering",
      "question": "Rank these controls by expected risk reduction (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Define rollout guardrails",
        "Identify primary risk",
        "Define post-rollout validation",
        "Choose highest-leverage control",
        "Set success constraint"
      ],
      "correctOrder": [1, 4, 3, 0, 2],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Good ordering protects both delivery speed and system reliability. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-091",
      "type": "ordering",
      "question": "Order these options by operational maturity (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Capture current signal",
        "Pick first mitigation",
        "Measure impact",
        "Form diagnosis hypothesis",
        "Iterate controls"
      ],
      "correctOrder": [0, 3, 1, 2, 4],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Interviewers expect you to justify transitions, not just the final order. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-092",
      "type": "ordering",
      "question": "Arrange these controls by real-world robustness under failure (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "State assumptions",
        "Evaluate tradeoffs",
        "Summarize risks",
        "Clarify requirement",
        "Propose design"
      ],
      "correctOrder": [3, 0, 4, 1, 2],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Prioritize steps that improve decision confidence before hard commitment. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-093",
      "type": "ordering",
      "question": "Rank these choices by long-term reliability impact (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Verify with drills",
        "Map trust/flow boundaries",
        "Prioritize failure/abuse paths",
        "Implement controls",
        "List assets or users"
      ],
      "correctOrder": [4, 1, 2, 3, 0],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "This ordering should move from framing to decision to validation. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-094",
      "type": "ordering",
      "question": "Order these controls by how strongly they reduce repeat incidents (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Compare alternatives",
        "Review residual risk",
        "Plan migration",
        "Select approach",
        "Define objective"
      ],
      "correctOrder": [4, 0, 3, 2, 1],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "The wrong sequence often causes rework and hidden residual risk. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-095",
      "type": "ordering",
      "question": "Arrange these options from reactive posture to proactive posture for live capacity reasoning fluency.",
      "items": [
        "Capture baseline metrics",
        "Monitor outcomes",
        "Apply constraints",
        "Estimate capacity or risk envelope",
        "Choose architecture change"
      ],
      "correctOrder": [0, 3, 2, 4, 1],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "This ranking is about dependency awareness between decisions. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-096",
      "type": "ordering",
      "question": "Rank these controls by defensive depth they add (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Define post-rollout validation",
        "Choose highest-leverage control",
        "Define rollout guardrails",
        "Identify primary risk",
        "Set success constraint"
      ],
      "correctOrder": [3, 4, 1, 2, 0],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "A solid sequence reduces uncertainty before committing to expensive changes. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "int-cr-097",
      "type": "ordering",
      "question": "Order these choices by resilience under production stress (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Pick first mitigation",
        "Form diagnosis hypothesis",
        "Capture current signal",
        "Iterate controls",
        "Measure impact"
      ],
      "correctOrder": [2, 1, 0, 4, 3],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "A mature order avoids premature optimization and late-stage surprises. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ]
    },
    {
      "id": "int-cr-098",
      "type": "ordering",
      "question": "Arrange these controls from baseline hygiene to hardened practice for live capacity reasoning fluency.",
      "items": [
        "State assumptions",
        "Clarify requirement",
        "Evaluate tradeoffs",
        "Propose design",
        "Summarize risks"
      ],
      "correctOrder": [1, 0, 3, 2, 4],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "The best sequence makes rollback and validation straightforward. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ]
    },
    {
      "id": "int-cr-099",
      "type": "ordering",
      "question": "Rank these options by consistency of outcomes over time (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "List assets or users",
        "Implement controls",
        "Prioritize failure/abuse paths",
        "Verify with drills",
        "Map trust/flow boundaries"
      ],
      "correctOrder": [0, 4, 2, 1, 3],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Ordering items measure execution discipline more than terminology recall. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ]
    },
    {
      "id": "int-cr-100",
      "type": "ordering",
      "question": "Order these controls by production-readiness maturity (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Select approach",
        "Review residual risk",
        "Define objective",
        "Plan migration",
        "Compare alternatives"
      ],
      "correctOrder": [2, 4, 0, 3, 1],
      "explanation": "This sequence is best because it moves from objective framing to option evaluation, then implementation planning and residual-risk review. In live capacity reasoning and unit-safe estimation, changing this order often causes premature commitment and weaker validation.",
      "detailedExplanation": "Prioritize steps that improve decision confidence before hard commitment. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    }
  ]
}
