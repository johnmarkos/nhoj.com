{
  "unit": 12,
  "unitTitle": "Interview Execution & Design Communication",
  "chapter": 5,
  "chapterTitle": "Capacity Reasoning in Live Whiteboarding",
  "chapterDescription": "Strengthen real-time capacity math, bottleneck identification, and approximation discipline during interview discussion.",
  "problems": [
    {
      "id": "int-cr-001",
      "type": "multiple-choice",
      "question": "For inventory reservation service, primary risk is unit conversion mistakes under time pressure while supporting multi-tenant isolation. Which response is strongest?",
      "options": [
        "normalize units before calculating and narrate assumptions",
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "Treat inventory reservation service as a risk-reduction sequencing problem. \"normalize units before calculating and narrate assumptions\" wins because it targets unit conversion mistakes under time pressure while supporting multi-tenant isolation while keeping rollout risk controlled.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In inventory reservation service, normalize units before calculating and narrate assumptions should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-002",
      "type": "multiple-choice",
      "question": "In catalog read API, highest-risk gap is sizing to average instead of peak with frequent schema evolution. Which choice best improves the design?",
      "options": [
        "ignore replication and failover capacity impact",
        "compute average and peak separately with headroom",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 1,
      "explanation": "The highest-leverage move for catalog read API is \"compute average and peak separately with headroom\". It addresses sizing to average instead of peak with frequent schema evolution faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In catalog read API, compute average and peak separately with headroom should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-003",
      "type": "multiple-choice",
      "question": "During a design review for Profile graph service, you suspect forgetting headroom for failure scenarios under aggressive latency targets. Which action should be prioritized first?",
      "options": [
        "hide assumptions to avoid challenge",
        "optimize only one bottleneck dimension",
        "link each capacity number to a design decision",
        "mix bits and bytes inconsistently"
      ],
      "correct": 2,
      "explanation": "This scenario centers on Profile graph service. Prioritize \"link each capacity number to a design decision\" first because it reduces forgetting headroom for failure scenarios under aggressive latency targets without deferring mitigation.",
      "detailedExplanation": "Good staff-level reasoning names both immediate impact and downstream tradeoffs. In Profile graph service, link each capacity number to a design decision should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-004",
      "type": "multiple-choice",
      "question": "In media transcoding pipeline, the dominant concern is throughput and latency assumptions misaligned during bot-driven traffic spikes. What is the best next move?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions",
        "use order-of-magnitude checks to catch errors"
      ],
      "correct": 3,
      "explanation": "In media transcoding pipeline, \"use order-of-magnitude checks to catch errors\" is strongest because it directly mitigates throughput and latency assumptions misaligned during bot-driven traffic spikes for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In media transcoding pipeline, use order-of-magnitude checks to catch errors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-005",
      "type": "multiple-choice",
      "question": "For experiment assignment service, primary risk is ignoring storage growth and retention multipliers while operating across two regions. Which response is strongest?",
      "options": [
        "explicitly include replication and redundancy factors",
        "hide assumptions to avoid challenge",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time"
      ],
      "correct": 0,
      "explanation": "Treat experiment assignment service as a risk-reduction sequencing problem. \"explicitly include replication and redundancy factors\" wins because it targets ignoring storage growth and retention multipliers while operating across two regions while keeping rollout risk controlled.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In experiment assignment service, explicitly include replication and redundancy factors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-006",
      "type": "multiple-choice",
      "question": "During incident preparation for feature flag control plane, highest-risk gap is missing read/write amplification effects under peak traffic. Which choice best improves the design?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "estimate queue growth under burst mismatch",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees"
      ],
      "correct": 1,
      "explanation": "The highest-leverage move for feature flag control plane is \"estimate queue growth under burst mismatch\". It addresses missing read/write amplification effects under peak traffic faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In feature flag control plane, estimate queue growth under burst mismatch should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-007",
      "type": "multiple-choice",
      "question": "During a design review for analytics ingestion pipeline, you suspect network bandwidth underestimated by bits/bytes confusion during a regional failover drill. Which action should be prioritized first?",
      "options": [
        "skip peak calculations to save time",
        "mix bits and bytes inconsistently",
        "translate latency targets into concurrency budgets",
        "optimize only one bottleneck dimension"
      ],
      "correct": 2,
      "explanation": "This scenario centers on analytics ingestion pipeline. Prioritize \"translate latency targets into concurrency budgets\" first because it reduces network bandwidth underestimated by bits/bytes confusion during a regional failover drill without deferring mitigation.",
      "detailedExplanation": "Good staff-level reasoning names both immediate impact and downstream tradeoffs. In analytics ingestion pipeline, translate latency targets into concurrency budgets should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-008",
      "type": "multiple-choice",
      "question": "In webhook processing service, the dominant concern is queueing effects ignored at high utilization while deployment velocity is high. What is the best next move?",
      "options": [
        "ignore replication and failover capacity impact",
        "leave math disconnected from architecture decisions",
        "treat rough estimates as exact guarantees",
        "track read/write amplification in storage math"
      ],
      "correct": 3,
      "explanation": "In webhook processing service, \"track read/write amplification in storage math\" is strongest because it directly mitigates queueing effects ignored at high utilization while deployment velocity is high for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In webhook processing service, track read/write amplification in storage math should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-009",
      "type": "multiple-choice",
      "question": "For partner integration gateway, primary risk is unclear confidence in approximated numbers when one dependency is degraded. Which response is strongest?",
      "options": [
        "state confidence and margin for each estimate",
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "Treat partner integration gateway as a risk-reduction sequencing problem. \"state confidence and margin for each estimate\" wins because it targets unclear confidence in approximated numbers when one dependency is degraded while keeping rollout risk controlled.",
      "detailedExplanation": "Strong answers connect one decision to one observable outcome. In partner integration gateway, state confidence and margin for each estimate should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-010",
      "type": "multiple-choice",
      "question": "During incident preparation for admin operations console, highest-risk gap is failing to tie math back to architecture choices with strict compliance scope. Which choice best improves the design?",
      "options": [
        "ignore replication and failover capacity impact",
        "adjust architecture when math breaks constraints",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 1,
      "explanation": "This scenario centers on admin operations console. Prioritize \"adjust architecture when math breaks constraints\" first because it reduces failing to tie math back to architecture choices with strict compliance scope without deferring mitigation.",
      "detailedExplanation": "Good staff-level reasoning names both immediate impact and downstream tradeoffs. In admin operations console, adjust architecture when math breaks constraints should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-011",
      "type": "multiple-choice",
      "question": "In model inference endpoint, the dominant concern is calculations not checked for plausibility while supporting multi-tenant isolation. What is the best next move?",
      "options": [
        "mix bits and bytes inconsistently",
        "optimize only one bottleneck dimension",
        "hide assumptions to avoid challenge",
        "keep calculations simple, legible, and auditable"
      ],
      "correct": 3,
      "explanation": "In model inference endpoint, \"keep calculations simple, legible, and auditable\" is strongest because it directly mitigates calculations not checked for plausibility while supporting multi-tenant isolation for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In model inference endpoint, keep calculations simple, legible, and auditable should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-012",
      "type": "multiple-choice",
      "question": "During a design review for session gateway, you suspect resource budget omitted for safety margin with frequent schema evolution. Which action should be prioritized first?",
      "options": [
        "summarize final capacity envelope and risk areas",
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 0,
      "explanation": "Treat session gateway as a risk-reduction sequencing problem. \"summarize final capacity envelope and risk areas\" wins because it targets resource budget omitted for safety margin with frequent schema evolution while keeping rollout risk controlled.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In session gateway, summarize final capacity envelope and risk areas should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-013",
      "type": "multiple-choice",
      "question": "During incident preparation for billing reconciliation batch, highest-risk gap is unit conversion mistakes under time pressure under aggressive latency targets. Which choice best improves the design?",
      "options": [
        "hide assumptions to avoid challenge",
        "skip peak calculations to save time",
        "normalize units before calculating and narrate assumptions",
        "optimize only one bottleneck dimension"
      ],
      "correct": 2,
      "explanation": "The highest-leverage move for billing reconciliation batch is \"normalize units before calculating and narrate assumptions\". It addresses unit conversion mistakes under time pressure under aggressive latency targets faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In billing reconciliation batch, normalize units before calculating and narrate assumptions should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-014",
      "type": "multiple-choice",
      "question": "For support workflow automation, primary risk is sizing to average instead of peak during bot-driven traffic spikes. Which response is strongest?",
      "options": [
        "compute average and peak separately with headroom",
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "ignore replication and failover capacity impact"
      ],
      "correct": 0,
      "explanation": "This scenario centers on support workflow automation. Prioritize \"compute average and peak separately with headroom\" first because it reduces sizing to average instead of peak during bot-driven traffic spikes without deferring mitigation.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In support workflow automation, compute average and peak separately with headroom should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-015",
      "type": "multiple-choice",
      "question": "In checkout API gateway, the dominant concern is forgetting headroom for failure scenarios while operating across two regions. What is the best next move?",
      "options": [
        "optimize only one bottleneck dimension",
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "link each capacity number to a design decision"
      ],
      "correct": 3,
      "explanation": "In checkout API gateway, \"link each capacity number to a design decision\" is strongest because it directly mitigates forgetting headroom for failure scenarios while operating across two regions for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In checkout API gateway, link each capacity number to a design decision should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-016",
      "type": "multiple-choice",
      "question": "During a design review for identity token service, you suspect throughput and latency assumptions misaligned under peak traffic. Which action should be prioritized first?",
      "options": [
        "use order-of-magnitude checks to catch errors",
        "ignore replication and failover capacity impact",
        "leave math disconnected from architecture decisions",
        "treat rough estimates as exact guarantees"
      ],
      "correct": 0,
      "explanation": "Treat identity token service as a risk-reduction sequencing problem. \"use order-of-magnitude checks to catch errors\" wins because it targets throughput and latency assumptions misaligned under peak traffic while keeping rollout risk controlled.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In identity token service, use order-of-magnitude checks to catch errors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-017",
      "type": "multiple-choice",
      "question": "In search indexing pipeline, highest-risk gap is ignoring storage growth and retention multipliers during a regional failover drill. Which choice best improves the design?",
      "options": [
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge",
        "explicitly include replication and redundancy factors",
        "mix bits and bytes inconsistently"
      ],
      "correct": 2,
      "explanation": "The highest-leverage move for search indexing pipeline is \"explicitly include replication and redundancy factors\". It addresses ignoring storage growth and retention multipliers during a regional failover drill faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "Treat this as a leverage decision: small change, large risk reduction. In search indexing pipeline, explicitly include replication and redundancy factors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-018",
      "type": "multiple-choice",
      "question": "For recommendation ranking service, primary risk is missing read/write amplification effects while deployment velocity is high. Which response is strongest?",
      "options": [
        "estimate queue growth under burst mismatch",
        "ignore replication and failover capacity impact",
        "leave math disconnected from architecture decisions",
        "avoid revisiting incorrect early numbers"
      ],
      "correct": 0,
      "explanation": "This scenario centers on recommendation ranking service. Prioritize \"estimate queue growth under burst mismatch\" first because it reduces missing read/write amplification effects while deployment velocity is high without deferring mitigation.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In recommendation ranking service, estimate queue growth under burst mismatch should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-019",
      "type": "multiple-choice",
      "question": "A scenario of chat delivery workers surfaced this issue: the dominant concern is network bandwidth underestimated by bits/bytes confusion when one dependency is degraded. What is the best next move?",
      "options": [
        "hide assumptions to avoid challenge",
        "optimize only one bottleneck dimension",
        "mix bits and bytes inconsistently",
        "translate latency targets into concurrency budgets"
      ],
      "correct": 3,
      "explanation": "In A scenario of chat delivery workers surfaced this issue: the dominant concern is network bandwidth underestimated by bits/bytes confusion when one dependency is degraded, \"translate latency targets into concurrency budgets\" is strongest because it directly mitigates network bandwidth underestimated by bits/bytes confusion when one dependency is degraded for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In this system, translate latency targets into concurrency budgets should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-020",
      "type": "multiple-choice",
      "question": "During a design review for notification fanout dispatcher, you suspect queueing effects ignored at high utilization with strict compliance scope. Which action should be prioritized first?",
      "options": [
        "track read/write amplification in storage math",
        "avoid revisiting incorrect early numbers",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 0,
      "explanation": "The highest-leverage move for notification fanout dispatcher is \"track read/write amplification in storage math\". It addresses queueing effects ignored at high utilization with strict compliance scope faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "Focus on what you can deploy first without painting the team into a corner. In notification fanout dispatcher, track read/write amplification in storage math should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-021",
      "type": "multiple-choice",
      "question": "During a design review for fraud scoring engine, you suspect unclear confidence in approximated numbers while supporting multi-tenant isolation. Which action should be prioritized first?",
      "options": [
        "state confidence and margin for each estimate",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "This scenario centers on fraud scoring engine. Prioritize \"state confidence and margin for each estimate\" first because it reduces unclear confidence in approximated numbers while supporting multi-tenant isolation without deferring mitigation.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In fraud scoring engine, state confidence and margin for each estimate should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-022",
      "type": "multiple-choice",
      "question": "In ad auction edge service, the dominant concern is failing to tie math back to architecture choices with frequent schema evolution. What is the best next move?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "adjust architecture when math breaks constraints"
      ],
      "correct": 3,
      "explanation": "In ad auction edge service, \"adjust architecture when math breaks constraints\" is strongest because it directly mitigates failing to tie math back to architecture choices with frequent schema evolution for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In ad auction edge service, adjust architecture when math breaks constraints should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-023",
      "type": "multiple-choice",
      "question": "For document collaboration backend, primary risk is calculations not checked for plausibility under aggressive latency targets. Which response is strongest?",
      "options": [
        "skip peak calculations to save time",
        "optimize only one bottleneck dimension",
        "keep calculations simple, legible, and auditable",
        "mix bits and bytes inconsistently"
      ],
      "correct": 2,
      "explanation": "Treat document collaboration backend as a risk-reduction sequencing problem. \"keep calculations simple, legible, and auditable\" wins because it targets calculations not checked for plausibility under aggressive latency targets while keeping rollout risk controlled.",
      "detailedExplanation": "This scenario rewards concrete execution thinking over abstract principles. In document collaboration backend, keep calculations simple, legible, and auditable should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-024",
      "type": "multiple-choice",
      "question": "During incident preparation for payments orchestration service, highest-risk gap is resource budget omitted for safety margin during bot-driven traffic spikes. Which choice best improves the design?",
      "options": [
        "leave math disconnected from architecture decisions",
        "summarize final capacity envelope and risk areas",
        "treat rough estimates as exact guarantees",
        "ignore replication and failover capacity impact"
      ],
      "correct": 1,
      "explanation": "The highest-leverage move for payments orchestration service is \"summarize final capacity envelope and risk areas\". It addresses resource budget omitted for safety margin during bot-driven traffic spikes faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "A high-quality response balances speed, safety, and ownership. In payments orchestration service, summarize final capacity envelope and risk areas should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-025",
      "type": "multiple-choice",
      "question": "During a design review for inventory reservation service, you suspect unit conversion mistakes under time pressure while operating across two regions. Which action should be prioritized first?",
      "options": [
        "normalize units before calculating and narrate assumptions",
        "mix bits and bytes inconsistently",
        "hide assumptions to avoid challenge",
        "skip peak calculations to save time"
      ],
      "correct": 0,
      "explanation": "This scenario centers on inventory reservation service. Prioritize \"normalize units before calculating and narrate assumptions\" first because it reduces unit conversion mistakes under time pressure while operating across two regions without deferring mitigation.",
      "detailedExplanation": "The key is selecting a step that is measurable and reversible. In inventory reservation service, normalize units before calculating and narrate assumptions should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-026",
      "type": "multiple-choice",
      "question": "In catalog read API, the dominant concern is sizing to average instead of peak under peak traffic. What is the best next move?",
      "options": [
        "ignore replication and failover capacity impact",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions",
        "compute average and peak separately with headroom"
      ],
      "correct": 3,
      "explanation": "In catalog read API, \"compute average and peak separately with headroom\" is strongest because it directly mitigates sizing to average instead of peak under peak traffic for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "This is primarily a sequencing problem, not a tooling problem. In catalog read API, compute average and peak separately with headroom should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-027",
      "type": "multiple-choice",
      "question": "For profile graph service, primary risk is forgetting headroom for failure scenarios during a regional failover drill. Which response is strongest?",
      "options": [
        "hide assumptions to avoid challenge",
        "mix bits and bytes inconsistently",
        "link each capacity number to a design decision",
        "optimize only one bottleneck dimension"
      ],
      "correct": 2,
      "explanation": "Treat profile graph service as a risk-reduction sequencing problem. \"link each capacity number to a design decision\" wins because it targets forgetting headroom for failure scenarios during a regional failover drill while keeping rollout risk controlled.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In profile graph service, link each capacity number to a design decision should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-028",
      "type": "multiple-choice",
      "question": "During incident preparation for media transcoding pipeline, highest-risk gap is throughput and latency assumptions misaligned while deployment velocity is high. Which choice best improves the design?",
      "options": [
        "leave math disconnected from architecture decisions",
        "treat rough estimates as exact guarantees",
        "use order-of-magnitude checks to catch errors",
        "avoid revisiting incorrect early numbers"
      ],
      "correct": 2,
      "explanation": "The highest-leverage move for media transcoding pipeline is \"use order-of-magnitude checks to catch errors\". It addresses throughput and latency assumptions misaligned while deployment velocity is high faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "Focus on what you can deploy first without painting the team into a corner. In media transcoding pipeline, use order-of-magnitude checks to catch errors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-029",
      "type": "multiple-choice",
      "question": "During a design review for experiment assignment service, you suspect ignoring storage growth and retention multipliers when one dependency is degraded. Which action should be prioritized first?",
      "options": [
        "explicitly include replication and redundancy factors",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time",
        "hide assumptions to avoid challenge"
      ],
      "correct": 0,
      "explanation": "This scenario centers on experiment assignment service. Prioritize \"explicitly include replication and redundancy factors\" first because it reduces ignoring storage growth and retention multipliers when one dependency is degraded without deferring mitigation.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In experiment assignment service, explicitly include replication and redundancy factors should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-030",
      "type": "multiple-choice",
      "question": "In feature flag control plane, the dominant concern is missing read/write amplification effects with strict compliance scope. What is the best next move?",
      "options": [
        "avoid revisiting incorrect early numbers",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "estimate queue growth under burst mismatch"
      ],
      "correct": 3,
      "explanation": "Treat feature flag control plane as a risk-reduction sequencing problem. \"estimate queue growth under burst mismatch\" wins because it targets missing read/write amplification effects with strict compliance scope while keeping rollout risk controlled.",
      "detailedExplanation": "Interviewers care about whether your first move is both effective and operable. In feature flag control plane, estimate queue growth under burst mismatch should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-031",
      "type": "multiple-choice",
      "question": "During incident preparation for analytics ingestion pipeline, highest-risk gap is network bandwidth underestimated by bits/bytes confusion while supporting multi-tenant isolation. Which choice best improves the design?",
      "options": [
        "mix bits and bytes inconsistently",
        "translate latency targets into concurrency budgets",
        "optimize only one bottleneck dimension",
        "skip peak calculations to save time"
      ],
      "correct": 1,
      "explanation": "The highest-leverage move for analytics ingestion pipeline is \"translate latency targets into concurrency budgets\". It addresses network bandwidth underestimated by bits/bytes confusion while supporting multi-tenant isolation faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "The right answer should reduce uncertainty and operational risk at the same time. In analytics ingestion pipeline, translate latency targets into concurrency budgets should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-032",
      "type": "multiple-choice",
      "question": "For webhook processing service, primary risk is queueing effects ignored at high utilization with frequent schema evolution. Which response is strongest?",
      "options": [
        "track read/write amplification in storage math",
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "leave math disconnected from architecture decisions"
      ],
      "correct": 0,
      "explanation": "This scenario centers on webhook processing service. Prioritize \"track read/write amplification in storage math\" first because it reduces queueing effects ignored at high utilization with frequent schema evolution without deferring mitigation.",
      "detailedExplanation": "This question is testing prioritization quality under constraints. In webhook processing service, track read/write amplification in storage math should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-033",
      "type": "multiple-choice",
      "question": "While reviewing partner integration gateway, the dominant concern is unclear confidence in approximated numbers under aggressive latency targets. What is the best next move?",
      "options": [
        "skip peak calculations to save time",
        "mix bits and bytes inconsistently",
        "hide assumptions to avoid challenge",
        "state confidence and margin for each estimate"
      ],
      "correct": 3,
      "explanation": "In partner integration gateway, \"state confidence and margin for each estimate\" is strongest because it directly mitigates unclear confidence in approximated numbers under aggressive latency targets for Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "The strongest answer starts with causal reasoning, not buzzwords. In partner integration gateway, state confidence and margin for each estimate should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-034",
      "type": "multiple-choice",
      "question": "During a design review for admin operations console, you suspect failing to tie math back to architecture choices during bot-driven traffic spikes. Which action should be prioritized first?",
      "options": [
        "adjust architecture when math breaks constraints",
        "avoid revisiting incorrect early numbers",
        "leave math disconnected from architecture decisions",
        "ignore replication and failover capacity impact"
      ],
      "correct": 0,
      "explanation": "Treat admin operations console as a risk-reduction sequencing problem. \"adjust architecture when math breaks constraints\" wins because it targets failing to tie math back to architecture choices during bot-driven traffic spikes while keeping rollout risk controlled.",
      "detailedExplanation": "Strong answers connect one decision to one observable outcome. In admin operations console, adjust architecture when math breaks constraints should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-035",
      "type": "multiple-choice",
      "question": "In model inference endpoint, highest-risk gap is calculations not checked for plausibility while operating across two regions. Which choice best improves the design?",
      "options": [
        "mix bits and bytes inconsistently",
        "keep calculations simple, legible, and auditable",
        "optimize only one bottleneck dimension",
        "hide assumptions to avoid challenge"
      ],
      "correct": 1,
      "explanation": "The highest-leverage move for model inference endpoint is \"keep calculations simple, legible, and auditable\". It addresses calculations not checked for plausibility while operating across two regions faster than alternatives that rely on brittle assumptions.",
      "detailedExplanation": "Treat this as a leverage decision: small change, large risk reduction. In model inference endpoint, keep calculations simple, legible, and auditable should be justified by expected risk reduction speed, blast-radius containment, and operational cost. A strong answer also names one residual risk and one post-rollout verification signal.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-036",
      "type": "two-stage",
      "stages": [
        {
          "question": "For notification fanout dispatcher, what is the most likely core problem behind unit conversion mistakes under time pressure while supporting multi-tenant isolation?",
          "options": [
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios",
            "ignoring storage growth and retention multipliers",
            "network bandwidth underestimated by bits/bytes confusion"
          ],
          "correct": 0,
          "explanation": "At stage 1, prioritize \"unit conversion mistakes under time pressure\" for notification fanout dispatcher. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In notification fanout dispatcher, unit conversion mistakes best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in notification fanout dispatcher, which adjustment gives the best risk reduction?",
          "options": [
            "skip peak calculations to save time",
            "normalize units before calculating and narrate assumptions",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently"
          ],
          "correct": 1,
          "explanation": "Stage 2: for With diagnosis confirmed in notification fanout dispatcher, which adjustment gives the best risk reduction, \"normalize units before calculating and narrate assumptions\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In notification fanout dispatcher, normalize units before calculating and narrate assumptions is high leverage because it lowers unit conversion mistakes without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "The scoring is sequential for notification fanout dispatcher: stage 1 should isolate the governing risk, and stage 2 should prioritize \"normalize units before calculating and narrate assumptions\" to reduce recurrence.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of ad auction edge service, which diagnosis is most defensible for sizing to average instead of peak during bot-driven traffic spikes?",
          "options": [
            "throughput and latency assumptions misaligned",
            "queueing effects ignored at high utilization",
            "sizing to average instead of peak",
            "missing read/write amplification effects"
          ],
          "correct": 2,
          "explanation": "Stage 1: for ad auction edge service, \"sizing to average instead of peak\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. In this system, sizing to average instead of peak best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for ad auction edge service, what is the strongest immediate response?",
          "options": [
            "compute average and peak separately with headroom",
            "leave math disconnected from architecture decisions",
            "ignore replication and failover capacity impact",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 0,
          "explanation": "At stage 2, prioritize \"compute average and peak separately with headroom\" for Now that root cause is clear for ad auction edge service, what is the strongest immediate response. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "The right first step should be high ROI and low coordination overhead. In this system, compute average and peak separately with headroom is high leverage because it lowers sizing to average instead of peak without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage item tests diagnosis then mitigation in Capacity Reasoning in Live Whiteboarding: identify the core risk for ad auction edge service, then apply \"compute average and peak separately with headroom\" as the highest-leverage follow-up.",
      "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. Now the signal is whether you can choose the highest-leverage next action. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "In payments orchestration service, what is the highest-priority diagnosis given forgetting headroom for failure scenarios during a regional failover drill?",
          "options": [
            "forgetting headroom for failure scenarios",
            "network bandwidth underestimated by bits/bytes confusion",
            "unclear confidence in approximated numbers",
            "ignoring storage growth and retention multipliers"
          ],
          "correct": 0,
          "explanation": "At stage 1, prioritize \"forgetting headroom for failure scenarios\" for payments orchestration service. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In payments orchestration service, forgetting headroom for failure scenarios best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Given that diagnosis in payments orchestration service, which next change should be prioritized first?",
          "options": [
            "mix bits and bytes inconsistently",
            "hide assumptions to avoid challenge",
            "optimize only one bottleneck dimension",
            "link each capacity number to a design decision"
          ],
          "correct": 3,
          "explanation": "Stage 2 is about controllability under stress for Given that diagnosis in payments orchestration service, which next change should be prioritized first. \"link each capacity number to a design decision\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In payments orchestration service, link each capacity number to a design decision is high leverage because it lowers forgetting headroom for failure scenarios without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This prompt rewards continuity across both stages in Capacity Reasoning in Live Whiteboarding. Carry the stage-1 diagnosis (the incident signal) directly into stage-2 action (\"link each capacity number to a design decision\").",
      "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. This phase checks whether your mitigation plan is practical, not theoretical. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "In catalog read API, the strongest diagnosis is needed. Which primary issue best explains throughput and latency assumptions misaligned with strict compliance scope?",
          "options": [
            "missing read/write amplification effects",
            "failing to tie math back to architecture choices",
            "queueing effects ignored at high utilization",
            "throughput and latency assumptions misaligned"
          ],
          "correct": 3,
          "explanation": "Stage 1 is about controllability under stress for catalog read API. \"throughput and latency assumptions misaligned\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. In catalog read API, throughput and latency assumptions misaligned best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "After diagnosing catalog read API, what should change first before broad rollout?",
          "options": [
            "avoid revisiting incorrect early numbers",
            "treat rough estimates as exact guarantees",
            "use order-of-magnitude checks to catch errors",
            "leave math disconnected from architecture decisions"
          ],
          "correct": 2,
          "explanation": "At stage 2, prioritize \"use order-of-magnitude checks to catch errors\" for After diagnosing catalog read API, what should change first before broad rollout. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "Choose the action that creates momentum for subsequent hardening work. In catalog read API, use order-of-magnitude checks to catch errors is high leverage because it lowers throughput and latency assumptions misaligned without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "Treat this as a linked decision chain for catalog read API. Strong responses diagnose the dominant failure path first, then execute \"use order-of-magnitude checks to catch errors\" to move from triage to durable control.",
      "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. The best response reduces exposure quickly without destabilizing the system. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "For media transcoding pipeline, what is the most likely core problem behind ignoring storage growth and retention multipliers under aggressive latency targets?",
          "options": [
            "unclear confidence in approximated numbers",
            "network bandwidth underestimated by bits/bytes confusion",
            "ignoring storage growth and retention multipliers",
            "calculations not checked for plausibility"
          ],
          "correct": 2,
          "explanation": "Stage 1: for media transcoding pipeline, \"ignoring storage growth and retention multipliers\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In media transcoding pipeline, ignoring storage growth and retention multipliers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in media transcoding pipeline, which adjustment gives the best risk reduction?",
          "options": [
            "hide assumptions to avoid challenge",
            "explicitly include replication and redundancy factors",
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension"
          ],
          "correct": 1,
          "explanation": "At stage 2, prioritize \"explicitly include replication and redundancy factors\" for With diagnosis confirmed in media transcoding pipeline, which adjustment gives the best risk reduction. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In media transcoding pipeline, explicitly include replication and redundancy factors is high leverage because it lowers ignoring storage growth and retention multipliers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage item tests diagnosis then mitigation in Capacity Reasoning in Live Whiteboarding: identify the core risk for media transcoding pipeline, then apply \"explicitly include replication and redundancy factors\" as the highest-leverage follow-up.",
      "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. The right first step should be high ROI and low coordination overhead. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of feature flag control plane, which diagnosis is most defensible for missing read/write amplification effects under peak traffic?",
          "options": [
            "queueing effects ignored at high utilization",
            "resource budget omitted for safety margin",
            "missing read/write amplification effects",
            "failing to tie math back to architecture choices"
          ],
          "correct": 2,
          "explanation": "For stage 1 in Capacity Reasoning in Live Whiteboarding, \"missing read/write amplification effects\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for feature flag control plane.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In this system, missing read/write amplification effects best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for feature flag control plane, what is the strongest immediate response?",
          "options": [
            "estimate queue growth under burst mismatch",
            "treat rough estimates as exact guarantees",
            "avoid revisiting incorrect early numbers",
            "ignore replication and failover capacity impact"
          ],
          "correct": 0,
          "explanation": "Stage 2 is about controllability under stress for Now that root cause is clear for feature flag control plane, what is the strongest immediate response. \"estimate queue growth under burst mismatch\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In this system, estimate queue growth under burst mismatch is high leverage because it lowers missing read/write amplification effects without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This prompt rewards continuity across both stages in Capacity Reasoning in Live Whiteboarding. Carry the stage-1 diagnosis (the incident signal) directly into stage-2 action (\"estimate queue growth under burst mismatch\").",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "In webhook processing service, what is the highest-priority diagnosis given network bandwidth underestimated by bits/bytes confusion when one dependency is degraded?",
          "options": [
            "network bandwidth underestimated by bits/bytes confusion",
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "unclear confidence in approximated numbers"
          ],
          "correct": 0,
          "explanation": "Stage 1 is about controllability under stress for webhook processing service. \"network bandwidth underestimated by bits/bytes confusion\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. In webhook processing service, network bandwidth best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in webhook processing service, which next change should be prioritized first?",
          "options": [
            "skip peak calculations to save time",
            "mix bits and bytes inconsistently",
            "optimize only one bottleneck dimension",
            "translate latency targets into concurrency budgets"
          ],
          "correct": 3,
          "explanation": "At stage 2, prioritize \"translate latency targets into concurrency budgets\" for Given that diagnosis in webhook processing service, which next change should be prioritized first. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "The best response reduces exposure quickly without destabilizing the system. In webhook processing service, translate latency targets into concurrency budgets is high leverage because it lowers network bandwidth without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "Treat this as a linked decision chain for webhook processing service. Strong responses diagnose the dominant failure path first, then execute \"translate latency targets into concurrency budgets\" to move from triage to durable control.",
      "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. Now the signal is whether you can choose the highest-leverage next action. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "In admin operations console, the strongest diagnosis is needed. Which primary issue best explains queueing effects ignored at high utilization with frequent schema evolution?",
          "options": [
            "failing to tie math back to architecture choices",
            "sizing to average instead of peak",
            "resource budget omitted for safety margin",
            "queueing effects ignored at high utilization"
          ],
          "correct": 3,
          "explanation": "For stage 1 in Capacity Reasoning in Live Whiteboarding, \"queueing effects ignored at high utilization\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for admin operations console.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In admin operations console, queueing effects ignored at high utilization best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "After diagnosing admin operations console, what should change first before broad rollout?",
          "options": [
            "ignore replication and failover capacity impact",
            "leave math disconnected from architecture decisions",
            "track read/write amplification in storage math",
            "treat rough estimates as exact guarantees"
          ],
          "correct": 2,
          "explanation": "Stage 2: for After diagnosing admin operations console, what should change first before broad rollout, \"track read/write amplification in storage math\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In admin operations console, track read/write amplification in storage math is high leverage because it lowers queueing effects ignored at high utilization without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "The scoring is sequential for admin operations console: stage 1 should isolate the governing risk, and stage 2 should prioritize \"track read/write amplification in storage math\" to reduce recurrence.",
      "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. A strong stage-2 answer balances immediate impact with operational safety. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "For session gateway, what is the most likely core problem behind unclear confidence in approximated numbers while operating across two regions?",
          "options": [
            "unclear confidence in approximated numbers",
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios"
          ],
          "correct": 0,
          "explanation": "Stage 1: for session gateway, \"unclear confidence in approximated numbers\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. In session gateway, unclear confidence in approximated numbers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in session gateway, which adjustment gives the best risk reduction?",
          "options": [
            "skip peak calculations to save time",
            "state confidence and margin for each estimate",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently"
          ],
          "correct": 1,
          "explanation": "For stage 2 in Capacity Reasoning in Live Whiteboarding, \"state confidence and margin for each estimate\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for With diagnosis confirmed in session gateway, which adjustment gives the best risk reduction.",
          "detailedExplanation": "Now the signal is whether you can choose the highest-leverage next action. In session gateway, state confidence and margin for each estimate is high leverage because it lowers unclear confidence in approximated numbers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage item tests diagnosis then mitigation in Capacity Reasoning in Live Whiteboarding: identify the core risk for session gateway, then apply \"state confidence and margin for each estimate\" as the highest-leverage follow-up.",
      "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. The right first step should be high ROI and low coordination overhead. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of support workflow automation, which diagnosis is most defensible for failing to tie math back to architecture choices while deployment velocity is high?",
          "options": [
            "resource budget omitted for safety margin",
            "throughput and latency assumptions misaligned",
            "failing to tie math back to architecture choices",
            "sizing to average instead of peak"
          ],
          "correct": 2,
          "explanation": "At stage 1, prioritize \"failing to tie math back to architecture choices\" for support workflow automation. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. In this system, failing to tie math back to architecture choices best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for support workflow automation, what is the strongest immediate response?",
          "options": [
            "adjust architecture when math breaks constraints",
            "leave math disconnected from architecture decisions",
            "ignore replication and failover capacity impact",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 0,
          "explanation": "Stage 2 is about controllability under stress for Now that root cause is clear for support workflow automation, what is the strongest immediate response. \"adjust architecture when math breaks constraints\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "Stage 2 rewards changes that are effective, measurable, and rollout-safe. In this system, adjust architecture when math breaks constraints is high leverage because it lowers failing to tie math back to architecture choices without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This prompt rewards continuity across both stages in Capacity Reasoning in Live Whiteboarding. Carry the stage-1 diagnosis (the incident signal) directly into stage-2 action (\"adjust architecture when math breaks constraints\").",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of identity token service, which diagnosis is most defensible for calculations not checked for plausibility while supporting multi-tenant isolation?",
          "options": [
            "forgetting headroom for failure scenarios",
            "ignoring storage growth and retention multipliers",
            "unit conversion mistakes under time pressure",
            "calculations not checked for plausibility"
          ],
          "correct": 3,
          "explanation": "Stage 1 is about controllability under stress for identity token service. \"calculations not checked for plausibility\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "Stage 1 rewards causal clarity and evidence-based thinking. In this system, calculations not checked for plausibility best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "After diagnosing identity token service, what should change first before broad rollout?",
          "options": [
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently",
            "keep calculations simple, legible, and auditable",
            "optimize only one bottleneck dimension"
          ],
          "correct": 2,
          "explanation": "At stage 2, prioritize \"keep calculations simple, legible, and auditable\" for After diagnosing identity token service, what should change first before broad rollout. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "The right first step should be high ROI and low coordination overhead. In this system, keep calculations simple, legible, and auditable is high leverage because it lowers calculations not checked for plausibility without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "Treat this as a linked decision chain for identity token service. Strong responses diagnose the dominant failure path first, then execute \"keep calculations simple, legible, and auditable\" to move from triage to durable control.",
      "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. Prioritize the smallest change that closes the largest risk gap. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "For recommendation ranking service, what is the most likely core problem behind resource budget omitted for safety margin during bot-driven traffic spikes?",
          "options": [
            "throughput and latency assumptions misaligned",
            "missing read/write amplification effects",
            "resource budget omitted for safety margin",
            "sizing to average instead of peak"
          ],
          "correct": 2,
          "explanation": "For stage 1 in Capacity Reasoning in Live Whiteboarding, \"resource budget omitted for safety margin\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for recommendation ranking service.",
          "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. In recommendation ranking service, resource budget omitted for safety margin best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "Given that diagnosis in recommendation ranking service, which next change should be prioritized first?",
          "options": [
            "treat rough estimates as exact guarantees",
            "summarize final capacity envelope and risk areas",
            "leave math disconnected from architecture decisions",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 1,
          "explanation": "Stage 2: for Given that diagnosis in recommendation ranking service, which next change should be prioritized first, \"summarize final capacity envelope and risk areas\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This is a prioritization question: what should ship first and why. In recommendation ranking service, summarize final capacity envelope and risk areas is high leverage because it lowers resource budget omitted for safety margin without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "The scoring is sequential for recommendation ranking service: stage 1 should isolate the governing risk, and stage 2 should prioritize \"summarize final capacity envelope and risk areas\" to reduce recurrence.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "In notification fanout dispatcher, the strongest diagnosis is needed. Which primary issue best explains unit conversion mistakes under time pressure during a regional failover drill?",
          "options": [
            "forgetting headroom for failure scenarios",
            "unit conversion mistakes under time pressure",
            "network bandwidth underestimated by bits/bytes confusion",
            "ignoring storage growth and retention multipliers"
          ],
          "correct": 1,
          "explanation": "Stage 1: for notification fanout dispatcher, \"unit conversion mistakes under time pressure\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In notification fanout dispatcher, unit conversion mistakes under time pressure best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for notification fanout dispatcher, what is the strongest immediate response?",
          "options": [
            "normalize units before calculating and narrate assumptions",
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension",
            "hide assumptions to avoid challenge"
          ],
          "correct": 0,
          "explanation": "For stage 2 in Capacity Reasoning in Live Whiteboarding, \"normalize units before calculating and narrate assumptions\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for Now that root cause is clear for notification fanout dispatcher, what is the strongest immediate response.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In notification fanout dispatcher, normalize units before calculating and narrate assumptions is high leverage because it lowers unit conversion mistakes under time pressure without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage item tests diagnosis then mitigation in Capacity Reasoning in Live Whiteboarding: identify the core risk for notification fanout dispatcher, then apply \"normalize units before calculating and narrate assumptions\" as the highest-leverage follow-up.",
      "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. Stage 2 is first-move prioritization under real delivery constraints. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "In ad auction edge service, what is the highest-priority diagnosis given sizing to average instead of peak with strict compliance scope?",
          "options": [
            "sizing to average instead of peak",
            "missing read/write amplification effects",
            "throughput and latency assumptions misaligned",
            "queueing effects ignored at high utilization"
          ],
          "correct": 0,
          "explanation": "For stage 1 in Capacity Reasoning in Live Whiteboarding, \"sizing to average instead of peak\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for ad auction edge service.",
          "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. In ad auction edge service, sizing to average instead of peak best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in ad auction edge service, which adjustment gives the best risk reduction?",
          "options": [
            "avoid revisiting incorrect early numbers",
            "treat rough estimates as exact guarantees",
            "ignore replication and failover capacity impact",
            "compute average and peak separately with headroom"
          ],
          "correct": 3,
          "explanation": "Stage 2 is about controllability under stress for With diagnosis confirmed in ad auction edge service, which adjustment gives the best risk reduction. \"compute average and peak separately with headroom\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "A strong stage-2 answer balances immediate impact with operational safety. In ad auction edge service, compute average and peak separately with headroom is high leverage because it lowers sizing to average instead of peak without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This prompt rewards continuity across both stages in Capacity Reasoning in Live Whiteboarding. Carry the stage-1 diagnosis (the incident signal) directly into stage-2 action (\"compute average and peak separately with headroom\").",
      "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. This is a prioritization question: what should ship first and why. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of payments orchestration service, which diagnosis is most defensible for forgetting headroom for failure scenarios under aggressive latency targets?",
          "options": [
            "network bandwidth underestimated by bits/bytes confusion",
            "unclear confidence in approximated numbers",
            "ignoring storage growth and retention multipliers",
            "forgetting headroom for failure scenarios"
          ],
          "correct": 3,
          "explanation": "For stage 1 in Capacity Reasoning in Live Whiteboarding, \"forgetting headroom for failure scenarios\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for payments orchestration service.",
          "detailedExplanation": "A defensible diagnosis should be falsifiable with concrete telemetry. In this system, forgetting headroom for failure scenarios best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "After diagnosing payments orchestration service, what should change first before broad rollout?",
          "options": [
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension",
            "link each capacity number to a design decision",
            "mix bits and bytes inconsistently"
          ],
          "correct": 2,
          "explanation": "Stage 2: for After diagnosing payments orchestration service, what should change first before broad rollout, \"link each capacity number to a design decision\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This is a prioritization question: what should ship first and why. In this system, link each capacity number to a design decision is high leverage because it lowers forgetting headroom for failure scenarios without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "The scoring is sequential for payments orchestration service: stage 1 should isolate the governing risk, and stage 2 should prioritize \"link each capacity number to a design decision\" to reduce recurrence.",
      "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. A good stage-2 answer includes rollout guardrails and success criteria. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "For catalog read API, what is the most likely core problem behind throughput and latency assumptions misaligned under peak traffic?",
          "options": [
            "queueing effects ignored at high utilization",
            "failing to tie math back to architecture choices",
            "throughput and latency assumptions misaligned",
            "missing read/write amplification effects"
          ],
          "correct": 2,
          "explanation": "Stage 1: for catalog read API, \"throughput and latency assumptions misaligned\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In catalog read API, throughput and latency assumptions misaligned best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in catalog read API, which next change should be prioritized first?",
          "options": [
            "leave math disconnected from architecture decisions",
            "use order-of-magnitude checks to catch errors",
            "treat rough estimates as exact guarantees",
            "ignore replication and failover capacity impact"
          ],
          "correct": 1,
          "explanation": "For stage 2 in Capacity Reasoning in Live Whiteboarding, \"use order-of-magnitude checks to catch errors\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for Given that diagnosis in catalog read API, which next change should be prioritized first.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In catalog read API, use order-of-magnitude checks to catch errors is high leverage because it lowers throughput and latency assumptions misaligned without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage item tests diagnosis then mitigation in Capacity Reasoning in Live Whiteboarding: identify the core risk for catalog read API, then apply \"use order-of-magnitude checks to catch errors\" as the highest-leverage follow-up.",
      "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. Choose the action that creates momentum for subsequent hardening work. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "In media transcoding pipeline, the strongest diagnosis is needed. Which primary issue best explains ignoring storage growth and retention multipliers when one dependency is degraded?",
          "options": [
            "network bandwidth underestimated by bits/bytes confusion",
            "ignoring storage growth and retention multipliers",
            "calculations not checked for plausibility",
            "unclear confidence in approximated numbers"
          ],
          "correct": 1,
          "explanation": "At stage 1, prioritize \"ignoring storage growth and retention multipliers\" for media transcoding pipeline. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. In media transcoding pipeline, ignoring storage growth and retention multipliers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for media transcoding pipeline, what is the strongest immediate response?",
          "options": [
            "explicitly include replication and redundancy factors",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently",
            "skip peak calculations to save time"
          ],
          "correct": 0,
          "explanation": "Stage 2 is about controllability under stress for Now that root cause is clear for media transcoding pipeline, what is the strongest immediate response. \"explicitly include replication and redundancy factors\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "Stage 2 rewards changes that are effective, measurable, and rollout-safe. In media transcoding pipeline, explicitly include replication and redundancy factors is high leverage because it lowers ignoring storage growth and retention multipliers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This prompt rewards continuity across both stages in Capacity Reasoning in Live Whiteboarding. Carry the stage-1 diagnosis (the incident signal) directly into stage-2 action (\"explicitly include replication and redundancy factors\").",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "In feature flag control plane, what is the highest-priority diagnosis given missing read/write amplification effects with frequent schema evolution?",
          "options": [
            "missing read/write amplification effects",
            "failing to tie math back to architecture choices",
            "queueing effects ignored at high utilization",
            "resource budget omitted for safety margin"
          ],
          "correct": 0,
          "explanation": "Stage 1 is about controllability under stress for feature flag control plane. \"missing read/write amplification effects\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. In feature flag control plane, missing read/write amplification effects best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in feature flag control plane, which adjustment gives the best risk reduction?",
          "options": [
            "ignore replication and failover capacity impact",
            "leave math disconnected from architecture decisions",
            "avoid revisiting incorrect early numbers",
            "estimate queue growth under burst mismatch"
          ],
          "correct": 3,
          "explanation": "For stage 2 in Capacity Reasoning in Live Whiteboarding, \"estimate queue growth under burst mismatch\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for With diagnosis confirmed in feature flag control plane, which adjustment gives the best risk reduction.",
          "detailedExplanation": "Now the signal is whether you can choose the highest-leverage next action. In feature flag control plane, estimate queue growth under burst mismatch is high leverage because it lowers missing read/write amplification effects without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "Treat this as a linked decision chain for feature flag control plane. Strong responses diagnose the dominant failure path first, then execute \"estimate queue growth under burst mismatch\" to move from triage to durable control.",
      "detailedExplanation": "This first step checks whether you can isolate the root driver of risk. The best response reduces exposure quickly without destabilizing the system. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of webhook processing service, which diagnosis is most defensible for network bandwidth underestimated by bits/bytes confusion while operating across two regions?",
          "options": [
            "unclear confidence in approximated numbers",
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "network bandwidth underestimated by bits/bytes confusion"
          ],
          "correct": 3,
          "explanation": "At stage 1, prioritize \"network bandwidth underestimated by bits/bytes confusion\" for webhook processing service. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "The goal here is precise problem framing before intervention design. In this system, network bandwidth best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "After diagnosing webhook processing service, what should change first before broad rollout?",
          "options": [
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently",
            "translate latency targets into concurrency budgets",
            "optimize only one bottleneck dimension"
          ],
          "correct": 2,
          "explanation": "Stage 2: for After diagnosing webhook processing service, what should change first before broad rollout, \"translate latency targets into concurrency budgets\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "With diagnosis set, this step tests execution sequencing quality. In this system, translate latency targets into concurrency budgets is high leverage because it lowers network bandwidth without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "The scoring is sequential for webhook processing service: stage 1 should isolate the governing risk, and stage 2 should prioritize \"translate latency targets into concurrency budgets\" to reduce recurrence.",
      "detailedExplanation": "A strong stage-1 answer narrows ambiguity to one testable hypothesis. Stage 2 rewards changes that are effective, measurable, and rollout-safe. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "For admin operations console, what is the most likely core problem behind queueing effects ignored at high utilization while deployment velocity is high?",
          "options": [
            "resource budget omitted for safety margin",
            "sizing to average instead of peak",
            "queueing effects ignored at high utilization",
            "failing to tie math back to architecture choices"
          ],
          "correct": 2,
          "explanation": "Stage 1: for admin operations console, \"queueing effects ignored at high utilization\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In admin operations console, queueing effects ignored at high utilization best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in admin operations console, which next change should be prioritized first?",
          "options": [
            "treat rough estimates as exact guarantees",
            "track read/write amplification in storage math",
            "leave math disconnected from architecture decisions",
            "avoid revisiting incorrect early numbers"
          ],
          "correct": 1,
          "explanation": "At stage 2, prioritize \"track read/write amplification in storage math\" for Given that diagnosis in admin operations console, which next change should be prioritized first. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In admin operations console, track read/write amplification in storage math is high leverage because it lowers queueing effects ignored at high utilization without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage item tests diagnosis then mitigation in Capacity Reasoning in Live Whiteboarding: identify the core risk for admin operations console, then apply \"track read/write amplification in storage math\" as the highest-leverage follow-up.",
      "detailedExplanation": "Treat stage 1 as triage: choose the most explanatory failure mechanism. Now the signal is whether you can choose the highest-leverage next action. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "For session gateway, what is the most likely core problem behind unclear confidence in approximated numbers while supporting multi-tenant isolation?",
          "options": [
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios",
            "unclear confidence in approximated numbers",
            "calculations not checked for plausibility"
          ],
          "correct": 2,
          "explanation": "For stage 1 in Capacity Reasoning in Live Whiteboarding, \"unclear confidence in approximated numbers\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for session gateway.",
          "detailedExplanation": "At stage 1, hypothesis quality matters more than solution completeness. In session gateway, unclear confidence in approximated numbers best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        },
        {
          "question": "Given that diagnosis in session gateway, which next change should be prioritized first?",
          "options": [
            "hide assumptions to avoid challenge",
            "state confidence and margin for each estimate",
            "skip peak calculations to save time",
            "optimize only one bottleneck dimension"
          ],
          "correct": 1,
          "explanation": "Stage 2 is about controllability under stress for Given that diagnosis in session gateway, which next change should be prioritized first. \"state confidence and margin for each estimate\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "A good stage-2 answer includes rollout guardrails and success criteria. In session gateway, state confidence and margin for each estimate is high leverage because it lowers unclear confidence in approximated numbers without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            }
          ]
        }
      ],
      "explanation": "This prompt rewards continuity across both stages in Capacity Reasoning in Live Whiteboarding. Carry the stage-1 diagnosis (the incident signal) directly into stage-2 action (\"state confidence and margin for each estimate\").",
      "detailedExplanation": "The goal here is precise problem framing before intervention design. With diagnosis set, this step tests execution sequencing quality. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "During review of support workflow automation, which diagnosis is most defensible for failing to tie math back to architecture choices during bot-driven traffic spikes?",
          "options": [
            "sizing to average instead of peak",
            "throughput and latency assumptions misaligned",
            "resource budget omitted for safety margin",
            "failing to tie math back to architecture choices"
          ],
          "correct": 3,
          "explanation": "Stage 1 is about controllability under stress for support workflow automation. \"failing to tie math back to architecture choices\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. In this system, failing to tie math back to architecture choices best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        },
        {
          "question": "After diagnosing support workflow automation, what should change first before broad rollout?",
          "options": [
            "adjust architecture when math breaks constraints",
            "treat rough estimates as exact guarantees",
            "avoid revisiting incorrect early numbers",
            "ignore replication and failover capacity impact"
          ],
          "correct": 0,
          "explanation": "For stage 2 in Capacity Reasoning in Live Whiteboarding, \"adjust architecture when math breaks constraints\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for After diagnosing support workflow automation, what should change first before broad rollout.",
          "detailedExplanation": "Prioritize the smallest change that closes the largest risk gap. In this system, adjust architecture when math breaks constraints is high leverage because it lowers failing to tie math back to architecture choices without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            }
          ]
        }
      ],
      "explanation": "Treat this as a linked decision chain for support workflow automation. Strong responses diagnose the dominant failure path first, then execute \"adjust architecture when math breaks constraints\" to move from triage to durable control.",
      "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. Stage 2 is first-move prioritization under real delivery constraints. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "In identity token service, what is the highest-priority diagnosis given calculations not checked for plausibility during a regional failover drill?",
          "options": [
            "calculations not checked for plausibility",
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios",
            "ignoring storage growth and retention multipliers"
          ],
          "correct": 0,
          "explanation": "At stage 1, prioritize \"calculations not checked for plausibility\" for identity token service. It best reduces the named risk before deeper optimization.",
          "detailedExplanation": "Stage 1 is diagnosis quality: identify the mechanism, not just the symptom. In identity token service, calculations not checked for plausibility best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        },
        {
          "question": "With diagnosis confirmed in identity token service, which adjustment gives the best risk reduction?",
          "options": [
            "skip peak calculations to save time",
            "mix bits and bytes inconsistently",
            "optimize only one bottleneck dimension",
            "keep calculations simple, legible, and auditable"
          ],
          "correct": 3,
          "explanation": "Stage 2: for With diagnosis confirmed in identity token service, which adjustment gives the best risk reduction, \"keep calculations simple, legible, and auditable\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This phase checks whether your mitigation plan is practical, not theoretical. In identity token service, keep calculations simple, legible, and auditable is high leverage because it lowers calculations not checked for plausibility without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Google SRE Workbook",
              "url": "https://sre.google/workbook/table-of-contents/"
            }
          ]
        }
      ],
      "explanation": "The scoring is sequential for identity token service: stage 1 should isolate the governing risk, and stage 2 should prioritize \"keep calculations simple, legible, and auditable\" to reduce recurrence.",
      "detailedExplanation": "This step is about choosing the diagnosis that best fits constraints and signals. A strong stage-2 answer balances immediate impact with operational safety. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "In recommendation ranking service, the strongest diagnosis is needed. Which primary issue best explains resource budget omitted for safety margin with strict compliance scope?",
          "options": [
            "sizing to average instead of peak",
            "missing read/write amplification effects",
            "resource budget omitted for safety margin",
            "throughput and latency assumptions misaligned"
          ],
          "correct": 2,
          "explanation": "Stage 1: for recommendation ranking service, \"resource budget omitted for safety margin\" is correct because it addresses the incident signal and preserves clear next actions.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In recommendation ranking service, resource budget omitted for safety margin best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Now that root cause is clear for recommendation ranking service, what is the strongest immediate response?",
          "options": [
            "ignore replication and failover capacity impact",
            "leave math disconnected from architecture decisions",
            "summarize final capacity envelope and risk areas",
            "treat rough estimates as exact guarantees"
          ],
          "correct": 2,
          "explanation": "For stage 2 in Capacity Reasoning in Live Whiteboarding, \"summarize final capacity envelope and risk areas\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for Now that root cause is clear for recommendation ranking service, what is the strongest immediate response.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In recommendation ranking service, summarize final capacity envelope and risk areas is high leverage because it lowers resource budget omitted for safety margin without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "This two-stage item tests diagnosis then mitigation in Capacity Reasoning in Live Whiteboarding: identify the core risk for recommendation ranking service, then apply \"summarize final capacity envelope and risk areas\" as the highest-leverage follow-up.",
      "detailedExplanation": "Start by naming the core risk driver that unlocks a mitigation path. Choose the action that creates momentum for subsequent hardening work. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-060",
      "type": "two-stage",
      "stages": [
        {
          "question": "For notification fanout dispatcher, what is the most likely core problem behind unit conversion mistakes under time pressure under aggressive latency targets?",
          "options": [
            "ignoring storage growth and retention multipliers",
            "network bandwidth underestimated by bits/bytes confusion",
            "unit conversion mistakes under time pressure",
            "forgetting headroom for failure scenarios"
          ],
          "correct": 2,
          "explanation": "Stage 1 is about controllability under stress for notification fanout dispatcher. \"unit conversion mistakes under time pressure\" is strongest because it tackles the scenario risk with explicit follow-through.",
          "detailedExplanation": "This phase tests whether your mental model is coherent under pressure. In notification fanout dispatcher, unit conversion mistakes best matches the evidence and gives a falsifiable next step. State which telemetry or logs you would inspect first to validate the diagnosis.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        },
        {
          "question": "Given that diagnosis in notification fanout dispatcher, which next change should be prioritized first?",
          "options": [
            "skip peak calculations to save time",
            "normalize units before calculating and narrate assumptions",
            "hide assumptions to avoid challenge",
            "mix bits and bytes inconsistently"
          ],
          "correct": 1,
          "explanation": "For stage 2 in Capacity Reasoning in Live Whiteboarding, \"normalize units before calculating and narrate assumptions\" is the highest-signal answer. It links immediate mitigation with recurrence reduction for Given that diagnosis in notification fanout dispatcher, which next change should be prioritized first.",
          "detailedExplanation": "Stage 2 is first-move prioritization under real delivery constraints. In notification fanout dispatcher, normalize units before calculating and narrate assumptions is high leverage because it lowers unit conversion mistakes without requiring a full redesign. Mention rollout safety checks and a rollback trigger to complete the answer.",
          "references": [
            {
              "title": "Latency Numbers Every Programmer Should Know",
              "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
            },
            {
              "title": "Little's Law",
              "url": "https://en.wikipedia.org/wiki/Little%27s_law"
            },
            {
              "title": "AWS Well-Architected Framework",
              "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
            }
          ]
        }
      ],
      "explanation": "Treat this as a linked decision chain for notification fanout dispatcher. Strong responses diagnose the dominant failure path first, then execute \"normalize units before calculating and narrate assumptions\" to move from triage to durable control.",
      "detailedExplanation": "Pick the diagnosis that best explains both likelihood and blast radius. Prioritize the smallest change that closes the largest risk gap. The strongest answers connect diagnosis, first action, and validation criteria as one coherent plan.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-061",
      "type": "multi-select",
      "question": "In notification fanout dispatcher, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "explicitly include replication and redundancy factors",
        "normalize units before calculating and narrate assumptions",
        "treat rough estimates as exact guarantees",
        "track read/write amplification in storage math",
        "ignore replication and failover capacity impact"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "notification fanout dispatcher requires layered controls, not a single tactic. The strongest set is explicitly include replication and redundancy factors, normalize units before calculating and narrate assumptions, and track read/write amplification in storage math. That combination closes the key gaps in this chapter.",
      "detailedExplanation": "Multi-select problems test whether your control set works as a system. In notification fanout dispatcher, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-062",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in payments orchestration service? (Select all that apply)",
      "options": [
        "mix bits and bytes inconsistently",
        "skip peak calculations to save time",
        "compute average and peak separately with headroom",
        "estimate queue growth under burst mismatch",
        "state confidence and margin for each estimate"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "In Capacity Reasoning in Live Whiteboarding, this is a bundle decision for Which measures are most valuable for live capacity reasoning fluency in payments orchestration service. The strongest set is compute average and peak separately with headroom, estimate queue growth under burst mismatch, and state confidence and margin for each estimate. Together they cover prevention, detection, and containment.",
      "detailedExplanation": "Select controls that improve both correctness and day-2 operability. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-063",
      "type": "multi-select",
      "question": "For media transcoding pipeline, select the controls that most directly improve live capacity reasoning fluency. (Select all that apply)",
      "options": [
        "translate latency targets into concurrency budgets",
        "adjust architecture when math breaks constraints",
        "ignore replication and failover capacity impact",
        "link each capacity number to a design decision",
        "leave math disconnected from architecture decisions"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "The right answer is a coordinated control set for media transcoding pipeline. The strongest set is translate latency targets into concurrency budgets, adjust architecture when math breaks constraints, and link each capacity number to a design decision. The bundle reduces both incident frequency and impact.",
      "detailedExplanation": "These options should form a coherent plan, not a random collection of good ideas. In media transcoding pipeline, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-064",
      "type": "multi-select",
      "question": "For webhook processing service, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "use order-of-magnitude checks to catch errors",
        "hide assumptions to avoid challenge",
        "track read/write amplification in storage math",
        "mix bits and bytes inconsistently",
        "keep calculations simple, legible, and auditable"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "This question tests compositional judgment for webhook processing service. The strongest set is use order-of-magnitude checks to catch errors, track read/write amplification in storage math, and keep calculations simple, legible, and auditable. Omitting one of these leaves a material risk gap.",
      "detailedExplanation": "The best selections should complement each other rather than overlap. In webhook processing service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-065",
      "type": "multi-select",
      "question": "In session gateway, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "leave math disconnected from architecture decisions",
        "avoid revisiting incorrect early numbers",
        "state confidence and margin for each estimate",
        "summarize final capacity envelope and risk areas",
        "explicitly include replication and redundancy factors"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "session gateway requires layered controls, not a single tactic. The strongest set is state confidence and margin for each estimate, summarize final capacity envelope and risk areas, and explicitly include replication and redundancy factors. That combination closes the key gaps in this chapter.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In session gateway, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-066",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in identity token service? (Select all that apply)",
      "options": [
        "estimate queue growth under burst mismatch",
        "optimize only one bottleneck dimension",
        "normalize units before calculating and narrate assumptions",
        "adjust architecture when math breaks constraints",
        "hide assumptions to avoid challenge"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "In Capacity Reasoning in Live Whiteboarding, this is a bundle decision for Which measures are most valuable for live capacity reasoning fluency in identity token service. The strongest set is estimate queue growth under burst mismatch, normalize units before calculating and narrate assumptions, and adjust architecture when math breaks constraints. Together they cover prevention, detection, and containment.",
      "detailedExplanation": "Your selected options should reduce bypass potential across different attack paths. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-067",
      "type": "multi-select",
      "question": "For notification fanout dispatcher, select the controls that most directly improve live capacity reasoning fluency. (Select all that apply)",
      "options": [
        "keep calculations simple, legible, and auditable",
        "avoid revisiting incorrect early numbers",
        "compute average and peak separately with headroom",
        "treat rough estimates as exact guarantees",
        "translate latency targets into concurrency budgets"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "The right answer is a coordinated control set for notification fanout dispatcher. The strongest set is keep calculations simple, legible, and auditable, compute average and peak separately with headroom, and translate latency targets into concurrency budgets. The bundle reduces both incident frequency and impact.",
      "detailedExplanation": "These options should form a coherent plan, not a random collection of good ideas. In notification fanout dispatcher, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-068",
      "type": "multi-select",
      "question": "For payments orchestration service, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "link each capacity number to a design decision",
        "summarize final capacity envelope and risk areas",
        "track read/write amplification in storage math",
        "skip peak calculations to save time",
        "optimize only one bottleneck dimension"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "This question tests compositional judgment for payments orchestration service. The strongest set is link each capacity number to a design decision, summarize final capacity envelope and risk areas, and track read/write amplification in storage math. Omitting one of these leaves a material risk gap.",
      "detailedExplanation": "The best selections should complement each other rather than overlap. In payments orchestration service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-069",
      "type": "multi-select",
      "question": "In media transcoding pipeline, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "ignore replication and failover capacity impact",
        "state confidence and margin for each estimate",
        "treat rough estimates as exact guarantees",
        "use order-of-magnitude checks to catch errors",
        "normalize units before calculating and narrate assumptions"
      ],
      "correctIndices": [1, 3, 4],
      "explanation": "media transcoding pipeline requires layered controls, not a single tactic. The strongest set is state confidence and margin for each estimate, use order-of-magnitude checks to catch errors, and normalize units before calculating and narrate assumptions. That combination closes the key gaps in this chapter.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In media transcoding pipeline, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-070",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in webhook processing service? (Select all that apply)",
      "options": [
        "adjust architecture when math breaks constraints",
        "skip peak calculations to save time",
        "explicitly include replication and redundancy factors",
        "compute average and peak separately with headroom",
        "mix bits and bytes inconsistently"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "The right answer is a coordinated control set for Which measures are most valuable for live capacity reasoning fluency in webhook processing service. The strongest set is adjust architecture when math breaks constraints, explicitly include replication and redundancy factors, and compute average and peak separately with headroom. The bundle reduces both incident frequency and impact.",
      "detailedExplanation": "This item rewards layered reasoning and explicit residual-risk thinking. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-071",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in session gateway? (Select all that apply)",
      "options": [
        "keep calculations simple, legible, and auditable",
        "leave math disconnected from architecture decisions",
        "estimate queue growth under burst mismatch",
        "ignore replication and failover capacity impact",
        "link each capacity number to a design decision"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "This question tests compositional judgment for Which measures are most valuable for live capacity reasoning fluency in session gateway. The strongest set is keep calculations simple, legible, and auditable, estimate queue growth under burst mismatch, and link each capacity number to a design decision. Omitting one of these leaves a material risk gap.",
      "detailedExplanation": "Select controls that improve both correctness and day-2 operability. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-072",
      "type": "multi-select",
      "question": "In identity token service, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "use order-of-magnitude checks to catch errors",
        "hide assumptions to avoid challenge",
        "translate latency targets into concurrency budgets",
        "summarize final capacity envelope and risk areas",
        "mix bits and bytes inconsistently"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "identity token service requires layered controls, not a single tactic. The strongest set is use order-of-magnitude checks to catch errors, translate latency targets into concurrency budgets, and summarize final capacity envelope and risk areas. That combination closes the key gaps in this chapter.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In identity token service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-073",
      "type": "multi-select",
      "question": "For notification fanout dispatcher, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "normalize units before calculating and narrate assumptions",
        "track read/write amplification in storage math",
        "leave math disconnected from architecture decisions",
        "avoid revisiting incorrect early numbers",
        "explicitly include replication and redundancy factors"
      ],
      "correctIndices": [0, 1, 4],
      "explanation": "In Capacity Reasoning in Live Whiteboarding, this is a bundle decision for notification fanout dispatcher. The strongest set is normalize units before calculating and narrate assumptions, track read/write amplification in storage math, and explicitly include replication and redundancy factors. Together they cover prevention, detection, and containment.",
      "detailedExplanation": "The interview signal is whether your chosen controls still hold under stress. In notification fanout dispatcher, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-074",
      "type": "multi-select",
      "question": "For payments orchestration service, select the controls that most directly improve live capacity reasoning fluency. (Select all that apply)",
      "options": [
        "optimize only one bottleneck dimension",
        "compute average and peak separately with headroom",
        "estimate queue growth under burst mismatch",
        "state confidence and margin for each estimate",
        "hide assumptions to avoid challenge"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "The right answer is a coordinated control set for payments orchestration service. The strongest set is compute average and peak separately with headroom, estimate queue growth under burst mismatch, and state confidence and margin for each estimate. The bundle reduces both incident frequency and impact.",
      "detailedExplanation": "You are being tested on mitigation composition, not checkbox coverage. In payments orchestration service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-075",
      "type": "multi-select",
      "question": "Which measures are most valuable for live capacity reasoning fluency in media transcoding pipeline? (Select all that apply)",
      "options": [
        "link each capacity number to a design decision",
        "treat rough estimates as exact guarantees",
        "translate latency targets into concurrency budgets",
        "avoid revisiting incorrect early numbers",
        "adjust architecture when math breaks constraints"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "This question tests compositional judgment for Which measures are most valuable for live capacity reasoning fluency in media transcoding pipeline. The strongest set is link each capacity number to a design decision, translate latency targets into concurrency budgets, and adjust architecture when math breaks constraints. Omitting one of these leaves a material risk gap.",
      "detailedExplanation": "Your selected options should reduce bypass potential across different attack paths. In this system, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-076",
      "type": "multi-select",
      "question": "In webhook processing service, which actions should be combined to improve live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "keep calculations simple, legible, and auditable",
        "optimize only one bottleneck dimension",
        "track read/write amplification in storage math",
        "skip peak calculations to save time",
        "use order-of-magnitude checks to catch errors"
      ],
      "correctIndices": [0, 2, 4],
      "explanation": "webhook processing service requires layered controls, not a single tactic. The strongest set is keep calculations simple, legible, and auditable, track read/write amplification in storage math, and use order-of-magnitude checks to catch errors. That combination closes the key gaps in this chapter.",
      "detailedExplanation": "The best set lowers risk while keeping false positives and toil manageable. In webhook processing service, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-077",
      "type": "multi-select",
      "question": "For session gateway, which controls best strengthen live capacity reasoning fluency? (Select all that apply)",
      "options": [
        "ignore replication and failover capacity impact",
        "treat rough estimates as exact guarantees",
        "explicitly include replication and redundancy factors",
        "state confidence and margin for each estimate",
        "summarize final capacity envelope and risk areas"
      ],
      "correctIndices": [2, 3, 4],
      "explanation": "In Capacity Reasoning in Live Whiteboarding, this is a bundle decision for session gateway. The strongest set is explicitly include replication and redundancy factors, state confidence and margin for each estimate, and summarize final capacity envelope and risk areas. Together they cover prevention, detection, and containment.",
      "detailedExplanation": "The interview signal is whether your chosen controls still hold under stress. In session gateway, defend the selected set in terms of coverage, operability, and residual risk. Mention one metric and one likely bypass path to show depth.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-078",
      "type": "numeric-input",
      "question": "In a 45-minute interview, you allocate 15% to requirements and scoping. How many minutes is that? During live capacity reasoning.",
      "answer": 6.75,
      "unit": "minutes",
      "tolerance": 0.15,
      "explanation": "This calculation anchors the tradeoff for a 45-minute interview: 6.75 minutes. Responses within +/-15% indicate sound judgment.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a 45-minute interview, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-079",
      "type": "numeric-input",
      "question": "While whiteboarding recommendation ranking service, you estimate 860 QPS and 140ms average latency. Using Little's Law, how many in-flight requests are expected? During live capacity reasoning.",
      "answer": 120.4,
      "unit": "requests",
      "tolerance": 0.15,
      "explanation": "Capacity Reasoning in Live Whiteboarding expects quick quantitative triage: While whiteboarding recommendation ranking service, you estimate 860 QPS and 140ms average latency yields 120.4 requests. Use within +/-15% as the grading bound.",
      "detailedExplanation": "Back-of-envelope math should be auditable and tied to thresholds. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-080",
      "type": "numeric-input",
      "question": "After interview feedback, design explanation time dropped from 20 to 14 minutes while preserving coverage. What is the percent reduction? During live capacity reasoning.",
      "answer": 30,
      "unit": "percent",
      "tolerance": 0.15,
      "explanation": "For After interview feedback, design explanation time dropped from 20 to 14 minutes while preserving coverage in Capacity Reasoning in Live Whiteboarding, the expected result is 30 percent. Answers within +/-15% show correct sizing.",
      "detailedExplanation": "Keep the arithmetic simple, then explain the operational implication. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-081",
      "type": "numeric-input",
      "question": "You discuss 9 serial dependencies each at 99.9% monthly reliability assumptions in an interview drill. Approximate combined downtime-hours/year if failures are independent and additive by rough estimate? During live capacity reasoning.",
      "answer": 78.84,
      "unit": "hours/year",
      "tolerance": 0.2,
      "explanation": "This calculation anchors the tradeoff for You discuss 9 serial dependencies each at 99: 78.84 hours/year. Responses within +/-20% indicate sound judgment.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-082",
      "type": "numeric-input",
      "question": "For a live design walkthrough, you estimate 380,000 DAU and 10 requests/user/day. What is average QPS? During live capacity reasoning.",
      "answer": 44,
      "unit": "qps",
      "tolerance": 0.15,
      "explanation": "Capacity Reasoning in Live Whiteboarding expects quick quantitative triage: a live design walkthrough yields 44 qps. Use within +/-15% as the grading bound.",
      "detailedExplanation": "A good estimate closes with an actionable design consequence. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a live design walkthrough, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-083",
      "type": "numeric-input",
      "question": "In a mock interview retro, your design suffered 8 incidents/month with 17 min MTTR each. Total monthly downtime minutes? During live capacity reasoning.",
      "answer": 136,
      "unit": "minutes/month",
      "tolerance": 0.15,
      "explanation": "The operations math for a mock interview retro evaluates to 136 minutes/month. In interview pace, responses within +/-15% are acceptable.",
      "detailedExplanation": "The interviewer is checking both correctness and usefulness of the math. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a mock interview retro, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-084",
      "type": "numeric-input",
      "question": "A whiteboard estimate gives 12,000 QPS steady load. If you require 30% headroom, what throughput target should you state? During live capacity reasoning.",
      "answer": 15600,
      "unit": "QPS",
      "tolerance": 0.15,
      "explanation": "For A whiteboard estimate gives 12,000 QPS steady load in Capacity Reasoning in Live Whiteboarding, the expected result is 15600 QPS. Answers within +/-15% show correct sizing.",
      "detailedExplanation": "This is a decision-support estimate, not just arithmetic. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a 45-minute interview, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-085",
      "type": "numeric-input",
      "question": "While whiteboarding session gateway, you estimate 1220 QPS and 260ms average latency. Using Little's Law, how many in-flight requests are expected? During live capacity reasoning.",
      "answer": 317.2,
      "unit": "requests",
      "tolerance": 0.15,
      "explanation": "This calculation anchors the tradeoff for While whiteboarding session gateway, you estimate 1220 QPS and 260ms average latency: 317.2 requests. Responses within +/-15% indicate sound judgment.",
      "detailedExplanation": "Interview quality depends on clean assumptions and explicit units. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-086",
      "type": "numeric-input",
      "question": "After interview feedback, design explanation time dropped from 26 to 22 minutes while preserving coverage. What is the percent reduction? During live capacity reasoning.",
      "answer": 15.38,
      "unit": "percent",
      "tolerance": 0.15,
      "explanation": "Capacity Reasoning in Live Whiteboarding expects quick quantitative triage: After interview feedback, design explanation time dropped from 26 to 22 minutes while preserving coverage yields 15.38 percent. Use within +/-15% as the grading bound.",
      "detailedExplanation": "The value of this number is in how it changes the design choice. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-087",
      "type": "numeric-input",
      "question": "You discuss 8 serial dependencies each at 99.9% monthly reliability assumptions in an interview drill. Approximate combined downtime-hours/year if failures are independent and additive by rough estimate? During live capacity reasoning.",
      "answer": 70.08,
      "unit": "hours/year",
      "tolerance": 0.2,
      "explanation": "The operations math for You discuss 8 serial dependencies each at 99 evaluates to 70.08 hours/year. In interview pace, responses within +/-20% are acceptable.",
      "detailedExplanation": "Numeric prompts test whether your reasoning survives unit pressure. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in this system, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-088",
      "type": "numeric-input",
      "question": "For a live design walkthrough, you estimate 500,000 DAU and 6 requests/user/day. What is average QPS? During live capacity reasoning.",
      "answer": 35,
      "unit": "qps",
      "tolerance": 0.15,
      "explanation": "For a live design walkthrough in Capacity Reasoning in Live Whiteboarding, the expected result is 35 qps. Answers within +/-15% show correct sizing.",
      "detailedExplanation": "This is a decision-support estimate, not just arithmetic. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a live design walkthrough, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-089",
      "type": "numeric-input",
      "question": "In a mock interview retro, your design suffered 8 incidents/month with 15 min MTTR each. Total monthly downtime minutes? During live capacity reasoning.",
      "answer": 120,
      "unit": "minutes/month",
      "tolerance": 0.15,
      "explanation": "This calculation anchors the tradeoff for a mock interview retro: 120 minutes/month. Responses within +/-15% indicate sound judgment.",
      "detailedExplanation": "Unit errors in interviews often become architecture errors in production. In live capacity reasoning and unit-safe estimation, show units, assumptions, and headroom explicitly. Then map the result to a decision in a mock interview retro, such as capacity limits, queue depth, or timeout budget.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-090",
      "type": "ordering",
      "question": "Rank these controls by expected risk reduction (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Define rollout guardrails",
        "Identify primary risk",
        "Define post-rollout validation",
        "Choose highest-leverage control",
        "Set success constraint"
      ],
      "correctOrder": [1, 4, 3, 0, 2],
      "explanation": "The correct sequence is dependency-driven for Rank these controls by expected risk reduction (lowest to highest) for live capacity reasoning fluency: Identify primary risk must precede Define post-rollout validation to minimize rollback risk.",
      "detailedExplanation": "Good ordering protects both delivery speed and system reliability. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-091",
      "type": "ordering",
      "question": "Order these options by operational maturity (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Capture current signal",
        "Pick first mitigation",
        "Measure impact",
        "Form diagnosis hypothesis",
        "Iterate controls"
      ],
      "correctOrder": [0, 3, 1, 2, 4],
      "explanation": "Order starts at Capture current signal and ends at Iterate controls because Order these options by operational maturity (lowest to highest) for live capacity reasoning fluency requires stabilization before optimization in Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "Interviewers expect you to justify transitions, not just the final order. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-092",
      "type": "ordering",
      "question": "Arrange these controls by real-world robustness under failure (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "State assumptions",
        "Evaluate tradeoffs",
        "Summarize risks",
        "Clarify requirement",
        "Propose design"
      ],
      "correctOrder": [3, 0, 4, 1, 2],
      "explanation": "For Arrange these controls by real-world robustness under failure (lowest to highest) for live capacity reasoning fluency, this ordering reduces rework and blast radius: Clarify requirement comes first and Summarize risks comes last.",
      "detailedExplanation": "Prioritize steps that improve decision confidence before hard commitment. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-093",
      "type": "ordering",
      "question": "Rank these choices by long-term reliability impact (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Verify with drills",
        "Map trust/flow boundaries",
        "Prioritize failure/abuse paths",
        "Implement controls",
        "List assets or users"
      ],
      "correctOrder": [4, 1, 2, 3, 0],
      "explanation": "In Capacity Reasoning in Live Whiteboarding, safe execution order matters more than speed. Begin with List assets or users, then progress toward Verify with drills.",
      "detailedExplanation": "This ordering should move from framing to decision to validation. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-094",
      "type": "ordering",
      "question": "Order these controls by how strongly they reduce repeat incidents (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Compare alternatives",
        "Review residual risk",
        "Plan migration",
        "Select approach",
        "Define objective"
      ],
      "correctOrder": [4, 0, 3, 2, 1],
      "explanation": "The correct sequence is dependency-driven for Order these controls by how strongly they reduce repeat incidents (lowest to highest) for live capacity reasoning fluency: Define objective must precede Review residual risk to minimize rollback risk.",
      "detailedExplanation": "The wrong sequence often causes rework and hidden residual risk. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-095",
      "type": "ordering",
      "question": "Arrange these options from reactive posture to proactive posture for live capacity reasoning fluency.",
      "items": [
        "Capture baseline metrics",
        "Monitor outcomes",
        "Apply constraints",
        "Estimate capacity or risk envelope",
        "Choose architecture change"
      ],
      "correctOrder": [0, 3, 2, 4, 1],
      "explanation": "Order starts at Capture baseline metrics and ends at Monitor outcomes because Arrange these options from reactive posture to proactive posture for live capacity reasoning fluency requires stabilization before optimization in Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "This ranking is about dependency awareness between decisions. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-096",
      "type": "ordering",
      "question": "Rank these controls by defensive depth they add (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Define post-rollout validation",
        "Choose highest-leverage control",
        "Define rollout guardrails",
        "Identify primary risk",
        "Set success constraint"
      ],
      "correctOrder": [3, 4, 1, 2, 0],
      "explanation": "For Rank these controls by defensive depth they add (lowest to highest) for live capacity reasoning fluency, this ordering reduces rework and blast radius: Identify primary risk comes first and Define post-rollout validation comes last.",
      "detailedExplanation": "A solid sequence reduces uncertainty before committing to expensive changes. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-097",
      "type": "ordering",
      "question": "Order these choices by resilience under production stress (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Pick first mitigation",
        "Form diagnosis hypothesis",
        "Capture current signal",
        "Iterate controls",
        "Measure impact"
      ],
      "correctOrder": [2, 1, 0, 4, 3],
      "explanation": "In Capacity Reasoning in Live Whiteboarding, safe execution order matters more than speed. Begin with Capture current signal, then progress toward Iterate controls.",
      "detailedExplanation": "A mature order avoids premature optimization and late-stage surprises. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-098",
      "type": "ordering",
      "question": "Arrange these controls from baseline hygiene to hardened practice for live capacity reasoning fluency.",
      "items": [
        "State assumptions",
        "Clarify requirement",
        "Evaluate tradeoffs",
        "Propose design",
        "Summarize risks"
      ],
      "correctOrder": [1, 0, 3, 2, 4],
      "explanation": "The correct sequence is dependency-driven for Arrange these controls from baseline hygiene to hardened practice for live capacity reasoning fluency: Clarify requirement must precede Summarize risks to minimize rollback risk.",
      "detailedExplanation": "The best sequence makes rollback and validation straightforward. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-099",
      "type": "ordering",
      "question": "Rank these options by consistency of outcomes over time (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "List assets or users",
        "Implement controls",
        "Prioritize failure/abuse paths",
        "Verify with drills",
        "Map trust/flow boundaries"
      ],
      "correctOrder": [0, 4, 2, 1, 3],
      "explanation": "Order starts at List assets or users and ends at Verify with drills because Rank these options by consistency of outcomes over time (lowest to highest) for live capacity reasoning fluency requires stabilization before optimization in Capacity Reasoning in Live Whiteboarding.",
      "detailedExplanation": "Ordering items measure execution discipline more than terminology recall. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Latency Numbers Every Programmer Should Know",
          "url": "https://colin-scott.github.io/personal_website/research/interactive_latency.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    },
    {
      "id": "int-cr-100",
      "type": "ordering",
      "question": "Order these controls by production-readiness maturity (lowest to highest) for live capacity reasoning fluency.",
      "items": [
        "Select approach",
        "Review residual risk",
        "Define objective",
        "Plan migration",
        "Compare alternatives"
      ],
      "correctOrder": [2, 4, 0, 3, 1],
      "explanation": "For Order these controls by production-readiness maturity (lowest to highest) for live capacity reasoning fluency, this ordering reduces rework and blast radius: Define objective comes first and Review residual risk comes last.",
      "detailedExplanation": "Prioritize steps that improve decision confidence before hard commitment. In live capacity reasoning and unit-safe estimation, explain why each transition is next and what risk it prevents. That reasoning is what interviewers use to judge design maturity.",
      "references": [
        {
          "title": "Google SRE Workbook",
          "url": "https://sre.google/workbook/table-of-contents/"
        },
        {
          "title": "AWS Well-Architected Framework",
          "url": "https://docs.aws.amazon.com/wellarchitected/latest/framework/welcome.html"
        },
        {
          "title": "Little's Law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ],
      "tags": [
        "interview-execution",
        "capacity-reasoning-in-live-whiteboarding"
      ],
      "difficulty": "staff-level"
    }
  ]
}
