{
  "unit": 6,
  "unitTitle": "Messaging & Async",
  "chapter": 8,
  "chapterTitle": "Messaging Scenarios",
  "chapterDescription": "Integrated real-world messaging design scenarios spanning queues, pub/sub, retries, ordering, delivery guarantees, replay, and operational trade-offs.",
  "problems": [
    {
      "id": "msg-scn-001",
      "type": "multiple-choice",
      "question": "Your checkout service must charge cards and publish an OrderPaid event. If event publish fails after payment commit, downstream fulfillment never starts. Which pattern should you adopt first?",
      "options": [
        "Two-phase commit across payment DB and broker",
        "Transactional outbox from payment DB to broker relay",
        "Best-effort retry in API handler only",
        "Synchronous polling by fulfillment every 5 minutes"
      ],
      "correct": 1,
      "explanation": "Transactional outbox avoids dual-write inconsistency by writing business state and outbound event in one DB transaction, then reliably relaying to the broker.",
      "detailedExplanation": "Read this as a scenario about \"your checkout service must charge cards and publish an OrderPaid event\". Eliminate options that ignore delivery semantics or backpressure behavior. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-002",
      "type": "multiple-choice",
      "question": "A notifications pipeline occasionally sends duplicate emails after worker restarts. Product says duplicates are worse than delayed sends. What is the highest-leverage fix?",
      "options": [
        "Disable retries",
        "Increase queue visibility timeout only",
        "Use idempotency keys at email provider integration",
        "Move to in-memory queue for speed"
      ],
      "correct": 2,
      "explanation": "Idempotency at side-effect boundary prevents duplicate sends across retries and crashes; timeout tuning alone cannot guarantee this.",
      "detailedExplanation": "The key clue in this question is \"notifications pipeline occasionally sends duplicate emails after worker restarts\". Prioritize the option that best protects the reliability objective under the stated failure conditions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-003",
      "type": "multiple-choice",
      "question": "A ride dispatch stream must preserve per-driver event order while scaling throughput. Which partition key is best?",
      "options": [
        "driver_id",
        "random UUID per message",
        "event_type",
        "city_id"
      ],
      "correct": 0,
      "explanation": "Partitioning by driver_id keeps each driver stream ordered while still parallelizing across drivers.",
      "detailedExplanation": "Start from \"ride dispatch stream must preserve per-driver event order while scaling throughput\", then pressure-test the result against the options. Reject designs that improve throughput while weakening reliability guarantees. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-004",
      "type": "multiple-choice",
      "question": "You run worker queues where messages often take 30-90 seconds. Visibility timeout is 20 seconds, causing duplicate processing. What should change first?",
      "options": [
        "Increase visibility timeout or heartbeat/extend per long task",
        "Switch to pub/sub immediately",
        "Commit message before processing",
        "Lower retry backoff"
      ],
      "correct": 0,
      "explanation": "Visibility must exceed expected processing time (or be extended) to prevent redelivery during active processing.",
      "detailedExplanation": "If you keep \"you run worker queues where messages often take 30-90 seconds\" in view, the correct answer separates faster. Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. Tie the decision to concrete operational outcomes, not abstract reliability language. Numbers such as 30 and 90 seconds should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-005",
      "type": "multiple-choice",
      "question": "An analytics consumer was down for 2 days and needs replay from original events. Which architecture best supports this without impacting OLTP services?",
      "options": [
        "RabbitMQ auto-delete queue",
        "Kafka topic with retention and independent consumer offsets",
        "SQS queue with low retention",
        "Redis Pub/Sub channel"
      ],
      "correct": 1,
      "explanation": "Kafka log retention plus independent offsets enables backfill and replay for recovering consumers.",
      "detailedExplanation": "The core signal here is \"analytics consumer was down for 2 days and needs replay from original events\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. A good message-system answer defines guarantees clearly for both producer and consumer paths. Numbers such as 2 days should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "msg-scn-006",
      "type": "multiple-choice",
      "question": "Order workflow has steps: reserve inventory, charge card, create shipment. If shipment creation fails permanently, what is the usual recovery model?",
      "options": [
        "Manual SQL patch as default",
        "Block forever until shipment succeeds",
        "Saga compensation for prior steps",
        "Drop message and continue"
      ],
      "correct": 2,
      "explanation": "Saga compensation explicitly undoes prior side effects when downstream steps fail irrecoverably.",
      "detailedExplanation": "Use \"order workflow has steps: reserve inventory, charge card, create shipment\" as your starting point, then verify tradeoffs carefully. Prioritize the option that best protects the reliability objective under the stated failure conditions. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-007",
      "type": "multiple-choice",
      "question": "A hot partition is causing consumer lag in one tenant while others are healthy. Which is the most direct design fix?",
      "options": [
        "Lower broker retention",
        "Disable ordering requirements globally",
        "Add more consumers without repartitioning",
        "Repartition using a higher-cardinality tenant+entity key"
      ],
      "correct": 3,
      "explanation": "Throughput ceiling is per partition; better key distribution reduces skew and lag hotspots.",
      "detailedExplanation": "This prompt is really about \"hot partition is causing consumer lag in one tenant while others are healthy\". Eliminate options that ignore delivery semantics or backpressure behavior. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-008",
      "type": "multiple-choice",
      "question": "A dead-letter queue is growing with validation errors caused by old schema producers. What should happen before blindly re-driving DLQ messages?",
      "options": [
        "Fix producer/schema compatibility and add transform before replay",
        "Increase consumer threads only",
        "Disable schema checks",
        "Delete DLQ daily"
      ],
      "correct": 0,
      "explanation": "Replay without fixing root compatibility issue just re-poisons the queue.",
      "detailedExplanation": "The decision turns on \"dead-letter queue is growing with validation errors caused by old schema producers\". Reject designs that improve throughput while weakening reliability guarantees. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-009",
      "type": "multiple-choice",
      "question": "You need fan-out of user events to fraud, analytics, recommendations, and email preferences with independent failure domains. Best topology?",
      "options": [
        "Single shared work queue",
        "Pub/sub topic with separate subscriptions or consumer groups per domain",
        "One HTTP webhook chain",
        "Cron batch export once per day"
      ],
      "correct": 1,
      "explanation": "Pub/sub fan-out gives independent consumption, retries, and deployment cadence per downstream system.",
      "detailedExplanation": "Read this as a scenario about \"you need fan-out of user events to fraud, analytics, recommendations, and email\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-010",
      "type": "multiple-choice",
      "question": "A team wants exactly-once across Kafka and an external REST API side effect. Which statement is correct?",
      "options": [
        "Disable retries to get exactly-once",
        "Kafka transactions alone make external REST calls exactly-once",
        "Exactly-once with external systems needs idempotent side effects and dedupe strategy",
        "At-most-once is equivalent and simpler"
      ],
      "correct": 2,
      "explanation": "Kafka EOS does not cover external side effects; idempotency and dedupe are required at integration boundaries.",
      "detailedExplanation": "Start from \"team wants exactly-once across Kafka and an external REST API side effect\", then pressure-test the result against the options. Prefer the choice that keeps client behavior explicit while preserving evolvability. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-011",
      "type": "multiple-choice",
      "question": "Consumers frequently rebalance during deployments and stall processing. What deployment change usually reduces disruption most?",
      "options": [
        "Lower replication factor",
        "Use shorter message retention",
        "Kill all consumers simultaneously for clean restart",
        "Use rolling deploy with cooperative rebalancing and graceful shutdown"
      ],
      "correct": 3,
      "explanation": "Graceful rolling changes reduce group churn and rebalance pauses.",
      "detailedExplanation": "The key clue in this question is \"consumers frequently rebalance during deployments and stall processing\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-012",
      "type": "multiple-choice",
      "question": "An outbox table is growing unbounded and slowing writes. What is the right operational strategy?",
      "options": [
        "Archive/TTL processed outbox records after safe retention window",
        "Move outbox into application memory",
        "Run relay less often",
        "Never delete outbox rows"
      ],
      "correct": 0,
      "explanation": "Outbox requires lifecycle management; processed rows should be compacted/archived safely.",
      "detailedExplanation": "Read this as a scenario about \"outbox table is growing unbounded and slowing writes\". Eliminate options that ignore delivery semantics or backpressure behavior. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "msg-scn-013",
      "type": "multiple-choice",
      "question": "Product asks for \"real-time\" dashboard but allows 60-second freshness. Best cost/perf compromise?",
      "options": [
        "Synchronous writes from OLTP to dashboard DB",
        "Stream updates with micro-batching/windowed aggregation",
        "Nightly batch only",
        "Websocket polling to OLTP"
      ],
      "correct": 1,
      "explanation": "Micro-batched stream aggregation meets freshness SLO with lower compute overhead than strict per-event updates.",
      "detailedExplanation": "The decision turns on \"product asks for real-time dashboard but allows 60-second freshness\". Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. Tie the decision to concrete operational outcomes, not abstract reliability language. Keep quantities like 60 in aligned units before selecting an answer. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-014",
      "type": "multiple-choice",
      "question": "A queue consumer performs a DB write then ACKs. Crash between write and ACK causes duplicate write on redelivery. Best consumer contract?",
      "options": [
        "Use random sleep before ACK",
        "ACK before DB write",
        "Idempotent write keyed by message/event ID before ACK",
        "No retries on crash"
      ],
      "correct": 2,
      "explanation": "Idempotent sink semantics make redelivery safe while preserving at-least-once reliability.",
      "detailedExplanation": "This prompt is really about \"queue consumer performs a DB write then ACKs\". Prefer the choice that keeps client behavior explicit while preserving evolvability. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "msg-scn-015",
      "type": "multiple-choice",
      "question": "Your retry policy causes synchronized retry storms during regional outage. What adjustment helps most?",
      "options": [
        "Immediate infinite retries",
        "Disable retries entirely",
        "Fixed 1-second retry interval",
        "Exponential backoff with jitter and capped retries to DLQ"
      ],
      "correct": 3,
      "explanation": "Jitter spreads retries over time and prevents thundering herd behavior.",
      "detailedExplanation": "Use \"your retry policy causes synchronized retry storms during regional outage\" as your starting point, then verify tradeoffs carefully. Prioritize the option that best protects the reliability objective under the stated failure conditions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "msg-scn-016",
      "type": "multiple-choice",
      "question": "A service emits events where consumers depend on schema evolution over months. Which governance control is most important?",
      "options": [
        "Schema registry with compatibility checks in CI/CD",
        "Manual Slack approval only",
        "Hard delete old fields without deprecation",
        "No versioning; rely on docs"
      ],
      "correct": 0,
      "explanation": "Automated compatibility enforcement prevents producer changes from breaking downstream consumers.",
      "detailedExplanation": "The core signal here is \"service emits events where consumers depend on schema evolution over months\". Reject designs that improve throughput while weakening reliability guarantees. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-017",
      "type": "multiple-choice",
      "question": "A payment queue must avoid starvation between high-priority fraud checks and normal tasks. Which approach is best?",
      "options": [
        "Single FIFO queue only",
        "Priority queues with fairness controls or weighted scheduling",
        "Process low priority first always",
        "Duplicate all messages into both queues"
      ],
      "correct": 1,
      "explanation": "Priority with fairness balances urgency and prevents lower classes from permanent starvation.",
      "detailedExplanation": "If you keep \"payment queue must avoid starvation between high-priority fraud checks and normal tasks\" in view, the correct answer separates faster. Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-018",
      "type": "multiple-choice",
      "question": "A team uses event sourcing and needs to rebuild a projection after bug fix. Which capability is essential?",
      "options": [
        "Disable consumer offsets",
        "Delete historical events after first consume",
        "Replay immutable event log from offset 0",
        "Store only latest snapshot with no events"
      ],
      "correct": 2,
      "explanation": "Projection rebuild relies on retained immutable event history with replay.",
      "detailedExplanation": "Start from \"team uses event sourcing and needs to rebuild a projection after bug fix\", then pressure-test the result against the options. Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Compound annual growth rate",
          "url": "https://www.investopedia.com/terms/c/cagr.asp"
        }
      ]
    },
    {
      "id": "msg-scn-019",
      "type": "multiple-choice",
      "question": "You need to process file uploads asynchronously and avoid placing 50MB payloads directly in the broker. Best pattern?",
      "options": [
        "Use larger broker replicas only",
        "Split file into queue message per KB",
        "Embed full binary in each message",
        "Claim-check pattern: store blob in object storage and send pointer"
      ],
      "correct": 3,
      "explanation": "Claim-check keeps messages lightweight and shifts large payload handling to blob storage.",
      "detailedExplanation": "The key clue in this question is \"you need to process file uploads asynchronously and avoid placing 50MB payloads\". Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Keep quantities like 50MB in aligned units before selecting an answer. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-020",
      "type": "multiple-choice",
      "question": "A team wants strict global order across all users and also very high throughput. What is the core trade-off?",
      "options": [
        "Global order usually constrains parallelism and throughput",
        "Higher throughput improves global order",
        "Only consumer code determines this",
        "No trade-off; both are free"
      ],
      "correct": 0,
      "explanation": "Global ordering often forces serialization, which caps scalability.",
      "detailedExplanation": "Use \"team wants strict global order across all users and also very high throughput\" as your starting point, then verify tradeoffs carefully. Reject designs that improve throughput while weakening reliability guarantees. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-021",
      "type": "multiple-choice",
      "question": "During incident response, engineers need to trace one business event through producer, broker, and three consumers. What instrumentation is mandatory?",
      "options": [
        "Only host-level CPU metrics",
        "End-to-end correlation IDs propagated in message headers",
        "Bigger log retention only",
        "Turn off sampling for all logs forever"
      ],
      "correct": 1,
      "explanation": "Correlation IDs enable cross-service traceability for asynchronous hops.",
      "detailedExplanation": "This prompt is really about \"during incident response, engineers need to trace one business event through producer,\". Reject choices that sound good generally but do not reduce the concrete reliability risk in this scenario. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-022",
      "type": "multiple-choice",
      "question": "A team uses SQS Standard for worker jobs and observes occasional duplicates and out-of-order delivery. What should they conclude?",
      "options": [
        "Duplicates imply producer bug only",
        "Service is broken and unusable",
        "Behavior matches at-least-once, best-effort ordering semantics",
        "They configured FIFO already"
      ],
      "correct": 2,
      "explanation": "SQS Standard intentionally prioritizes scale with at-least-once and non-strict ordering characteristics.",
      "detailedExplanation": "If you keep \"team uses SQS Standard for worker jobs and observes occasional duplicates and\" in view, the correct answer separates faster. Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-023",
      "type": "multiple-choice",
      "question": "Consumers of an event stream need to read past 14 days for audits, but current retention is 24 hours. What should be changed first?",
      "options": [
        "Reduce batch size",
        "Move all consumers to sync HTTP",
        "Increase retention to meet replay/audit requirement",
        "Add more partitions only"
      ],
      "correct": 2,
      "explanation": "Retention policy must align with replay and audit windows; otherwise required history disappears.",
      "detailedExplanation": "The core signal here is \"consumers of an event stream need to read past 14 days for audits, but current\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Numbers such as 14 days and 24 hours should be normalized first so downstream reasoning stays consistent. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "msg-scn-024",
      "type": "multiple-choice",
      "question": "A stream join requires user-profile updates and click events keyed by user_id. Which mistake most likely breaks join correctness?",
      "options": [
        "Different partitioning keys causing cross-partition join mismatch",
        "Adding watermark handling",
        "Using changelog state stores",
        "Using same key and partitioning for both streams"
      ],
      "correct": 0,
      "explanation": "Co-partitioned keys are required for efficient and correct distributed stream joins.",
      "detailedExplanation": "The key clue in this question is \"stream join requires user-profile updates and click events keyed by user_id\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "msg-scn-025",
      "type": "multiple-choice",
      "question": "Queue depth has grown 10x but consumer CPU is low because each task waits on slow third-party API. Best scaling change?",
      "options": [
        "Increase broker disk only",
        "Raise consumer concurrency with bounded in-flight calls and backpressure",
        "Disable retries",
        "Shorten visibility timeout"
      ],
      "correct": 1,
      "explanation": "I/O-bound consumers need concurrency tuning and bounded parallelism to raise throughput safely.",
      "detailedExplanation": "Start from \"queue depth has grown 10x but consumer CPU is low because each task waits on slow\", then pressure-test the result against the options. Prefer the choice that keeps client behavior explicit while preserving evolvability. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Keep quantities like 10x in aligned units before selecting an answer. Common pitfall: interface design coupled too tightly to internal implementation.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-026",
      "type": "multiple-choice",
      "question": "A team wants to migrate from monolith DB polling to events with minimum risk. First incremental step?",
      "options": [
        "Adopt two brokers at once",
        "Rebuild all services around Kafka Streams immediately",
        "Publish domain events from one bounded context and onboard one consumer",
        "Delete polling jobs and hope"
      ],
      "correct": 2,
      "explanation": "Incremental adoption with one flow limits blast radius and validates contracts early.",
      "detailedExplanation": "The decision turns on \"team wants to migrate from monolith DB polling to events with minimum risk\". Eliminate options that ignore delivery semantics or backpressure behavior. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-027",
      "type": "multiple-choice",
      "question": "Message processing latency SLO is P95 < 2s, but occasional poison messages retry for hours. What policy prevents SLO sabotage?",
      "options": [
        "Disable all retries",
        "Process poison first at highest priority",
        "Infinite retries in main queue",
        "Bounded retries then DLQ with triage workflow"
      ],
      "correct": 3,
      "explanation": "Bounded retries protect healthy traffic and isolate pathological messages for investigation.",
      "detailedExplanation": "Read this as a scenario about \"message processing latency SLO is P95 < 2s, but occasional poison messages retry for\". Eliminate answers that do not directly address the failure mode, recovery path, or blast radius. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. If values like 2s appear, convert them into one unit basis before comparison. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-028",
      "type": "multiple-choice",
      "question": "A multi-tenant event platform needs noisy-neighbor isolation. Which architecture helps most?",
      "options": [
        "Per-tenant quotas/partitions or dedicated topics for top tenants",
        "No admission controls",
        "Global FIFO queue only",
        "Single shared partition for all tenants"
      ],
      "correct": 0,
      "explanation": "Capacity isolation and quota enforcement prevent one tenant from overwhelming others.",
      "detailedExplanation": "Use \"multi-tenant event platform needs noisy-neighbor isolation\" as your starting point, then verify tradeoffs carefully. Eliminate designs that create ambiguous API semantics or brittle versioning paths. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "msg-scn-029",
      "type": "multiple-choice",
      "question": "Exactly-once business outcome is required for coupon redemption. Which design is strongest?",
      "options": [
        "At-most-once consume with possible drop",
        "At-least-once plus idempotent redemption keyed by coupon+user",
        "Disable retries on failures",
        "Randomized duplicate suppression"
      ],
      "correct": 1,
      "explanation": "Business exactly-once typically comes from idempotent state transitions over at-least-once transport.",
      "detailedExplanation": "This prompt is really about \"exactly-once business outcome is required for coupon redemption\". Discard options that weaken contract clarity or compatibility over time. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-030",
      "type": "multiple-choice",
      "question": "An event payload now includes optional field `device_type`; old consumers ignore unknown fields. Which compatibility mode supports this?",
      "options": [
        "Binary payload with no contract",
        "Backward/forward compatible schema evolution",
        "Breaking change requiring immediate global cutover",
        "No schema versioning needed"
      ],
      "correct": 1,
      "explanation": "Adding optional fields is a standard compatible evolution when consumers tolerate unknown fields.",
      "detailedExplanation": "Read this as a scenario about \"event payload now includes optional field `device_type`\". Eliminate designs that create ambiguous API semantics or brittle versioning paths. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-031",
      "type": "multiple-choice",
      "question": "A data team wants to consume production events in a separate account without affecting primary workers. Best setup?",
      "options": [
        "Read directly from worker DB tables",
        "Mirror logs manually from app logs",
        "Share same consumer group as primary workers",
        "Use separate subscription/consumer group with independent offsets"
      ],
      "correct": 3,
      "explanation": "Independent groups preserve isolation and do not steal work from operational consumers.",
      "detailedExplanation": "The decision turns on \"data team wants to consume production events in a separate account without affecting\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-032",
      "type": "multiple-choice",
      "question": "During failover, producer retries can reorder related events if they are keyed inconsistently. What fixes this?",
      "options": [
        "Use stable domain key per ordering boundary and idempotent producer config",
        "Lower topic retention",
        "Use one consumer only",
        "Use random partition keys for load"
      ],
      "correct": 0,
      "explanation": "Stable keys preserve partition order; idempotent producer settings reduce duplicate/reorder effects on retry.",
      "detailedExplanation": "Start from \"during failover, producer retries can reorder related events if they are keyed\", then pressure-test the result against the options. Prioritize the option that best protects the reliability objective under the stated failure conditions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-033",
      "type": "multiple-choice",
      "question": "A team asks whether to store PII directly in long-retention event logs. What is best practice?",
      "options": [
        "Store full PII forever for convenience",
        "Minimize payload PII and use tokenization/reference where possible",
        "Encrypt nothing if private network exists",
        "Rely solely on broker ACL names"
      ],
      "correct": 1,
      "explanation": "Data minimization and tokenization reduce compliance and breach exposure in replayable logs.",
      "detailedExplanation": "The key clue in this question is \"team asks whether to store PII directly in long-retention event logs\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        }
      ]
    },
    {
      "id": "msg-scn-034",
      "type": "multiple-choice",
      "question": "A CDC pipeline floods downstream with change events from noisy update statements that do not change values. Best mitigation?",
      "options": [
        "Disable consumer lag metrics",
        "Drop CDC entirely",
        "Filter no-op changes or enforce update-if-changed semantics upstream",
        "Double broker partitions only"
      ],
      "correct": 2,
      "explanation": "Reducing no-op event volume lowers cost and lag without sacrificing meaningful change propagation.",
      "detailedExplanation": "The core signal here is \"cDC pipeline floods downstream with change events from noisy update statements that do\". Eliminate options that ignore delivery semantics or backpressure behavior. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-035",
      "type": "multiple-choice",
      "question": "A queue consumer sometimes takes 15 minutes for batch image processing. Which anti-pattern most likely causes duplicate storms?",
      "options": [
        "Using idempotent output keys",
        "Bounded worker concurrency",
        "Heartbeat extensions during processing",
        "Visibility timeout shorter than processing time with no extension"
      ],
      "correct": 3,
      "explanation": "If visibility expires mid-task, broker redelivers in-flight work, creating duplicate processing.",
      "detailedExplanation": "If you keep \"queue consumer sometimes takes 15 minutes for batch image processing\" in view, the correct answer separates faster. Eliminate options that ignore delivery semantics or backpressure behavior. A good message-system answer defines guarantees clearly for both producer and consumer paths. Numbers such as 15 minutes should be normalized first so downstream reasoning stays consistent. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "msg-scn-036",
      "type": "multiple-choice",
      "question": "A domain emits both command events and audit events. Audit consumers need complete history, while command workers should treat messages as tasks. What is a pragmatic architecture?",
      "options": [
        "Separate log-oriented stream for audit and queue-oriented channel for command execution",
        "Synchronous RPC only",
        "Randomly duplicate messages to all systems",
        "One shared task queue for everything"
      ],
      "correct": 0,
      "explanation": "Different workloads often need different semantics: replayable logs for audit and queue semantics for work distribution.",
      "detailedExplanation": "This prompt is really about \"domain emits both command events and audit events\". Prefer the choice that keeps ordering/acknowledgment behavior predictable under failure. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-037",
      "type": "two-stage",
      "stages": [
        {
          "question": "Flash-sale checkout pipeline: Traffic spikes 20x and order-created events accumulate. What is the first protection to keep API responsive?",
          "options": [
            "Process synchronously in request thread",
            "Queue writes and apply backpressure/load shedding at ingress",
            "Disable inventory checks",
            "Retry client calls immediately on 429"
          ],
          "correct": 1,
          "explanation": "Queue buffering plus explicit backpressure keeps upstream stable during spikes.",
          "detailedExplanation": "The decision turns on \"flash-sale checkout pipeline: Traffic spikes 20x and order-created events accumulate\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Interface decisions should be justified by contract stability and client impact over time. Keep quantities like 20x in aligned units before selecting an answer. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "After buffering, backlog recovery is too slow. Which scaling move improves catch-up while preserving per-order-key ordering?",
          "options": [
            "Lower retention to speed reads",
            "Increase partitions and consumers keyed by order/customer boundary",
            "Add consumers only with same partition count",
            "Use global FIFO single partition"
          ],
          "correct": 1,
          "explanation": "Partition parallelism controls throughput; preserving key choice keeps local ordering guarantees.",
          "detailedExplanation": "Start from \"after buffering, backlog recovery is too slow\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        }
      ],
      "detailedExplanation": "Use \"messaging Scenarios\" as your starting point, then verify tradeoffs carefully. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-038",
      "type": "two-stage",
      "stages": [
        {
          "question": "Payment + fulfillment integration: Payment commit succeeds but fulfillment event publish fails. What consistency bug is this?",
          "options": [
            "Deadlock",
            "Clock skew",
            "Read skew",
            "Dual-write inconsistency"
          ],
          "correct": 3,
          "explanation": "State change and event emission are not atomic, so systems diverge.",
          "detailedExplanation": "Read this as a scenario about \"payment + fulfillment integration: Payment commit succeeds but fulfillment event\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "Which concrete fix is standard?",
          "options": [
            "Sleep and retry in web thread only",
            "Disable payment retries",
            "Use smaller messages",
            "Outbox table in same DB transaction as payment state"
          ],
          "correct": 3,
          "explanation": "Outbox pattern atomically records both business state and pending event.",
          "detailedExplanation": "The key clue in this question is \"concrete fix is standard\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"messaging Scenarios\". Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-039",
      "type": "two-stage",
      "stages": [
        {
          "question": "Notification fan-out: Email consumer outage should not block push notifications. Which topology best isolates failures?",
          "options": [
            "Single work queue for all channels",
            "Pub/sub with separate subscriptions per channel",
            "Synchronous chain: email then push",
            "One topic but shared consumer group"
          ],
          "correct": 1,
          "explanation": "Separate subscriptions allow each channel to fail/recover independently.",
          "detailedExplanation": "Use \"notification fan-out: Email consumer outage should not block push notifications\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        },
        {
          "question": "Email provider times out and retries cause duplicates. Which boundary should enforce dedupe?",
          "options": [
            "CPU throttling",
            "Broker dedupe across all topics globally",
            "Idempotency key at email send operation",
            "Producer instance ID only"
          ],
          "correct": 2,
          "explanation": "Side-effect idempotency at the provider call prevents duplicate customer-visible sends.",
          "detailedExplanation": "The core signal here is \"email provider times out and retries cause duplicates\". Solve this as chained reasoning where stage two must respect stage one assumptions. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "The decision turns on \"messaging Scenarios\". Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-040",
      "type": "two-stage",
      "stages": [
        {
          "question": "Driver dispatch: Assignments for one driver must stay ordered. Which partition key?",
          "options": ["rider_id", "event_type", "zone_id", "driver_id"],
          "correct": 3,
          "explanation": "Driver-scoped ordering requires stable key per driver.",
          "detailedExplanation": "The key clue in this question is \"driver dispatch: Assignments for one driver must stay ordered\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "A few drivers are extremely hot and cause lag. Which redesign helps without breaking order per driver?",
          "options": [
            "Introduce sub-entities for independent streams where business-safe",
            "Force global single partition",
            "Disable retries",
            "Randomize key each event"
          ],
          "correct": 0,
          "explanation": "Only split order boundaries where domain permits; keep each boundary stable.",
          "detailedExplanation": "Read this as a scenario about \"few drivers are extremely hot and cause lag\". Solve this as chained reasoning where stage two must respect stage one assumptions. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency."
        }
      ],
      "detailedExplanation": "If you keep \"messaging Scenarios\" in view, the correct answer separates faster. Solve this as chained reasoning where stage two must respect stage one assumptions. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-041",
      "type": "two-stage",
      "stages": [
        {
          "question": "Fraud pipeline replay: Fraud model bug fixed; need reprocess last 7 days quickly. What storage/transport capability is required?",
          "options": [
            "Ephemeral queue deletion on ack",
            "Retained immutable event log with replay offsets",
            "In-memory channel only",
            "Webhook retry cache"
          ],
          "correct": 1,
          "explanation": "Replay demands retained history and independent cursors.",
          "detailedExplanation": "The core signal here is \"fraud pipeline replay: Fraud model bug fixed\". Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Keep quantities like 7 days in aligned units before selecting an answer. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "Reprocessing must not trigger customer notifications again. What guard is necessary?",
          "options": [
            "Lower partition count",
            "Disable replay",
            "Separate side-effect path or replay mode with idempotent suppression",
            "Shorter retention"
          ],
          "correct": 2,
          "explanation": "Replay should be isolated from external side effects unless explicitly intended.",
          "detailedExplanation": "Use \"reprocessing must not trigger customer notifications again\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "The core signal here is \"messaging Scenarios\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-042",
      "type": "two-stage",
      "stages": [
        {
          "question": "DLQ growth incident: DLQ contains schema-deserialization failures after producer deploy. First triage action?",
          "options": [
            "Increase consumer replicas",
            "Delete oldest DLQ first",
            "Replay DLQ immediately",
            "Pinpoint schema compatibility break and stop bad producer"
          ],
          "correct": 3,
          "explanation": "Root-cause containment comes before replay.",
          "detailedExplanation": "The decision turns on \"dLQ growth incident: DLQ contains schema-deserialization failures after producer deploy\". Do not reset assumptions between stages; carry forward prior constraints directly. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "After fix, safest replay method?",
          "options": [
            "Replay in controlled batches with monitoring and idempotent consumers",
            "Replay directly into primary queue without limits",
            "Manually edit broker logs",
            "Bulk replay all at max rate"
          ],
          "correct": 0,
          "explanation": "Controlled replay prevents second incident and exposes latent issues early.",
          "detailedExplanation": "Start from \"after fix, safest replay method\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "Use \"messaging Scenarios\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-043",
      "type": "two-stage",
      "stages": [
        {
          "question": "Inventory reservation saga: Reserve inventory succeeds, payment fails permanently. What next?",
          "options": [
            "Keep reservation forever",
            "Compensate by releasing reservation",
            "Ship anyway",
            "Retry infinitely"
          ],
          "correct": 1,
          "explanation": "Compensation restores consistency when saga path aborts.",
          "detailedExplanation": "Start from \"inventory reservation saga: Reserve inventory succeeds, payment fails permanently\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "What metadata best supports safe compensation?",
          "options": [
            "Broker partition only",
            "Only human-readable logs",
            "Saga ID + step status with idempotent handlers",
            "Random retry counter"
          ],
          "correct": 2,
          "explanation": "Explicit saga state and idempotent step execution make retries and rollback safe.",
          "detailedExplanation": "The decision turns on \"metadata best supports safe compensation\". Do not reset assumptions between stages; carry forward prior constraints directly. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: interface design coupled too tightly to internal implementation."
        }
      ],
      "detailedExplanation": "This prompt is really about \"messaging Scenarios\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-044",
      "type": "two-stage",
      "stages": [
        {
          "question": "Multi-region order events: Producer failover causes occasional duplicates. Which producer setting helps in Kafka?",
          "options": [
            "Single replica topics",
            "No batching",
            "Disable acknowledgments",
            "Idempotent producer with proper acks and retries"
          ],
          "correct": 3,
          "explanation": "Idempotent producer reduces duplicates from retry/failover scenarios.",
          "detailedExplanation": "Use \"multi-region order events: Producer failover causes occasional duplicates\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "Business still needs exactly-once order fulfillment. What completes the design?",
          "options": [
            "Idempotent consumer side effects keyed by order event ID",
            "Disable consumer restarts",
            "At-most-once consume",
            "Trust broker only"
          ],
          "correct": 0,
          "explanation": "Outcome correctness requires idempotency at the state-change boundary too.",
          "detailedExplanation": "The core signal here is \"business still needs exactly-once order fulfillment\". Solve this as chained reasoning where stage two must respect stage one assumptions. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes."
        }
      ],
      "detailedExplanation": "The decision turns on \"messaging Scenarios\". Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-045",
      "type": "two-stage",
      "stages": [
        {
          "question": "Customer activity stream: Need \"active session\" windows ending after 30 minutes inactivity. Which windowing model?",
          "options": [
            "Tumbling windows",
            "Session windows",
            "Global window",
            "Count window only"
          ],
          "correct": 1,
          "explanation": "Session windows are activity-gap based.",
          "detailedExplanation": "Read this as a scenario about \"customer activity stream: Need active session windows ending after 30 minutes inactivity\". Do not reset assumptions between stages; carry forward prior constraints directly. A good message-system answer defines guarantees clearly for both producer and consumer paths. Numbers such as 30 minutes should be normalized first so downstream reasoning stays consistent. Common pitfall: consumer lag growth under burst traffic."
        },
        {
          "question": "Events can arrive 5 minutes late. What stream-time control is needed?",
          "options": [
            "More partitions",
            "Disable watermarks",
            "Watermarks + allowed lateness policy",
            "Commit offsets faster only"
          ],
          "correct": 2,
          "explanation": "Watermarks and lateness policy define when windows finalize and how late events are handled.",
          "detailedExplanation": "The key clue in this question is \"events can arrive 5 minutes late\". Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. If values like 5 minutes appear, convert them into one unit basis before comparison. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"messaging Scenarios\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-046",
      "type": "two-stage",
      "stages": [
        {
          "question": "Bulk import pipeline: Import workers hit third-party API rate limits and queue backlog explodes. First control?",
          "options": [
            "Disable DLQ",
            "Lower message size",
            "Increase retries without bounds",
            "Consumer-side rate limiting and bounded concurrency"
          ],
          "correct": 3,
          "explanation": "Throughput must match external dependency limits.",
          "detailedExplanation": "If you keep \"bulk import pipeline: Import workers hit third-party API rate limits and queue backlog\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "Some tasks exceed max attempts repeatedly. Where should they go?",
          "options": [
            "DLQ with reason codes and remediation workflow",
            "Dropped silently",
            "To producer memory",
            "Back to main queue forever"
          ],
          "correct": 0,
          "explanation": "DLQ isolates pathological tasks and preserves main flow health.",
          "detailedExplanation": "This prompt is really about \"some tasks exceed max attempts repeatedly\". Do not reset assumptions between stages; carry forward prior constraints directly. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "The key clue in this question is \"messaging Scenarios\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-047",
      "type": "two-stage",
      "stages": [
        {
          "question": "Search indexing events: Indexer service down 6 hours; must catch up without data loss. Needed characteristic?",
          "options": [
            "At-most-once delivery",
            "Durable retention and consumer offsets",
            "Ephemeral pub/sub only",
            "Synchronous writes only"
          ],
          "correct": 1,
          "explanation": "Durable logs plus offsets support downtime recovery.",
          "detailedExplanation": "This prompt is really about \"search indexing events: Indexer service down 6 hours\". Solve this as chained reasoning where stage two must respect stage one assumptions. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Keep quantities like 6 hours in aligned units before selecting an answer. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "Indexer updates same document repeatedly during replay. Best write semantics?",
          "options": [
            "Drop duplicates by timestamp only",
            "Insert-only with random IDs",
            "Idempotent upsert by document ID and version",
            "Disable replay"
          ],
          "correct": 2,
          "explanation": "Upsert by deterministic key prevents duplicate state growth during replay.",
          "detailedExplanation": "If you keep \"indexer updates same document repeatedly during replay\" in view, the correct answer separates faster. Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes."
        }
      ],
      "detailedExplanation": "Start from \"messaging Scenarios\", then pressure-test the result against the options. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-048",
      "type": "two-stage",
      "stages": [
        {
          "question": "IoT telemetry: Millions of sensors send updates; one manufacturer floods malformed messages. System-wide impact must be contained. Which control?",
          "options": [
            "Bigger message payloads",
            "Single consumer group",
            "Global shared quota only",
            "Per-tenant/producer quotas and schema validation at ingress"
          ],
          "correct": 3,
          "explanation": "Ingress quotas and validation isolate bad actors.",
          "detailedExplanation": "The key clue in this question is \"ioT telemetry: Millions of sensors send updates\". Do not reset assumptions between stages; carry forward prior constraints directly. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes."
        },
        {
          "question": "Malformed messages should be retained for diagnostics. Where?",
          "options": [
            "DLQ/invalid-topic with metadata for forensic analysis",
            "Main topic unchanged",
            "App server logs only",
            "Dropped permanently"
          ],
          "correct": 0,
          "explanation": "Quarantine streams enable debugging without polluting primary pipelines.",
          "detailedExplanation": "Read this as a scenario about \"malformed messages should be retained for diagnostics\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes."
        }
      ],
      "detailedExplanation": "If you keep \"messaging Scenarios\" in view, the correct answer separates faster. Solve this as chained reasoning where stage two must respect stage one assumptions. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-049",
      "type": "two-stage",
      "stages": [
        {
          "question": "Order state projection: Read model rebuilt from events is slow after code fix. What accelerates rebuild while preserving correctness?",
          "options": [
            "Delete old events",
            "Use snapshots plus replay from latest snapshot point",
            "Switch to synchronous APIs",
            "Lower durability"
          ],
          "correct": 1,
          "explanation": "Snapshots reduce replay length while retaining event-sourced correctness.",
          "detailedExplanation": "The core signal here is \"order state projection: Read model rebuilt from events is slow after code fix\". Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "How do you validate projection correctness after rebuild?",
          "options": [
            "Increase partition count",
            "Assume success",
            "Deterministic checksums/invariants against source of truth",
            "Manual spot check one order"
          ],
          "correct": 2,
          "explanation": "Automated invariants catch subtle drift and replay bugs.",
          "detailedExplanation": "Use \"you validate projection correctness after rebuild\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency."
        }
      ],
      "detailedExplanation": "The core signal here is \"messaging Scenarios\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-050",
      "type": "two-stage",
      "stages": [
        {
          "question": "Cross-service tracing: Incident team cannot correlate a failed order across async hops. Missing practice?",
          "options": [
            "Smaller partitions",
            "Disable retries",
            "Verbose logs only",
            "Propagate correlation/trace IDs in message headers"
          ],
          "correct": 3,
          "explanation": "Header-level correlation is required for end-to-end tracing.",
          "detailedExplanation": "Start from \"cross-service tracing: Incident team cannot correlate a failed order across async hops\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: assuming recovery speed without operational proof."
        },
        {
          "question": "Which metric best detects hidden queueing delay?",
          "options": [
            "End-to-end event age (now - event_time) percentiles",
            "Broker disk free",
            "Number of topics",
            "Producer CPU only"
          ],
          "correct": 0,
          "explanation": "Event age exposes user-visible freshness lag better than queue depth alone.",
          "detailedExplanation": "The decision turns on \"metric best detects hidden queueing delay\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "This prompt is really about \"messaging Scenarios\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-051",
      "type": "two-stage",
      "stages": [
        {
          "question": "Subscription billing: Monthly charge events occasionally processed twice. Which billing logic is safest?",
          "options": [
            "Increment balance blindly",
            "Idempotent charge ledger keyed by invoice_id",
            "Disable retries",
            "Use at-most-once transport"
          ],
          "correct": 1,
          "explanation": "Invoice-keyed idempotency ensures duplicate events do not double-charge.",
          "detailedExplanation": "The decision turns on \"subscription billing: Monthly charge events occasionally processed twice\". Do not reset assumptions between stages; carry forward prior constraints directly. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: consumer lag growth under burst traffic."
        },
        {
          "question": "Dispute team needs full replayable history for audits. Where should source-of-truth state come from?",
          "options": [
            "Cache snapshots only",
            "Only mutable current balance table",
            "Immutable ledger/events plus derived projections",
            "Application logs only"
          ],
          "correct": 2,
          "explanation": "Immutable ledgers support auditability and deterministic recomputation.",
          "detailedExplanation": "Start from \"dispute team needs full replayable history for audits\", then pressure-test the result against the options. Do not reset assumptions between stages; carry forward prior constraints directly. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes."
        }
      ],
      "detailedExplanation": "Use \"messaging Scenarios\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-052",
      "type": "two-stage",
      "stages": [
        {
          "question": "Feature flag event bus: Clients must get latest flag within seconds, but missing one update should self-heal quickly. Best model?",
          "options": [
            "Synchronous per-request DB read only",
            "No versioning",
            "Ephemeral fire-and-forget only",
            "Event stream plus periodic snapshot sync"
          ],
          "correct": 3,
          "explanation": "Event plus periodic state sync balances low latency with eventual repair.",
          "detailedExplanation": "The core signal here is \"feature flag event bus: Clients must get latest flag within seconds, but missing one\". Solve this as chained reasoning where stage two must respect stage one assumptions. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        },
        {
          "question": "How should conflicts between stale event and newer snapshot be resolved?",
          "options": [
            "Version/timestamp monotonic merge rule",
            "Always trust event arrival order",
            "Manual intervention always",
            "Random winner"
          ],
          "correct": 0,
          "explanation": "Deterministic version ordering prevents stale overwrite anomalies.",
          "detailedExplanation": "Use \"conflicts between stale event and newer snapshot be resolved\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: interface design coupled too tightly to internal implementation."
        }
      ],
      "detailedExplanation": "The core signal here is \"messaging Scenarios\". Solve this as chained reasoning where stage two must respect stage one assumptions. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-053",
      "type": "two-stage",
      "stages": [
        {
          "question": "On-call paging pipeline: Pager events are bursty; some can be delayed, P1 cannot. What queue strategy?",
          "options": [
            "Single FIFO for all severities",
            "Priority channels with bounded starvation controls",
            "Drop low priority randomly",
            "Disable retries"
          ],
          "correct": 1,
          "explanation": "Priority routing meets urgent SLOs while fairness prevents starvation.",
          "detailedExplanation": "The key clue in this question is \"on-call paging pipeline: Pager events are bursty\". Solve this as chained reasoning where stage two must respect stage one assumptions. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        },
        {
          "question": "Provider outage persists. Which fallback keeps durability?",
          "options": [
            "Turn off alerting",
            "Block producers and lose events",
            "Buffer to durable queue with circuit breaker around provider",
            "Write only to memory"
          ],
          "correct": 2,
          "explanation": "Circuit breaker + durable buffering protects both provider and message durability.",
          "detailedExplanation": "Read this as a scenario about \"provider outage persists\". Do not reset assumptions between stages; carry forward prior constraints directly. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Common pitfall: assuming recovery speed without operational proof."
        }
      ],
      "detailedExplanation": "If you keep \"messaging Scenarios\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-054",
      "type": "two-stage",
      "stages": [
        {
          "question": "ETL to warehouse: Warehouse loads require exactly-once row semantics from at-least-once events. What sink strategy?",
          "options": [
            "Disable retries",
            "Sample 10% events",
            "Append-only with no keys",
            "Merge/upsert using deterministic business key + load id"
          ],
          "correct": 3,
          "explanation": "Deterministic merge keys enforce idempotent ingestion.",
          "detailedExplanation": "This prompt is really about \"eTL to warehouse: Warehouse loads require exactly-once row semantics from at-least-once\". Solve this as chained reasoning where stage two must respect stage one assumptions. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: interface design coupled too tightly to internal implementation."
        },
        {
          "question": "Late arriving corrections should adjust prior aggregates. Which model supports this cleanly?",
          "options": [
            "Event-time processing with retractions/upserts",
            "Drop late events always",
            "Manual backfill only",
            "Processing-time-only windows with no correction"
          ],
          "correct": 0,
          "explanation": "Event-time with update semantics handles late corrections systematically.",
          "detailedExplanation": "If you keep \"late arriving corrections should adjust prior aggregates\" in view, the correct answer separates faster. Keep stage continuity explicit: the first-step outcome is a hard input to the next step. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "Start from \"messaging Scenarios\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-055",
      "type": "two-stage",
      "stages": [
        {
          "question": "Device command queue: Commands to same device must execute in order; different devices can run parallel. Best keying?",
          "options": [
            "Global single partition",
            "device_id",
            "command_type",
            "random UUID"
          ],
          "correct": 1,
          "explanation": "device_id key preserves per-device order and parallelizes across devices.",
          "detailedExplanation": "If you keep \"device command queue: Commands to same device must execute in order\" in view, the correct answer separates faster. Do not reset assumptions between stages; carry forward prior constraints directly. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes."
        },
        {
          "question": "Offline devices cause long retries and backlog. Which mitigation?",
          "options": [
            "Drop all failed commands instantly",
            "Infinite immediate retry",
            "Per-device retry backoff + TTL + dead-letter for expired commands",
            "Disable ordering"
          ],
          "correct": 2,
          "explanation": "Device-specific backoff and expiry avoid queue pollution by unreachable devices.",
          "detailedExplanation": "This prompt is really about \"offline devices cause long retries and backlog\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure."
        }
      ],
      "detailedExplanation": "The key clue in this question is \"messaging Scenarios\". Solve this as chained reasoning where stage two must respect stage one assumptions. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-056",
      "type": "two-stage",
      "stages": [
        {
          "question": "Marketplace payouts: Payout events require strict audit trail and replay years later. Which storage trait is essential?",
          "options": [
            "In-memory queue only",
            "Best-effort logs",
            "Short-lived ephemeral retention",
            "Long-term immutable retention with access controls"
          ],
          "correct": 3,
          "explanation": "Financial workflows need durable auditability and controlled replay.",
          "detailedExplanation": "Read this as a scenario about \"marketplace payouts: Payout events require strict audit trail and replay years later\". Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "Regulatory request asks to erase personal data while retaining accounting events. Practical approach?",
          "options": [
            "Tokenize PII and store removable reference outside immutable financial facts",
            "Ignore request",
            "Encrypt with shared static key only",
            "Delete all events"
          ],
          "correct": 0,
          "explanation": "Separating PII from immutable business facts balances compliance and audit needs.",
          "detailedExplanation": "The key clue in this question is \"regulatory request asks to erase personal data while retaining accounting events\". Solve this as chained reasoning where stage two must respect stage one assumptions. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes."
        }
      ],
      "detailedExplanation": "Read this as a scenario about \"messaging Scenarios\". Do not reset assumptions between stages; carry forward prior constraints directly. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-057",
      "type": "two-stage",
      "stages": [
        {
          "question": "Video processing jobs: Workers pull 500MB payloads from queue messages, causing broker pressure. Better design?",
          "options": [
            "Increase broker heap only",
            "Claim-check with object storage URIs in messages",
            "Split binary across many messages",
            "Disable compression everywhere"
          ],
          "correct": 1,
          "explanation": "Claim-check prevents brokers from carrying huge payload bytes.",
          "detailedExplanation": "Use \"video processing jobs: Workers pull 500MB payloads from queue messages, causing broker\" as your starting point, then verify tradeoffs carefully. Do not reset assumptions between stages; carry forward prior constraints directly. Interface decisions should be justified by contract stability and client impact over time. Keep quantities like 500MB in aligned units before selecting an answer. Common pitfall: breaking clients during version evolution."
        },
        {
          "question": "Some object URIs expire before processing. Which reliability fix?",
          "options": [
            "Use at-most-once",
            "No retries",
            "Generate long-enough signed URL at consume time or refresh token flow",
            "Store payload in message body"
          ],
          "correct": 2,
          "explanation": "Access token lifecycle must align with queue latency and retries.",
          "detailedExplanation": "The core signal here is \"some object URIs expire before processing\". Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "The decision turns on \"messaging Scenarios\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-058",
      "type": "two-stage",
      "stages": [
        {
          "question": "Partner webhook ingestion: Partners retry webhooks aggressively causing duplicates. Ingestion endpoint should do what first?",
          "options": [
            "Sleep before 200 response",
            "Process synchronously only",
            "Reject duplicates with idempotency key store",
            "Trust partner ordering"
          ],
          "correct": 2,
          "explanation": "Idempotency at ingress neutralizes partner retry behavior.",
          "detailedExplanation": "Start from \"partner webhook ingestion: Partners retry webhooks aggressively causing duplicates\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: meeting average goals while missing tail-risk."
        },
        {
          "question": "Some partners send out-of-order updates. Which event handling strategy is robust?",
          "options": [
            "Use versioned events and monotonic conflict resolution",
            "Drop old partners",
            "Disable buffering",
            "Apply blindly in arrival order"
          ],
          "correct": 0,
          "explanation": "Version-aware processing handles reordering safely.",
          "detailedExplanation": "The decision turns on \"some partners send out-of-order updates\". Keep stage continuity explicit: the first-step outcome is a hard input to the next step. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Common pitfall: breaking clients during version evolution."
        }
      ],
      "detailedExplanation": "This prompt is really about \"messaging Scenarios\". Do not reset assumptions between stages; carry forward prior constraints directly. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-059",
      "type": "two-stage",
      "stages": [
        {
          "question": "Internal audit stream: Security wants tamper evidence for audit events. Which design strengthens this?",
          "options": [
            "Mutable rows overwritten in place",
            "Append-only log with immutable storage controls and checksums",
            "Disable replication",
            "Keep only 24h retention"
          ],
          "correct": 1,
          "explanation": "Append-only immutable controls improve tamper resistance.",
          "detailedExplanation": "The decision turns on \"internal audit stream: Security wants tamper evidence for audit events\". Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency."
        },
        {
          "question": "Auditors query by case_id frequently; full scan replay is expensive. What read model helps?",
          "options": [
            "Use smaller messages",
            "No index needed",
            "Derived indexed projection keyed by case_id",
            "Only raw topic browsing"
          ],
          "correct": 2,
          "explanation": "Purpose-built projections enable efficient audit retrieval while preserving canonical log.",
          "detailedExplanation": "Start from \"auditors query by case_id frequently\", then pressure-test the result against the options. Solve this as chained reasoning where stage two must respect stage one assumptions. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: consumer lag growth under burst traffic."
        }
      ],
      "detailedExplanation": "Use \"messaging Scenarios\" as your starting point, then verify tradeoffs carefully. Solve this as chained reasoning where stage two must respect stage one assumptions. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-060",
      "type": "multi-select",
      "question": "You are designing idempotent consumers for at-least-once delivery. Which techniques are valid? (Select all that apply)",
      "options": [
        "Store processed event IDs with TTL",
        "Use deterministic upsert keys in sink DB",
        "ACK before side effects to avoid duplicates",
        "Design side effects to be commutative when possible"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Event ID tracking, deterministic upserts, and commutative/idempotent operations reduce duplicate harm. ACK-before-side-effect risks loss.",
      "detailedExplanation": "The key clue in this question is \"you are designing idempotent consumers for at-least-once delivery\". Validate each option independently; do not select statements that are only partially true. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "gRPC Documentation",
          "url": "https://grpc.io/docs/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-061",
      "type": "multi-select",
      "question": "A resilient retry strategy for transient failures usually includes which elements? (Select all that apply)",
      "options": [
        "Immediate infinite tight-loop retries",
        "Exponential backoff",
        "Random jitter",
        "Bounded max attempts"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "Backoff, jitter, and bounded attempts prevent retry storms and allow DLQ escape for persistent failures.",
      "detailedExplanation": "Start from \"resilient retry strategy for transient failures usually includes which elements?\", then pressure-test the result against the options. Validate each option independently; do not select statements that are only partially true. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "msg-scn-062",
      "type": "multi-select",
      "question": "What are strong reasons to adopt an outbox pattern? (Select all that apply)",
      "options": [
        "Eliminate need for any retries in relay",
        "Improve auditability of emitted events",
        "Prevent dual-write inconsistency",
        "Atomically persist state change and outbound event intent"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "Outbox provides atomic intent recording and traceability; relay retries are still required for delivery.",
      "detailedExplanation": "The decision turns on \"strong reasons to adopt an outbox pattern? (Select all that apply)\". Treat every option as a separate true/false test under the same constraints. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-063",
      "type": "multi-select",
      "question": "Signals that a partitioning key is poor in production include which? (Select all that apply)",
      "options": [
        "Frequent hot keys dominating throughput",
        "Uniform distribution and low lag",
        "Needless cross-partition joins due to wrong key",
        "One partition has sustained lag while others are idle"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "Skew symptoms include hot partitions and expensive cross-partition operations.",
      "detailedExplanation": "Read this as a scenario about \"signals that a partitioning key is poor in production include which? (Select all that\". Avoid pattern guessing and evaluate each candidate directly against the scenario. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-064",
      "type": "multi-select",
      "question": "To make DLQs operationally useful, include which metadata? (Select all that apply)",
      "options": [
        "Original topic/queue and offset/message ID",
        "Failure reason or exception class",
        "Raw payload or pointer to it",
        "Delete everything but a counter"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Rich metadata enables targeted remediation and safe replay.",
      "detailedExplanation": "Use \"to make DLQs operationally useful, include which metadata? (Select all that apply)\" as your starting point, then verify tradeoffs carefully. Avoid pattern guessing and evaluate each candidate directly against the scenario. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-065",
      "type": "multi-select",
      "question": "For schema evolution in event systems, which practices reduce breakages? (Select all that apply)",
      "options": [
        "Consumer tolerance for unknown optional fields",
        "Compatibility checks in CI",
        "Versioned schemas with clear deprecation windows",
        "Removing required fields without migration"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Compatibility enforcement and tolerant readers help safe evolution; abrupt breaking removals do not.",
      "detailedExplanation": "This prompt is really about \"for schema evolution in event systems, which practices reduce breakages? (Select all\". Treat every option as a separate true/false test under the same constraints. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-066",
      "type": "multi-select",
      "question": "Useful async observability metrics include which? (Select all that apply)",
      "options": [
        "DLQ rate",
        "Only host disk usage",
        "Queue depth/lag",
        "End-to-end event age"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "Lag, age, and DLQ trends directly represent message health and freshness.",
      "detailedExplanation": "If you keep \"useful async observability metrics include which? (Select all that apply)\" in view, the correct answer separates faster. Treat every option as a separate true/false test under the same constraints. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-067",
      "type": "multi-select",
      "question": "When evaluating broker technology, which dimensions are typically first-class? (Select all that apply)",
      "options": [
        "Replay retention needs",
        "Operational ownership constraints",
        "Team coffee preference",
        "Ordering guarantees needed"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Ordering, replay, and ops model drive platform fit; irrelevant factors should not.",
      "detailedExplanation": "The core signal here is \"evaluating broker technology, which dimensions are typically first-class? (Select all\". Treat every option as a separate true/false test under the same constraints. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-068",
      "type": "multi-select",
      "question": "For safe replay of historical events, what controls are commonly needed? (Select all that apply)",
      "options": [
        "Isolate replay consumers from live side effects",
        "Rate limit replay traffic",
        "Idempotent sink handling",
        "Disable monitoring during replay"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Replay should be controlled, observable, and side-effect safe.",
      "detailedExplanation": "The key clue in this question is \"for safe replay of historical events, what controls are commonly needed? (Select all\". Validate each option independently; do not select statements that are only partially true. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-069",
      "type": "multi-select",
      "question": "Backpressure can be applied at which layers? (Select all that apply)",
      "options": [
        "Ignoring lag alerts",
        "Ingress request throttling",
        "Consumer concurrency limits",
        "Broker-side quotas"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "Backpressure is multi-layered; ignoring signals is the opposite of control.",
      "detailedExplanation": "Start from \"backpressure can be applied at which layers? (Select all that apply)\", then pressure-test the result against the options. Avoid pattern guessing and evaluate each candidate directly against the scenario. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-070",
      "type": "multi-select",
      "question": "Common causes of duplicate message effects include which? (Select all that apply)",
      "options": [
        "Idempotent sink writes",
        "Visibility timeout expiry during long processing",
        "Consumer crash after side effect before ACK/offset commit",
        "Producer retry after uncertain ack"
      ],
      "correctIndices": [1, 2, 3],
      "explanation": "Failures around acknowledgement boundaries and timeouts cause redelivery duplicates.",
      "detailedExplanation": "The core signal here is \"common causes of duplicate message effects include which? (Select all that apply)\". Avoid pattern guessing and evaluate each candidate directly against the scenario. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-071",
      "type": "multi-select",
      "question": "A robust saga orchestration implementation should include which? (Select all that apply)",
      "options": [
        "Compensation handlers",
        "Persistent saga state",
        "Best-effort memory-only state",
        "Step timeouts"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Durable state, timeouts, and compensation are core saga controls.",
      "detailedExplanation": "If you keep \"robust saga orchestration implementation should include which? (Select all that apply)\" in view, the correct answer separates faster. Avoid pattern guessing and evaluate each candidate directly against the scenario. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-072",
      "type": "multi-select",
      "question": "Which practices improve multi-tenant fairness on shared messaging infrastructure? (Select all that apply)",
      "options": [
        "Per-tenant quotas",
        "Isolation for top noisy tenants",
        "Global unlimited burst for all tenants",
        "Admission controls at ingress"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Quota and isolation mechanisms prevent noisy-neighbor incidents.",
      "detailedExplanation": "This prompt is really about \"practices improve multi-tenant fairness on shared messaging infrastructure? (Select all\". Avoid pattern guessing and evaluate each candidate directly against the scenario. Interface decisions should be justified by contract stability and client impact over time. Common pitfall: breaking clients during version evolution.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-073",
      "type": "multi-select",
      "question": "Which are valid reasons to choose queue semantics over log semantics? (Select all that apply)",
      "options": [
        "Per-message delay/priority features",
        "Competing workers consume tasks once",
        "Need simple work distribution without long replay history",
        "Independent long-term replay for many consumers"
      ],
      "correctIndices": [0, 1, 2],
      "explanation": "Queue semantics fit work distribution and workflow controls; long replay is usually log-centric.",
      "detailedExplanation": "Use \"valid reasons to choose queue semantics over log semantics? (Select all that apply)\" as your starting point, then verify tradeoffs carefully. Avoid pattern guessing and evaluate each candidate directly against the scenario. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-074",
      "type": "multi-select",
      "question": "To satisfy compliance in event-driven systems, which are strong controls? (Select all that apply)",
      "options": [
        "Access controls and audit logs",
        "Store all secrets in cleartext for debugging",
        "Data minimization in payloads",
        "Encryption in transit and at rest"
      ],
      "correctIndices": [0, 2, 3],
      "explanation": "Security/compliance requires minimization, encryption, and auditable access governance.",
      "detailedExplanation": "Read this as a scenario about \"to satisfy compliance in event-driven systems, which are strong controls? (Select all\". Treat every option as a separate true/false test under the same constraints. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-075",
      "type": "multi-select",
      "question": "For graceful consumer shutdown during deploy, what steps are recommended? (Select all that apply)",
      "options": [
        "Finish or checkpoint in-flight work",
        "Commit offsets/ACK appropriately before exit",
        "Hard kill immediately for speed",
        "Stop pulling new work"
      ],
      "correctIndices": [0, 1, 3],
      "explanation": "Graceful drain reduces duplicate processing and rebalance churn.",
      "detailedExplanation": "The decision turns on \"for graceful consumer shutdown during deploy, what steps are recommended? (Select all\". Avoid pattern guessing and evaluate each candidate directly against the scenario. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-076",
      "type": "numeric-input",
      "question": "A queue receives 1,200 messages/second for 10 minutes while consumers are down. Roughly how many messages accumulate?",
      "answer": 720000,
      "unit": "messages",
      "tolerance": 0.02,
      "explanation": "Backlog = rate * duration = 1,200 * 600 = 720,000 messages.",
      "detailedExplanation": "Start from \"queue receives 1,200 messages/second for 10 minutes while consumers are down\", then pressure-test the result against the options. Keep every transformation in one unit system and check order of magnitude at the end. A good message-system answer defines guarantees clearly for both producer and consumer paths. Keep quantities like 1,200 and 10 minutes in aligned units before selecting an answer. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-077",
      "type": "numeric-input",
      "question": "Each message averages 4 KB. If 720,000 messages are retained, what is approximate raw payload storage?",
      "answer": 2949120000,
      "unit": "bytes",
      "tolerance": 0.05,
      "explanation": "720,000 * 4,096 bytes = 2,949,120,000 bytes (~2.75 GiB), excluding replication/overhead.",
      "detailedExplanation": "The key clue in this question is \"each message averages 4 KB\". Keep every transformation in one unit system and check order of magnitude at the end. Good API choices balance client ergonomics, compatibility, and long-term evolvability. Keep quantities like 4 KB and 720,000 in aligned units before selecting an answer. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-078",
      "type": "numeric-input",
      "question": "A consumer handles 250 msg/s. Backlog is 3,000,000 messages and no new traffic arrives. How many seconds to drain?",
      "answer": 12000,
      "unit": "seconds",
      "tolerance": 0.01,
      "explanation": "Drain time = 3,000,000 / 250 = 12,000 seconds (~3.33 hours).",
      "detailedExplanation": "The core signal here is \"consumer handles 250 msg/s\". Keep every transformation in one unit system and check order of magnitude at the end. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Keep quantities like 250 and 3,000 in aligned units before selecting an answer. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-079",
      "type": "numeric-input",
      "question": "Ingress is 10,000 msg/s and one consumer group can process 8,000 msg/s. What backlog growth rate occurs?",
      "answer": 2000,
      "unit": "msg/s",
      "tolerance": 0,
      "explanation": "Growth rate is net difference: 10,000 - 8,000 = 2,000 msg/s.",
      "detailedExplanation": "If you keep \"ingress is 10,000 msg/s and one consumer group can process 8,000 msg/s\" in view, the correct answer separates faster. Keep every transformation in one unit system and check order of magnitude at the end. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Keep quantities like 10,000 and 8,000 in aligned units before selecting an answer. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        }
      ]
    },
    {
      "id": "msg-scn-080",
      "type": "numeric-input",
      "question": "If backlog grows at 2,000 msg/s, how many messages are added in 15 minutes?",
      "answer": 1800000,
      "unit": "messages",
      "tolerance": 0,
      "explanation": "2,000 * 900 seconds = 1,800,000 added messages.",
      "detailedExplanation": "The decision turns on \"if backlog grows at 2,000 msg/s, how many messages are added in 15 minutes\". Normalize units before computing so conversion mistakes do not propagate. Throughput is only one part; replay behavior and consumer lag handling matter equally. If values like 2,000 and 15 minutes appear, convert them into one unit basis before comparison. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-081",
      "type": "numeric-input",
      "question": "An SLO allows max queue age of 120 seconds. Ingress is 5,000 msg/s. Approximate max safe queue depth before violating SLO?",
      "answer": 600000,
      "unit": "messages",
      "tolerance": 0.01,
      "explanation": "Depth bound  rate * allowed age = 5,000 * 120 = 600,000.",
      "detailedExplanation": "Read this as a scenario about \"sLO allows max queue age of 120 seconds\". Write the unit conversion path explicitly, then calculate, then sanity-check magnitude. Tie the decision to concrete operational outcomes, not abstract reliability language. Numbers such as 120 seconds and 5,000 should be normalized first so downstream reasoning stays consistent. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-082",
      "type": "numeric-input",
      "question": "A topic has 12 partitions and each partition sustains 1,500 msg/s. What is total topic throughput capacity?",
      "answer": 18000,
      "unit": "msg/s",
      "tolerance": 0,
      "explanation": "Total capacity approximates sum across partitions: 12 * 1,500 = 18,000 msg/s.",
      "detailedExplanation": "The key clue in this question is \"topic has 12 partitions and each partition sustains 1,500 msg/s\". Keep every transformation in one unit system and check order of magnitude at the end. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Keep quantities like 12 and 1,500 in aligned units before selecting an answer. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "msg-scn-083",
      "type": "numeric-input",
      "question": "Retry policy: initial delay 2s, exponential factor 2, 4 retries total. What is delay before 4th retry attempt (just that interval)?",
      "answer": 16,
      "unit": "seconds",
      "tolerance": 0,
      "explanation": "Delays are 2, 4, 8, 16 seconds for retries 1..4.",
      "detailedExplanation": "Start from \"retry policy: initial delay 2s, exponential factor 2, 4 retries total\", then pressure-test the result against the options. Keep every transformation in one unit system and check order of magnitude at the end. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 2s and 2 in aligned units before selecting an answer. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "msg-scn-084",
      "type": "numeric-input",
      "question": "Consumer processes 40 messages/batch and takes 200 ms per batch. Approximate throughput?",
      "answer": 200,
      "unit": "msg/s",
      "tolerance": 0.05,
      "explanation": "5 batches/sec * 40 messages = ~200 msg/s.",
      "detailedExplanation": "If you keep \"consumer processes 40 messages/batch and takes 200 ms per batch\" in view, the correct answer separates faster. Keep every transformation in one unit system and check order of magnitude at the end. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Keep quantities like 40 and 200 ms in aligned units before selecting an answer. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-085",
      "type": "numeric-input",
      "question": "An outage pauses consumers for 25 minutes at 3,600 msg/s ingress. How many messages must replay after recovery?",
      "answer": 5400000,
      "unit": "messages",
      "tolerance": 0.01,
      "explanation": "3,600 * (25 * 60) = 5,400,000 messages.",
      "detailedExplanation": "The core signal here is \"outage pauses consumers for 25 minutes at 3,600 msg/s ingress\". Keep every transformation in one unit system and check order of magnitude at the end. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 25 minutes and 3,600 in aligned units before selecting an answer. Common pitfall: assuming recovery speed without operational proof.",
      "references": [
        {
          "title": "RFC 9110: HTTP Semantics",
          "url": "https://www.rfc-editor.org/rfc/rfc9110"
        },
        {
          "title": "NGINX Load Balancing",
          "url": "https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-086",
      "type": "ordering",
      "question": "Order the reliability pipeline for a worker task from earliest to latest.",
      "items": [
        "Consume message",
        "Perform idempotent side effect",
        "ACK/commit offset",
        "Delete dedupe marker after retention window"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "ACK follows successful side effect; dedupe cleanup happens later to preserve replay safety.",
      "detailedExplanation": "Use \"order the reliability pipeline for a worker task from earliest to latest\" as your starting point, then verify tradeoffs carefully. Build the rank from biggest differences first, then refine with adjacent checks. A good message-system answer defines guarantees clearly for both producer and consumer paths. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Little's law",
          "url": "https://en.wikipedia.org/wiki/Little%27s_law"
        }
      ]
    },
    {
      "id": "msg-scn-087",
      "type": "ordering",
      "question": "Order these retries by increasing wait time under exponential backoff (base 1s).",
      "items": ["Retry #3", "Retry #1", "Retry #4", "Retry #2"],
      "correctOrder": [1, 3, 0, 2],
      "explanation": "Backoff intervals progress as 1s, 2s, 4s, 8s.",
      "detailedExplanation": "This prompt is really about \"order these retries by increasing wait time under exponential backoff (base 1s)\". Place obvious extremes first, then sort the middle by pairwise comparison. The strongest answer explains how failure mode, mitigation speed, and blast radius interact. Keep quantities like 1s and 2s in aligned units before selecting an answer. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "Retry pattern",
          "url": "https://learn.microsoft.com/en-us/azure/architecture/patterns/retry"
        }
      ]
    },
    {
      "id": "msg-scn-088",
      "type": "ordering",
      "question": "Order incident response steps for DLQ spike handling.",
      "items": [
        "Contain bad producer/consumer deploy",
        "Classify failure reasons",
        "Patch/fix root cause",
        "Controlled replay with monitoring"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Contain first, then diagnose, fix, and replay safely.",
      "detailedExplanation": "The decision turns on \"order incident response steps for DLQ spike handling\". Order by relative scale and bottleneck effect, then validate neighboring items. Tie the decision to concrete operational outcomes, not abstract reliability language. Common pitfall: retry storms during partial failure.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-089",
      "type": "ordering",
      "question": "Order event-time window lifecycle for late-data-aware processing.",
      "items": [
        "Assign event to window by event_time",
        "Advance watermark",
        "Emit window result when watermark passes end",
        "Handle very late events per policy"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Window assignment precedes watermark-driven closure and late-event handling.",
      "detailedExplanation": "Read this as a scenario about \"order event-time window lifecycle for late-data-aware processing\". Order by relative scale and bottleneck effect, then validate neighboring items. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-090",
      "type": "ordering",
      "question": "Order architecture evolution from simplest to most complex for async adoption.",
      "items": [
        "Single managed queue for background jobs",
        "Add DLQ + retries + idempotency",
        "Fan-out pub/sub domains",
        "Introduce stream processing and replay-driven analytics"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Maturity grows from simple queues to resilient patterns to broader event platforms.",
      "detailedExplanation": "Start from \"order architecture evolution from simplest to most complex for async adoption\", then pressure-test the result against the options. Build the rank from biggest differences first, then refine with adjacent checks. The important tradeoffs are delivery semantics, ordering scope, and backpressure under failure. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-091",
      "type": "ordering",
      "question": "Order by strongest delivery guarantee (weakest to strongest typical semantics).",
      "items": [
        "Exactly-once outcome with idempotent sink design",
        "At-most-once",
        "At-least-once",
        "Effectively-once within constrained boundary"
      ],
      "correctOrder": [1, 2, 3, 0],
      "explanation": "At-most-once drops possible; at-least-once duplicates possible; effectively/exactly-once require stronger controls.",
      "detailedExplanation": "The key clue in this question is \"order by strongest delivery guarantee (weakest to strongest typical semantics)\". Place obvious extremes first, then sort the middle by pairwise comparison. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: ordering loss during partition or replay changes.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-092",
      "type": "ordering",
      "question": "Order backlog metrics from most immediate to most user-impact-oriented.",
      "items": [
        "Queue depth",
        "Consumer lag in offsets",
        "Event age (now - event_time)",
        "Business freshness SLA breach rate"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Raw queue signals are early indicators; freshness/SLA metrics reflect user impact directly.",
      "detailedExplanation": "Read this as a scenario about \"order backlog metrics from most immediate to most user-impact-oriented\". Build the rank from biggest differences first, then refine with adjacent checks. Map the choice to measurable reliability impact such as error budget burn and recovery behavior. Common pitfall: meeting average goals while missing tail-risk.",
      "references": [
        {
          "title": "Google SRE Book: Service Level Objectives",
          "url": "https://sre.google/sre-book/service-level-objectives/"
        },
        {
          "title": "Google SRE Book: Embracing Risk (Error Budgets)",
          "url": "https://sre.google/sre-book/embracing-risk/"
        },
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        }
      ]
    },
    {
      "id": "msg-scn-093",
      "type": "ordering",
      "question": "Order these components in an outbox relay flow.",
      "items": [
        "Business transaction writes domain row + outbox row",
        "Relay reads pending outbox rows",
        "Relay publishes to broker",
        "Relay marks outbox row sent"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Transactional write first, then relay publish, then sent marker update.",
      "detailedExplanation": "The decision turns on \"order these components in an outbox relay flow\". Order by relative scale and bottleneck effect, then validate neighboring items. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: consumer lag growth under burst traffic.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-094",
      "type": "ordering",
      "question": "Order processing stages in a claim-check workflow.",
      "items": [
        "Upload large payload to object storage",
        "Publish message with pointer/metadata",
        "Consumer fetches payload by pointer",
        "Consumer processes and records result"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Large payload lives in object storage; message carries reference for downstream fetch.",
      "detailedExplanation": "This prompt is really about \"order processing stages in a claim-check workflow\". Place obvious extremes first, then sort the middle by pairwise comparison. Prioritize explicit semantics and upgrade safety, not just short-term convenience. Common pitfall: ambiguous contracts that hide behavior changes.",
      "references": [
        {
          "title": "Amazon S3 FAQs",
          "url": "https://aws.amazon.com/s3/faqs/"
        },
        {
          "title": "Google Cloud Storage pricing",
          "url": "https://cloud.google.com/storage/pricing"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    },
    {
      "id": "msg-scn-095",
      "type": "ordering",
      "question": "Order scalability actions when partition throughput is saturated.",
      "items": [
        "Detect hotspot via lag/throughput metrics",
        "Redesign partition key / increase partition count",
        "Scale consumers to match new partitions",
        "Verify ordering and correctness invariants"
      ],
      "correctOrder": [0, 1, 2, 3],
      "explanation": "Measure first, then repartition, then scale consumers, then validate correctness assumptions.",
      "detailedExplanation": "Use \"order scalability actions when partition throughput is saturated\" as your starting point, then verify tradeoffs carefully. Place obvious extremes first, then sort the middle by pairwise comparison. Throughput is only one part; replay behavior and consumer lag handling matter equally. Common pitfall: assuming exactly-once without idempotency.",
      "references": [
        {
          "title": "Apache Kafka documentation",
          "url": "https://kafka.apache.org/documentation/"
        },
        {
          "title": "RabbitMQ Tutorials",
          "url": "https://www.rabbitmq.com/tutorials"
        },
        {
          "title": "System Design Primer: Back-of-the-envelope estimation",
          "url": "https://github.com/donnemartin/system-design-primer#back-of-the-envelope-estimation"
        }
      ]
    }
  ]
}
